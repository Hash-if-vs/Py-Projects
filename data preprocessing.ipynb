{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aba5798b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Hashif\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "C:\\Users\\Hashif\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>distance</th>\n",
       "      <th>ratings</th>\n",
       "      <th>ac</th>\n",
       "      <th>area</th>\n",
       "      <th>attached</th>\n",
       "      <th>backup</th>\n",
       "      <th>bathroom</th>\n",
       "      <th>bed</th>\n",
       "      <th>breakfast</th>\n",
       "      <th>...</th>\n",
       "      <th>queen</th>\n",
       "      <th>reception</th>\n",
       "      <th>restaurant</th>\n",
       "      <th>seating</th>\n",
       "      <th>sized</th>\n",
       "      <th>speed</th>\n",
       "      <th>tv</th>\n",
       "      <th>wardrobe</th>\n",
       "      <th>washroom</th>\n",
       "      <th>wifi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1199.000000</td>\n",
       "      <td>5.1</td>\n",
       "      <td>4.60000</td>\n",
       "      <td>0.128555</td>\n",
       "      <td>0.417493</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.168691</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.417493</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.129835</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.160229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>799.000000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.00000</td>\n",
       "      <td>0.157117</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.206171</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469837</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.544623</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.469837</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.158681</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.195829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>747.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.36129</td>\n",
       "      <td>0.255487</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.335252</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.258030</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.318435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>576.000000</td>\n",
       "      <td>8.8</td>\n",
       "      <td>3.10000</td>\n",
       "      <td>0.249882</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.327898</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.252369</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>699.000000</td>\n",
       "      <td>1.7</td>\n",
       "      <td>2.30000</td>\n",
       "      <td>0.255487</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.335252</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.258030</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.318435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>1153.977778</td>\n",
       "      <td>5.1</td>\n",
       "      <td>4.70000</td>\n",
       "      <td>0.307017</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.402870</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.310073</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.382662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>1153.977778</td>\n",
       "      <td>8.2</td>\n",
       "      <td>4.10000</td>\n",
       "      <td>0.221461</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.223666</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.276026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>1153.977778</td>\n",
       "      <td>5.7</td>\n",
       "      <td>4.30000</td>\n",
       "      <td>0.107249</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.140733</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.517525</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.108316</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.133674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>1153.977778</td>\n",
       "      <td>1.6</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>0.307017</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.402870</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.310073</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.382662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>1153.977778</td>\n",
       "      <td>3.1</td>\n",
       "      <td>3.40000</td>\n",
       "      <td>0.255487</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.335252</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.258030</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.318435</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          price  distance  ratings        ac      area  attached    backup  \\\n",
       "0   1199.000000       5.1  4.60000  0.128555  0.417493       0.0  0.168691   \n",
       "1    799.000000       5.0  4.00000  0.157117  0.000000       0.0  0.206171   \n",
       "2    747.000000       4.0  3.36129  0.255487  0.000000       0.0  0.335252   \n",
       "3    576.000000       8.8  3.10000  0.249882  0.000000       0.0  0.327898   \n",
       "4    699.000000       1.7  2.30000  0.255487  0.000000       0.0  0.335252   \n",
       "..          ...       ...      ...       ...       ...       ...       ...   \n",
       "95  1153.977778       5.1  4.70000  0.307017  0.000000       0.0  0.402870   \n",
       "96  1153.977778       8.2  4.10000  0.221461  0.000000       0.0  0.000000   \n",
       "97  1153.977778       5.7  4.30000  0.107249  0.000000       0.0  0.140733   \n",
       "98  1153.977778       1.6  2.00000  0.307017  0.000000       0.0  0.402870   \n",
       "99  1153.977778       3.1  3.40000  0.255487  0.000000       0.0  0.335252   \n",
       "\n",
       "    bathroom       bed  breakfast  ...     queen  reception  restaurant  \\\n",
       "0        0.0  0.000000   0.000000  ...  0.000000        0.0         0.0   \n",
       "1        0.0  0.469837   0.000000  ...  0.544623        0.0         0.0   \n",
       "2        0.0  0.000000   0.000000  ...  0.000000        0.0         0.0   \n",
       "3        0.0  0.000000   0.000000  ...  0.000000        0.0         0.0   \n",
       "4        0.0  0.000000   0.000000  ...  0.000000        0.0         0.0   \n",
       "..       ...       ...        ...  ...       ...        ...         ...   \n",
       "95       0.0  0.000000   0.000000  ...  0.000000        0.0         0.0   \n",
       "96       0.0  0.000000   0.000000  ...  0.000000        0.0         0.0   \n",
       "97       0.0  0.000000   0.517525  ...  0.000000        0.0         0.0   \n",
       "98       0.0  0.000000   0.000000  ...  0.000000        0.0         0.0   \n",
       "99       0.0  0.000000   0.000000  ...  0.000000        0.0         0.0   \n",
       "\n",
       "     seating     sized  speed        tv  wardrobe  washroom      wifi  \n",
       "0   0.417493  0.000000    0.0  0.129835       0.0       0.0  0.160229  \n",
       "1   0.000000  0.469837    0.0  0.158681       0.0       0.0  0.195829  \n",
       "2   0.000000  0.000000    0.0  0.258030       0.0       0.0  0.318435  \n",
       "3   0.000000  0.000000    0.0  0.252369       0.0       0.0  0.000000  \n",
       "4   0.000000  0.000000    0.0  0.258030       0.0       0.0  0.318435  \n",
       "..       ...       ...    ...       ...       ...       ...       ...  \n",
       "95  0.000000  0.000000    0.0  0.310073       0.0       0.0  0.382662  \n",
       "96  0.000000  0.000000    0.0  0.223666       0.0       0.0  0.276026  \n",
       "97  0.000000  0.000000    0.0  0.108316       0.0       0.0  0.133674  \n",
       "98  0.000000  0.000000    0.0  0.310073       0.0       0.0  0.382662  \n",
       "99  0.000000  0.000000    0.0  0.258030       0.0       0.0  0.318435  \n",
       "\n",
       "[100 rows x 48 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df= pd.read_csv('test1.csv')\n",
    "df.drop(['Unnamed: 0'],axis=1)\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "import pandas as pd\n",
    "df['amneties'].fillna('', inplace=True)\n",
    "def custom_tokenizer(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    return tokens\n",
    "vectorizer = TfidfVectorizer(tokenizer=custom_tokenizer)\n",
    "amenities_tfidf = vectorizer.fit_transform(df['amneties'])\n",
    "amenities_df = pd.DataFrame(amenities_tfidf.toarray(), columns=vectorizer.get_feature_names())\n",
    "df_processed = pd.concat([df, amenities_df], axis=1)\n",
    "df_processed = df_processed.drop(columns=['Unnamed: 0','amneties'],axis=1)\n",
    "df_processed.to_csv('preprocessedoyo.csv',index=False)\n",
    "df=pd.read_csv('preprocessedoyo.csv')\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "64eb4cfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "int32\n",
      "    bathroom  reception        price\n",
      "0        0.0        0.0  1199.000000\n",
      "1        0.0        0.0   799.000000\n",
      "2        0.0        0.0   747.000000\n",
      "3        0.0        0.0   576.000000\n",
      "4        0.0        0.0   699.000000\n",
      "..       ...        ...          ...\n",
      "95       0.0        0.0  1153.977778\n",
      "96       0.0        0.0  1153.977778\n",
      "97       0.0        0.0  1153.977778\n",
      "98       0.0        0.0  1153.977778\n",
      "99       0.0        0.0  1153.977778\n",
      "\n",
      "[100 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "\n",
    "k = 2\n",
    "df_temp = df.drop('price', axis=1)\n",
    "selector = SelectKBest(score_func=chi2, k=k)\n",
    "df['price']=df['price'].astype('int')\n",
    "selected_features = selector.fit_transform(df_temp, df['price'])\n",
    "print(df['price'].dtype)\n",
    "feature_names = df_temp.columns[selector.get_support()]\n",
    "df_selected = pd.DataFrame(selected_features, columns=feature_names)\n",
    "df_selected['price'] = df_processed['price']\n",
    "print(df_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "af93b7f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7947d507",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Hashif\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Hashif\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "C:\\Users\\Hashif\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:404: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens [\"'d\", \"'ll\", \"'re\", \"'s\", \"'ve\", 'could', 'might', 'must', 'need', 'sha', 'wo', 'would'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['price', 'location', 'ratings', 'type', '(', ')', '2', 'air', 'airport', 'bar', 'breakfast', 'centre', 'closed', 'conditioning', 'desk', 'facilities', 'family', 'fitness', 'front', 'garden', 'guests', 'housekeeping', 'laundry', 'maker', 'non-smoking', 'parking', 'pool', 'pools', 'restaurant', 'room', 'rooms', 'service', 'shuttle', 'site', 'spa', 'superb', 'swimming', 'tea/coffee', 'terrace', 'wellness', 'wifi']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hashif\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "df = pd.read_csv('test.csv')\n",
    "df = df.drop(['Unnamed: 0'], axis=1)\n",
    "df['amenities'].fillna('', inplace=True)\n",
    "stemmer = PorterStemmer()\n",
    "def custom_tokenizer(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    pos_tags = pos_tag(tokens)  # Perform POS tagging\n",
    "    filtered_tokens = [token for token, pos in pos_tags if pos not in ['RB', 'JJ', 'VB']]  # Filter out adverbs, adjectives, and verbs\n",
    "    return filtered_tokens\n",
    "nltk.download('stopwords')\n",
    "stopwords_list = set(stopwords.words('english'))\n",
    "vectorizer = TfidfVectorizer(tokenizer=custom_tokenizer, stop_words=stopwords_list)\n",
    "amenities_tfidf = vectorizer.fit_transform(df['amenities'])\n",
    "amenities_df = pd.DataFrame(amenities_tfidf.toarray(), columns=vectorizer.get_feature_names())\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# Perform label encoding for categorical features\n",
    "categorical_features = ['type', 'location']\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoders={}\n",
    "for feature in categorical_features:\n",
    "    df[feature] = label_encoder.fit_transform(df[feature])\n",
    "    label_encoders[feature] = label_encoder\n",
    "df_processed = pd.concat([df, amenities_df], axis=1)\n",
    "\n",
    "df_processed.drop(columns=['amenities','distance'], axis=1, inplace=True)\n",
    "df_processed.to_csv('preprocessed.csv', index=False)\n",
    "df_processed = pd.read_csv('preprocessed.csv')\n",
    "df_processed\n",
    "column_names = df_processed.columns.tolist()\n",
    "\n",
    "# Print the column names\n",
    "print(column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9fa8f9a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading averaged_perceptron_tagger: <urlopen error\n",
      "[nltk_data]     [Errno 11001] getaddrinfo failed>\n",
      "[nltk_data] Error loading stopwords: <urlopen error [Errno 11001]\n",
      "[nltk_data]     getaddrinfo failed>\n",
      "C:\\Users\\Hashif\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:404: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens [\"'d\", \"'ll\", \"'re\", \"'s\", \"'ve\", 'could', 'might', 'must', 'need', 'sha', 'wo', 'would'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['price', 'location', 'ratings', 'type', 'air', 'air conditioning', 'airport', 'airport family', 'airport room', 'airport shuttle', 'airport spa', 'airport wifi', 'bar', 'bar air', 'bar breakfast', 'bar closed', 'bar housekeeping', 'bar superb', 'bar tea/coffee', 'breakfast', 'centre', 'centre closed', 'centre facilities', 'centre front', 'centre room', 'centre rooms', 'centre spa', 'centre tea/coffee', 'centre wifi', 'closed', 'closed breakfast', 'closed non-smoking', 'closed parking', 'closed room', 'conditioning', 'conditioning breakfast', 'conditioning superb', 'conditioning tea/coffee', 'desk', 'desk air', 'desk bar', 'desk breakfast', 'desk garden', 'desk housekeeping', 'desk laundry', 'desk tea/coffee', 'desk terrace', 'facilities', 'facilities guests', 'family', 'family rooms', 'fitness', 'fitness centre', 'fitness housekeeping', 'front', 'front desk', 'garden', 'garden air', 'garden bar', 'garden breakfast', 'garden housekeeping', 'garden laundry', 'garden tea/coffee', 'guests', 'guests airport', 'guests bar', 'guests desk', 'guests family', 'guests front', 'guests laundry', 'guests room', 'guests spa', 'guests tea/coffee', 'guests terrace', 'housekeeping', 'housekeeping air', 'housekeeping breakfast', 'housekeeping superb', 'housekeeping tea/coffee', 'laundry', 'laundry air', 'laundry breakfast', 'laundry housekeeping', 'laundry superb', 'laundry tea/coffee', 'maker', 'maker rooms', 'non-smoking', 'non-smoking rooms', 'parking', 'parking air', 'parking airport', 'parking bar', 'parking breakfast', 'parking desk', 'parking facilities', 'parking family', 'parking front', 'parking garden', 'parking housekeeping', 'parking restaurant', 'parking room', 'parking rooms', 'parking site', 'parking spa', 'parking tea/coffee', 'parking terrace', 'parking wifi', 'pool', 'pool airport', 'pool parking', 'pool room', 'pool spa', 'pool wifi', 'pools', 'pools airport', 'pools rooms', 'pools spa', 'pools wifi', 'restaurant', 'restaurant air', 'restaurant closed', 'restaurant facilities', 'restaurant family', 'restaurant front', 'restaurant parking', 'restaurant room', 'restaurant wifi', 'room', 'room service', 'rooms', 'rooms air', 'rooms airport', 'rooms bar', 'rooms breakfast', 'rooms desk', 'rooms facilities', 'rooms family', 'rooms garden', 'rooms housekeeping', 'rooms parking', 'rooms restaurant', 'rooms room', 'rooms rooms', 'rooms spa', 'rooms superb', 'rooms tea/coffee', 'rooms terrace', 'rooms wifi', 'service', 'service airport', 'service desk', 'service facilities', 'service family', 'service fitness', 'service front', 'service housekeeping', 'service parking', 'service restaurant', 'service rooms', 'service tea/coffee', 'service wifi', 'shuttle', 'shuttle family', 'shuttle fitness', 'shuttle front', 'shuttle non-smoking', 'shuttle parking', 'shuttle room', 'shuttle rooms', 'shuttle spa', 'shuttle wifi', 'site', 'site front', 'spa', 'spa centre', 'spa wellness', 'superb', 'superb breakfast', 'swimming', 'swimming pool', 'swimming pools', 'tea/coffee', 'tea/coffee maker', 'terrace', 'terrace air', 'terrace bar', 'terrace breakfast', 'terrace garden', 'terrace housekeeping', 'terrace laundry', 'terrace tea/coffee', 'wellness', 'wellness centre', 'wifi', 'wifi air', 'wifi airport', 'wifi bar', 'wifi desk', 'wifi facilities', 'wifi family', 'wifi front', 'wifi housekeeping', 'wifi laundry', 'wifi non-smoking', 'wifi parking', 'wifi restaurant', 'wifi room', 'wifi rooms', 'wifi spa', 'wifi tea/coffee', 'wifi terrace']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hashif\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag\n",
    "import nltk\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "df = pd.read_csv('test.csv')\n",
    "df = df.drop(['Unnamed: 0'], axis=1)\n",
    "df['amenities'].fillna('', inplace=True)\n",
    "def custom_tokenizer(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    pos_tags = pos_tag(tokens)\n",
    "    filtered_tokens = [token for token, pos in pos_tags if pos not in ['RB', 'JJ', 'VB']]  # Filter out adverbs, adjectives, and verbs\n",
    "    return filtered_tokens\n",
    "nltk.download('stopwords')\n",
    "stopwords_list = set(stopwords.words('english'))\n",
    "custom_stopwords = ['(',')','2'] \n",
    "all_stopwords = stopwords_list.union(custom_stopwords)\n",
    "vectorizer = TfidfVectorizer(tokenizer=custom_tokenizer,ngram_range=(1, 2), stop_words=all_stopwords)\n",
    "amenities_tfidf = vectorizer.fit_transform(df['amenities'])\n",
    "amenities_df = pd.DataFrame(amenities_tfidf.toarray(), columns=vectorizer.get_feature_names())\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "categorical_features = ['type', 'location']\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoders={}\n",
    "for feature in categorical_features:\n",
    "    df[feature] = label_encoder.fit_transform(df[feature])\n",
    "    label_encoders[feature] = label_encoder\n",
    "df_processed = pd.concat([df, amenities_df], axis=1)\n",
    "\n",
    "df_processed.drop(columns=['amenities','distance'], axis=1, inplace=True)\n",
    "df_processed.to_csv('preprocessed.csv', index=False)\n",
    "df_processed = pd.read_csv('preprocessed.csv')\n",
    "df_processed\n",
    "column_names = df_processed.columns.tolist()\n",
    "\n",
    "# Print the column names\n",
    "print(column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a5654902",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     location  ratings  type  24-hour front  air conditioning  \\\n",
      "0        22.0      8.5  15.0       0.171027          0.224802   \n",
      "1        21.0      8.3  90.0       0.000000          0.000000   \n",
      "2        28.0      8.4  90.0       0.132391          0.000000   \n",
      "3        28.0      7.8  14.0       0.000000          0.000000   \n",
      "4        21.0      8.0  93.0       0.000000          0.000000   \n",
      "..        ...      ...   ...            ...               ...   \n",
      "730      28.0      1.0   9.0       0.199160          0.000000   \n",
      "731       6.0      4.6   9.0       0.000000          0.000000   \n",
      "732      18.0      1.0   9.0       0.000000          0.257179   \n",
      "733      18.0      2.3   9.0       0.242209          0.000000   \n",
      "734      24.0      4.0   9.0       0.000000          0.226619   \n",
      "\n",
      "     centre non-smoking  daily housekeeping  family rooms  fitness centre  \\\n",
      "0              0.000000            0.000000      0.199289        0.000000   \n",
      "1              0.268677            0.000000      0.000000        0.263301   \n",
      "2              0.000000            0.000000      0.154268        0.000000   \n",
      "3              0.196357            0.000000      0.092721        0.192428   \n",
      "4              0.000000            0.000000      0.000000        0.000000   \n",
      "..                  ...                 ...           ...             ...   \n",
      "730            0.000000            0.275844      0.232072        0.000000   \n",
      "731            0.000000            0.000000      0.000000        0.000000   \n",
      "732            0.000000            0.270993      0.000000        0.000000   \n",
      "733            0.000000            0.335467      0.000000        0.000000   \n",
      "734            0.000000            0.238792      0.000000        0.000000   \n",
      "\n",
      "     free parking  ...  front desk  housekeeping air  non-smoking rooms  \\\n",
      "0        0.205844  ...    0.171027          0.000000           0.181698   \n",
      "1        0.131043  ...    0.000000          0.000000           0.115672   \n",
      "2        0.159342  ...    0.132391          0.000000           0.140651   \n",
      "3        0.095770  ...    0.000000          0.000000           0.084536   \n",
      "4        0.123149  ...    0.000000          0.000000           0.108704   \n",
      "..            ...  ...         ...               ...                ...   \n",
      "730      0.000000  ...    0.199160          0.000000           0.000000   \n",
      "731      0.000000  ...    0.000000          0.000000           0.000000   \n",
      "732      0.000000  ...    0.000000          0.335116           0.000000   \n",
      "733      0.000000  ...    0.242209          0.000000           0.000000   \n",
      "734      0.000000  ...    0.000000          0.295296           0.183167   \n",
      "\n",
      "     restaurant free  room service  rooms 24-hour  rooms restaurant  \\\n",
      "0           0.000000      0.152250       0.215143          0.000000   \n",
      "1           0.187702      0.096924       0.000000          0.188113   \n",
      "2           0.000000      0.117856       0.166541          0.000000   \n",
      "3           0.000000      0.070835       0.000000          0.000000   \n",
      "4           0.176396      0.091086       0.000000          0.176782   \n",
      "..               ...           ...            ...               ...   \n",
      "730         0.000000      0.177295       0.250534          0.000000   \n",
      "731         0.000000      0.000000       0.000000          0.000000   \n",
      "732         0.000000      0.174177       0.000000          0.000000   \n",
      "733         0.000000      0.215617       0.000000          0.000000   \n",
      "734         0.000000      0.153480       0.000000          0.000000   \n",
      "\n",
      "     service fitness  service non-smoking  price  \n",
      "0           0.000000             0.219702    900  \n",
      "1           0.268677             0.000000   4125  \n",
      "2           0.000000             0.170070   1259  \n",
      "3           0.000000             0.000000    920  \n",
      "4           0.000000             0.131441   2000  \n",
      "..               ...                  ...    ...  \n",
      "730         0.000000             0.000000    489  \n",
      "731         0.000000             0.000000    929  \n",
      "732         0.000000             0.000000    970  \n",
      "733         0.000000             0.000000    487  \n",
      "734         0.000000             0.221478    437  \n",
      "\n",
      "[735 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "X = df_processed.drop('price', axis=1)\n",
    "y = df_processed['price']\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_regression\n",
    "k = 20\n",
    "selector = SelectKBest(score_func=mutual_info_regression, k=k)\n",
    "X_new = selector.fit_transform(X, y)\n",
    "feature_names = X.columns[selector.get_support()]\n",
    "df_selected = pd.DataFrame(X_new, columns=feature_names)\n",
    "df_selected['price'] = y\n",
    "print(df_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eac9f2d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     2 swimming  centre tea/coffee  pools airport  pools free  pools spa  \\\n",
      "0           0.0                0.0            0.0         0.0        0.0   \n",
      "1           0.0                0.0            0.0         0.0        0.0   \n",
      "2           0.0                0.0            0.0         0.0        0.0   \n",
      "3           0.0                0.0            0.0         0.0        0.0   \n",
      "4           0.0                0.0            0.0         0.0        0.0   \n",
      "..          ...                ...            ...         ...        ...   \n",
      "730         0.0                0.0            0.0         0.0        0.0   \n",
      "731         0.0                0.0            0.0         0.0        0.0   \n",
      "732         0.0                0.0            0.0         0.0        0.0   \n",
      "733         0.0                0.0            0.0         0.0        0.0   \n",
      "734         0.0                0.0            0.0         0.0        0.0   \n",
      "\n",
      "     price  \n",
      "0      900  \n",
      "1     4125  \n",
      "2     1259  \n",
      "3      920  \n",
      "4     2000  \n",
      "..     ...  \n",
      "730    489  \n",
      "731    929  \n",
      "732    970  \n",
      "733    487  \n",
      "734    437  \n",
      "\n",
      "[735 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "X = df_processed.drop('price', axis=1)\n",
    "y = df_processed['price']\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_regression\n",
    "model = LinearRegression()\n",
    "k = 5\n",
    "rfe = RFE(estimator=model, n_features_to_select=k)\n",
    "X_rfe = rfe.fit_transform(X, y)\n",
    "feature_names = X.columns[rfe.support_]\n",
    "\n",
    "\n",
    "df_selected = pd.DataFrame(X_rfe, columns=feature_names)\n",
    "df_selected['price'] = y\n",
    "\n",
    "print(df_selected)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6f25fc80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     location  type  service laundry  price\n",
      "0        22.0  15.0              0.0    900\n",
      "1        21.0  90.0              0.0   4125\n",
      "2        28.0  90.0              0.0   1259\n",
      "3        28.0  14.0              0.0    920\n",
      "4        21.0  93.0              0.0   2000\n",
      "..        ...   ...              ...    ...\n",
      "730      28.0   9.0              0.0    489\n",
      "731       6.0   9.0              0.0    929\n",
      "732      18.0   9.0              0.0    970\n",
      "733      18.0   9.0              0.0    487\n",
      "734      24.0   9.0              0.0    437\n",
      "\n",
      "[735 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "\n",
    "k = 3\n",
    "df_temp = df_processed.drop('price', axis=1)\n",
    "\n",
    "selector = SelectKBest(score_func=chi2, k=k)\n",
    "selected_features = selector.fit_transform(df_temp, df_processed['price'])\n",
    "feature_names = df_temp.columns[selector.get_support()]\n",
    "df_selected = pd.DataFrame(selected_features, columns=feature_names)\n",
    "df_selected['price'] = df_processed['price']\n",
    "print(df_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab08555",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0091f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62698d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = df['type'].tolist()\n",
    "\n",
    "# Print the column names\n",
    "print(column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18ff6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_value = label_encoder.inverse_transform(df['location'])[2]\n",
    "real_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6283569d",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_name = 'type'\n",
    "label = df[''].mode()\n",
    "label_encoder = label_encoders[column_name]\n",
    "real_value = label_encoder.inverse_transform([label])[0]\n",
    "\n",
    "real_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e2ea07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Read the dataset\n",
    "df = pd.read_csv('test.csv')\n",
    "df = df.drop(['Unnamed: 0'], axis=1)\n",
    "\n",
    "# Perform label encoding for categorical features\n",
    "categorical_features = ['type', 'location', 'amenities']\n",
    "label_encoders = {}\n",
    "\n",
    "for feature in categorical_features:\n",
    "    label_encoder = LabelEncoder()\n",
    "    df[feature] = label_encoder.fit_transform(df[feature])\n",
    "    label_encoders[feature] = label_encoder\n",
    "\n",
    "# Save the preprocessed data\n",
    "df.to_csv('preprocessed.csv', index=False)\n",
    "\n",
    "# Read the preprocessed data\n",
    "df = pd.read_csv('preprocessed.csv')\n",
    "\n",
    "# Retrieve the real value of a specified label in a column\n",
    "column_name = 'location'\n",
    "label = 2\n",
    "label_encoder = label_encoders[column_name]\n",
    "real_value = label_encoder.inverse_transform([label])[0]\n",
    "\n",
    "print(f\"Real value of column '{column_name}' with label {label}: {real_value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c8cc7200",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"preprocessed.csv\")\n",
    "zero_counts = {}\n",
    "for column in df.columns:\n",
    "    zero_count = (df[column] == 0).sum()\n",
    "    zero_counts[column] = zero_count\n",
    "lst=[]\n",
    "for column in df.columns:\n",
    "    minz= zero_counts[column]\n",
    "    for columns in df.columns:\n",
    "        if column in columns:\n",
    "            if zero_counts[columns]<=minz:\n",
    "                minz= zero_counts[columns]\n",
    "            else:\n",
    "                lst.append(columns)\n",
    "                \n",
    "df_dropped = df.drop(columns=lst)\n",
    "df_dropped.to_csv('ndf.csv',index= True)\n",
    "            \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c8528c52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   price  location  distance  \\\n",
      "0    900        22       NaN   \n",
      "1   4125        21       NaN   \n",
      "2   1259        28       NaN   \n",
      "3    920        28       NaN   \n",
      "4   2000        21       NaN   \n",
      "\n",
      "                                           amenities  ratings  type  \n",
      "0  Room service Non-smoking rooms Free WiFi Free ...      8.5    15  \n",
      "1  Airport shuttle Room service Fitness centre No...      8.3    90  \n",
      "2  Airport shuttle Room service Non-smoking rooms...      8.4    90  \n",
      "3  Room service Free parking Spa and wellness cen...      7.8    14  \n",
      "4  Airport shuttle Spa and wellness centre Room s...      8.0    93  \n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bd0198b5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  0  0 ... 23 15 16]\n",
      " [ 0  0  0 ... 41 34 12]\n",
      " [ 0  0  0 ... 41 34 12]\n",
      " ...\n",
      " [ 0  0  0 ... 20 15 16]\n",
      " [ 0  0  0 ...  8 19 20]\n",
      " [ 0  0  0 ... 20 15 16]]\n",
      "Epoch 1/10\n",
      "19/19 [==============================] - 2s 32ms/step - loss: -2748.6187 - accuracy: 0.0000e+00 - val_loss: -6659.8535 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "19/19 [==============================] - 0s 13ms/step - loss: -18491.5801 - accuracy: 0.0000e+00 - val_loss: -12507.5830 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "19/19 [==============================] - 0s 12ms/step - loss: -26599.2461 - accuracy: 0.0000e+00 - val_loss: -15697.3438 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "19/19 [==============================] - 0s 13ms/step - loss: -31799.6230 - accuracy: 0.0000e+00 - val_loss: -18129.0332 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "19/19 [==============================] - 0s 13ms/step - loss: -36193.6875 - accuracy: 0.0000e+00 - val_loss: -20302.8438 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "19/19 [==============================] - 0s 12ms/step - loss: -40105.5430 - accuracy: 0.0000e+00 - val_loss: -22321.8750 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "19/19 [==============================] - 0s 13ms/step - loss: -43809.8984 - accuracy: 0.0000e+00 - val_loss: -24264.8691 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/10\n",
      "19/19 [==============================] - 0s 13ms/step - loss: -47439.3984 - accuracy: 0.0000e+00 - val_loss: -26210.7949 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/10\n",
      "19/19 [==============================] - 0s 13ms/step - loss: -51087.9023 - accuracy: 0.0000e+00 - val_loss: -28047.3535 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/10\n",
      "19/19 [==============================] - 0s 12ms/step - loss: -54605.5430 - accuracy: 0.0000e+00 - val_loss: -29884.1660 - val_accuracy: 0.0000e+00\n",
      "5/5 [==============================] - 0s 6ms/step - loss: -29884.1660 - accuracy: 0.0000e+00\n",
      "Test Loss: -29884.166015625, Test Accuracy: 0.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv('test.csv')\n",
    "df['amenities'].fillna('', inplace=True)\n",
    "df.drop(columns=['Unnamed: 0', 'distance'], axis=1, inplace=True)\n",
    "# Preprocess the text data\n",
    "text_data = df['amenities'].values\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(text_data)\n",
    "sequences = tokenizer.texts_to_sequences(text_data)\n",
    "max_sequence_length = max(len(seq) for seq in sequences)\n",
    "padded_sequences = pad_sequences(sequences, maxlen=max_sequence_length)\n",
    "print(padded_sequences)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "labels = df['price'].values\n",
    "train_size = int(0.8 * len(padded_sequences))\n",
    "train_sequences = padded_sequences[:train_size]\n",
    "train_labels = labels[:train_size]\n",
    "test_sequences = padded_sequences[train_size:]\n",
    "test_labels = labels[train_size:]\n",
    "\n",
    "# Build and train the LSTM model\n",
    "embedding_dim = 100\n",
    "lstm_units = 64\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=embedding_dim, input_length=max_sequence_length))\n",
    "model.add(LSTM(units=lstm_units))\n",
    "model.add(Dense(units=1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(train_sequences, train_labels, epochs=10, batch_size=32, validation_data=(test_sequences, test_labels))\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(test_sequences, test_labels)\n",
    "print(f\"Test Loss: {loss}, Test Accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c14390",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
