{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc1f50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping bookings.com\n",
    "import requests\n",
    "from bs4 import BeautifulSoup as Soup\n",
    "import pandas as pd\n",
    "df = pd.DataFrame()\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/113.0.0.0 Safari/537.36'}\n",
    "for pages in range(0, 39):\n",
    "    req = requests.get(f\"https://www.booking.com/searchresults.en-gb.html?label=gog235jc-1FCAIobDgOSAlYA2hsiAEBmAEJuAEXyAEM2AEB6AEB-AECiAIBqAIDuAKw3J2jBsACAdICJDNlOWY5MDE2LWRkNzMtNDBhZS1iMjQ2LTQ5ZTk2ZDJmYjU5ZdgCBeACAQ&sid=78a835dba3d7708eeae1b91933ba50ae&aid=356980&checkin=2023-06-01&checkout=2023-06-02&dest_id=-2106102&dest_type=city&srpvid=c0886213ab84013a&track_hp_back_button=1&offset={pages*25}\", headers=headers).text\n",
    "    soup = Soup(req, 'html.parser')\n",
    "    apts = soup.find_all(\"div\", {\"class\": \"d20f4628d0\"})\n",
    "    l = []\n",
    "    obj = {}\n",
    "    for a in range(0, len(apts)):\n",
    "        try:\n",
    "            obj[\"pricing\"] = apts[a].find(\"span\", {\"class\": \"fcab3ed991 fbd1d3018c e729ed5ab6\"}).text\n",
    "        except:\n",
    "            obj[\"pricing\"] = None\n",
    "        try:\n",
    "            obj[\"Distance\"] = apts[a].find(\"span\", {\"class\": \"cb5ebe3ffb\"}).text\n",
    "        except:\n",
    "            obj[\"Distance\"] = None\n",
    "        try:\n",
    "            ap1=apts[a].find('a',href=True)\n",
    "            link = ap1['href']\n",
    "            req1 = requests.get(link, headers=headers).text\n",
    "            soup2 = Soup(req1, 'html.parser')\n",
    "            obj[\"amenities\"] = soup2.find(\"div\", {\"class\": \"e5e0727360\"}).text\n",
    "        except:\n",
    "            obj[\"amenities\"] = None\n",
    "        try:\n",
    "            obj[\"ratings\"] = apts[a].find(\"div\", {\"class\": \"b5cd09854e d10a6220b4\"}).text\n",
    "        except:\n",
    "            obj[\"ratings\"] = None\n",
    "        try:\n",
    "            obj[\"type\"] = apts[a].find(\"span\", {\"class\": \"df597226dd\"}).text\n",
    "        except:\n",
    "            obj[\"type\"] = None\n",
    "        try:\n",
    "            obj[\"location\"] = apts[a].find(\"span\", {\"class\": \"f4bd0794db b4273d69aa\"}).text\n",
    "        except:\n",
    "            obj[\"location\"] = None\n",
    "    \n",
    "    \n",
    "        l.append(obj)\n",
    "        obj = {}\n",
    "        for i in l:\n",
    "            price = i[\"pricing\"]\n",
    "            distance = i[\"Distance\"]\n",
    "            amenities = i[\"amenities\"]\n",
    "            ratings = i[\"ratings\"]\n",
    "            room_type=i[\"type\"]\n",
    "            location=i[\"location\"]\n",
    "            df = df.append({\"price\": price, \"location\":location,\"distance\": distance,\"amenities\": amenities, \"ratings\": ratings,\"type\":room_type}, ignore_index=True)\n",
    "# dataCleaning\n",
    "df[\"price\"] = df[\"price\"].str.replace(r\"₹\", \"\")\n",
    "df[\"price\"] = df[\"price\"].str.replace(r\" \", \"\")\n",
    "df[\"price\"] = df[\"price\"].str.replace(r\",\", \"\")\n",
    "df[\"price\"] = df[\"price\"].str.strip() \n",
    "df['price'] = pd.to_numeric(df['price'])\n",
    "df['ratings'] = pd.to_numeric(df['ratings'], errors='coerce')\n",
    "df['ratings'] = df['ratings'].fillna(df['ratings'].mean())\n",
    "dfd=dfd.drop_duplicates(ignore_index=True)\n",
    "df.to_csv('test.csv')\n",
    "df   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a4ebde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Web Scrapping OYO Working Code\n",
    "import requests\n",
    "from bs4 import BeautifulSoup as Soup\n",
    "import pandas as pd\n",
    "def delhi():\n",
    "    df = pd.DataFrame()\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/111.0.0.0 Safari/537.36'}\n",
    "    for pages in range(1, 6):\n",
    "        req = requests.get(\n",
    "            f\"https://www.oyorooms.com/hotels-in-delhi/?page={pages}\", headers=headers).text\n",
    "        soup = Soup(req, 'html.parser')\n",
    "        apts = soup.find_all(\n",
    "            \"div\", {\"class\": \"oyo-row oyo-row--no-spacing listingHotelDescription\"})\n",
    "        l = []\n",
    "        obj = {}\n",
    "        apts1 = soup.find_all(itemprop='url')\n",
    "        for a in range(0, len(apts)):\n",
    "            try:\n",
    "                obj[\"pricing\"] = apts[a].find(\n",
    "                    \"span\", {\"class\": \"listingPrice__finalPrice\"}).text\n",
    "            except:\n",
    "                obj[\"pricing\"] = None\n",
    "            try:\n",
    "                obj[\"Distance\"] = apts[a].find(\n",
    "                    \"span\", {\"class\": \"listingHotelDescription__distanceText\"}).text\n",
    "            except:\n",
    "                obj[\"Distance\"] = None\n",
    "            try:\n",
    "                link = apts1[a].get('content')\n",
    "                req1 = requests.get(link, headers=headers).text\n",
    "                soup2 = Soup(req1, 'html.parser')\n",
    "                ap=soup2.find_all(\"div\", {\"class\": \"c-riklip\"})\n",
    "                stri=''\n",
    "                for b in range(0,len(ap)):\n",
    "                    if \"striked\" not in ap[b].get(\"class\", []):\n",
    "                        stri += ap[b].find(\"div\", {\"class\": \"c-12w6zty\"}).text + \" \"\n",
    "                obj[\"amneties\"] = stri.strip()\n",
    "            except:\n",
    "                obj[\"amneties\"] = None\n",
    "            try:\n",
    "                obj[\"ratings\"] = apts[a].find(\n",
    "                    \"div\", {\"class\": \"hotelRating\"}).text\n",
    "            except:\n",
    "                obj[\"ratings\"] = None\n",
    "\n",
    "            l.append(obj)\n",
    "            obj = {}\n",
    "        for i in l:\n",
    "            price = i[\"pricing\"]\n",
    "            distance = i[\"Distance\"]\n",
    "            amneties = i[\"amneties\"]\n",
    "            ratings = i[\"ratings\"]\n",
    "            df = df.append({\"price\": price, \"distance\": distance,\n",
    "                           \"amneties\": amneties, \"ratings\": ratings}, ignore_index=True)\n",
    "# dataCleaning\n",
    "    df[\"price\"] = df[\"price\"].str.replace(r\"₹\", \"\")\n",
    "    df[\"ratings\"] = df[\"ratings\"].str.replace(r\"₹\", \"\")\n",
    "    df['price'] = pd.to_numeric(df['price'])\n",
    "    df['distance'] = df['distance'].str.replace(r\"km\", \"\")\n",
    "    df['distance'] = pd.to_numeric(df['distance'])\n",
    "    df[['ratings', 'last_name', 'y', 'x']\n",
    "       ] = df['ratings'].str.split(' ', expand=True)\n",
    "    df = df.drop(columns=['last_name', 'y', 'x'], axis=1)\n",
    "    df['ratings'] = pd.to_numeric(df['ratings'], errors='coerce')\n",
    "    df['ratings'] = df['ratings'].fillna(df['ratings'].mean())\n",
    "    return df\n",
    "df = delhi()\n",
    "df['price'] = df['price'].fillna(df['price'].mean())\n",
    "df.to_csv('test1.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
