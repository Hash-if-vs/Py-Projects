2023-04-24 21:00:35,497:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-24 21:00:35,497:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-24 21:00:35,497:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-24 21:00:35,497:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-24 21:00:37,115:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-04-24 22:47:43,304:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-24 22:47:43,304:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-24 22:47:43,304:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-24 22:47:43,304:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-24 22:47:43,878:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-04-24 22:47:44,158:INFO:PyCaret RegressionExperiment
2023-04-24 22:47:44,158:INFO:Logging name: price_recom_partial
2023-04-24 22:47:44,158:INFO:ML Usecase: MLUsecase.REGRESSION
2023-04-24 22:47:44,158:INFO:version 3.0.0
2023-04-24 22:47:44,158:INFO:Initializing setup()
2023-04-24 22:47:44,158:INFO:self.USI: a252
2023-04-24 22:47:44,158:INFO:self._variable_keys: {'log_plots_param', 'memory', 'y', 'USI', 'fold_groups_param', 'fold_shuffle_param', 'X', 'idx', 'target_param', '_available_plots', 'pipeline', 'X_train', 'X_test', 'fold_generator', 'n_jobs_param', '_ml_usecase', 'gpu_param', 'data', 'logging_param', 'html_param', 'y_test', 'exp_name_log', 'exp_id', 'y_train', 'seed', 'transform_target_param', 'gpu_n_jobs_param'}
2023-04-24 22:47:44,158:INFO:Checking environment
2023-04-24 22:47:44,158:INFO:python_version: 3.10.5
2023-04-24 22:47:44,158:INFO:python_build: ('tags/v3.10.5:f377153', 'Jun  6 2022 16:14:13')
2023-04-24 22:47:44,158:INFO:machine: AMD64
2023-04-24 22:47:44,158:INFO:platform: Windows-10-10.0.22000-SP0
2023-04-24 22:47:44,158:INFO:Memory: svmem(total=16497119232, available=6251020288, percent=62.1, used=10246098944, free=6251020288)
2023-04-24 22:47:44,158:INFO:Physical Core: 8
2023-04-24 22:47:44,158:INFO:Logical Core: 16
2023-04-24 22:47:44,158:INFO:Checking libraries
2023-04-24 22:47:44,158:INFO:System:
2023-04-24 22:47:44,158:INFO:    python: 3.10.5 (tags/v3.10.5:f377153, Jun  6 2022, 16:14:13) [MSC v.1929 64 bit (AMD64)]
2023-04-24 22:47:44,158:INFO:executable: C:\Users\Hashif\AppData\Local\Programs\Python\Python310\python.exe
2023-04-24 22:47:44,158:INFO:   machine: Windows-10-10.0.22000-SP0
2023-04-24 22:47:44,158:INFO:PyCaret required dependencies:
2023-04-24 22:47:44,158:INFO:                 pip: 23.1.1
2023-04-24 22:47:44,158:INFO:          setuptools: 58.1.0
2023-04-24 22:47:44,158:INFO:             pycaret: 3.0.0
2023-04-24 22:47:44,158:INFO:             IPython: 8.4.0
2023-04-24 22:47:44,158:INFO:          ipywidgets: 7.7.0
2023-04-24 22:47:44,158:INFO:                tqdm: 4.65.0
2023-04-24 22:47:44,158:INFO:               numpy: 1.23.0
2023-04-24 22:47:44,158:INFO:              pandas: 1.4.3
2023-04-24 22:47:44,158:INFO:              jinja2: 3.1.2
2023-04-24 22:47:44,158:INFO:               scipy: 1.9.3
2023-04-24 22:47:44,158:INFO:              joblib: 1.2.0
2023-04-24 22:47:44,158:INFO:             sklearn: 1.1.2
2023-04-24 22:47:44,158:INFO:                pyod: 1.0.9
2023-04-24 22:47:44,158:INFO:            imblearn: 0.10.1
2023-04-24 22:47:44,158:INFO:   category_encoders: 2.6.0
2023-04-24 22:47:44,158:INFO:            lightgbm: 3.3.5
2023-04-24 22:47:44,158:INFO:               numba: 0.56.4
2023-04-24 22:47:44,158:INFO:            requests: 2.28.1
2023-04-24 22:47:44,158:INFO:          matplotlib: 3.6.2
2023-04-24 22:47:44,158:INFO:          scikitplot: 0.3.7
2023-04-24 22:47:44,158:INFO:         yellowbrick: 1.5
2023-04-24 22:47:44,158:INFO:              plotly: 5.14.1
2023-04-24 22:47:44,158:INFO:             kaleido: 0.2.1
2023-04-24 22:47:44,158:INFO:         statsmodels: 0.13.5
2023-04-24 22:47:44,158:INFO:              sktime: 0.17.1
2023-04-24 22:47:44,158:INFO:               tbats: 1.1.3
2023-04-24 22:47:44,158:INFO:            pmdarima: 2.0.3
2023-04-24 22:47:44,158:INFO:              psutil: 5.9.1
2023-04-24 22:47:44,158:INFO:PyCaret optional dependencies:
2023-04-24 22:47:44,172:INFO:                shap: Not installed
2023-04-24 22:47:44,172:INFO:           interpret: Not installed
2023-04-24 22:47:44,172:INFO:                umap: Not installed
2023-04-24 22:47:44,172:INFO:    pandas_profiling: Not installed
2023-04-24 22:47:44,172:INFO:  explainerdashboard: Not installed
2023-04-24 22:47:44,172:INFO:             autoviz: Not installed
2023-04-24 22:47:44,172:INFO:           fairlearn: Not installed
2023-04-24 22:47:44,172:INFO:             xgboost: Not installed
2023-04-24 22:47:44,172:INFO:            catboost: Not installed
2023-04-24 22:47:44,172:INFO:              kmodes: Not installed
2023-04-24 22:47:44,172:INFO:             mlxtend: Not installed
2023-04-24 22:47:44,172:INFO:       statsforecast: Not installed
2023-04-24 22:47:44,172:INFO:        tune_sklearn: Not installed
2023-04-24 22:47:44,172:INFO:                 ray: Not installed
2023-04-24 22:47:44,172:INFO:            hyperopt: Not installed
2023-04-24 22:47:44,172:INFO:              optuna: Not installed
2023-04-24 22:47:44,172:INFO:               skopt: Not installed
2023-04-24 22:47:44,172:INFO:              mlflow: 2.3.0
2023-04-24 22:47:44,172:INFO:              gradio: Not installed
2023-04-24 22:47:44,172:INFO:             fastapi: Not installed
2023-04-24 22:47:44,173:INFO:             uvicorn: Not installed
2023-04-24 22:47:44,173:INFO:              m2cgen: Not installed
2023-04-24 22:47:44,173:INFO:           evidently: Not installed
2023-04-24 22:47:44,173:INFO:               fugue: Not installed
2023-04-24 22:47:44,173:INFO:           streamlit: Not installed
2023-04-24 22:47:44,173:INFO:             prophet: Not installed
2023-04-24 22:47:44,173:INFO:None
2023-04-24 22:47:44,173:INFO:Set up GPU usage.
2023-04-24 22:47:44,173:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-24 22:47:44,173:WARNING:cuML is outdated or not found. Required version is >=22.10, got 3.0.0
2023-04-24 22:47:44,173:INFO:Set up data.
2023-04-24 22:47:44,183:INFO:Set up train/test split.
2023-04-24 22:47:44,186:INFO:Set up index.
2023-04-24 22:47:44,186:INFO:Set up folding strategy.
2023-04-24 22:47:44,186:INFO:Assigning column types.
2023-04-24 22:47:44,189:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-04-24 22:47:44,189:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-24 22:47:44,189:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-04-24 22:47:44,189:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-24 22:47:44,194:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-24 22:47:44,194:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-24 22:47:44,199:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-24 22:47:44,199:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-24 22:47:44,260:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-24 22:47:44,260:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-24 22:47:44,298:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-24 22:47:44,298:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-24 22:47:44,298:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-24 22:47:44,298:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 22:47:49,352:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 22:47:49,352:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-24 22:47:49,352:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-04-24 22:47:49,352:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-24 22:47:49,352:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-24 22:47:49,352:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-24 22:47:49,352:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-24 22:47:49,352:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-24 22:47:49,434:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-24 22:47:49,435:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-24 22:47:49,472:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-24 22:47:49,472:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-24 22:47:49,472:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-24 22:47:49,472:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 22:47:49,535:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 22:47:49,535:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-04-24 22:47:49,535:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-24 22:47:49,535:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-24 22:47:49,535:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-24 22:47:49,535:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-24 22:47:49,552:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-24 22:47:49,552:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-24 22:47:49,613:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-24 22:47:49,613:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-24 22:47:49,661:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-24 22:47:49,676:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-24 22:47:49,676:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-24 22:47:49,676:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 22:47:49,709:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 22:47:49,709:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-24 22:47:49,709:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-24 22:47:49,709:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-24 22:47:49,709:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-24 22:47:49,723:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-24 22:47:49,723:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-24 22:47:49,786:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-24 22:47:49,786:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-24 22:47:49,833:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-24 22:47:49,833:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-24 22:47:49,833:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-24 22:47:49,849:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 22:47:49,880:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 22:47:49,880:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-04-24 22:47:49,880:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-24 22:47:49,880:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-24 22:47:49,880:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-24 22:47:49,896:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-24 22:47:49,896:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-24 22:47:49,959:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-24 22:47:49,959:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-24 22:47:50,006:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-24 22:47:50,006:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-24 22:47:50,006:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-24 22:47:50,006:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 22:47:50,037:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 22:47:50,052:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-24 22:47:50,052:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-24 22:47:50,053:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-24 22:47:50,053:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-24 22:47:50,053:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-24 22:47:50,131:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-24 22:47:50,131:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-24 22:47:50,178:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-24 22:47:50,178:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-24 22:47:50,178:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-24 22:47:50,178:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 22:47:50,225:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 22:47:50,225:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-04-24 22:47:50,225:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-24 22:47:50,225:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-24 22:47:50,225:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-24 22:47:50,241:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-24 22:47:50,304:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-24 22:47:50,304:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-24 22:47:50,354:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-24 22:47:50,354:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-24 22:47:50,354:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-24 22:47:50,367:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 22:47:50,398:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 22:47:50,398:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-24 22:47:50,398:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-24 22:47:50,398:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-24 22:47:50,413:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-24 22:47:50,476:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-24 22:47:50,476:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-24 22:47:50,538:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-24 22:47:50,538:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-24 22:47:50,538:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-24 22:47:50,538:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 22:47:50,585:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 22:47:50,585:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-04-24 22:47:50,585:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-24 22:47:50,585:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-24 22:47:50,585:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-24 22:47:50,585:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-24 22:47:50,677:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-24 22:47:50,677:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-24 22:47:50,733:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-24 22:47:50,733:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-24 22:47:50,734:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 22:47:50,776:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 22:47:50,776:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-24 22:47:50,776:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-24 22:47:50,783:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-24 22:47:50,791:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-24 22:47:50,864:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-24 22:47:50,864:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-24 22:47:50,911:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-24 22:47:50,911:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-24 22:47:50,911:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 22:47:50,964:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 22:47:50,965:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-04-24 22:47:50,965:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-24 22:47:50,965:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-24 22:47:50,966:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-24 22:47:50,966:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-24 22:47:51,045:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-24 22:47:51,091:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-24 22:47:51,091:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-24 22:47:51,091:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 22:47:51,123:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 22:47:51,123:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-24 22:47:51,123:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-24 22:47:51,138:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-24 22:47:51,138:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-24 22:47:51,217:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-24 22:47:51,270:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-24 22:47:51,270:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-24 22:47:51,270:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 22:47:51,304:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 22:47:51,304:INFO:Preparing preprocessing pipeline...
2023-04-24 22:47:51,304:INFO:Set up target transformation.
2023-04-24 22:47:51,304:INFO:Set up simple imputation.
2023-04-24 22:47:51,304:INFO:Set up custom pipeline.
2023-04-24 22:47:51,304:INFO:Set up column name cleaning.
2023-04-24 22:57:37,849:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-24 22:57:37,849:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-24 22:57:37,849:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-24 22:57:37,849:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-24 22:57:38,343:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-04-24 22:57:38,576:INFO:PyCaret RegressionExperiment
2023-04-24 22:57:38,576:INFO:Logging name: your_experiment_name
2023-04-24 22:57:38,576:INFO:ML Usecase: MLUsecase.REGRESSION
2023-04-24 22:57:38,576:INFO:version 3.0.0
2023-04-24 22:57:38,576:INFO:Initializing setup()
2023-04-24 22:57:38,576:INFO:self.USI: 3321
2023-04-24 22:57:38,576:INFO:self._variable_keys: {'gpu_n_jobs_param', '_available_plots', 'X_test', 'X_train', 'html_param', 'USI', 'fold_generator', 'transform_target_param', 'data', 'pipeline', 'logging_param', 'n_jobs_param', 'target_param', '_ml_usecase', 'exp_id', 'y', 'seed', 'exp_name_log', 'gpu_param', 'log_plots_param', 'fold_groups_param', 'idx', 'X', 'y_train', 'y_test', 'memory', 'fold_shuffle_param'}
2023-04-24 22:57:38,576:INFO:Checking environment
2023-04-24 22:57:38,576:INFO:python_version: 3.10.5
2023-04-24 22:57:38,576:INFO:python_build: ('tags/v3.10.5:f377153', 'Jun  6 2022 16:14:13')
2023-04-24 22:57:38,576:INFO:machine: AMD64
2023-04-24 22:57:38,576:INFO:platform: Windows-10-10.0.22000-SP0
2023-04-24 22:57:38,576:INFO:Memory: svmem(total=16497119232, available=6292385792, percent=61.9, used=10204733440, free=6292385792)
2023-04-24 22:57:38,576:INFO:Physical Core: 8
2023-04-24 22:57:38,576:INFO:Logical Core: 16
2023-04-24 22:57:38,576:INFO:Checking libraries
2023-04-24 22:57:38,576:INFO:System:
2023-04-24 22:57:38,576:INFO:    python: 3.10.5 (tags/v3.10.5:f377153, Jun  6 2022, 16:14:13) [MSC v.1929 64 bit (AMD64)]
2023-04-24 22:57:38,576:INFO:executable: C:\Users\Hashif\AppData\Local\Programs\Python\Python310\python.exe
2023-04-24 22:57:38,576:INFO:   machine: Windows-10-10.0.22000-SP0
2023-04-24 22:57:38,576:INFO:PyCaret required dependencies:
2023-04-24 22:57:38,576:INFO:                 pip: 23.1.1
2023-04-24 22:57:38,576:INFO:          setuptools: 58.1.0
2023-04-24 22:57:38,576:INFO:             pycaret: 3.0.0
2023-04-24 22:57:38,576:INFO:             IPython: 8.4.0
2023-04-24 22:57:38,576:INFO:          ipywidgets: 7.7.0
2023-04-24 22:57:38,576:INFO:                tqdm: 4.65.0
2023-04-24 22:57:38,576:INFO:               numpy: 1.23.0
2023-04-24 22:57:38,576:INFO:              pandas: 1.4.3
2023-04-24 22:57:38,576:INFO:              jinja2: 3.1.2
2023-04-24 22:57:38,576:INFO:               scipy: 1.9.3
2023-04-24 22:57:38,576:INFO:              joblib: 1.2.0
2023-04-24 22:57:38,576:INFO:             sklearn: 1.1.2
2023-04-24 22:57:38,576:INFO:                pyod: 1.0.9
2023-04-24 22:57:38,576:INFO:            imblearn: 0.10.1
2023-04-24 22:57:38,576:INFO:   category_encoders: 2.6.0
2023-04-24 22:57:38,576:INFO:            lightgbm: 3.3.5
2023-04-24 22:57:38,576:INFO:               numba: 0.56.4
2023-04-24 22:57:38,576:INFO:            requests: 2.28.1
2023-04-24 22:57:38,576:INFO:          matplotlib: 3.6.2
2023-04-24 22:57:38,576:INFO:          scikitplot: 0.3.7
2023-04-24 22:57:38,576:INFO:         yellowbrick: 1.5
2023-04-24 22:57:38,576:INFO:              plotly: 5.14.1
2023-04-24 22:57:38,576:INFO:             kaleido: 0.2.1
2023-04-24 22:57:38,576:INFO:         statsmodels: 0.13.5
2023-04-24 22:57:38,576:INFO:              sktime: 0.17.1
2023-04-24 22:57:38,576:INFO:               tbats: 1.1.3
2023-04-24 22:57:38,576:INFO:            pmdarima: 2.0.3
2023-04-24 22:57:38,576:INFO:              psutil: 5.9.1
2023-04-24 22:57:38,576:INFO:PyCaret optional dependencies:
2023-04-24 22:57:38,592:INFO:                shap: Not installed
2023-04-24 22:57:38,592:INFO:           interpret: Not installed
2023-04-24 22:57:38,592:INFO:                umap: Not installed
2023-04-24 22:57:38,592:INFO:    pandas_profiling: Not installed
2023-04-24 22:57:38,592:INFO:  explainerdashboard: Not installed
2023-04-24 22:57:38,592:INFO:             autoviz: Not installed
2023-04-24 22:57:38,592:INFO:           fairlearn: Not installed
2023-04-24 22:57:38,592:INFO:             xgboost: Not installed
2023-04-24 22:57:38,592:INFO:            catboost: Not installed
2023-04-24 22:57:38,592:INFO:              kmodes: Not installed
2023-04-24 22:57:38,592:INFO:             mlxtend: Not installed
2023-04-24 22:57:38,592:INFO:       statsforecast: Not installed
2023-04-24 22:57:38,592:INFO:        tune_sklearn: Not installed
2023-04-24 22:57:38,592:INFO:                 ray: Not installed
2023-04-24 22:57:38,592:INFO:            hyperopt: Not installed
2023-04-24 22:57:38,592:INFO:              optuna: Not installed
2023-04-24 22:57:38,592:INFO:               skopt: Not installed
2023-04-24 22:57:38,592:INFO:              mlflow: 2.3.0
2023-04-24 22:57:38,592:INFO:              gradio: Not installed
2023-04-24 22:57:38,592:INFO:             fastapi: Not installed
2023-04-24 22:57:38,592:INFO:             uvicorn: Not installed
2023-04-24 22:57:38,592:INFO:              m2cgen: Not installed
2023-04-24 22:57:38,592:INFO:           evidently: Not installed
2023-04-24 22:57:38,592:INFO:               fugue: Not installed
2023-04-24 22:57:38,592:INFO:           streamlit: Not installed
2023-04-24 22:57:38,592:INFO:             prophet: Not installed
2023-04-24 22:57:38,592:INFO:None
2023-04-24 22:57:38,592:INFO:Set up data.
2023-04-24 22:57:38,592:INFO:Set up train/test split.
2023-04-24 22:57:38,592:INFO:Set up index.
2023-04-24 22:57:38,592:INFO:Set up folding strategy.
2023-04-24 22:57:38,592:INFO:Assigning column types.
2023-04-24 22:57:38,592:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-04-24 22:57:38,592:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-04-24 22:57:38,607:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-24 22:57:38,607:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-24 22:57:38,670:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-24 22:57:38,701:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-24 22:57:38,717:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 22:57:38,717:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 22:57:38,717:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-04-24 22:57:38,733:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-24 22:57:38,733:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-24 22:57:38,780:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-24 22:57:38,827:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-24 22:57:38,827:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 22:57:38,827:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 22:57:38,827:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-04-24 22:57:38,842:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-24 22:57:38,844:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-24 22:57:38,890:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-24 22:57:38,937:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-24 22:57:38,944:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 22:57:38,944:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 22:57:38,944:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-24 22:57:38,953:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-24 22:57:39,000:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-24 22:57:39,047:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-24 22:57:39,047:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 22:57:39,047:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 22:57:39,047:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-04-24 22:57:39,047:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-24 22:57:39,109:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-24 22:57:39,145:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-24 22:57:39,145:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 22:57:39,157:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 22:57:39,157:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-24 22:57:39,219:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-24 22:57:39,251:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-24 22:57:39,251:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 22:57:39,251:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 22:57:39,251:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-04-24 22:57:39,313:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-24 22:57:39,361:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-24 22:57:39,361:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 22:57:39,361:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 22:57:39,423:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-24 22:57:39,470:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-24 22:57:39,470:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 22:57:39,470:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 22:57:39,470:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-04-24 22:57:39,549:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-24 22:57:39,596:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 22:57:39,596:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 22:57:39,674:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-24 22:57:39,706:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 22:57:39,706:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 22:57:39,706:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-04-24 22:57:39,817:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 22:57:39,817:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 22:57:39,925:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 22:57:39,925:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 22:57:39,925:INFO:Preparing preprocessing pipeline...
2023-04-24 22:57:39,925:INFO:Set up simple imputation.
2023-04-24 22:57:39,925:INFO:Set up feature normalization.
2023-04-24 22:57:39,925:INFO:Set up column name cleaning.
2023-04-24 22:57:39,957:INFO:Finished creating preprocessing pipeline.
2023-04-24 22:57:39,973:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Hashif\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['distance', 'ratings', 'wifi',
                                             'AC', 'TV', 'Queen Sized Bed',
                                             'Geyser', 'King Sized Bed',
                                             'Power backup', 'Mini Fridge'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-04-24 22:57:39,973:INFO:Creating final display dataframe.
2023-04-24 22:57:40,047:INFO:Setup _display_container:                     Description                 Value
0                    Session id                   123
1                        Target                 price
2                   Target type            Regression
3           Original data shape             (100, 11)
4        Transformed data shape             (100, 11)
5   Transformed train set shape              (80, 11)
6    Transformed test set shape              (20, 11)
7              Numeric features                    10
8                    Preprocess                  True
9               Imputation type                simple
10           Numeric imputation                  mean
11       Categorical imputation                  mode
12                    Normalize                  True
13             Normalize method                zscore
14               Fold Generator                 KFold
15                  Fold Number                    10
16                     CPU Jobs                    -1
17                      Use GPU                 False
18               Log Experiment          MlflowLogger
19              Experiment Name  your_experiment_name
20                          USI                  3321
2023-04-24 22:57:40,154:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 22:57:40,154:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 22:57:40,276:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 22:57:40,276:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 22:57:40,277:INFO:Logging experiment in loggers
2023-04-24 22:57:40,515:INFO:SubProcess save_model() called ==================================
2023-04-24 22:57:40,524:INFO:Initializing save_model()
2023-04-24 22:57:40,524:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\Hashif\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['distance', 'ratings', 'wifi',
                                             'AC', 'TV', 'Queen Sized Bed',
                                             'Geyser', 'King Sized Bed',
                                             'Power backup', 'Mini Fridge'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), model_name=C:\Users\Hashif\AppData\Local\Temp\tmpa9tjmnem\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\Hashif\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['distance', 'ratings', 'wifi',
                                             'AC', 'TV', 'Queen Sized Bed',
                                             'Geyser', 'King Sized Bed',
                                             'Power backup', 'Mini Fridge'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=False, use_case=MLUsecase.REGRESSION, kwargs={})
2023-04-24 22:57:40,524:INFO:Adding model into prep_pipe
2023-04-24 22:57:40,524:WARNING:Only Model saved as it was a pipeline.
2023-04-24 22:57:40,527:INFO:C:\Users\Hashif\AppData\Local\Temp\tmpa9tjmnem\Transformation Pipeline.pkl saved in current working directory
2023-04-24 22:57:40,531:INFO:Pipeline(memory=FastMemory(location=C:\Users\Hashif\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['distance', 'ratings', 'wifi',
                                             'AC', 'TV', 'Queen Sized Bed',
                                             'Geyser', 'King Sized Bed',
                                             'Power backup', 'Mini Fridge'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-04-24 22:57:40,531:INFO:save_model() successfully completed......................................
2023-04-24 22:57:40,599:INFO:SubProcess save_model() end ==================================
2023-04-24 22:57:40,655:INFO:setup() successfully completed in 1.7s...............
2023-04-24 22:57:40,655:INFO:Initializing compare_models()
2023-04-24 22:57:40,655:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B0DCCDBA90>, include=None, fold=5, round=4, cross_validation=True, sort=RMSLE, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001B0DCCDBA90>, 'include': None, 'exclude': ['catboost'], 'fold': 5, 'round': 4, 'cross_validation': True, 'sort': 'RMSLE', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=['catboost'])
2023-04-24 22:57:40,655:INFO:Checking exceptions
2023-04-24 22:57:40,670:INFO:Preparing display monitor
2023-04-24 22:57:40,690:INFO:Initializing Linear Regression
2023-04-24 22:57:40,690:INFO:Total runtime is 0.0 minutes
2023-04-24 22:57:40,700:INFO:SubProcess create_model() called ==================================
2023-04-24 22:57:40,700:INFO:Initializing create_model()
2023-04-24 22:57:40,701:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B0DCCDBA90>, estimator=lr, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B0A2C4FF40>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 22:57:40,701:INFO:Checking exceptions
2023-04-24 22:57:40,701:INFO:Importing libraries
2023-04-24 22:57:40,701:INFO:Copying training dataset
2023-04-24 22:57:40,705:INFO:Defining folds
2023-04-24 22:57:40,705:INFO:Declaring metric variables
2023-04-24 22:57:40,709:INFO:Importing untrained model
2023-04-24 22:57:40,712:INFO:Linear Regression Imported successfully
2023-04-24 22:57:40,719:INFO:Starting cross validation
2023-04-24 22:57:40,726:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 22:57:43,457:INFO:Calculating mean and std
2023-04-24 22:57:43,457:INFO:Creating metrics dataframe
2023-04-24 22:57:43,479:INFO:Uploading results into container
2023-04-24 22:57:43,481:INFO:Uploading model into container now
2023-04-24 22:57:43,482:INFO:_master_model_container: 1
2023-04-24 22:57:43,482:INFO:_display_container: 2
2023-04-24 22:57:43,482:INFO:LinearRegression(n_jobs=-1)
2023-04-24 22:57:43,482:INFO:create_model() successfully completed......................................
2023-04-24 22:57:43,553:INFO:SubProcess create_model() end ==================================
2023-04-24 22:57:43,553:INFO:Creating metrics dataframe
2023-04-24 22:57:43,569:INFO:Initializing Lasso Regression
2023-04-24 22:57:43,569:INFO:Total runtime is 0.04797200759251912 minutes
2023-04-24 22:57:43,583:INFO:SubProcess create_model() called ==================================
2023-04-24 22:57:43,583:INFO:Initializing create_model()
2023-04-24 22:57:43,583:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B0DCCDBA90>, estimator=lasso, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B0A2C4FF40>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 22:57:43,584:INFO:Checking exceptions
2023-04-24 22:57:43,584:INFO:Importing libraries
2023-04-24 22:57:43,584:INFO:Copying training dataset
2023-04-24 22:57:43,587:INFO:Defining folds
2023-04-24 22:57:43,589:INFO:Declaring metric variables
2023-04-24 22:57:43,592:INFO:Importing untrained model
2023-04-24 22:57:43,597:INFO:Lasso Regression Imported successfully
2023-04-24 22:57:43,606:INFO:Starting cross validation
2023-04-24 22:57:43,607:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 22:57:45,686:INFO:Calculating mean and std
2023-04-24 22:57:45,686:INFO:Creating metrics dataframe
2023-04-24 22:57:45,691:INFO:Uploading results into container
2023-04-24 22:57:45,691:INFO:Uploading model into container now
2023-04-24 22:57:45,691:INFO:_master_model_container: 2
2023-04-24 22:57:45,691:INFO:_display_container: 2
2023-04-24 22:57:45,691:INFO:Lasso(random_state=123)
2023-04-24 22:57:45,691:INFO:create_model() successfully completed......................................
2023-04-24 22:57:45,757:INFO:SubProcess create_model() end ==================================
2023-04-24 22:57:45,757:INFO:Creating metrics dataframe
2023-04-24 22:57:45,757:INFO:Initializing Ridge Regression
2023-04-24 22:57:45,757:INFO:Total runtime is 0.0844507614771525 minutes
2023-04-24 22:57:45,773:INFO:SubProcess create_model() called ==================================
2023-04-24 22:57:45,773:INFO:Initializing create_model()
2023-04-24 22:57:45,773:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B0DCCDBA90>, estimator=ridge, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B0A2C4FF40>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 22:57:45,773:INFO:Checking exceptions
2023-04-24 22:57:45,773:INFO:Importing libraries
2023-04-24 22:57:45,774:INFO:Copying training dataset
2023-04-24 22:57:45,777:INFO:Defining folds
2023-04-24 22:57:45,777:INFO:Declaring metric variables
2023-04-24 22:57:45,779:INFO:Importing untrained model
2023-04-24 22:57:45,783:INFO:Ridge Regression Imported successfully
2023-04-24 22:57:45,789:INFO:Starting cross validation
2023-04-24 22:57:45,789:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 22:57:47,824:INFO:Calculating mean and std
2023-04-24 22:57:47,824:INFO:Creating metrics dataframe
2023-04-24 22:57:47,844:INFO:Uploading results into container
2023-04-24 22:57:47,845:INFO:Uploading model into container now
2023-04-24 22:57:47,847:INFO:_master_model_container: 3
2023-04-24 22:57:47,847:INFO:_display_container: 2
2023-04-24 22:57:47,847:INFO:Ridge(random_state=123)
2023-04-24 22:57:47,847:INFO:create_model() successfully completed......................................
2023-04-24 22:57:47,901:INFO:SubProcess create_model() end ==================================
2023-04-24 22:57:47,901:INFO:Creating metrics dataframe
2023-04-24 22:57:47,917:INFO:Initializing Elastic Net
2023-04-24 22:57:47,917:INFO:Total runtime is 0.12043659687042235 minutes
2023-04-24 22:57:47,917:INFO:SubProcess create_model() called ==================================
2023-04-24 22:57:47,917:INFO:Initializing create_model()
2023-04-24 22:57:47,917:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B0DCCDBA90>, estimator=en, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B0A2C4FF40>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 22:57:47,917:INFO:Checking exceptions
2023-04-24 22:57:47,917:INFO:Importing libraries
2023-04-24 22:57:47,926:INFO:Copying training dataset
2023-04-24 22:57:47,929:INFO:Defining folds
2023-04-24 22:57:47,929:INFO:Declaring metric variables
2023-04-24 22:57:47,932:INFO:Importing untrained model
2023-04-24 22:57:47,937:INFO:Elastic Net Imported successfully
2023-04-24 22:57:47,942:INFO:Starting cross validation
2023-04-24 22:57:47,942:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 22:57:49,489:INFO:Calculating mean and std
2023-04-24 22:57:49,489:INFO:Creating metrics dataframe
2023-04-24 22:57:49,503:INFO:Uploading results into container
2023-04-24 22:57:49,503:INFO:Uploading model into container now
2023-04-24 22:57:49,507:INFO:_master_model_container: 4
2023-04-24 22:57:49,507:INFO:_display_container: 2
2023-04-24 22:57:49,507:INFO:ElasticNet(random_state=123)
2023-04-24 22:57:49,507:INFO:create_model() successfully completed......................................
2023-04-24 22:57:49,568:INFO:SubProcess create_model() end ==================================
2023-04-24 22:57:49,568:INFO:Creating metrics dataframe
2023-04-24 22:57:49,568:INFO:Initializing Least Angle Regression
2023-04-24 22:57:49,568:INFO:Total runtime is 0.14796368678410848 minutes
2023-04-24 22:57:49,585:INFO:SubProcess create_model() called ==================================
2023-04-24 22:57:49,586:INFO:Initializing create_model()
2023-04-24 22:57:49,586:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B0DCCDBA90>, estimator=lar, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B0A2C4FF40>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 22:57:49,586:INFO:Checking exceptions
2023-04-24 22:57:49,586:INFO:Importing libraries
2023-04-24 22:57:49,586:INFO:Copying training dataset
2023-04-24 22:57:49,590:INFO:Defining folds
2023-04-24 22:57:49,590:INFO:Declaring metric variables
2023-04-24 22:57:49,591:INFO:Importing untrained model
2023-04-24 22:57:49,598:INFO:Least Angle Regression Imported successfully
2023-04-24 22:57:49,607:INFO:Starting cross validation
2023-04-24 22:57:49,608:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 22:57:49,660:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 22:57:49,667:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 22:57:49,671:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 22:57:49,678:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 22:57:49,683:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:741: RuntimeWarning: overflow encountered in divide
  z = -coef[active] / (least_squares + tiny32)

 i.e. alpha=5.364e-07, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-04-24 22:57:49,683:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 22:57:49,688:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=3.058e+00, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-04-24 22:57:49,689:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=8.906e-01, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-04-24 22:57:49,690:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=3.211e-01, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-04-24 22:57:49,716:INFO:Calculating mean and std
2023-04-24 22:57:49,717:INFO:Creating metrics dataframe
2023-04-24 22:57:49,721:INFO:Uploading results into container
2023-04-24 22:57:49,721:INFO:Uploading model into container now
2023-04-24 22:57:49,722:INFO:_master_model_container: 5
2023-04-24 22:57:49,722:INFO:_display_container: 2
2023-04-24 22:57:49,722:INFO:Lars(random_state=123)
2023-04-24 22:57:49,722:INFO:create_model() successfully completed......................................
2023-04-24 22:57:49,779:INFO:SubProcess create_model() end ==================================
2023-04-24 22:57:49,779:INFO:Creating metrics dataframe
2023-04-24 22:57:49,795:INFO:Initializing Lasso Least Angle Regression
2023-04-24 22:57:49,795:INFO:Total runtime is 0.15174614985783896 minutes
2023-04-24 22:57:49,798:INFO:SubProcess create_model() called ==================================
2023-04-24 22:57:49,799:INFO:Initializing create_model()
2023-04-24 22:57:49,799:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B0DCCDBA90>, estimator=llar, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B0A2C4FF40>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 22:57:49,799:INFO:Checking exceptions
2023-04-24 22:57:49,799:INFO:Importing libraries
2023-04-24 22:57:49,799:INFO:Copying training dataset
2023-04-24 22:57:49,803:INFO:Defining folds
2023-04-24 22:57:49,803:INFO:Declaring metric variables
2023-04-24 22:57:49,805:INFO:Importing untrained model
2023-04-24 22:57:49,808:INFO:Lasso Least Angle Regression Imported successfully
2023-04-24 22:57:49,815:INFO:Starting cross validation
2023-04-24 22:57:49,815:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 22:57:49,870:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-24 22:57:49,876:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-24 22:57:49,881:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-24 22:57:49,888:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-24 22:57:49,890:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-24 22:57:49,892:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=3.058e+00, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-04-24 22:57:49,915:INFO:Calculating mean and std
2023-04-24 22:57:49,917:INFO:Creating metrics dataframe
2023-04-24 22:57:49,921:INFO:Uploading results into container
2023-04-24 22:57:49,922:INFO:Uploading model into container now
2023-04-24 22:57:49,922:INFO:_master_model_container: 6
2023-04-24 22:57:49,922:INFO:_display_container: 2
2023-04-24 22:57:49,922:INFO:LassoLars(random_state=123)
2023-04-24 22:57:49,922:INFO:create_model() successfully completed......................................
2023-04-24 22:57:49,983:INFO:SubProcess create_model() end ==================================
2023-04-24 22:57:49,983:INFO:Creating metrics dataframe
2023-04-24 22:57:49,983:INFO:Initializing Orthogonal Matching Pursuit
2023-04-24 22:57:49,983:INFO:Total runtime is 0.15488098065058392 minutes
2023-04-24 22:57:49,999:INFO:SubProcess create_model() called ==================================
2023-04-24 22:57:49,999:INFO:Initializing create_model()
2023-04-24 22:57:49,999:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B0DCCDBA90>, estimator=omp, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B0A2C4FF40>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 22:57:49,999:INFO:Checking exceptions
2023-04-24 22:57:49,999:INFO:Importing libraries
2023-04-24 22:57:49,999:INFO:Copying training dataset
2023-04-24 22:57:50,000:INFO:Defining folds
2023-04-24 22:57:50,000:INFO:Declaring metric variables
2023-04-24 22:57:50,000:INFO:Importing untrained model
2023-04-24 22:57:50,000:INFO:Orthogonal Matching Pursuit Imported successfully
2023-04-24 22:57:50,000:INFO:Starting cross validation
2023-04-24 22:57:50,000:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 22:57:50,048:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 22:57:50,067:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 22:57:50,067:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 22:57:50,080:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 22:57:50,080:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 22:57:50,111:INFO:Calculating mean and std
2023-04-24 22:57:50,111:INFO:Creating metrics dataframe
2023-04-24 22:57:50,120:INFO:Uploading results into container
2023-04-24 22:57:50,120:INFO:Uploading model into container now
2023-04-24 22:57:50,120:INFO:_master_model_container: 7
2023-04-24 22:57:50,120:INFO:_display_container: 2
2023-04-24 22:57:50,120:INFO:OrthogonalMatchingPursuit()
2023-04-24 22:57:50,120:INFO:create_model() successfully completed......................................
2023-04-24 22:57:50,185:INFO:SubProcess create_model() end ==================================
2023-04-24 22:57:50,185:INFO:Creating metrics dataframe
2023-04-24 22:57:50,185:INFO:Initializing Bayesian Ridge
2023-04-24 22:57:50,185:INFO:Total runtime is 0.1582512180010478 minutes
2023-04-24 22:57:50,185:INFO:SubProcess create_model() called ==================================
2023-04-24 22:57:50,185:INFO:Initializing create_model()
2023-04-24 22:57:50,201:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B0DCCDBA90>, estimator=br, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B0A2C4FF40>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 22:57:50,201:INFO:Checking exceptions
2023-04-24 22:57:50,201:INFO:Importing libraries
2023-04-24 22:57:50,201:INFO:Copying training dataset
2023-04-24 22:57:50,204:INFO:Defining folds
2023-04-24 22:57:50,204:INFO:Declaring metric variables
2023-04-24 22:57:50,207:INFO:Importing untrained model
2023-04-24 22:57:50,210:INFO:Bayesian Ridge Imported successfully
2023-04-24 22:57:50,218:INFO:Starting cross validation
2023-04-24 22:57:50,218:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 22:57:50,342:INFO:Calculating mean and std
2023-04-24 22:57:50,342:INFO:Creating metrics dataframe
2023-04-24 22:57:50,349:INFO:Uploading results into container
2023-04-24 22:57:50,349:INFO:Uploading model into container now
2023-04-24 22:57:50,349:INFO:_master_model_container: 8
2023-04-24 22:57:50,349:INFO:_display_container: 2
2023-04-24 22:57:50,353:INFO:BayesianRidge()
2023-04-24 22:57:50,353:INFO:create_model() successfully completed......................................
2023-04-24 22:57:50,424:INFO:SubProcess create_model() end ==================================
2023-04-24 22:57:50,424:INFO:Creating metrics dataframe
2023-04-24 22:57:50,437:INFO:Initializing Passive Aggressive Regressor
2023-04-24 22:57:50,437:INFO:Total runtime is 0.16244932413101199 minutes
2023-04-24 22:57:50,439:INFO:SubProcess create_model() called ==================================
2023-04-24 22:57:50,439:INFO:Initializing create_model()
2023-04-24 22:57:50,439:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B0DCCDBA90>, estimator=par, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B0A2C4FF40>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 22:57:50,439:INFO:Checking exceptions
2023-04-24 22:57:50,439:INFO:Importing libraries
2023-04-24 22:57:50,439:INFO:Copying training dataset
2023-04-24 22:57:50,444:INFO:Defining folds
2023-04-24 22:57:50,444:INFO:Declaring metric variables
2023-04-24 22:57:50,447:INFO:Importing untrained model
2023-04-24 22:57:50,451:INFO:Passive Aggressive Regressor Imported successfully
2023-04-24 22:57:50,457:INFO:Starting cross validation
2023-04-24 22:57:50,458:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 22:57:50,571:INFO:Calculating mean and std
2023-04-24 22:57:50,576:INFO:Creating metrics dataframe
2023-04-24 22:57:50,580:INFO:Uploading results into container
2023-04-24 22:57:50,581:INFO:Uploading model into container now
2023-04-24 22:57:50,581:INFO:_master_model_container: 9
2023-04-24 22:57:50,581:INFO:_display_container: 2
2023-04-24 22:57:50,581:INFO:PassiveAggressiveRegressor(random_state=123)
2023-04-24 22:57:50,581:INFO:create_model() successfully completed......................................
2023-04-24 22:57:50,647:INFO:SubProcess create_model() end ==================================
2023-04-24 22:57:50,647:INFO:Creating metrics dataframe
2023-04-24 22:57:50,655:INFO:Initializing Huber Regressor
2023-04-24 22:57:50,655:INFO:Total runtime is 0.16608530680338543 minutes
2023-04-24 22:57:50,659:INFO:SubProcess create_model() called ==================================
2023-04-24 22:57:50,659:INFO:Initializing create_model()
2023-04-24 22:57:50,659:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B0DCCDBA90>, estimator=huber, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B0A2C4FF40>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 22:57:50,660:INFO:Checking exceptions
2023-04-24 22:57:50,660:INFO:Importing libraries
2023-04-24 22:57:50,660:INFO:Copying training dataset
2023-04-24 22:57:50,663:INFO:Defining folds
2023-04-24 22:57:50,663:INFO:Declaring metric variables
2023-04-24 22:57:50,666:INFO:Importing untrained model
2023-04-24 22:57:50,668:INFO:Huber Regressor Imported successfully
2023-04-24 22:57:50,673:INFO:Starting cross validation
2023-04-24 22:57:50,673:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 22:57:50,777:INFO:Calculating mean and std
2023-04-24 22:57:50,777:INFO:Creating metrics dataframe
2023-04-24 22:57:50,786:INFO:Uploading results into container
2023-04-24 22:57:50,786:INFO:Uploading model into container now
2023-04-24 22:57:50,786:INFO:_master_model_container: 10
2023-04-24 22:57:50,786:INFO:_display_container: 2
2023-04-24 22:57:50,786:INFO:HuberRegressor()
2023-04-24 22:57:50,786:INFO:create_model() successfully completed......................................
2023-04-24 22:57:50,851:INFO:SubProcess create_model() end ==================================
2023-04-24 22:57:50,851:INFO:Creating metrics dataframe
2023-04-24 22:57:50,851:INFO:Initializing K Neighbors Regressor
2023-04-24 22:57:50,851:INFO:Total runtime is 0.16934397220611574 minutes
2023-04-24 22:57:50,865:INFO:SubProcess create_model() called ==================================
2023-04-24 22:57:50,865:INFO:Initializing create_model()
2023-04-24 22:57:50,865:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B0DCCDBA90>, estimator=knn, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B0A2C4FF40>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 22:57:50,865:INFO:Checking exceptions
2023-04-24 22:57:50,865:INFO:Importing libraries
2023-04-24 22:57:50,865:INFO:Copying training dataset
2023-04-24 22:57:50,868:INFO:Defining folds
2023-04-24 22:57:50,868:INFO:Declaring metric variables
2023-04-24 22:57:50,871:INFO:Importing untrained model
2023-04-24 22:57:50,876:INFO:K Neighbors Regressor Imported successfully
2023-04-24 22:57:50,884:INFO:Starting cross validation
2023-04-24 22:57:50,884:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 22:57:51,015:INFO:Calculating mean and std
2023-04-24 22:57:51,015:INFO:Creating metrics dataframe
2023-04-24 22:57:51,021:INFO:Uploading results into container
2023-04-24 22:57:51,021:INFO:Uploading model into container now
2023-04-24 22:57:51,021:INFO:_master_model_container: 11
2023-04-24 22:57:51,021:INFO:_display_container: 2
2023-04-24 22:57:51,021:INFO:KNeighborsRegressor(n_jobs=-1)
2023-04-24 22:57:51,021:INFO:create_model() successfully completed......................................
2023-04-24 22:57:51,092:INFO:SubProcess create_model() end ==================================
2023-04-24 22:57:51,092:INFO:Creating metrics dataframe
2023-04-24 22:57:51,099:INFO:Initializing Decision Tree Regressor
2023-04-24 22:57:51,102:INFO:Total runtime is 0.1735336780548096 minutes
2023-04-24 22:57:51,105:INFO:SubProcess create_model() called ==================================
2023-04-24 22:57:51,105:INFO:Initializing create_model()
2023-04-24 22:57:51,105:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B0DCCDBA90>, estimator=dt, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B0A2C4FF40>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 22:57:51,105:INFO:Checking exceptions
2023-04-24 22:57:51,105:INFO:Importing libraries
2023-04-24 22:57:51,105:INFO:Copying training dataset
2023-04-24 22:57:51,109:INFO:Defining folds
2023-04-24 22:57:51,109:INFO:Declaring metric variables
2023-04-24 22:57:51,112:INFO:Importing untrained model
2023-04-24 22:57:51,116:INFO:Decision Tree Regressor Imported successfully
2023-04-24 22:57:51,123:INFO:Starting cross validation
2023-04-24 22:57:51,124:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 22:57:51,208:INFO:Calculating mean and std
2023-04-24 22:57:51,208:INFO:Creating metrics dataframe
2023-04-24 22:57:51,211:INFO:Uploading results into container
2023-04-24 22:57:51,212:INFO:Uploading model into container now
2023-04-24 22:57:51,212:INFO:_master_model_container: 12
2023-04-24 22:57:51,212:INFO:_display_container: 2
2023-04-24 22:57:51,212:INFO:DecisionTreeRegressor(random_state=123)
2023-04-24 22:57:51,212:INFO:create_model() successfully completed......................................
2023-04-24 22:57:51,278:INFO:SubProcess create_model() end ==================================
2023-04-24 22:57:51,279:INFO:Creating metrics dataframe
2023-04-24 22:57:51,283:INFO:Initializing Random Forest Regressor
2023-04-24 22:57:51,283:INFO:Total runtime is 0.17654527425765995 minutes
2023-04-24 22:57:51,283:INFO:SubProcess create_model() called ==================================
2023-04-24 22:57:51,283:INFO:Initializing create_model()
2023-04-24 22:57:51,283:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B0DCCDBA90>, estimator=rf, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B0A2C4FF40>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 22:57:51,283:INFO:Checking exceptions
2023-04-24 22:57:51,283:INFO:Importing libraries
2023-04-24 22:57:51,283:INFO:Copying training dataset
2023-04-24 22:57:51,294:INFO:Defining folds
2023-04-24 22:57:51,294:INFO:Declaring metric variables
2023-04-24 22:57:51,297:INFO:Importing untrained model
2023-04-24 22:57:51,298:INFO:Random Forest Regressor Imported successfully
2023-04-24 22:57:51,304:INFO:Starting cross validation
2023-04-24 22:57:51,304:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 22:57:51,721:INFO:Calculating mean and std
2023-04-24 22:57:51,722:INFO:Creating metrics dataframe
2023-04-24 22:57:51,730:INFO:Uploading results into container
2023-04-24 22:57:51,730:INFO:Uploading model into container now
2023-04-24 22:57:51,730:INFO:_master_model_container: 13
2023-04-24 22:57:51,730:INFO:_display_container: 2
2023-04-24 22:57:51,731:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2023-04-24 22:57:51,731:INFO:create_model() successfully completed......................................
2023-04-24 22:57:51,798:INFO:SubProcess create_model() end ==================================
2023-04-24 22:57:51,798:INFO:Creating metrics dataframe
2023-04-24 22:57:51,810:INFO:Initializing Extra Trees Regressor
2023-04-24 22:57:51,810:INFO:Total runtime is 0.18532671531041467 minutes
2023-04-24 22:57:51,814:INFO:SubProcess create_model() called ==================================
2023-04-24 22:57:51,814:INFO:Initializing create_model()
2023-04-24 22:57:51,814:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B0DCCDBA90>, estimator=et, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B0A2C4FF40>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 22:57:51,814:INFO:Checking exceptions
2023-04-24 22:57:51,814:INFO:Importing libraries
2023-04-24 22:57:51,815:INFO:Copying training dataset
2023-04-24 22:57:51,818:INFO:Defining folds
2023-04-24 22:57:51,818:INFO:Declaring metric variables
2023-04-24 22:57:51,821:INFO:Importing untrained model
2023-04-24 22:57:51,826:INFO:Extra Trees Regressor Imported successfully
2023-04-24 22:57:51,840:INFO:Starting cross validation
2023-04-24 22:57:51,840:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 22:57:52,158:INFO:Calculating mean and std
2023-04-24 22:57:52,158:INFO:Creating metrics dataframe
2023-04-24 22:57:52,166:INFO:Uploading results into container
2023-04-24 22:57:52,166:INFO:Uploading model into container now
2023-04-24 22:57:52,167:INFO:_master_model_container: 14
2023-04-24 22:57:52,167:INFO:_display_container: 2
2023-04-24 22:57:52,167:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-04-24 22:57:52,168:INFO:create_model() successfully completed......................................
2023-04-24 22:57:52,235:INFO:SubProcess create_model() end ==================================
2023-04-24 22:57:52,235:INFO:Creating metrics dataframe
2023-04-24 22:57:52,242:INFO:Initializing AdaBoost Regressor
2023-04-24 22:57:52,242:INFO:Total runtime is 0.19252557754516605 minutes
2023-04-24 22:57:52,249:INFO:SubProcess create_model() called ==================================
2023-04-24 22:57:52,249:INFO:Initializing create_model()
2023-04-24 22:57:52,249:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B0DCCDBA90>, estimator=ada, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B0A2C4FF40>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 22:57:52,249:INFO:Checking exceptions
2023-04-24 22:57:52,249:INFO:Importing libraries
2023-04-24 22:57:52,249:INFO:Copying training dataset
2023-04-24 22:57:52,249:INFO:Defining folds
2023-04-24 22:57:52,249:INFO:Declaring metric variables
2023-04-24 22:57:52,256:INFO:Importing untrained model
2023-04-24 22:57:52,260:INFO:AdaBoost Regressor Imported successfully
2023-04-24 22:57:52,266:INFO:Starting cross validation
2023-04-24 22:57:52,268:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 22:57:52,386:INFO:Calculating mean and std
2023-04-24 22:57:52,386:INFO:Creating metrics dataframe
2023-04-24 22:57:52,394:INFO:Uploading results into container
2023-04-24 22:57:52,394:INFO:Uploading model into container now
2023-04-24 22:57:52,394:INFO:_master_model_container: 15
2023-04-24 22:57:52,394:INFO:_display_container: 2
2023-04-24 22:57:52,394:INFO:AdaBoostRegressor(random_state=123)
2023-04-24 22:57:52,394:INFO:create_model() successfully completed......................................
2023-04-24 22:57:52,460:INFO:SubProcess create_model() end ==================================
2023-04-24 22:57:52,460:INFO:Creating metrics dataframe
2023-04-24 22:57:52,469:INFO:Initializing Gradient Boosting Regressor
2023-04-24 22:57:52,469:INFO:Total runtime is 0.19631105661392215 minutes
2023-04-24 22:57:52,476:INFO:SubProcess create_model() called ==================================
2023-04-24 22:57:52,476:INFO:Initializing create_model()
2023-04-24 22:57:52,477:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B0DCCDBA90>, estimator=gbr, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B0A2C4FF40>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 22:57:52,477:INFO:Checking exceptions
2023-04-24 22:57:52,477:INFO:Importing libraries
2023-04-24 22:57:52,477:INFO:Copying training dataset
2023-04-24 22:57:52,479:INFO:Defining folds
2023-04-24 22:57:52,480:INFO:Declaring metric variables
2023-04-24 22:57:52,484:INFO:Importing untrained model
2023-04-24 22:57:52,491:INFO:Gradient Boosting Regressor Imported successfully
2023-04-24 22:57:52,508:INFO:Starting cross validation
2023-04-24 22:57:52,509:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 22:57:52,680:INFO:Calculating mean and std
2023-04-24 22:57:52,680:INFO:Creating metrics dataframe
2023-04-24 22:57:52,696:INFO:Uploading results into container
2023-04-24 22:57:52,696:INFO:Uploading model into container now
2023-04-24 22:57:52,696:INFO:_master_model_container: 16
2023-04-24 22:57:52,696:INFO:_display_container: 2
2023-04-24 22:57:52,699:INFO:GradientBoostingRegressor(random_state=123)
2023-04-24 22:57:52,699:INFO:create_model() successfully completed......................................
2023-04-24 22:57:52,757:INFO:SubProcess create_model() end ==================================
2023-04-24 22:57:52,757:INFO:Creating metrics dataframe
2023-04-24 22:57:52,772:INFO:Initializing Light Gradient Boosting Machine
2023-04-24 22:57:52,772:INFO:Total runtime is 0.2013652324676514 minutes
2023-04-24 22:57:52,775:INFO:SubProcess create_model() called ==================================
2023-04-24 22:57:52,775:INFO:Initializing create_model()
2023-04-24 22:57:52,775:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B0DCCDBA90>, estimator=lightgbm, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B0A2C4FF40>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 22:57:52,775:INFO:Checking exceptions
2023-04-24 22:57:52,775:INFO:Importing libraries
2023-04-24 22:57:52,775:INFO:Copying training dataset
2023-04-24 22:57:52,775:INFO:Defining folds
2023-04-24 22:57:52,775:INFO:Declaring metric variables
2023-04-24 22:57:52,775:INFO:Importing untrained model
2023-04-24 22:57:52,784:INFO:Light Gradient Boosting Machine Imported successfully
2023-04-24 22:57:52,790:INFO:Starting cross validation
2023-04-24 22:57:52,791:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 22:57:52,910:INFO:Calculating mean and std
2023-04-24 22:57:52,910:INFO:Creating metrics dataframe
2023-04-24 22:57:52,922:INFO:Uploading results into container
2023-04-24 22:57:52,922:INFO:Uploading model into container now
2023-04-24 22:57:52,922:INFO:_master_model_container: 17
2023-04-24 22:57:52,922:INFO:_display_container: 2
2023-04-24 22:57:52,922:INFO:LGBMRegressor(random_state=123)
2023-04-24 22:57:52,922:INFO:create_model() successfully completed......................................
2023-04-24 22:57:52,981:INFO:SubProcess create_model() end ==================================
2023-04-24 22:57:52,981:INFO:Creating metrics dataframe
2023-04-24 22:57:52,997:INFO:Initializing Dummy Regressor
2023-04-24 22:57:52,997:INFO:Total runtime is 0.20510924657185875 minutes
2023-04-24 22:57:53,013:INFO:SubProcess create_model() called ==================================
2023-04-24 22:57:53,014:INFO:Initializing create_model()
2023-04-24 22:57:53,014:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B0DCCDBA90>, estimator=dummy, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B0A2C4FF40>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 22:57:53,014:INFO:Checking exceptions
2023-04-24 22:57:53,014:INFO:Importing libraries
2023-04-24 22:57:53,014:INFO:Copying training dataset
2023-04-24 22:57:53,027:INFO:Defining folds
2023-04-24 22:57:53,029:INFO:Declaring metric variables
2023-04-24 22:57:53,036:INFO:Importing untrained model
2023-04-24 22:57:53,040:INFO:Dummy Regressor Imported successfully
2023-04-24 22:57:53,048:INFO:Starting cross validation
2023-04-24 22:57:53,048:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 22:57:53,158:INFO:Calculating mean and std
2023-04-24 22:57:53,158:INFO:Creating metrics dataframe
2023-04-24 22:57:53,170:INFO:Uploading results into container
2023-04-24 22:57:53,171:INFO:Uploading model into container now
2023-04-24 22:57:53,171:INFO:_master_model_container: 18
2023-04-24 22:57:53,171:INFO:_display_container: 2
2023-04-24 22:57:53,171:INFO:DummyRegressor()
2023-04-24 22:57:53,171:INFO:create_model() successfully completed......................................
2023-04-24 22:57:53,230:INFO:SubProcess create_model() end ==================================
2023-04-24 22:57:53,230:INFO:Creating metrics dataframe
2023-04-24 22:57:53,261:INFO:Initializing create_model()
2023-04-24 22:57:53,261:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B0DCCDBA90>, estimator=DecisionTreeRegressor(random_state=123), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-24 22:57:53,261:INFO:Checking exceptions
2023-04-24 22:57:53,261:INFO:Importing libraries
2023-04-24 22:57:53,261:INFO:Copying training dataset
2023-04-24 22:57:53,261:INFO:Defining folds
2023-04-24 22:57:53,261:INFO:Declaring metric variables
2023-04-24 22:57:53,261:INFO:Importing untrained model
2023-04-24 22:57:53,261:INFO:Declaring custom model
2023-04-24 22:57:53,267:INFO:Decision Tree Regressor Imported successfully
2023-04-24 22:57:53,267:INFO:Cross validation set to False
2023-04-24 22:57:53,267:INFO:Fitting Model
2023-04-24 22:57:53,295:INFO:DecisionTreeRegressor(random_state=123)
2023-04-24 22:57:53,295:INFO:create_model() successfully completed......................................
2023-04-24 22:57:53,357:INFO:Creating Dashboard logs
2023-04-24 22:57:53,357:INFO:Model: Decision Tree Regressor
2023-04-24 22:57:53,392:INFO:Logged params: {'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'random_state': 123, 'splitter': 'best'}
2023-04-24 22:57:53,491:INFO:Initializing predict_model()
2023-04-24 22:57:53,491:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B0DCCDBA90>, estimator=DecisionTreeRegressor(random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000001B0A295A7A0>)
2023-04-24 22:57:53,491:INFO:Checking exceptions
2023-04-24 22:57:53,491:INFO:Preloading libraries
2023-04-24 22:57:53,783:INFO:Initializing create_model()
2023-04-24 22:57:53,783:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B0DCCDBA90>, estimator=GradientBoostingRegressor(random_state=123), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-24 22:57:53,783:INFO:Checking exceptions
2023-04-24 22:57:53,783:INFO:Importing libraries
2023-04-24 22:57:53,783:INFO:Copying training dataset
2023-04-24 22:57:53,790:INFO:Defining folds
2023-04-24 22:57:53,790:INFO:Declaring metric variables
2023-04-24 22:57:53,790:INFO:Importing untrained model
2023-04-24 22:57:53,790:INFO:Declaring custom model
2023-04-24 22:57:53,791:INFO:Gradient Boosting Regressor Imported successfully
2023-04-24 22:57:53,792:INFO:Cross validation set to False
2023-04-24 22:57:53,792:INFO:Fitting Model
2023-04-24 22:57:53,823:INFO:GradientBoostingRegressor(random_state=123)
2023-04-24 22:57:53,823:INFO:create_model() successfully completed......................................
2023-04-24 22:57:53,909:INFO:Creating Dashboard logs
2023-04-24 22:57:53,913:INFO:Model: Gradient Boosting Regressor
2023-04-24 22:57:53,963:INFO:Logged params: {'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': None, 'random_state': 123, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2023-04-24 22:57:54,070:INFO:Initializing predict_model()
2023-04-24 22:57:54,070:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B0DCCDBA90>, estimator=GradientBoostingRegressor(random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000001B0A32160E0>)
2023-04-24 22:57:54,070:INFO:Checking exceptions
2023-04-24 22:57:54,070:INFO:Preloading libraries
2023-04-24 22:57:54,326:INFO:Initializing create_model()
2023-04-24 22:57:54,329:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B0DCCDBA90>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-24 22:57:54,329:INFO:Checking exceptions
2023-04-24 22:57:54,331:INFO:Importing libraries
2023-04-24 22:57:54,331:INFO:Copying training dataset
2023-04-24 22:57:54,335:INFO:Defining folds
2023-04-24 22:57:54,335:INFO:Declaring metric variables
2023-04-24 22:57:54,336:INFO:Importing untrained model
2023-04-24 22:57:54,336:INFO:Declaring custom model
2023-04-24 22:57:54,336:INFO:Extra Trees Regressor Imported successfully
2023-04-24 22:57:54,338:INFO:Cross validation set to False
2023-04-24 22:57:54,338:INFO:Fitting Model
2023-04-24 22:57:54,460:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-04-24 22:57:54,460:INFO:create_model() successfully completed......................................
2023-04-24 22:57:54,533:INFO:Creating Dashboard logs
2023-04-24 22:57:54,533:INFO:Model: Extra Trees Regressor
2023-04-24 22:57:54,577:INFO:Logged params: {'bootstrap': False, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': 1.0, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 123, 'verbose': 0, 'warm_start': False}
2023-04-24 22:57:54,665:INFO:Initializing predict_model()
2023-04-24 22:57:54,665:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B0DCCDBA90>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000001B0A3217400>)
2023-04-24 22:57:54,665:INFO:Checking exceptions
2023-04-24 22:57:54,665:INFO:Preloading libraries
2023-04-24 22:57:54,895:INFO:Creating Dashboard logs
2023-04-24 22:57:54,911:INFO:Model: Random Forest Regressor
2023-04-24 22:57:54,956:INFO:Logged params: {'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': 1.0, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 123, 'verbose': 0, 'warm_start': False}
2023-04-24 22:57:55,136:INFO:Creating Dashboard logs
2023-04-24 22:57:55,136:INFO:Model: AdaBoost Regressor
2023-04-24 22:57:55,175:INFO:Logged params: {'base_estimator': None, 'learning_rate': 1.0, 'loss': 'linear', 'n_estimators': 50, 'random_state': 123}
2023-04-24 22:57:55,363:INFO:Creating Dashboard logs
2023-04-24 22:57:55,363:INFO:Model: K Neighbors Regressor
2023-04-24 22:57:55,404:INFO:Logged params: {'algorithm': 'auto', 'leaf_size': 30, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': -1, 'n_neighbors': 5, 'p': 2, 'weights': 'uniform'}
2023-04-24 22:57:55,594:INFO:Creating Dashboard logs
2023-04-24 22:57:55,594:INFO:Model: Elastic Net
2023-04-24 22:57:55,633:INFO:Logged params: {'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'l1_ratio': 0.5, 'max_iter': 1000, 'normalize': 'deprecated', 'positive': False, 'precompute': False, 'random_state': 123, 'selection': 'cyclic', 'tol': 0.0001, 'warm_start': False}
2023-04-24 22:57:55,837:INFO:Creating Dashboard logs
2023-04-24 22:57:55,837:INFO:Model: Bayesian Ridge
2023-04-24 22:57:55,876:INFO:Logged params: {'alpha_1': 1e-06, 'alpha_2': 1e-06, 'alpha_init': None, 'compute_score': False, 'copy_X': True, 'fit_intercept': True, 'lambda_1': 1e-06, 'lambda_2': 1e-06, 'lambda_init': None, 'n_iter': 300, 'normalize': 'deprecated', 'tol': 0.001, 'verbose': False}
2023-04-24 22:57:56,080:INFO:Creating Dashboard logs
2023-04-24 22:57:56,080:INFO:Model: Lasso Least Angle Regression
2023-04-24 22:57:56,119:INFO:Logged params: {'alpha': 1.0, 'copy_X': True, 'eps': 2.220446049250313e-16, 'fit_intercept': True, 'fit_path': True, 'jitter': None, 'max_iter': 500, 'normalize': 'deprecated', 'positive': False, 'precompute': 'auto', 'random_state': 123, 'verbose': False}
2023-04-24 22:57:56,307:INFO:Creating Dashboard logs
2023-04-24 22:57:56,307:INFO:Model: Ridge Regression
2023-04-24 22:57:56,342:INFO:Logged params: {'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'normalize': 'deprecated', 'positive': False, 'random_state': 123, 'solver': 'auto', 'tol': 0.001}
2023-04-24 22:57:56,546:INFO:Creating Dashboard logs
2023-04-24 22:57:56,546:INFO:Model: Passive Aggressive Regressor
2023-04-24 22:57:56,593:INFO:Logged params: {'C': 1.0, 'average': False, 'early_stopping': False, 'epsilon': 0.1, 'fit_intercept': True, 'loss': 'epsilon_insensitive', 'max_iter': 1000, 'n_iter_no_change': 5, 'random_state': 123, 'shuffle': True, 'tol': 0.001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2023-04-24 22:57:56,781:INFO:Creating Dashboard logs
2023-04-24 22:57:56,781:INFO:Model: Least Angle Regression
2023-04-24 22:57:56,835:INFO:Logged params: {'copy_X': True, 'eps': 2.220446049250313e-16, 'fit_intercept': True, 'fit_path': True, 'jitter': None, 'n_nonzero_coefs': 500, 'normalize': 'deprecated', 'precompute': 'auto', 'random_state': 123, 'verbose': False}
2023-04-24 22:57:57,023:INFO:Creating Dashboard logs
2023-04-24 22:57:57,023:INFO:Model: Lasso Regression
2023-04-24 22:57:57,072:INFO:Logged params: {'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'max_iter': 1000, 'normalize': 'deprecated', 'positive': False, 'precompute': False, 'random_state': 123, 'selection': 'cyclic', 'tol': 0.0001, 'warm_start': False}
2023-04-24 22:57:57,244:INFO:Creating Dashboard logs
2023-04-24 22:57:57,244:INFO:Model: Linear Regression
2023-04-24 22:57:57,306:INFO:Logged params: {'copy_X': True, 'fit_intercept': True, 'n_jobs': -1, 'normalize': 'deprecated', 'positive': False}
2023-04-24 22:57:57,479:INFO:Creating Dashboard logs
2023-04-24 22:57:57,479:INFO:Model: Light Gradient Boosting Machine
2023-04-24 22:57:57,527:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 123, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-04-24 22:57:57,715:INFO:Creating Dashboard logs
2023-04-24 22:57:57,731:INFO:Model: Orthogonal Matching Pursuit
2023-04-24 22:57:57,770:INFO:Logged params: {'fit_intercept': True, 'n_nonzero_coefs': None, 'normalize': 'deprecated', 'precompute': 'auto', 'tol': None}
2023-04-24 22:57:57,955:INFO:Creating Dashboard logs
2023-04-24 22:57:57,955:INFO:Model: Dummy Regressor
2023-04-24 22:57:57,999:INFO:Logged params: {'constant': None, 'quantile': None, 'strategy': 'mean'}
2023-04-24 22:57:58,177:INFO:Creating Dashboard logs
2023-04-24 22:57:58,177:INFO:Model: Huber Regressor
2023-04-24 22:57:58,221:INFO:Logged params: {'alpha': 0.0001, 'epsilon': 1.35, 'fit_intercept': True, 'max_iter': 100, 'tol': 1e-05, 'warm_start': False}
2023-04-24 22:57:58,421:INFO:_master_model_container: 18
2023-04-24 22:57:58,421:INFO:_display_container: 2
2023-04-24 22:57:58,421:INFO:[DecisionTreeRegressor(random_state=123), GradientBoostingRegressor(random_state=123), ExtraTreesRegressor(n_jobs=-1, random_state=123)]
2023-04-24 22:57:58,421:INFO:compare_models() successfully completed......................................
2023-04-24 23:18:12,851:INFO:PyCaret RegressionExperiment
2023-04-24 23:18:12,851:INFO:Logging name: your_experiment_name
2023-04-24 23:18:12,851:INFO:ML Usecase: MLUsecase.REGRESSION
2023-04-24 23:18:12,851:INFO:version 3.0.0
2023-04-24 23:18:12,851:INFO:Initializing setup()
2023-04-24 23:18:12,851:INFO:self.USI: 4b29
2023-04-24 23:18:12,851:INFO:self._variable_keys: {'gpu_n_jobs_param', '_available_plots', 'X_test', 'X_train', 'html_param', 'USI', 'fold_generator', 'transform_target_param', 'data', 'pipeline', 'logging_param', 'n_jobs_param', 'target_param', '_ml_usecase', 'exp_id', 'y', 'seed', 'exp_name_log', 'gpu_param', 'log_plots_param', 'fold_groups_param', 'idx', 'X', 'y_train', 'y_test', 'memory', 'fold_shuffle_param'}
2023-04-24 23:18:12,851:INFO:Checking environment
2023-04-24 23:18:12,851:INFO:python_version: 3.10.5
2023-04-24 23:18:12,851:INFO:python_build: ('tags/v3.10.5:f377153', 'Jun  6 2022 16:14:13')
2023-04-24 23:18:12,851:INFO:machine: AMD64
2023-04-24 23:18:12,851:INFO:platform: Windows-10-10.0.22000-SP0
2023-04-24 23:18:12,851:INFO:Memory: svmem(total=16497119232, available=6676922368, percent=59.5, used=9820196864, free=6676922368)
2023-04-24 23:18:12,851:INFO:Physical Core: 8
2023-04-24 23:18:12,851:INFO:Logical Core: 16
2023-04-24 23:18:12,851:INFO:Checking libraries
2023-04-24 23:18:12,851:INFO:System:
2023-04-24 23:18:12,851:INFO:    python: 3.10.5 (tags/v3.10.5:f377153, Jun  6 2022, 16:14:13) [MSC v.1929 64 bit (AMD64)]
2023-04-24 23:18:12,851:INFO:executable: C:\Users\Hashif\AppData\Local\Programs\Python\Python310\python.exe
2023-04-24 23:18:12,851:INFO:   machine: Windows-10-10.0.22000-SP0
2023-04-24 23:18:12,851:INFO:PyCaret required dependencies:
2023-04-24 23:18:12,851:INFO:                 pip: 23.1.1
2023-04-24 23:18:12,851:INFO:          setuptools: 58.1.0
2023-04-24 23:18:12,851:INFO:             pycaret: 3.0.0
2023-04-24 23:18:12,851:INFO:             IPython: 8.4.0
2023-04-24 23:18:12,851:INFO:          ipywidgets: 7.7.0
2023-04-24 23:18:12,851:INFO:                tqdm: 4.65.0
2023-04-24 23:18:12,851:INFO:               numpy: 1.23.0
2023-04-24 23:18:12,851:INFO:              pandas: 1.4.3
2023-04-24 23:18:12,851:INFO:              jinja2: 3.1.2
2023-04-24 23:18:12,851:INFO:               scipy: 1.9.3
2023-04-24 23:18:12,851:INFO:              joblib: 1.2.0
2023-04-24 23:18:12,851:INFO:             sklearn: 1.1.2
2023-04-24 23:18:12,861:INFO:                pyod: 1.0.9
2023-04-24 23:18:12,861:INFO:            imblearn: 0.10.1
2023-04-24 23:18:12,861:INFO:   category_encoders: 2.6.0
2023-04-24 23:18:12,861:INFO:            lightgbm: 3.3.5
2023-04-24 23:18:12,861:INFO:               numba: 0.56.4
2023-04-24 23:18:12,861:INFO:            requests: 2.28.1
2023-04-24 23:18:12,861:INFO:          matplotlib: 3.6.2
2023-04-24 23:18:12,861:INFO:          scikitplot: 0.3.7
2023-04-24 23:18:12,861:INFO:         yellowbrick: 1.5
2023-04-24 23:18:12,861:INFO:              plotly: 5.14.1
2023-04-24 23:18:12,861:INFO:             kaleido: 0.2.1
2023-04-24 23:18:12,861:INFO:         statsmodels: 0.13.5
2023-04-24 23:18:12,861:INFO:              sktime: 0.17.1
2023-04-24 23:18:12,861:INFO:               tbats: 1.1.3
2023-04-24 23:18:12,861:INFO:            pmdarima: 2.0.3
2023-04-24 23:18:12,861:INFO:              psutil: 5.9.1
2023-04-24 23:18:12,861:INFO:PyCaret optional dependencies:
2023-04-24 23:18:12,861:INFO:                shap: Not installed
2023-04-24 23:18:12,861:INFO:           interpret: Not installed
2023-04-24 23:18:12,861:INFO:                umap: Not installed
2023-04-24 23:18:12,861:INFO:    pandas_profiling: Not installed
2023-04-24 23:18:12,861:INFO:  explainerdashboard: Not installed
2023-04-24 23:18:12,861:INFO:             autoviz: Not installed
2023-04-24 23:18:12,861:INFO:           fairlearn: Not installed
2023-04-24 23:18:12,861:INFO:             xgboost: Not installed
2023-04-24 23:18:12,861:INFO:            catboost: Not installed
2023-04-24 23:18:12,861:INFO:              kmodes: Not installed
2023-04-24 23:18:12,861:INFO:             mlxtend: Not installed
2023-04-24 23:18:12,861:INFO:       statsforecast: Not installed
2023-04-24 23:18:12,861:INFO:        tune_sklearn: Not installed
2023-04-24 23:18:12,861:INFO:                 ray: Not installed
2023-04-24 23:18:12,861:INFO:            hyperopt: Not installed
2023-04-24 23:18:12,861:INFO:              optuna: Not installed
2023-04-24 23:18:12,861:INFO:               skopt: Not installed
2023-04-24 23:18:12,861:INFO:              mlflow: 2.3.0
2023-04-24 23:18:12,861:INFO:              gradio: Not installed
2023-04-24 23:18:12,861:INFO:             fastapi: Not installed
2023-04-24 23:18:12,861:INFO:             uvicorn: Not installed
2023-04-24 23:18:12,861:INFO:              m2cgen: Not installed
2023-04-24 23:18:12,861:INFO:           evidently: Not installed
2023-04-24 23:18:12,861:INFO:               fugue: Not installed
2023-04-24 23:18:12,861:INFO:           streamlit: Not installed
2023-04-24 23:18:12,861:INFO:             prophet: Not installed
2023-04-24 23:18:12,861:INFO:None
2023-04-24 23:18:12,861:INFO:Set up data.
2023-04-24 23:18:12,865:INFO:Set up train/test split.
2023-04-24 23:18:12,867:INFO:Set up index.
2023-04-24 23:18:12,867:INFO:Set up folding strategy.
2023-04-24 23:18:12,867:INFO:Assigning column types.
2023-04-24 23:18:12,870:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-04-24 23:18:12,870:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-04-24 23:18:12,870:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-24 23:18:12,881:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-24 23:18:12,922:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-24 23:18:12,970:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-24 23:18:12,970:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 23:18:12,970:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 23:18:12,970:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-04-24 23:18:12,970:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-24 23:18:12,985:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-24 23:18:13,032:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-24 23:18:13,079:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-24 23:18:13,079:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 23:18:13,079:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 23:18:13,079:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-04-24 23:18:13,079:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-24 23:18:13,095:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-24 23:18:13,142:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-24 23:18:13,189:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-24 23:18:13,189:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 23:18:13,189:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 23:18:13,189:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-24 23:18:13,189:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-24 23:18:13,251:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-24 23:18:13,298:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-24 23:18:13,298:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 23:18:13,298:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 23:18:13,298:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-04-24 23:18:13,298:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-24 23:18:13,361:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-24 23:18:13,408:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-24 23:18:13,408:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 23:18:13,408:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 23:18:13,424:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-24 23:18:13,487:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-24 23:18:13,518:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-24 23:18:13,518:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 23:18:13,518:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 23:18:13,518:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-04-24 23:18:13,596:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-24 23:18:13,628:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-24 23:18:13,628:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 23:18:13,628:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 23:18:13,691:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-24 23:18:13,737:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-24 23:18:13,737:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 23:18:13,737:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 23:18:13,737:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-04-24 23:18:13,800:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-24 23:18:13,847:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 23:18:13,847:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 23:18:13,920:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-24 23:18:13,968:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 23:18:13,968:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 23:18:13,968:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-04-24 23:18:14,077:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 23:18:14,077:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 23:18:14,175:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 23:18:14,175:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 23:18:14,190:INFO:Preparing preprocessing pipeline...
2023-04-24 23:18:14,190:INFO:Set up simple imputation.
2023-04-24 23:18:14,190:INFO:Set up feature normalization.
2023-04-24 23:18:14,190:INFO:Set up column name cleaning.
2023-04-24 23:18:14,207:INFO:Finished creating preprocessing pipeline.
2023-04-24 23:18:14,207:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Hashif\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['distance', 'ratings', 'wifi',
                                             'AC', 'TV', 'Queen Sized Bed',
                                             'Geyser', 'King Sized Bed',
                                             'Power backup', 'Mini Fridge'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-04-24 23:18:14,207:INFO:Creating final display dataframe.
2023-04-24 23:18:14,284:INFO:Setup _display_container:                     Description                 Value
0                    Session id                   123
1                        Target                 price
2                   Target type            Regression
3           Original data shape             (100, 11)
4        Transformed data shape             (100, 11)
5   Transformed train set shape              (80, 11)
6    Transformed test set shape              (20, 11)
7              Numeric features                    10
8                    Preprocess                  True
9               Imputation type                simple
10           Numeric imputation                  mean
11       Categorical imputation                  mode
12                    Normalize                  True
13             Normalize method                zscore
14               Fold Generator                 KFold
15                  Fold Number                    10
16                     CPU Jobs                    -1
17                      Use GPU                 False
18               Log Experiment          MlflowLogger
19              Experiment Name  your_experiment_name
20                          USI                  4b29
2023-04-24 23:18:14,390:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 23:18:14,390:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 23:18:14,525:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 23:18:14,525:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 23:18:14,525:INFO:Logging experiment in loggers
2023-04-24 23:18:14,588:INFO:SubProcess save_model() called ==================================
2023-04-24 23:18:14,604:INFO:Initializing save_model()
2023-04-24 23:18:14,604:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\Hashif\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['distance', 'ratings', 'wifi',
                                             'AC', 'TV', 'Queen Sized Bed',
                                             'Geyser', 'King Sized Bed',
                                             'Power backup', 'Mini Fridge'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), model_name=C:\Users\Hashif\AppData\Local\Temp\tmptis8da9g\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\Hashif\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['distance', 'ratings', 'wifi',
                                             'AC', 'TV', 'Queen Sized Bed',
                                             'Geyser', 'King Sized Bed',
                                             'Power backup', 'Mini Fridge'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=False, use_case=MLUsecase.REGRESSION, kwargs={})
2023-04-24 23:18:14,604:INFO:Adding model into prep_pipe
2023-04-24 23:18:14,604:WARNING:Only Model saved as it was a pipeline.
2023-04-24 23:18:14,604:INFO:C:\Users\Hashif\AppData\Local\Temp\tmptis8da9g\Transformation Pipeline.pkl saved in current working directory
2023-04-24 23:18:14,604:INFO:Pipeline(memory=FastMemory(location=C:\Users\Hashif\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['distance', 'ratings', 'wifi',
                                             'AC', 'TV', 'Queen Sized Bed',
                                             'Geyser', 'King Sized Bed',
                                             'Power backup', 'Mini Fridge'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-04-24 23:18:14,604:INFO:save_model() successfully completed......................................
2023-04-24 23:18:14,682:INFO:SubProcess save_model() end ==================================
2023-04-24 23:18:14,714:INFO:setup() successfully completed in 1.67s...............
2023-04-24 23:18:14,714:INFO:Initializing compare_models()
2023-04-24 23:18:14,714:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B0DCD99D80>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001B0DCD99D80>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-04-24 23:18:14,714:INFO:Checking exceptions
2023-04-24 23:18:14,714:INFO:Preparing display monitor
2023-04-24 23:18:14,736:INFO:Initializing Linear Regression
2023-04-24 23:18:14,736:INFO:Total runtime is 0.0 minutes
2023-04-24 23:18:14,751:INFO:SubProcess create_model() called ==================================
2023-04-24 23:18:14,751:INFO:Initializing create_model()
2023-04-24 23:18:14,751:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B0DCD99D80>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B0A2F57AF0>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 23:18:14,751:INFO:Checking exceptions
2023-04-24 23:18:14,751:INFO:Importing libraries
2023-04-24 23:18:14,751:INFO:Copying training dataset
2023-04-24 23:18:14,751:INFO:Defining folds
2023-04-24 23:18:14,757:INFO:Declaring metric variables
2023-04-24 23:18:14,760:INFO:Importing untrained model
2023-04-24 23:18:14,763:INFO:Linear Regression Imported successfully
2023-04-24 23:18:14,771:INFO:Starting cross validation
2023-04-24 23:18:14,772:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 23:18:18,038:INFO:Calculating mean and std
2023-04-24 23:18:18,038:INFO:Creating metrics dataframe
2023-04-24 23:18:18,064:INFO:Uploading results into container
2023-04-24 23:18:18,064:INFO:Uploading model into container now
2023-04-24 23:18:18,066:INFO:_master_model_container: 1
2023-04-24 23:18:18,066:INFO:_display_container: 2
2023-04-24 23:18:18,066:INFO:LinearRegression(n_jobs=-1)
2023-04-24 23:18:18,066:INFO:create_model() successfully completed......................................
2023-04-24 23:18:18,135:INFO:SubProcess create_model() end ==================================
2023-04-24 23:18:18,135:INFO:Creating metrics dataframe
2023-04-24 23:18:18,135:INFO:Initializing Lasso Regression
2023-04-24 23:18:18,150:INFO:Total runtime is 0.056896642843882246 minutes
2023-04-24 23:18:18,153:INFO:SubProcess create_model() called ==================================
2023-04-24 23:18:18,153:INFO:Initializing create_model()
2023-04-24 23:18:18,153:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B0DCD99D80>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B0A2F57AF0>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 23:18:18,153:INFO:Checking exceptions
2023-04-24 23:18:18,153:INFO:Importing libraries
2023-04-24 23:18:18,153:INFO:Copying training dataset
2023-04-24 23:18:18,156:INFO:Defining folds
2023-04-24 23:18:18,157:INFO:Declaring metric variables
2023-04-24 23:18:18,158:INFO:Importing untrained model
2023-04-24 23:18:18,166:INFO:Lasso Regression Imported successfully
2023-04-24 23:18:18,173:INFO:Starting cross validation
2023-04-24 23:18:18,174:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 23:18:20,339:INFO:Calculating mean and std
2023-04-24 23:18:20,339:INFO:Creating metrics dataframe
2023-04-24 23:18:20,355:INFO:Uploading results into container
2023-04-24 23:18:20,355:INFO:Uploading model into container now
2023-04-24 23:18:20,355:INFO:_master_model_container: 2
2023-04-24 23:18:20,355:INFO:_display_container: 2
2023-04-24 23:18:20,355:INFO:Lasso(random_state=123)
2023-04-24 23:18:20,355:INFO:create_model() successfully completed......................................
2023-04-24 23:18:20,415:INFO:SubProcess create_model() end ==================================
2023-04-24 23:18:20,415:INFO:Creating metrics dataframe
2023-04-24 23:18:20,430:INFO:Initializing Ridge Regression
2023-04-24 23:18:20,430:INFO:Total runtime is 0.09489639997482299 minutes
2023-04-24 23:18:20,441:INFO:SubProcess create_model() called ==================================
2023-04-24 23:18:20,441:INFO:Initializing create_model()
2023-04-24 23:18:20,441:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B0DCD99D80>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B0A2F57AF0>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 23:18:20,441:INFO:Checking exceptions
2023-04-24 23:18:20,441:INFO:Importing libraries
2023-04-24 23:18:20,441:INFO:Copying training dataset
2023-04-24 23:18:20,448:INFO:Defining folds
2023-04-24 23:18:20,448:INFO:Declaring metric variables
2023-04-24 23:18:20,454:INFO:Importing untrained model
2023-04-24 23:18:20,460:INFO:Ridge Regression Imported successfully
2023-04-24 23:18:20,468:INFO:Starting cross validation
2023-04-24 23:18:20,469:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 23:18:20,635:INFO:Calculating mean and std
2023-04-24 23:18:20,635:INFO:Creating metrics dataframe
2023-04-24 23:18:20,647:INFO:Uploading results into container
2023-04-24 23:18:20,647:INFO:Uploading model into container now
2023-04-24 23:18:20,647:INFO:_master_model_container: 3
2023-04-24 23:18:20,647:INFO:_display_container: 2
2023-04-24 23:18:20,647:INFO:Ridge(random_state=123)
2023-04-24 23:18:20,647:INFO:create_model() successfully completed......................................
2023-04-24 23:18:20,720:INFO:SubProcess create_model() end ==================================
2023-04-24 23:18:20,720:INFO:Creating metrics dataframe
2023-04-24 23:18:20,720:INFO:Initializing Elastic Net
2023-04-24 23:18:20,720:INFO:Total runtime is 0.09972134431203206 minutes
2023-04-24 23:18:20,732:INFO:SubProcess create_model() called ==================================
2023-04-24 23:18:20,733:INFO:Initializing create_model()
2023-04-24 23:18:20,733:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B0DCD99D80>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B0A2F57AF0>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 23:18:20,733:INFO:Checking exceptions
2023-04-24 23:18:20,733:INFO:Importing libraries
2023-04-24 23:18:20,733:INFO:Copying training dataset
2023-04-24 23:18:20,735:INFO:Defining folds
2023-04-24 23:18:20,735:INFO:Declaring metric variables
2023-04-24 23:18:20,739:INFO:Importing untrained model
2023-04-24 23:18:20,744:INFO:Elastic Net Imported successfully
2023-04-24 23:18:20,753:INFO:Starting cross validation
2023-04-24 23:18:20,754:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 23:18:20,888:INFO:Calculating mean and std
2023-04-24 23:18:20,888:INFO:Creating metrics dataframe
2023-04-24 23:18:20,903:INFO:Uploading results into container
2023-04-24 23:18:20,903:INFO:Uploading model into container now
2023-04-24 23:18:20,903:INFO:_master_model_container: 4
2023-04-24 23:18:20,903:INFO:_display_container: 2
2023-04-24 23:18:20,909:INFO:ElasticNet(random_state=123)
2023-04-24 23:18:20,909:INFO:create_model() successfully completed......................................
2023-04-24 23:18:20,968:INFO:SubProcess create_model() end ==================================
2023-04-24 23:18:20,968:INFO:Creating metrics dataframe
2023-04-24 23:18:20,985:INFO:Initializing Least Angle Regression
2023-04-24 23:18:20,985:INFO:Total runtime is 0.10414277712504068 minutes
2023-04-24 23:18:20,990:INFO:SubProcess create_model() called ==================================
2023-04-24 23:18:20,990:INFO:Initializing create_model()
2023-04-24 23:18:20,991:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B0DCD99D80>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B0A2F57AF0>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 23:18:20,991:INFO:Checking exceptions
2023-04-24 23:18:20,991:INFO:Importing libraries
2023-04-24 23:18:20,991:INFO:Copying training dataset
2023-04-24 23:18:20,995:INFO:Defining folds
2023-04-24 23:18:20,995:INFO:Declaring metric variables
2023-04-24 23:18:20,995:INFO:Importing untrained model
2023-04-24 23:18:21,001:INFO:Least Angle Regression Imported successfully
2023-04-24 23:18:21,010:INFO:Starting cross validation
2023-04-24 23:18:21,011:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 23:18:21,058:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 23:18:21,080:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 23:18:21,080:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=5.298e-07, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-04-24 23:18:21,090:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 23:18:21,105:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=6.728e-01, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-04-24 23:18:21,105:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 23:18:21,105:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=1.378e-06, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-04-24 23:18:21,121:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 23:18:21,121:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 23:18:21,136:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 23:18:21,136:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 23:18:21,136:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 23:18:21,136:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=3.037e-01, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-04-24 23:18:21,152:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 23:18:21,152:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=2.262e+00, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-04-24 23:18:21,152:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=7.734e-01, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-04-24 23:18:21,152:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=2.598e-01, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-04-24 23:18:21,180:INFO:Calculating mean and std
2023-04-24 23:18:21,184:INFO:Creating metrics dataframe
2023-04-24 23:18:21,188:INFO:Uploading results into container
2023-04-24 23:18:21,188:INFO:Uploading model into container now
2023-04-24 23:18:21,188:INFO:_master_model_container: 5
2023-04-24 23:18:21,188:INFO:_display_container: 2
2023-04-24 23:18:21,188:INFO:Lars(random_state=123)
2023-04-24 23:18:21,188:INFO:create_model() successfully completed......................................
2023-04-24 23:18:21,254:INFO:SubProcess create_model() end ==================================
2023-04-24 23:18:21,254:INFO:Creating metrics dataframe
2023-04-24 23:18:21,270:INFO:Initializing Lasso Least Angle Regression
2023-04-24 23:18:21,270:INFO:Total runtime is 0.10889395872751871 minutes
2023-04-24 23:18:21,276:INFO:SubProcess create_model() called ==================================
2023-04-24 23:18:21,276:INFO:Initializing create_model()
2023-04-24 23:18:21,276:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B0DCD99D80>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B0A2F57AF0>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 23:18:21,277:INFO:Checking exceptions
2023-04-24 23:18:21,277:INFO:Importing libraries
2023-04-24 23:18:21,277:INFO:Copying training dataset
2023-04-24 23:18:21,281:INFO:Defining folds
2023-04-24 23:18:21,281:INFO:Declaring metric variables
2023-04-24 23:18:21,286:INFO:Importing untrained model
2023-04-24 23:18:21,286:INFO:Lasso Least Angle Regression Imported successfully
2023-04-24 23:18:21,303:INFO:Starting cross validation
2023-04-24 23:18:21,304:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 23:18:21,358:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-24 23:18:21,358:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-24 23:18:21,380:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-24 23:18:21,390:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-24 23:18:21,390:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-24 23:18:21,405:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-24 23:18:21,421:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-24 23:18:21,421:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-24 23:18:21,421:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-24 23:18:21,436:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-04-24 23:18:21,436:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=2.262e+00, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-04-24 23:18:21,452:INFO:Calculating mean and std
2023-04-24 23:18:21,452:INFO:Creating metrics dataframe
2023-04-24 23:18:21,468:INFO:Uploading results into container
2023-04-24 23:18:21,468:INFO:Uploading model into container now
2023-04-24 23:18:21,468:INFO:_master_model_container: 6
2023-04-24 23:18:21,468:INFO:_display_container: 2
2023-04-24 23:18:21,471:INFO:LassoLars(random_state=123)
2023-04-24 23:18:21,471:INFO:create_model() successfully completed......................................
2023-04-24 23:18:21,525:INFO:SubProcess create_model() end ==================================
2023-04-24 23:18:21,525:INFO:Creating metrics dataframe
2023-04-24 23:18:21,539:INFO:Initializing Orthogonal Matching Pursuit
2023-04-24 23:18:21,539:INFO:Total runtime is 0.11338226795196532 minutes
2023-04-24 23:18:21,549:INFO:SubProcess create_model() called ==================================
2023-04-24 23:18:21,549:INFO:Initializing create_model()
2023-04-24 23:18:21,549:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B0DCD99D80>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B0A2F57AF0>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 23:18:21,549:INFO:Checking exceptions
2023-04-24 23:18:21,549:INFO:Importing libraries
2023-04-24 23:18:21,549:INFO:Copying training dataset
2023-04-24 23:18:21,549:INFO:Defining folds
2023-04-24 23:18:21,549:INFO:Declaring metric variables
2023-04-24 23:18:21,549:INFO:Importing untrained model
2023-04-24 23:18:21,549:INFO:Orthogonal Matching Pursuit Imported successfully
2023-04-24 23:18:21,549:INFO:Starting cross validation
2023-04-24 23:18:21,565:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 23:18:21,614:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 23:18:21,630:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 23:18:21,646:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 23:18:21,661:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 23:18:21,661:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 23:18:21,680:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 23:18:21,680:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 23:18:21,693:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 23:18:21,708:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 23:18:21,708:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-24 23:18:21,724:INFO:Calculating mean and std
2023-04-24 23:18:21,740:INFO:Creating metrics dataframe
2023-04-24 23:18:21,744:INFO:Uploading results into container
2023-04-24 23:18:21,744:INFO:Uploading model into container now
2023-04-24 23:18:21,744:INFO:_master_model_container: 7
2023-04-24 23:18:21,744:INFO:_display_container: 2
2023-04-24 23:18:21,744:INFO:OrthogonalMatchingPursuit()
2023-04-24 23:18:21,744:INFO:create_model() successfully completed......................................
2023-04-24 23:18:21,801:INFO:SubProcess create_model() end ==================================
2023-04-24 23:18:21,801:INFO:Creating metrics dataframe
2023-04-24 23:18:21,816:INFO:Initializing Bayesian Ridge
2023-04-24 23:18:21,816:INFO:Total runtime is 0.11799653768539428 minutes
2023-04-24 23:18:21,816:INFO:SubProcess create_model() called ==================================
2023-04-24 23:18:21,816:INFO:Initializing create_model()
2023-04-24 23:18:21,827:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B0DCD99D80>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B0A2F57AF0>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 23:18:21,827:INFO:Checking exceptions
2023-04-24 23:18:21,827:INFO:Importing libraries
2023-04-24 23:18:21,827:INFO:Copying training dataset
2023-04-24 23:18:21,829:INFO:Defining folds
2023-04-24 23:18:21,829:INFO:Declaring metric variables
2023-04-24 23:18:21,832:INFO:Importing untrained model
2023-04-24 23:18:21,836:INFO:Bayesian Ridge Imported successfully
2023-04-24 23:18:21,843:INFO:Starting cross validation
2023-04-24 23:18:21,844:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 23:18:22,033:INFO:Calculating mean and std
2023-04-24 23:18:22,033:INFO:Creating metrics dataframe
2023-04-24 23:18:22,044:INFO:Uploading results into container
2023-04-24 23:18:22,044:INFO:Uploading model into container now
2023-04-24 23:18:22,044:INFO:_master_model_container: 8
2023-04-24 23:18:22,044:INFO:_display_container: 2
2023-04-24 23:18:22,044:INFO:BayesianRidge()
2023-04-24 23:18:22,044:INFO:create_model() successfully completed......................................
2023-04-24 23:18:22,100:INFO:SubProcess create_model() end ==================================
2023-04-24 23:18:22,100:INFO:Creating metrics dataframe
2023-04-24 23:18:22,116:INFO:Initializing Passive Aggressive Regressor
2023-04-24 23:18:22,116:INFO:Total runtime is 0.12298423051834106 minutes
2023-04-24 23:18:22,116:INFO:SubProcess create_model() called ==================================
2023-04-24 23:18:22,116:INFO:Initializing create_model()
2023-04-24 23:18:22,116:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B0DCD99D80>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B0A2F57AF0>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 23:18:22,116:INFO:Checking exceptions
2023-04-24 23:18:22,116:INFO:Importing libraries
2023-04-24 23:18:22,116:INFO:Copying training dataset
2023-04-24 23:18:22,129:INFO:Defining folds
2023-04-24 23:18:22,130:INFO:Declaring metric variables
2023-04-24 23:18:22,135:INFO:Importing untrained model
2023-04-24 23:18:22,141:INFO:Passive Aggressive Regressor Imported successfully
2023-04-24 23:18:22,163:INFO:Starting cross validation
2023-04-24 23:18:22,166:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 23:18:22,352:INFO:Calculating mean and std
2023-04-24 23:18:22,352:INFO:Creating metrics dataframe
2023-04-24 23:18:22,368:INFO:Uploading results into container
2023-04-24 23:18:22,368:INFO:Uploading model into container now
2023-04-24 23:18:22,368:INFO:_master_model_container: 9
2023-04-24 23:18:22,368:INFO:_display_container: 2
2023-04-24 23:18:22,368:INFO:PassiveAggressiveRegressor(random_state=123)
2023-04-24 23:18:22,368:INFO:create_model() successfully completed......................................
2023-04-24 23:18:22,427:INFO:SubProcess create_model() end ==================================
2023-04-24 23:18:22,427:INFO:Creating metrics dataframe
2023-04-24 23:18:22,445:INFO:Initializing Huber Regressor
2023-04-24 23:18:22,445:INFO:Total runtime is 0.12848254839579265 minutes
2023-04-24 23:18:22,448:INFO:SubProcess create_model() called ==================================
2023-04-24 23:18:22,449:INFO:Initializing create_model()
2023-04-24 23:18:22,449:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B0DCD99D80>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B0A2F57AF0>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 23:18:22,449:INFO:Checking exceptions
2023-04-24 23:18:22,449:INFO:Importing libraries
2023-04-24 23:18:22,449:INFO:Copying training dataset
2023-04-24 23:18:22,452:INFO:Defining folds
2023-04-24 23:18:22,452:INFO:Declaring metric variables
2023-04-24 23:18:22,456:INFO:Importing untrained model
2023-04-24 23:18:22,460:INFO:Huber Regressor Imported successfully
2023-04-24 23:18:22,467:INFO:Starting cross validation
2023-04-24 23:18:22,467:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 23:18:22,633:INFO:Calculating mean and std
2023-04-24 23:18:22,633:INFO:Creating metrics dataframe
2023-04-24 23:18:22,643:INFO:Uploading results into container
2023-04-24 23:18:22,643:INFO:Uploading model into container now
2023-04-24 23:18:22,643:INFO:_master_model_container: 10
2023-04-24 23:18:22,643:INFO:_display_container: 2
2023-04-24 23:18:22,643:INFO:HuberRegressor()
2023-04-24 23:18:22,643:INFO:create_model() successfully completed......................................
2023-04-24 23:18:22,702:INFO:SubProcess create_model() end ==================================
2023-04-24 23:18:22,702:INFO:Creating metrics dataframe
2023-04-24 23:18:22,717:INFO:Initializing K Neighbors Regressor
2023-04-24 23:18:22,717:INFO:Total runtime is 0.13300711711247762 minutes
2023-04-24 23:18:22,738:INFO:SubProcess create_model() called ==================================
2023-04-24 23:18:22,739:INFO:Initializing create_model()
2023-04-24 23:18:22,739:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B0DCD99D80>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B0A2F57AF0>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 23:18:22,739:INFO:Checking exceptions
2023-04-24 23:18:22,739:INFO:Importing libraries
2023-04-24 23:18:22,739:INFO:Copying training dataset
2023-04-24 23:18:22,759:INFO:Defining folds
2023-04-24 23:18:22,759:INFO:Declaring metric variables
2023-04-24 23:18:22,764:INFO:Importing untrained model
2023-04-24 23:18:22,766:INFO:K Neighbors Regressor Imported successfully
2023-04-24 23:18:22,779:INFO:Starting cross validation
2023-04-24 23:18:22,781:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 23:18:22,977:INFO:Calculating mean and std
2023-04-24 23:18:22,977:INFO:Creating metrics dataframe
2023-04-24 23:18:22,985:INFO:Uploading results into container
2023-04-24 23:18:22,985:INFO:Uploading model into container now
2023-04-24 23:18:22,985:INFO:_master_model_container: 11
2023-04-24 23:18:22,985:INFO:_display_container: 2
2023-04-24 23:18:22,985:INFO:KNeighborsRegressor(n_jobs=-1)
2023-04-24 23:18:22,985:INFO:create_model() successfully completed......................................
2023-04-24 23:18:23,042:INFO:SubProcess create_model() end ==================================
2023-04-24 23:18:23,042:INFO:Creating metrics dataframe
2023-04-24 23:18:23,058:INFO:Initializing Decision Tree Regressor
2023-04-24 23:18:23,058:INFO:Total runtime is 0.13868690331776937 minutes
2023-04-24 23:18:23,065:INFO:SubProcess create_model() called ==================================
2023-04-24 23:18:23,065:INFO:Initializing create_model()
2023-04-24 23:18:23,065:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B0DCD99D80>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B0A2F57AF0>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 23:18:23,065:INFO:Checking exceptions
2023-04-24 23:18:23,065:INFO:Importing libraries
2023-04-24 23:18:23,065:INFO:Copying training dataset
2023-04-24 23:18:23,068:INFO:Defining folds
2023-04-24 23:18:23,069:INFO:Declaring metric variables
2023-04-24 23:18:23,072:INFO:Importing untrained model
2023-04-24 23:18:23,077:INFO:Decision Tree Regressor Imported successfully
2023-04-24 23:18:23,083:INFO:Starting cross validation
2023-04-24 23:18:23,083:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 23:18:23,235:INFO:Calculating mean and std
2023-04-24 23:18:23,235:INFO:Creating metrics dataframe
2023-04-24 23:18:23,249:INFO:Uploading results into container
2023-04-24 23:18:23,249:INFO:Uploading model into container now
2023-04-24 23:18:23,255:INFO:_master_model_container: 12
2023-04-24 23:18:23,255:INFO:_display_container: 2
2023-04-24 23:18:23,255:INFO:DecisionTreeRegressor(random_state=123)
2023-04-24 23:18:23,255:INFO:create_model() successfully completed......................................
2023-04-24 23:18:23,313:INFO:SubProcess create_model() end ==================================
2023-04-24 23:18:23,313:INFO:Creating metrics dataframe
2023-04-24 23:18:23,328:INFO:Initializing Random Forest Regressor
2023-04-24 23:18:23,328:INFO:Total runtime is 0.14319526354471843 minutes
2023-04-24 23:18:23,338:INFO:SubProcess create_model() called ==================================
2023-04-24 23:18:23,338:INFO:Initializing create_model()
2023-04-24 23:18:23,338:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B0DCD99D80>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B0A2F57AF0>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 23:18:23,338:INFO:Checking exceptions
2023-04-24 23:18:23,339:INFO:Importing libraries
2023-04-24 23:18:23,339:INFO:Copying training dataset
2023-04-24 23:18:23,342:INFO:Defining folds
2023-04-24 23:18:23,342:INFO:Declaring metric variables
2023-04-24 23:18:23,346:INFO:Importing untrained model
2023-04-24 23:18:23,350:INFO:Random Forest Regressor Imported successfully
2023-04-24 23:18:23,355:INFO:Starting cross validation
2023-04-24 23:18:23,359:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 23:18:23,866:INFO:Calculating mean and std
2023-04-24 23:18:23,866:INFO:Creating metrics dataframe
2023-04-24 23:18:23,866:INFO:Uploading results into container
2023-04-24 23:18:23,866:INFO:Uploading model into container now
2023-04-24 23:18:23,866:INFO:_master_model_container: 13
2023-04-24 23:18:23,866:INFO:_display_container: 2
2023-04-24 23:18:23,881:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2023-04-24 23:18:23,881:INFO:create_model() successfully completed......................................
2023-04-24 23:18:23,947:INFO:SubProcess create_model() end ==================================
2023-04-24 23:18:23,947:INFO:Creating metrics dataframe
2023-04-24 23:18:23,960:INFO:Initializing Extra Trees Regressor
2023-04-24 23:18:23,960:INFO:Total runtime is 0.15372397502263388 minutes
2023-04-24 23:18:23,964:INFO:SubProcess create_model() called ==================================
2023-04-24 23:18:23,964:INFO:Initializing create_model()
2023-04-24 23:18:23,964:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B0DCD99D80>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B0A2F57AF0>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 23:18:23,964:INFO:Checking exceptions
2023-04-24 23:18:23,964:INFO:Importing libraries
2023-04-24 23:18:23,964:INFO:Copying training dataset
2023-04-24 23:18:23,964:INFO:Defining folds
2023-04-24 23:18:23,964:INFO:Declaring metric variables
2023-04-24 23:18:23,972:INFO:Importing untrained model
2023-04-24 23:18:23,975:INFO:Extra Trees Regressor Imported successfully
2023-04-24 23:18:23,993:INFO:Starting cross validation
2023-04-24 23:18:23,995:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 23:18:24,504:INFO:Calculating mean and std
2023-04-24 23:18:24,504:INFO:Creating metrics dataframe
2023-04-24 23:18:24,520:INFO:Uploading results into container
2023-04-24 23:18:24,520:INFO:Uploading model into container now
2023-04-24 23:18:24,520:INFO:_master_model_container: 14
2023-04-24 23:18:24,520:INFO:_display_container: 2
2023-04-24 23:18:24,520:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-04-24 23:18:24,520:INFO:create_model() successfully completed......................................
2023-04-24 23:18:24,600:INFO:SubProcess create_model() end ==================================
2023-04-24 23:18:24,600:INFO:Creating metrics dataframe
2023-04-24 23:18:24,600:INFO:Initializing AdaBoost Regressor
2023-04-24 23:18:24,600:INFO:Total runtime is 0.16438868840535484 minutes
2023-04-24 23:18:24,613:INFO:SubProcess create_model() called ==================================
2023-04-24 23:18:24,614:INFO:Initializing create_model()
2023-04-24 23:18:24,614:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B0DCD99D80>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B0A2F57AF0>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 23:18:24,614:INFO:Checking exceptions
2023-04-24 23:18:24,614:INFO:Importing libraries
2023-04-24 23:18:24,614:INFO:Copying training dataset
2023-04-24 23:18:24,617:INFO:Defining folds
2023-04-24 23:18:24,617:INFO:Declaring metric variables
2023-04-24 23:18:24,622:INFO:Importing untrained model
2023-04-24 23:18:24,626:INFO:AdaBoost Regressor Imported successfully
2023-04-24 23:18:24,637:INFO:Starting cross validation
2023-04-24 23:18:24,638:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 23:18:24,869:INFO:Calculating mean and std
2023-04-24 23:18:24,869:INFO:Creating metrics dataframe
2023-04-24 23:18:24,886:INFO:Uploading results into container
2023-04-24 23:18:24,886:INFO:Uploading model into container now
2023-04-24 23:18:24,886:INFO:_master_model_container: 15
2023-04-24 23:18:24,886:INFO:_display_container: 2
2023-04-24 23:18:24,893:INFO:AdaBoostRegressor(random_state=123)
2023-04-24 23:18:24,893:INFO:create_model() successfully completed......................................
2023-04-24 23:18:24,952:INFO:SubProcess create_model() end ==================================
2023-04-24 23:18:24,952:INFO:Creating metrics dataframe
2023-04-24 23:18:24,970:INFO:Initializing Gradient Boosting Regressor
2023-04-24 23:18:24,970:INFO:Total runtime is 0.17055764198303225 minutes
2023-04-24 23:18:24,976:INFO:SubProcess create_model() called ==================================
2023-04-24 23:18:24,976:INFO:Initializing create_model()
2023-04-24 23:18:24,976:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B0DCD99D80>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B0A2F57AF0>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 23:18:24,976:INFO:Checking exceptions
2023-04-24 23:18:24,976:INFO:Importing libraries
2023-04-24 23:18:24,976:INFO:Copying training dataset
2023-04-24 23:18:24,980:INFO:Defining folds
2023-04-24 23:18:24,980:INFO:Declaring metric variables
2023-04-24 23:18:24,985:INFO:Importing untrained model
2023-04-24 23:18:24,997:INFO:Gradient Boosting Regressor Imported successfully
2023-04-24 23:18:25,013:INFO:Starting cross validation
2023-04-24 23:18:25,014:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 23:18:25,322:INFO:Calculating mean and std
2023-04-24 23:18:25,322:INFO:Creating metrics dataframe
2023-04-24 23:18:25,351:INFO:Uploading results into container
2023-04-24 23:18:25,351:INFO:Uploading model into container now
2023-04-24 23:18:25,352:INFO:_master_model_container: 16
2023-04-24 23:18:25,352:INFO:_display_container: 2
2023-04-24 23:18:25,352:INFO:GradientBoostingRegressor(random_state=123)
2023-04-24 23:18:25,353:INFO:create_model() successfully completed......................................
2023-04-24 23:18:25,409:INFO:SubProcess create_model() end ==================================
2023-04-24 23:18:25,409:INFO:Creating metrics dataframe
2023-04-24 23:18:25,424:INFO:Initializing Light Gradient Boosting Machine
2023-04-24 23:18:25,424:INFO:Total runtime is 0.17813345988591514 minutes
2023-04-24 23:18:25,435:INFO:SubProcess create_model() called ==================================
2023-04-24 23:18:25,435:INFO:Initializing create_model()
2023-04-24 23:18:25,435:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B0DCD99D80>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B0A2F57AF0>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 23:18:25,435:INFO:Checking exceptions
2023-04-24 23:18:25,435:INFO:Importing libraries
2023-04-24 23:18:25,435:INFO:Copying training dataset
2023-04-24 23:18:25,435:INFO:Defining folds
2023-04-24 23:18:25,435:INFO:Declaring metric variables
2023-04-24 23:18:25,435:INFO:Importing untrained model
2023-04-24 23:18:25,435:INFO:Light Gradient Boosting Machine Imported successfully
2023-04-24 23:18:25,455:INFO:Starting cross validation
2023-04-24 23:18:25,457:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 23:18:25,709:INFO:Calculating mean and std
2023-04-24 23:18:25,709:INFO:Creating metrics dataframe
2023-04-24 23:18:25,725:INFO:Uploading results into container
2023-04-24 23:18:25,725:INFO:Uploading model into container now
2023-04-24 23:18:25,725:INFO:_master_model_container: 17
2023-04-24 23:18:25,725:INFO:_display_container: 2
2023-04-24 23:18:25,725:INFO:LGBMRegressor(random_state=123)
2023-04-24 23:18:25,725:INFO:create_model() successfully completed......................................
2023-04-24 23:18:25,807:INFO:SubProcess create_model() end ==================================
2023-04-24 23:18:25,807:INFO:Creating metrics dataframe
2023-04-24 23:18:25,807:INFO:Initializing Dummy Regressor
2023-04-24 23:18:25,807:INFO:Total runtime is 0.18451208670934044 minutes
2023-04-24 23:18:25,823:INFO:SubProcess create_model() called ==================================
2023-04-24 23:18:25,823:INFO:Initializing create_model()
2023-04-24 23:18:25,823:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B0DCD99D80>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B0A2F57AF0>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 23:18:25,823:INFO:Checking exceptions
2023-04-24 23:18:25,823:INFO:Importing libraries
2023-04-24 23:18:25,823:INFO:Copying training dataset
2023-04-24 23:18:25,827:INFO:Defining folds
2023-04-24 23:18:25,827:INFO:Declaring metric variables
2023-04-24 23:18:25,831:INFO:Importing untrained model
2023-04-24 23:18:25,836:INFO:Dummy Regressor Imported successfully
2023-04-24 23:18:25,848:INFO:Starting cross validation
2023-04-24 23:18:25,850:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 23:18:26,066:INFO:Calculating mean and std
2023-04-24 23:18:26,066:INFO:Creating metrics dataframe
2023-04-24 23:18:26,087:INFO:Uploading results into container
2023-04-24 23:18:26,087:INFO:Uploading model into container now
2023-04-24 23:18:26,087:INFO:_master_model_container: 18
2023-04-24 23:18:26,087:INFO:_display_container: 2
2023-04-24 23:18:26,087:INFO:DummyRegressor()
2023-04-24 23:18:26,087:INFO:create_model() successfully completed......................................
2023-04-24 23:18:26,153:INFO:SubProcess create_model() end ==================================
2023-04-24 23:18:26,153:INFO:Creating metrics dataframe
2023-04-24 23:18:26,178:INFO:Initializing create_model()
2023-04-24 23:18:26,178:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B0DCD99D80>, estimator=GradientBoostingRegressor(random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-24 23:18:26,178:INFO:Checking exceptions
2023-04-24 23:18:26,181:INFO:Importing libraries
2023-04-24 23:18:26,181:INFO:Copying training dataset
2023-04-24 23:18:26,186:INFO:Defining folds
2023-04-24 23:18:26,186:INFO:Declaring metric variables
2023-04-24 23:18:26,187:INFO:Importing untrained model
2023-04-24 23:18:26,187:INFO:Declaring custom model
2023-04-24 23:18:26,187:INFO:Gradient Boosting Regressor Imported successfully
2023-04-24 23:18:26,188:INFO:Cross validation set to False
2023-04-24 23:18:26,188:INFO:Fitting Model
2023-04-24 23:18:26,226:INFO:GradientBoostingRegressor(random_state=123)
2023-04-24 23:18:26,226:INFO:create_model() successfully completed......................................
2023-04-24 23:18:26,309:INFO:Creating Dashboard logs
2023-04-24 23:18:26,309:INFO:Model: Gradient Boosting Regressor
2023-04-24 23:18:26,354:INFO:Logged params: {'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': None, 'random_state': 123, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2023-04-24 23:18:26,435:INFO:Initializing predict_model()
2023-04-24 23:18:26,435:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B0DCD99D80>, estimator=GradientBoostingRegressor(random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000001B0A2B07D90>)
2023-04-24 23:18:26,435:INFO:Checking exceptions
2023-04-24 23:18:26,435:INFO:Preloading libraries
2023-04-24 23:18:26,670:INFO:Creating Dashboard logs
2023-04-24 23:18:26,670:INFO:Model: Decision Tree Regressor
2023-04-24 23:18:26,711:INFO:Logged params: {'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'random_state': 123, 'splitter': 'best'}
2023-04-24 23:18:26,899:INFO:Creating Dashboard logs
2023-04-24 23:18:26,899:INFO:Model: Random Forest Regressor
2023-04-24 23:18:26,947:INFO:Logged params: {'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': 1.0, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 123, 'verbose': 0, 'warm_start': False}
2023-04-24 23:18:27,135:INFO:Creating Dashboard logs
2023-04-24 23:18:27,135:INFO:Model: Extra Trees Regressor
2023-04-24 23:18:27,195:INFO:Logged params: {'bootstrap': False, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': 1.0, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 123, 'verbose': 0, 'warm_start': False}
2023-04-24 23:18:27,390:INFO:Creating Dashboard logs
2023-04-24 23:18:27,390:INFO:Model: AdaBoost Regressor
2023-04-24 23:18:27,440:INFO:Logged params: {'base_estimator': None, 'learning_rate': 1.0, 'loss': 'linear', 'n_estimators': 50, 'random_state': 123}
2023-04-24 23:18:27,613:INFO:Creating Dashboard logs
2023-04-24 23:18:27,628:INFO:Model: K Neighbors Regressor
2023-04-24 23:18:27,683:INFO:Logged params: {'algorithm': 'auto', 'leaf_size': 30, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': -1, 'n_neighbors': 5, 'p': 2, 'weights': 'uniform'}
2023-04-24 23:18:27,856:INFO:Creating Dashboard logs
2023-04-24 23:18:27,871:INFO:Model: Elastic Net
2023-04-24 23:18:27,910:INFO:Logged params: {'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'l1_ratio': 0.5, 'max_iter': 1000, 'normalize': 'deprecated', 'positive': False, 'precompute': False, 'random_state': 123, 'selection': 'cyclic', 'tol': 0.0001, 'warm_start': False}
2023-04-24 23:18:28,099:INFO:Creating Dashboard logs
2023-04-24 23:18:28,099:INFO:Model: Light Gradient Boosting Machine
2023-04-24 23:18:28,132:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 123, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-04-24 23:18:28,336:INFO:Creating Dashboard logs
2023-04-24 23:18:28,336:INFO:Model: Bayesian Ridge
2023-04-24 23:18:28,375:INFO:Logged params: {'alpha_1': 1e-06, 'alpha_2': 1e-06, 'alpha_init': None, 'compute_score': False, 'copy_X': True, 'fit_intercept': True, 'lambda_1': 1e-06, 'lambda_2': 1e-06, 'lambda_init': None, 'n_iter': 300, 'normalize': 'deprecated', 'tol': 0.001, 'verbose': False}
2023-04-24 23:18:28,564:INFO:Creating Dashboard logs
2023-04-24 23:18:28,579:INFO:Model: Lasso Least Angle Regression
2023-04-24 23:18:28,622:INFO:Logged params: {'alpha': 1.0, 'copy_X': True, 'eps': 2.220446049250313e-16, 'fit_intercept': True, 'fit_path': True, 'jitter': None, 'max_iter': 500, 'normalize': 'deprecated', 'positive': False, 'precompute': 'auto', 'random_state': 123, 'verbose': False}
2023-04-24 23:18:28,814:INFO:Creating Dashboard logs
2023-04-24 23:18:28,814:INFO:Model: Ridge Regression
2023-04-24 23:18:28,860:INFO:Logged params: {'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'normalize': 'deprecated', 'positive': False, 'random_state': 123, 'solver': 'auto', 'tol': 0.001}
2023-04-24 23:18:29,027:INFO:Creating Dashboard logs
2023-04-24 23:18:29,043:INFO:Model: Lasso Regression
2023-04-24 23:18:29,084:INFO:Logged params: {'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'max_iter': 1000, 'normalize': 'deprecated', 'positive': False, 'precompute': False, 'random_state': 123, 'selection': 'cyclic', 'tol': 0.0001, 'warm_start': False}
2023-04-24 23:18:29,270:INFO:Creating Dashboard logs
2023-04-24 23:18:29,270:INFO:Model: Linear Regression
2023-04-24 23:18:29,312:INFO:Logged params: {'copy_X': True, 'fit_intercept': True, 'n_jobs': -1, 'normalize': 'deprecated', 'positive': False}
2023-04-24 23:18:29,501:INFO:Creating Dashboard logs
2023-04-24 23:18:29,501:INFO:Model: Least Angle Regression
2023-04-24 23:18:29,556:INFO:Logged params: {'copy_X': True, 'eps': 2.220446049250313e-16, 'fit_intercept': True, 'fit_path': True, 'jitter': None, 'n_nonzero_coefs': 500, 'normalize': 'deprecated', 'precompute': 'auto', 'random_state': 123, 'verbose': False}
2023-04-24 23:18:29,729:INFO:Creating Dashboard logs
2023-04-24 23:18:29,744:INFO:Model: Orthogonal Matching Pursuit
2023-04-24 23:18:29,794:INFO:Logged params: {'fit_intercept': True, 'n_nonzero_coefs': None, 'normalize': 'deprecated', 'precompute': 'auto', 'tol': None}
2023-04-24 23:18:29,980:INFO:Creating Dashboard logs
2023-04-24 23:18:29,980:INFO:Model: Passive Aggressive Regressor
2023-04-24 23:18:30,042:INFO:Logged params: {'C': 1.0, 'average': False, 'early_stopping': False, 'epsilon': 0.1, 'fit_intercept': True, 'loss': 'epsilon_insensitive', 'max_iter': 1000, 'n_iter_no_change': 5, 'random_state': 123, 'shuffle': True, 'tol': 0.001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2023-04-24 23:18:30,214:INFO:Creating Dashboard logs
2023-04-24 23:18:30,230:INFO:Model: Dummy Regressor
2023-04-24 23:18:30,269:INFO:Logged params: {'constant': None, 'quantile': None, 'strategy': 'mean'}
2023-04-24 23:18:30,442:INFO:Creating Dashboard logs
2023-04-24 23:18:30,442:INFO:Model: Huber Regressor
2023-04-24 23:18:30,495:INFO:Logged params: {'alpha': 0.0001, 'epsilon': 1.35, 'fit_intercept': True, 'max_iter': 100, 'tol': 1e-05, 'warm_start': False}
2023-04-24 23:18:30,696:INFO:_master_model_container: 18
2023-04-24 23:18:30,696:INFO:_display_container: 2
2023-04-24 23:18:30,705:INFO:GradientBoostingRegressor(random_state=123)
2023-04-24 23:18:30,705:INFO:compare_models() successfully completed......................................
2023-04-25 12:24:58,046:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 12:24:58,046:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 12:24:58,046:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 12:24:58,046:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 12:24:59,909:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-04-25 14:52:41,760:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 14:52:41,760:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 14:52:41,760:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 14:52:41,760:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 14:52:43,344:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-04-25 14:56:37,206:INFO:PyCaret RegressionExperiment
2023-04-25 14:56:37,206:INFO:Logging name: price_recom_partial
2023-04-25 14:56:37,206:INFO:ML Usecase: MLUsecase.REGRESSION
2023-04-25 14:56:37,206:INFO:version 3.0.0
2023-04-25 14:56:37,206:INFO:Initializing setup()
2023-04-25 14:56:37,206:INFO:self.USI: 7e37
2023-04-25 14:56:37,206:INFO:self._variable_keys: {'logging_param', 'seed', 'log_plots_param', 'exp_name_log', 'exp_id', 'y', 'gpu_param', 'X_test', 'X', '_available_plots', 'y_train', 'target_param', 'n_jobs_param', 'USI', 'pipeline', 'html_param', 'idx', 'X_train', '_ml_usecase', 'fold_groups_param', 'gpu_n_jobs_param', 'fold_generator', 'memory', 'data', 'fold_shuffle_param', 'y_test', 'transform_target_param'}
2023-04-25 14:56:37,206:INFO:Checking environment
2023-04-25 14:56:37,206:INFO:python_version: 3.10.5
2023-04-25 14:56:37,206:INFO:python_build: ('tags/v3.10.5:f377153', 'Jun  6 2022 16:14:13')
2023-04-25 14:56:37,206:INFO:machine: AMD64
2023-04-25 14:56:37,206:INFO:platform: Windows-10-10.0.22000-SP0
2023-04-25 14:56:37,206:INFO:Memory: svmem(total=16497119232, available=8927547392, percent=45.9, used=7569571840, free=8927547392)
2023-04-25 14:56:37,206:INFO:Physical Core: 8
2023-04-25 14:56:37,206:INFO:Logical Core: 16
2023-04-25 14:56:37,206:INFO:Checking libraries
2023-04-25 14:56:37,206:INFO:System:
2023-04-25 14:56:37,206:INFO:    python: 3.10.5 (tags/v3.10.5:f377153, Jun  6 2022, 16:14:13) [MSC v.1929 64 bit (AMD64)]
2023-04-25 14:56:37,206:INFO:executable: C:\Users\Hashif\AppData\Local\Programs\Python\Python310\python.exe
2023-04-25 14:56:37,206:INFO:   machine: Windows-10-10.0.22000-SP0
2023-04-25 14:56:37,206:INFO:PyCaret required dependencies:
2023-04-25 14:56:37,206:INFO:                 pip: 23.1.1
2023-04-25 14:56:37,206:INFO:          setuptools: 58.1.0
2023-04-25 14:56:37,206:INFO:             pycaret: 3.0.0
2023-04-25 14:56:37,206:INFO:             IPython: 8.4.0
2023-04-25 14:56:37,206:INFO:          ipywidgets: 7.7.0
2023-04-25 14:56:37,206:INFO:                tqdm: 4.65.0
2023-04-25 14:56:37,206:INFO:               numpy: 1.23.0
2023-04-25 14:56:37,206:INFO:              pandas: 1.4.3
2023-04-25 14:56:37,206:INFO:              jinja2: 3.1.2
2023-04-25 14:56:37,206:INFO:               scipy: 1.9.3
2023-04-25 14:56:37,206:INFO:              joblib: 1.2.0
2023-04-25 14:56:37,206:INFO:             sklearn: 1.1.2
2023-04-25 14:56:37,206:INFO:                pyod: 1.0.9
2023-04-25 14:56:37,206:INFO:            imblearn: 0.10.1
2023-04-25 14:56:37,206:INFO:   category_encoders: 2.6.0
2023-04-25 14:56:37,206:INFO:            lightgbm: 3.3.5
2023-04-25 14:56:37,206:INFO:               numba: 0.56.4
2023-04-25 14:56:37,206:INFO:            requests: 2.28.1
2023-04-25 14:56:37,206:INFO:          matplotlib: 3.6.2
2023-04-25 14:56:37,206:INFO:          scikitplot: 0.3.7
2023-04-25 14:56:37,206:INFO:         yellowbrick: 1.5
2023-04-25 14:56:37,206:INFO:              plotly: 5.14.1
2023-04-25 14:56:37,206:INFO:             kaleido: 0.2.1
2023-04-25 14:56:37,206:INFO:         statsmodels: 0.13.5
2023-04-25 14:56:37,206:INFO:              sktime: 0.17.1
2023-04-25 14:56:37,206:INFO:               tbats: 1.1.3
2023-04-25 14:56:37,206:INFO:            pmdarima: 2.0.3
2023-04-25 14:56:37,206:INFO:              psutil: 5.9.1
2023-04-25 14:56:37,206:INFO:PyCaret optional dependencies:
2023-04-25 14:56:37,232:INFO:                shap: Not installed
2023-04-25 14:56:37,232:INFO:           interpret: Not installed
2023-04-25 14:56:37,232:INFO:                umap: Not installed
2023-04-25 14:56:37,232:INFO:    pandas_profiling: Not installed
2023-04-25 14:56:37,232:INFO:  explainerdashboard: Not installed
2023-04-25 14:56:37,232:INFO:             autoviz: Not installed
2023-04-25 14:56:37,232:INFO:           fairlearn: Not installed
2023-04-25 14:56:37,232:INFO:             xgboost: Not installed
2023-04-25 14:56:37,232:INFO:            catboost: Not installed
2023-04-25 14:56:37,232:INFO:              kmodes: Not installed
2023-04-25 14:56:37,232:INFO:             mlxtend: Not installed
2023-04-25 14:56:37,232:INFO:       statsforecast: Not installed
2023-04-25 14:56:37,232:INFO:        tune_sklearn: Not installed
2023-04-25 14:56:37,232:INFO:                 ray: Not installed
2023-04-25 14:56:37,232:INFO:            hyperopt: Not installed
2023-04-25 14:56:37,232:INFO:              optuna: Not installed
2023-04-25 14:56:37,232:INFO:               skopt: Not installed
2023-04-25 14:56:37,232:INFO:              mlflow: 2.3.0
2023-04-25 14:56:37,232:INFO:              gradio: Not installed
2023-04-25 14:56:37,232:INFO:             fastapi: Not installed
2023-04-25 14:56:37,232:INFO:             uvicorn: Not installed
2023-04-25 14:56:37,232:INFO:              m2cgen: Not installed
2023-04-25 14:56:37,232:INFO:           evidently: Not installed
2023-04-25 14:56:37,232:INFO:               fugue: Not installed
2023-04-25 14:56:37,232:INFO:           streamlit: Not installed
2023-04-25 14:56:37,232:INFO:             prophet: Not installed
2023-04-25 14:56:37,232:INFO:None
2023-04-25 14:56:37,240:INFO:Set up GPU usage.
2023-04-25 14:56:37,240:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 14:56:37,240:WARNING:cuML is outdated or not found. Required version is >=22.10, got 3.0.0
2023-04-25 14:56:37,240:INFO:Set up data.
2023-04-25 14:56:37,248:INFO:Set up train/test split.
2023-04-25 14:56:37,255:INFO:Set up index.
2023-04-25 14:56:37,255:INFO:Set up folding strategy.
2023-04-25 14:56:37,255:INFO:Assigning column types.
2023-04-25 14:56:37,255:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-04-25 14:56:37,255:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 14:56:37,255:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-04-25 14:56:37,255:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 14:56:37,268:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-25 14:56:37,268:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 14:56:37,277:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-25 14:56:37,277:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 14:56:37,434:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-25 14:56:37,434:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 14:56:37,545:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-25 14:56:37,545:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 14:56:37,545:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 14:56:37,545:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 14:56:38,855:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 14:56:38,855:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 14:56:38,855:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-04-25 14:56:38,855:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 14:56:38,870:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-25 14:56:38,870:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 14:56:38,886:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-25 14:56:38,886:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 14:56:39,036:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-25 14:56:39,036:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 14:56:39,152:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-25 14:56:39,152:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 14:56:39,152:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 14:56:39,152:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 14:56:39,262:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 14:56:39,262:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-04-25 14:56:39,262:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 14:56:39,262:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 14:56:39,278:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-25 14:56:39,278:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 14:56:39,293:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-25 14:56:39,293:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 14:56:39,437:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-25 14:56:39,437:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 14:56:39,545:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-25 14:56:39,545:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 14:56:39,545:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 14:56:39,545:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 14:56:39,607:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 14:56:39,607:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 14:56:39,607:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 14:56:39,623:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-25 14:56:39,623:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 14:56:39,639:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-25 14:56:39,639:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 14:56:39,797:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-25 14:56:39,797:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 14:56:39,906:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-25 14:56:39,906:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 14:56:39,906:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 14:56:39,906:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 14:56:39,969:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 14:56:39,969:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-04-25 14:56:39,969:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 14:56:39,969:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 14:56:39,985:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 14:56:40,000:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-25 14:56:40,000:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 14:56:40,157:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-25 14:56:40,157:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 14:56:40,268:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-25 14:56:40,268:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 14:56:40,268:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 14:56:40,268:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 14:56:40,361:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 14:56:40,361:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 14:56:40,361:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 14:56:40,377:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 14:56:40,393:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-25 14:56:40,393:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 14:56:40,550:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-25 14:56:40,550:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 14:56:40,644:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-25 14:56:40,644:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 14:56:40,644:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 14:56:40,660:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 14:56:40,722:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 14:56:40,722:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-04-25 14:56:40,722:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 14:56:40,722:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 14:56:40,739:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 14:56:40,754:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 14:56:40,911:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-25 14:56:40,911:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 14:56:41,020:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-25 14:56:41,020:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 14:56:41,020:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 14:56:41,020:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 14:56:41,099:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 14:56:41,099:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 14:56:41,099:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 14:56:41,115:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 14:56:41,130:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 14:56:41,272:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-25 14:56:41,272:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 14:56:41,382:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-25 14:56:41,382:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 14:56:41,382:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 14:56:41,382:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 14:56:41,445:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 14:56:41,445:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-04-25 14:56:41,445:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 14:56:41,461:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 14:56:41,461:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 14:56:41,476:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 14:56:41,633:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-25 14:56:41,633:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 14:56:41,743:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 14:56:41,743:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 14:56:41,743:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 14:56:41,841:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 14:56:41,841:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 14:56:41,841:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 14:56:41,853:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 14:56:41,869:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 14:56:42,026:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-25 14:56:42,026:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 14:56:42,120:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 14:56:42,120:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 14:56:42,120:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 14:56:42,199:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 14:56:42,207:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-04-25 14:56:42,207:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 14:56:42,207:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 14:56:42,222:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 14:56:42,222:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 14:56:42,380:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 14:56:42,489:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 14:56:42,489:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 14:56:42,489:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 14:56:42,552:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 14:56:42,552:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 14:56:42,552:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 14:56:42,568:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 14:56:42,583:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 14:56:42,724:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 14:56:42,843:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 14:56:42,843:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 14:56:42,843:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 14:56:42,928:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 14:56:42,944:INFO:Preparing preprocessing pipeline...
2023-04-25 14:56:42,944:INFO:Set up target transformation.
2023-04-25 14:56:42,944:INFO:Set up simple imputation.
2023-04-25 14:56:42,944:INFO:Set up encoding of categorical features.
2023-04-25 14:56:42,960:INFO:Set up custom pipeline.
2023-04-25 15:09:34,483:INFO:PyCaret RegressionExperiment
2023-04-25 15:09:34,483:INFO:Logging name: price_recom_partial
2023-04-25 15:09:34,483:INFO:ML Usecase: MLUsecase.REGRESSION
2023-04-25 15:09:34,483:INFO:version 3.0.0
2023-04-25 15:09:34,483:INFO:Initializing setup()
2023-04-25 15:09:34,483:INFO:self.USI: 416f
2023-04-25 15:09:34,483:INFO:self._variable_keys: {'logging_param', 'seed', 'log_plots_param', 'exp_name_log', 'exp_id', 'y', 'gpu_param', 'X_test', 'X', '_available_plots', 'y_train', 'target_param', 'n_jobs_param', 'USI', 'pipeline', 'html_param', 'idx', 'X_train', '_ml_usecase', 'fold_groups_param', 'gpu_n_jobs_param', 'fold_generator', 'memory', 'data', 'fold_shuffle_param', 'y_test', 'transform_target_param'}
2023-04-25 15:09:34,483:INFO:Checking environment
2023-04-25 15:09:34,483:INFO:python_version: 3.10.5
2023-04-25 15:09:34,483:INFO:python_build: ('tags/v3.10.5:f377153', 'Jun  6 2022 16:14:13')
2023-04-25 15:09:34,483:INFO:machine: AMD64
2023-04-25 15:09:34,483:INFO:platform: Windows-10-10.0.22000-SP0
2023-04-25 15:09:34,483:INFO:Memory: svmem(total=16497119232, available=8576671744, percent=48.0, used=7920447488, free=8576671744)
2023-04-25 15:09:34,483:INFO:Physical Core: 8
2023-04-25 15:09:34,483:INFO:Logical Core: 16
2023-04-25 15:09:34,483:INFO:Checking libraries
2023-04-25 15:09:34,483:INFO:System:
2023-04-25 15:09:34,483:INFO:    python: 3.10.5 (tags/v3.10.5:f377153, Jun  6 2022, 16:14:13) [MSC v.1929 64 bit (AMD64)]
2023-04-25 15:09:34,483:INFO:executable: C:\Users\Hashif\AppData\Local\Programs\Python\Python310\python.exe
2023-04-25 15:09:34,483:INFO:   machine: Windows-10-10.0.22000-SP0
2023-04-25 15:09:34,483:INFO:PyCaret required dependencies:
2023-04-25 15:09:34,483:INFO:                 pip: 23.1.1
2023-04-25 15:09:34,483:INFO:          setuptools: 58.1.0
2023-04-25 15:09:34,483:INFO:             pycaret: 3.0.0
2023-04-25 15:09:34,483:INFO:             IPython: 8.4.0
2023-04-25 15:09:34,483:INFO:          ipywidgets: 7.7.0
2023-04-25 15:09:34,483:INFO:                tqdm: 4.65.0
2023-04-25 15:09:34,483:INFO:               numpy: 1.23.0
2023-04-25 15:09:34,483:INFO:              pandas: 1.4.3
2023-04-25 15:09:34,483:INFO:              jinja2: 3.1.2
2023-04-25 15:09:34,483:INFO:               scipy: 1.9.3
2023-04-25 15:09:34,483:INFO:              joblib: 1.2.0
2023-04-25 15:09:34,483:INFO:             sklearn: 1.1.2
2023-04-25 15:09:34,483:INFO:                pyod: 1.0.9
2023-04-25 15:09:34,483:INFO:            imblearn: 0.10.1
2023-04-25 15:09:34,483:INFO:   category_encoders: 2.6.0
2023-04-25 15:09:34,483:INFO:            lightgbm: 3.3.5
2023-04-25 15:09:34,483:INFO:               numba: 0.56.4
2023-04-25 15:09:34,483:INFO:            requests: 2.28.1
2023-04-25 15:09:34,483:INFO:          matplotlib: 3.6.2
2023-04-25 15:09:34,483:INFO:          scikitplot: 0.3.7
2023-04-25 15:09:34,483:INFO:         yellowbrick: 1.5
2023-04-25 15:09:34,483:INFO:              plotly: 5.14.1
2023-04-25 15:09:34,483:INFO:             kaleido: 0.2.1
2023-04-25 15:09:34,483:INFO:         statsmodels: 0.13.5
2023-04-25 15:09:34,483:INFO:              sktime: 0.17.1
2023-04-25 15:09:34,483:INFO:               tbats: 1.1.3
2023-04-25 15:09:34,483:INFO:            pmdarima: 2.0.3
2023-04-25 15:09:34,483:INFO:              psutil: 5.9.1
2023-04-25 15:09:34,483:INFO:PyCaret optional dependencies:
2023-04-25 15:09:34,483:INFO:                shap: Not installed
2023-04-25 15:09:34,483:INFO:           interpret: Not installed
2023-04-25 15:09:34,483:INFO:                umap: Not installed
2023-04-25 15:09:34,483:INFO:    pandas_profiling: Not installed
2023-04-25 15:09:34,483:INFO:  explainerdashboard: Not installed
2023-04-25 15:09:34,483:INFO:             autoviz: Not installed
2023-04-25 15:09:34,483:INFO:           fairlearn: Not installed
2023-04-25 15:09:34,483:INFO:             xgboost: Not installed
2023-04-25 15:09:34,483:INFO:            catboost: Not installed
2023-04-25 15:09:34,483:INFO:              kmodes: Not installed
2023-04-25 15:09:34,483:INFO:             mlxtend: Not installed
2023-04-25 15:09:34,483:INFO:       statsforecast: Not installed
2023-04-25 15:09:34,483:INFO:        tune_sklearn: Not installed
2023-04-25 15:09:34,483:INFO:                 ray: Not installed
2023-04-25 15:09:34,483:INFO:            hyperopt: Not installed
2023-04-25 15:09:34,483:INFO:              optuna: Not installed
2023-04-25 15:09:34,483:INFO:               skopt: Not installed
2023-04-25 15:09:34,483:INFO:              mlflow: 2.3.0
2023-04-25 15:09:34,483:INFO:              gradio: Not installed
2023-04-25 15:09:34,483:INFO:             fastapi: Not installed
2023-04-25 15:09:34,483:INFO:             uvicorn: Not installed
2023-04-25 15:09:34,483:INFO:              m2cgen: Not installed
2023-04-25 15:09:34,483:INFO:           evidently: Not installed
2023-04-25 15:09:34,483:INFO:               fugue: Not installed
2023-04-25 15:09:34,483:INFO:           streamlit: Not installed
2023-04-25 15:09:34,483:INFO:             prophet: Not installed
2023-04-25 15:09:34,483:INFO:None
2023-04-25 15:09:34,483:INFO:Set up GPU usage.
2023-04-25 15:09:34,483:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 15:09:34,483:WARNING:cuML is outdated or not found. Required version is >=22.10, got 3.0.0
2023-04-25 15:09:34,483:INFO:Set up data.
2023-04-25 15:09:34,499:INFO:Set up train/test split.
2023-04-25 15:09:34,507:INFO:Set up index.
2023-04-25 15:09:34,507:INFO:Set up folding strategy.
2023-04-25 15:09:34,507:INFO:Assigning column types.
2023-04-25 15:09:34,510:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-04-25 15:09:34,515:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 15:09:34,515:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-04-25 15:09:34,515:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 15:09:34,518:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-25 15:09:34,518:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 15:09:34,532:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-25 15:09:34,532:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 15:09:34,666:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-25 15:09:34,666:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 15:09:34,775:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-25 15:09:34,775:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 15:09:34,775:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 15:09:34,775:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 15:09:34,854:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 15:09:34,854:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 15:09:34,854:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-04-25 15:09:34,854:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 15:09:34,870:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-25 15:09:34,870:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 15:09:34,885:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-25 15:09:34,885:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 15:09:35,057:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-25 15:09:35,057:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 15:09:35,167:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-25 15:09:35,167:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 15:09:35,167:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 15:09:35,167:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 15:09:35,246:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 15:09:35,246:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-04-25 15:09:35,246:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 15:09:35,246:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 15:09:35,261:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-25 15:09:35,261:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 15:09:35,277:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-25 15:09:35,277:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 15:09:35,418:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-25 15:09:35,418:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 15:09:35,539:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-25 15:09:35,539:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 15:09:35,539:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 15:09:35,555:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 15:09:35,634:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 15:09:35,634:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 15:09:35,634:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 15:09:35,649:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-25 15:09:35,649:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 15:09:35,665:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-25 15:09:35,665:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 15:09:35,812:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-25 15:09:35,812:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 15:09:35,943:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-25 15:09:35,943:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 15:09:35,943:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 15:09:35,943:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 15:09:36,033:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 15:09:36,033:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-04-25 15:09:36,033:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 15:09:36,033:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 15:09:36,049:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 15:09:36,064:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-25 15:09:36,064:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 15:09:36,221:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-25 15:09:36,221:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 15:09:36,335:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-25 15:09:36,335:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 15:09:36,335:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 15:09:36,335:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 15:09:36,424:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 15:09:36,425:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 15:09:36,425:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 15:09:36,439:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 15:09:36,439:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-25 15:09:36,453:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 15:09:36,600:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-25 15:09:36,600:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 15:09:36,727:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-25 15:09:36,727:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 15:09:36,727:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 15:09:36,735:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 15:09:36,800:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 15:09:36,800:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-04-25 15:09:36,800:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 15:09:36,800:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 15:09:36,821:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 15:09:36,835:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 15:09:36,982:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-25 15:09:36,982:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 15:09:37,092:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-25 15:09:37,092:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 15:09:37,092:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 15:09:37,098:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 15:09:37,182:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 15:09:37,182:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 15:09:37,182:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 15:09:37,196:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 15:09:37,216:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 15:09:37,362:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-25 15:09:37,362:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 15:09:37,474:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-25 15:09:37,474:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 15:09:37,474:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 15:09:37,474:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 15:09:37,543:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 15:09:37,543:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-04-25 15:09:37,543:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 15:09:37,543:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 15:09:37,559:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 15:09:37,571:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 15:09:37,723:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-25 15:09:37,723:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 15:09:37,827:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 15:09:37,827:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 15:09:37,827:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 15:09:37,898:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 15:09:37,898:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 15:09:37,898:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 15:09:37,917:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 15:09:37,933:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 15:09:38,084:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-25 15:09:38,084:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 15:09:38,188:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 15:09:38,188:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 15:09:38,192:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 15:09:38,257:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 15:09:38,257:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-04-25 15:09:38,257:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 15:09:38,257:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 15:09:38,267:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 15:09:38,281:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 15:09:38,439:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 15:09:38,541:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 15:09:38,549:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 15:09:38,549:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 15:09:38,612:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 15:09:38,612:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 15:09:38,612:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 15:09:38,638:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 15:09:38,654:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 15:09:38,799:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 15:09:38,910:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 15:09:38,910:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 15:09:38,910:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 15:09:38,979:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 15:09:38,985:INFO:Set up custom pipeline.
2023-04-25 20:31:47,354:INFO:PyCaret RegressionExperiment
2023-04-25 20:31:47,354:INFO:Logging name: price_recom_partial
2023-04-25 20:31:47,354:INFO:ML Usecase: MLUsecase.REGRESSION
2023-04-25 20:31:47,354:INFO:version 3.0.0
2023-04-25 20:31:47,354:INFO:Initializing setup()
2023-04-25 20:31:47,354:INFO:self.USI: 73d3
2023-04-25 20:31:47,354:INFO:self._variable_keys: {'logging_param', 'seed', 'log_plots_param', 'exp_name_log', 'exp_id', 'y', 'gpu_param', 'X_test', 'X', '_available_plots', 'y_train', 'target_param', 'n_jobs_param', 'USI', 'pipeline', 'html_param', 'idx', 'X_train', '_ml_usecase', 'fold_groups_param', 'gpu_n_jobs_param', 'fold_generator', 'memory', 'data', 'fold_shuffle_param', 'y_test', 'transform_target_param'}
2023-04-25 20:31:47,354:INFO:Checking environment
2023-04-25 20:31:47,354:INFO:python_version: 3.10.5
2023-04-25 20:31:47,354:INFO:python_build: ('tags/v3.10.5:f377153', 'Jun  6 2022 16:14:13')
2023-04-25 20:31:47,354:INFO:machine: AMD64
2023-04-25 20:31:47,354:INFO:platform: Windows-10-10.0.22000-SP0
2023-04-25 20:31:47,354:INFO:Memory: svmem(total=16497119232, available=8701521920, percent=47.3, used=7795597312, free=8701521920)
2023-04-25 20:31:47,354:INFO:Physical Core: 8
2023-04-25 20:31:47,354:INFO:Logical Core: 16
2023-04-25 20:31:47,354:INFO:Checking libraries
2023-04-25 20:31:47,354:INFO:System:
2023-04-25 20:31:47,354:INFO:    python: 3.10.5 (tags/v3.10.5:f377153, Jun  6 2022, 16:14:13) [MSC v.1929 64 bit (AMD64)]
2023-04-25 20:31:47,354:INFO:executable: C:\Users\Hashif\AppData\Local\Programs\Python\Python310\python.exe
2023-04-25 20:31:47,354:INFO:   machine: Windows-10-10.0.22000-SP0
2023-04-25 20:31:47,354:INFO:PyCaret required dependencies:
2023-04-25 20:31:47,354:INFO:                 pip: 23.1.1
2023-04-25 20:31:47,354:INFO:          setuptools: 58.1.0
2023-04-25 20:31:47,354:INFO:             pycaret: 3.0.0
2023-04-25 20:31:47,354:INFO:             IPython: 8.4.0
2023-04-25 20:31:47,354:INFO:          ipywidgets: 7.7.0
2023-04-25 20:31:47,354:INFO:                tqdm: 4.65.0
2023-04-25 20:31:47,354:INFO:               numpy: 1.23.0
2023-04-25 20:31:47,354:INFO:              pandas: 1.4.3
2023-04-25 20:31:47,354:INFO:              jinja2: 3.1.2
2023-04-25 20:31:47,354:INFO:               scipy: 1.9.3
2023-04-25 20:31:47,354:INFO:              joblib: 1.2.0
2023-04-25 20:31:47,354:INFO:             sklearn: 1.1.2
2023-04-25 20:31:47,354:INFO:                pyod: 1.0.9
2023-04-25 20:31:47,354:INFO:            imblearn: 0.10.1
2023-04-25 20:31:47,354:INFO:   category_encoders: 2.6.0
2023-04-25 20:31:47,354:INFO:            lightgbm: 3.3.5
2023-04-25 20:31:47,354:INFO:               numba: 0.56.4
2023-04-25 20:31:47,362:INFO:            requests: 2.28.1
2023-04-25 20:31:47,362:INFO:          matplotlib: 3.6.2
2023-04-25 20:31:47,362:INFO:          scikitplot: 0.3.7
2023-04-25 20:31:47,362:INFO:         yellowbrick: 1.5
2023-04-25 20:31:47,362:INFO:              plotly: 5.14.1
2023-04-25 20:31:47,362:INFO:             kaleido: 0.2.1
2023-04-25 20:31:47,362:INFO:         statsmodels: 0.13.5
2023-04-25 20:31:47,362:INFO:              sktime: 0.17.1
2023-04-25 20:31:47,362:INFO:               tbats: 1.1.3
2023-04-25 20:31:47,362:INFO:            pmdarima: 2.0.3
2023-04-25 20:31:47,362:INFO:              psutil: 5.9.1
2023-04-25 20:31:47,362:INFO:PyCaret optional dependencies:
2023-04-25 20:31:47,362:INFO:                shap: Not installed
2023-04-25 20:31:47,362:INFO:           interpret: Not installed
2023-04-25 20:31:47,362:INFO:                umap: Not installed
2023-04-25 20:31:47,362:INFO:    pandas_profiling: Not installed
2023-04-25 20:31:47,362:INFO:  explainerdashboard: Not installed
2023-04-25 20:31:47,362:INFO:             autoviz: Not installed
2023-04-25 20:31:47,362:INFO:           fairlearn: Not installed
2023-04-25 20:31:47,362:INFO:             xgboost: Not installed
2023-04-25 20:31:47,362:INFO:            catboost: Not installed
2023-04-25 20:31:47,362:INFO:              kmodes: Not installed
2023-04-25 20:31:47,362:INFO:             mlxtend: Not installed
2023-04-25 20:31:47,362:INFO:       statsforecast: Not installed
2023-04-25 20:31:47,362:INFO:        tune_sklearn: Not installed
2023-04-25 20:31:47,362:INFO:                 ray: Not installed
2023-04-25 20:31:47,362:INFO:            hyperopt: Not installed
2023-04-25 20:31:47,362:INFO:              optuna: Not installed
2023-04-25 20:31:47,362:INFO:               skopt: Not installed
2023-04-25 20:31:47,362:INFO:              mlflow: 2.3.0
2023-04-25 20:31:47,362:INFO:              gradio: Not installed
2023-04-25 20:31:47,362:INFO:             fastapi: Not installed
2023-04-25 20:31:47,362:INFO:             uvicorn: Not installed
2023-04-25 20:31:47,362:INFO:              m2cgen: Not installed
2023-04-25 20:31:47,362:INFO:           evidently: Not installed
2023-04-25 20:31:47,362:INFO:               fugue: Not installed
2023-04-25 20:31:47,362:INFO:           streamlit: Not installed
2023-04-25 20:31:47,362:INFO:             prophet: Not installed
2023-04-25 20:31:47,362:INFO:None
2023-04-25 20:31:47,362:INFO:Set up GPU usage.
2023-04-25 20:31:47,362:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:31:47,362:WARNING:cuML is outdated or not found. Required version is >=22.10, got 3.0.0
2023-04-25 20:31:47,362:INFO:Set up data.
2023-04-25 20:31:47,362:INFO:Set up train/test split.
2023-04-25 20:31:47,362:INFO:Set up index.
2023-04-25 20:31:47,362:INFO:Set up folding strategy.
2023-04-25 20:31:47,362:INFO:Assigning column types.
2023-04-25 20:31:47,362:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-04-25 20:31:47,362:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:31:47,362:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-04-25 20:31:47,378:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:31:47,378:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-25 20:31:47,378:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:31:47,394:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-25 20:31:47,394:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:31:47,472:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-25 20:31:47,472:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:31:47,551:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-25 20:31:47,551:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:31:47,551:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:31:47,551:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 20:31:47,661:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 20:31:47,661:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:31:47,661:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-04-25 20:31:47,661:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:31:47,661:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-25 20:31:47,661:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:31:47,676:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-25 20:31:47,676:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:31:47,786:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-25 20:31:47,786:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:31:47,880:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-25 20:31:47,880:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:31:47,880:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:31:47,880:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 20:31:47,956:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 20:31:47,956:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-04-25 20:31:47,956:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:31:47,956:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:31:47,972:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-25 20:31:47,972:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:31:47,977:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-25 20:31:47,977:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:31:48,089:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-25 20:31:48,089:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:31:48,149:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-25 20:31:48,149:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:31:48,149:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:31:48,149:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 20:31:48,211:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 20:31:48,211:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:31:48,211:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:31:48,227:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-25 20:31:48,227:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:31:48,244:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-25 20:31:48,244:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:31:48,349:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-25 20:31:48,349:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:31:48,428:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-25 20:31:48,428:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:31:48,428:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:31:48,432:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 20:31:48,504:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 20:31:48,504:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-04-25 20:31:48,509:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:31:48,509:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:31:48,518:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:31:48,525:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-25 20:31:48,525:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:31:48,629:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-25 20:31:48,637:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:31:48,719:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-25 20:31:48,719:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:31:48,719:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:31:48,719:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 20:31:48,829:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 20:31:48,829:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:31:48,830:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:31:48,844:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:31:48,854:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-25 20:31:48,854:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:31:48,967:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-25 20:31:48,967:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:31:49,056:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-25 20:31:49,056:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:31:49,057:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:31:49,057:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 20:31:49,135:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 20:31:49,135:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-04-25 20:31:49,140:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:31:49,140:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:31:49,149:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:31:49,159:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:31:49,264:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-25 20:31:49,264:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:31:49,327:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-25 20:31:49,327:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:31:49,327:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:31:49,327:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 20:31:49,390:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 20:31:49,390:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:31:49,390:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:31:49,405:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:31:49,421:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:31:49,515:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-25 20:31:49,515:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:31:49,594:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-25 20:31:49,594:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:31:49,594:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:31:49,594:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 20:31:49,676:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 20:31:49,676:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-04-25 20:31:49,676:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:31:49,676:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:31:49,687:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:31:49,697:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:31:49,797:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-25 20:31:49,797:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:31:49,870:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:31:49,870:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:31:49,870:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 20:31:49,917:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 20:31:49,917:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:31:49,917:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:31:49,933:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:31:49,933:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:31:50,045:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-25 20:31:50,045:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:31:50,135:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:31:50,135:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:31:50,135:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 20:31:50,190:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 20:31:50,190:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-04-25 20:31:50,190:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:31:50,206:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:31:50,206:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:31:50,222:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:31:50,315:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:31:50,394:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:31:50,394:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:31:50,394:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 20:31:50,447:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 20:31:50,447:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:31:50,447:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:31:50,457:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:31:50,464:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:31:50,574:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:31:50,637:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:31:50,652:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:31:50,652:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 20:31:50,699:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 20:31:50,699:INFO:Set up custom pipeline.
2023-04-25 20:31:50,731:INFO:Finished creating preprocessing pipeline.
2023-04-25 20:31:50,840:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Hashif\AppData\Local\Temp\joblib),
         steps=[('custom_step',
                 TransformerWrapper(transformer=FeatureUnion(n_jobs=1,
                                                             transformer_list=[('pipeline-1',
                                                                                Pipeline(steps=[('functiontransformer',
                                                                                                 FunctionTransformer(func=operator.itemgetter('amneties'))),
                                                                                                ('tfidfvectorizer',
                                                                                                 TfidfVectorizer(max_features=10000,
                                                                                                                 ngram_range=(1,
                                                                                                                              2),
                                                                                                                 token_pattern='\\w+'))])),
                                                                               ('pipeline-2',
                                                                                Pipeline(steps=[('functiontransformer-1',
                                                                                                 FunctionTransformer(func=operator.itemgetter(['ratings', 'distance']))),
                                                                                                ('functiontransformer-2',
                                                                                                 FunctionTransformer(func=<function to_records at 0x000001A1EF0B92D0>)),
                                                                                                ('dictvectorizer',
                                                                                                 DictVectorizer())]))])))])
2023-04-25 20:31:50,840:INFO:Creating final display dataframe.
2023-04-25 20:31:50,950:INFO:Setup _display_container:                    Description       Value
0                   Session id          42
1                       Target       price
2                  Target type  Regression
3          Original data shape      (2, 4)
4       Transformed data shape     (2, 12)
5  Transformed train set shape     (1, 12)
6   Transformed test set shape     (1, 12)
7             Numeric features           2
8         Categorical features           1
2023-04-25 20:31:50,966:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:31:50,966:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:31:50,973:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:31:50,979:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:31:51,065:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:31:51,144:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:31:51,144:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:31:51,144:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 20:31:51,191:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 20:31:51,191:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:31:51,191:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:31:51,207:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:31:51,222:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:31:51,316:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:31:51,396:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:31:51,396:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:31:51,396:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 20:31:51,442:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 20:31:51,442:INFO:Logging experiment in loggers
2023-04-25 20:31:51,846:INFO:SubProcess save_model() called ==================================
2023-04-25 20:31:52,019:INFO:Initializing save_model()
2023-04-25 20:31:52,019:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\Hashif\AppData\Local\Temp\joblib),
         steps=[('custom_step',
                 TransformerWrapper(transformer=FeatureUnion(n_jobs=1,
                                                             transformer_list=[('pipeline-1',
                                                                                Pipeline(steps=[('functiontransformer',
                                                                                                 FunctionTransformer(func=operator.itemgetter('amneties'))),
                                                                                                ('tfidfvectorizer',
                                                                                                 TfidfVectorizer(max_features=10000,
                                                                                                                 ngram_range=(1,
                                                                                                                              2),
                                                                                                                 token_pattern='\\w+'))])),
                                                                               ('pipeline-2',
                                                                                Pipeline(steps=[('functiontransformer-1',
                                                                                                 FunctionTransformer(func=operator.itemgetter(['ratings', 'distance']))),
                                                                                                ('functiontransformer-2',
                                                                                                 FunctionTransformer(func=<function to_records at 0x000001A1EF0B92D0>)),
                                                                                                ('dictvectorizer',
                                                                                                 DictVectorizer())]))])))]), model_name=C:\Users\Hashif\AppData\Local\Temp\tmpropny9hj\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\Hashif\AppData\Local\Temp\joblib),
         steps=[('custom_step',
                 TransformerWrapper(transformer=FeatureUnion(n_jobs=1,
                                                             transformer_list=[('pipeline-1',
                                                                                Pipeline(steps=[('functiontransformer',
                                                                                                 FunctionTransformer(func=operator.itemgetter('amneties'))),
                                                                                                ('tfidfvectorizer',
                                                                                                 TfidfVectorizer(max_features=10000,
                                                                                                                 ngram_range=(1,
                                                                                                                              2),
                                                                                                                 token_pattern='\\w+'))])),
                                                                               ('pipeline-2',
                                                                                Pipeline(steps=[('functiontransformer-1',
                                                                                                 FunctionTransformer(func=operator.itemgetter(['ratings', 'distance']))),
                                                                                                ('functiontransformer-2',
                                                                                                 FunctionTransformer(func=<function to_records at 0x000001A1EF0B92D0>)),
                                                                                                ('dictvectorizer',
                                                                                                 DictVectorizer())]))])))]), verbose=False, use_case=MLUsecase.REGRESSION, kwargs={})
2023-04-25 20:31:52,019:INFO:Adding model into prep_pipe
2023-04-25 20:31:52,019:WARNING:Only Model saved as it was a pipeline.
2023-04-25 20:31:52,019:INFO:C:\Users\Hashif\AppData\Local\Temp\tmpropny9hj\Transformation Pipeline.pkl saved in current working directory
2023-04-25 20:31:52,113:INFO:Pipeline(memory=FastMemory(location=C:\Users\Hashif\AppData\Local\Temp\joblib),
         steps=[('custom_step',
                 TransformerWrapper(transformer=FeatureUnion(n_jobs=1,
                                                             transformer_list=[('pipeline-1',
                                                                                Pipeline(steps=[('functiontransformer',
                                                                                                 FunctionTransformer(func=operator.itemgetter('amneties'))),
                                                                                                ('tfidfvectorizer',
                                                                                                 TfidfVectorizer(max_features=10000,
                                                                                                                 ngram_range=(1,
                                                                                                                              2),
                                                                                                                 token_pattern='\\w+'))])),
                                                                               ('pipeline-2',
                                                                                Pipeline(steps=[('functiontransformer-1',
                                                                                                 FunctionTransformer(func=operator.itemgetter(['ratings', 'distance']))),
                                                                                                ('functiontransformer-2',
                                                                                                 FunctionTransformer(func=<function to_records at 0x000001A1EF0B92D0>)),
                                                                                                ('dictvectorizer',
                                                                                                 DictVectorizer())]))])))])
2023-04-25 20:31:52,113:INFO:save_model() successfully completed......................................
2023-04-25 20:31:52,254:INFO:SubProcess save_model() end ==================================
2023-04-25 20:31:52,317:INFO:setup() successfully completed in 4.11s...............
2023-04-25 20:31:52,317:INFO:Initializing compare_models()
2023-04-25 20:31:52,317:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A1868BC7F0>, include=['lr', 'lasso', 'ridge', 'en', 'huber', 'knn', 'ada', 'gbr'], fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001A1868BC7F0>, 'include': ['lr', 'lasso', 'ridge', 'en', 'huber', 'knn', 'ada', 'gbr'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-04-25 20:31:52,317:INFO:Checking exceptions
2023-04-25 20:31:52,317:INFO:Preparing display monitor
2023-04-25 20:31:52,382:INFO:Initializing Linear Regression
2023-04-25 20:31:52,382:INFO:Total runtime is 0.0 minutes
2023-04-25 20:31:52,382:INFO:SubProcess create_model() called ==================================
2023-04-25 20:31:52,390:INFO:Initializing create_model()
2023-04-25 20:31:52,390:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A1868BC7F0>, estimator=lr, fold=ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A186E132B0>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 20:31:52,390:INFO:Checking exceptions
2023-04-25 20:31:52,390:INFO:Importing libraries
2023-04-25 20:31:52,390:INFO:Copying training dataset
2023-04-25 20:31:52,390:INFO:Defining folds
2023-04-25 20:31:52,390:INFO:Declaring metric variables
2023-04-25 20:31:52,398:INFO:Importing untrained model
2023-04-25 20:31:52,398:INFO:Linear Regression Imported successfully
2023-04-25 20:31:52,418:INFO:Starting cross validation
2023-04-25 20:31:52,431:INFO:Cross validating with ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), n_jobs=1
2023-04-25 20:31:52,431:WARNING:create_model() for lr raised an exception or returned all 0.0, trying without fit_kwargs:
2023-04-25 20:31:52,486:WARNING:Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 862, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in cross_validate
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1085, in __call__
    if self.dispatch_one_batch(iterator):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 873, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in <genexpr>
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1622, in split
    for train, test in self._iter_indices(X, y, groups):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1730, in _iter_indices
    n_train, n_test = _validate_shuffle_split(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 2126, in _validate_shuffle_split
    raise ValueError(
ValueError: With n_samples=1, test_size=None and train_size=0.9230769230769231, the resulting train set will be empty. Adjust any of the aforementioned parameters.

2023-04-25 20:31:52,486:INFO:Initializing create_model()
2023-04-25 20:31:52,486:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A1868BC7F0>, estimator=lr, fold=ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A186E132B0>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 20:31:52,486:INFO:Checking exceptions
2023-04-25 20:31:52,486:INFO:Importing libraries
2023-04-25 20:31:52,486:INFO:Copying training dataset
2023-04-25 20:31:52,486:INFO:Defining folds
2023-04-25 20:31:52,486:INFO:Declaring metric variables
2023-04-25 20:31:52,501:INFO:Importing untrained model
2023-04-25 20:31:52,506:INFO:Linear Regression Imported successfully
2023-04-25 20:31:52,511:INFO:Starting cross validation
2023-04-25 20:31:52,511:INFO:Cross validating with ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), n_jobs=1
2023-04-25 20:31:52,521:ERROR:create_model() for lr raised an exception or returned all 0.0:
2023-04-25 20:31:52,521:ERROR:Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 862, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in cross_validate
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1085, in __call__
    if self.dispatch_one_batch(iterator):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 873, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in <genexpr>
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1622, in split
    for train, test in self._iter_indices(X, y, groups):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1730, in _iter_indices
    n_train, n_test = _validate_shuffle_split(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 2126, in _validate_shuffle_split
    raise ValueError(
ValueError: With n_samples=1, test_size=None and train_size=0.9230769230769231, the resulting train set will be empty. Adjust any of the aforementioned parameters.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 862, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 810, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in cross_validate
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1085, in __call__
    if self.dispatch_one_batch(iterator):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 873, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in <genexpr>
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1622, in split
    for train, test in self._iter_indices(X, y, groups):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1730, in _iter_indices
    n_train, n_test = _validate_shuffle_split(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 2126, in _validate_shuffle_split
    raise ValueError(
ValueError: With n_samples=1, test_size=None and train_size=0.9230769230769231, the resulting train set will be empty. Adjust any of the aforementioned parameters.

2023-04-25 20:31:52,551:INFO:Initializing Lasso Regression
2023-04-25 20:31:52,551:INFO:Total runtime is 0.0028110782305399576 minutes
2023-04-25 20:31:52,551:INFO:SubProcess create_model() called ==================================
2023-04-25 20:31:52,551:INFO:Initializing create_model()
2023-04-25 20:31:52,551:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A1868BC7F0>, estimator=lasso, fold=ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A186E132B0>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 20:31:52,551:INFO:Checking exceptions
2023-04-25 20:31:52,551:INFO:Importing libraries
2023-04-25 20:31:52,551:INFO:Copying training dataset
2023-04-25 20:31:52,565:INFO:Defining folds
2023-04-25 20:31:52,565:INFO:Declaring metric variables
2023-04-25 20:31:52,570:INFO:Importing untrained model
2023-04-25 20:31:52,576:INFO:Lasso Regression Imported successfully
2023-04-25 20:31:52,584:INFO:Starting cross validation
2023-04-25 20:31:52,591:INFO:Cross validating with ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), n_jobs=1
2023-04-25 20:31:52,591:WARNING:create_model() for lasso raised an exception or returned all 0.0, trying without fit_kwargs:
2023-04-25 20:31:52,591:WARNING:Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 862, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in cross_validate
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1085, in __call__
    if self.dispatch_one_batch(iterator):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 873, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in <genexpr>
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1622, in split
    for train, test in self._iter_indices(X, y, groups):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1730, in _iter_indices
    n_train, n_test = _validate_shuffle_split(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 2126, in _validate_shuffle_split
    raise ValueError(
ValueError: With n_samples=1, test_size=None and train_size=0.9230769230769231, the resulting train set will be empty. Adjust any of the aforementioned parameters.

2023-04-25 20:31:52,591:INFO:Initializing create_model()
2023-04-25 20:31:52,591:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A1868BC7F0>, estimator=lasso, fold=ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A186E132B0>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 20:31:52,591:INFO:Checking exceptions
2023-04-25 20:31:52,591:INFO:Importing libraries
2023-04-25 20:31:52,591:INFO:Copying training dataset
2023-04-25 20:31:52,597:INFO:Defining folds
2023-04-25 20:31:52,597:INFO:Declaring metric variables
2023-04-25 20:31:52,604:INFO:Importing untrained model
2023-04-25 20:31:52,604:INFO:Lasso Regression Imported successfully
2023-04-25 20:31:52,618:INFO:Starting cross validation
2023-04-25 20:31:52,618:INFO:Cross validating with ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), n_jobs=1
2023-04-25 20:31:52,623:ERROR:create_model() for lasso raised an exception or returned all 0.0:
2023-04-25 20:31:52,623:ERROR:Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 862, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in cross_validate
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1085, in __call__
    if self.dispatch_one_batch(iterator):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 873, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in <genexpr>
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1622, in split
    for train, test in self._iter_indices(X, y, groups):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1730, in _iter_indices
    n_train, n_test = _validate_shuffle_split(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 2126, in _validate_shuffle_split
    raise ValueError(
ValueError: With n_samples=1, test_size=None and train_size=0.9230769230769231, the resulting train set will be empty. Adjust any of the aforementioned parameters.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 862, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 810, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in cross_validate
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1085, in __call__
    if self.dispatch_one_batch(iterator):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 873, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in <genexpr>
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1622, in split
    for train, test in self._iter_indices(X, y, groups):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1730, in _iter_indices
    n_train, n_test = _validate_shuffle_split(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 2126, in _validate_shuffle_split
    raise ValueError(
ValueError: With n_samples=1, test_size=None and train_size=0.9230769230769231, the resulting train set will be empty. Adjust any of the aforementioned parameters.

2023-04-25 20:31:52,657:INFO:Initializing Ridge Regression
2023-04-25 20:31:52,657:INFO:Total runtime is 0.004580159982045491 minutes
2023-04-25 20:31:52,664:INFO:SubProcess create_model() called ==================================
2023-04-25 20:31:52,664:INFO:Initializing create_model()
2023-04-25 20:31:52,664:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A1868BC7F0>, estimator=ridge, fold=ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A186E132B0>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 20:31:52,664:INFO:Checking exceptions
2023-04-25 20:31:52,664:INFO:Importing libraries
2023-04-25 20:31:52,664:INFO:Copying training dataset
2023-04-25 20:31:52,672:INFO:Defining folds
2023-04-25 20:31:52,672:INFO:Declaring metric variables
2023-04-25 20:31:52,680:INFO:Importing untrained model
2023-04-25 20:31:52,680:INFO:Ridge Regression Imported successfully
2023-04-25 20:31:52,700:INFO:Starting cross validation
2023-04-25 20:31:52,701:INFO:Cross validating with ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), n_jobs=1
2023-04-25 20:31:52,701:WARNING:create_model() for ridge raised an exception or returned all 0.0, trying without fit_kwargs:
2023-04-25 20:31:52,701:WARNING:Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 862, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in cross_validate
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1085, in __call__
    if self.dispatch_one_batch(iterator):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 873, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in <genexpr>
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1622, in split
    for train, test in self._iter_indices(X, y, groups):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1730, in _iter_indices
    n_train, n_test = _validate_shuffle_split(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 2126, in _validate_shuffle_split
    raise ValueError(
ValueError: With n_samples=1, test_size=None and train_size=0.9230769230769231, the resulting train set will be empty. Adjust any of the aforementioned parameters.

2023-04-25 20:31:52,701:INFO:Initializing create_model()
2023-04-25 20:31:52,701:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A1868BC7F0>, estimator=ridge, fold=ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A186E132B0>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 20:31:52,701:INFO:Checking exceptions
2023-04-25 20:31:52,701:INFO:Importing libraries
2023-04-25 20:31:52,701:INFO:Copying training dataset
2023-04-25 20:31:52,709:INFO:Defining folds
2023-04-25 20:31:52,709:INFO:Declaring metric variables
2023-04-25 20:31:52,715:INFO:Importing untrained model
2023-04-25 20:31:52,722:INFO:Ridge Regression Imported successfully
2023-04-25 20:31:52,729:INFO:Starting cross validation
2023-04-25 20:31:52,729:INFO:Cross validating with ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), n_jobs=1
2023-04-25 20:31:52,729:ERROR:create_model() for ridge raised an exception or returned all 0.0:
2023-04-25 20:31:52,738:ERROR:Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 862, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in cross_validate
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1085, in __call__
    if self.dispatch_one_batch(iterator):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 873, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in <genexpr>
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1622, in split
    for train, test in self._iter_indices(X, y, groups):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1730, in _iter_indices
    n_train, n_test = _validate_shuffle_split(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 2126, in _validate_shuffle_split
    raise ValueError(
ValueError: With n_samples=1, test_size=None and train_size=0.9230769230769231, the resulting train set will be empty. Adjust any of the aforementioned parameters.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 862, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 810, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in cross_validate
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1085, in __call__
    if self.dispatch_one_batch(iterator):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 873, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in <genexpr>
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1622, in split
    for train, test in self._iter_indices(X, y, groups):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1730, in _iter_indices
    n_train, n_test = _validate_shuffle_split(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 2126, in _validate_shuffle_split
    raise ValueError(
ValueError: With n_samples=1, test_size=None and train_size=0.9230769230769231, the resulting train set will be empty. Adjust any of the aforementioned parameters.

2023-04-25 20:31:52,766:INFO:Initializing Elastic Net
2023-04-25 20:31:52,766:INFO:Total runtime is 0.006395924091339111 minutes
2023-04-25 20:31:52,772:INFO:SubProcess create_model() called ==================================
2023-04-25 20:31:52,772:INFO:Initializing create_model()
2023-04-25 20:31:52,772:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A1868BC7F0>, estimator=en, fold=ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A186E132B0>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 20:31:52,772:INFO:Checking exceptions
2023-04-25 20:31:52,772:INFO:Importing libraries
2023-04-25 20:31:52,772:INFO:Copying training dataset
2023-04-25 20:31:52,778:INFO:Defining folds
2023-04-25 20:31:52,778:INFO:Declaring metric variables
2023-04-25 20:31:52,784:INFO:Importing untrained model
2023-04-25 20:31:52,784:INFO:Elastic Net Imported successfully
2023-04-25 20:31:52,799:INFO:Starting cross validation
2023-04-25 20:31:52,799:INFO:Cross validating with ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), n_jobs=1
2023-04-25 20:31:52,799:WARNING:create_model() for en raised an exception or returned all 0.0, trying without fit_kwargs:
2023-04-25 20:31:52,804:WARNING:Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 862, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in cross_validate
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1085, in __call__
    if self.dispatch_one_batch(iterator):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 873, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in <genexpr>
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1622, in split
    for train, test in self._iter_indices(X, y, groups):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1730, in _iter_indices
    n_train, n_test = _validate_shuffle_split(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 2126, in _validate_shuffle_split
    raise ValueError(
ValueError: With n_samples=1, test_size=None and train_size=0.9230769230769231, the resulting train set will be empty. Adjust any of the aforementioned parameters.

2023-04-25 20:31:52,804:INFO:Initializing create_model()
2023-04-25 20:31:52,804:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A1868BC7F0>, estimator=en, fold=ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A186E132B0>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 20:31:52,804:INFO:Checking exceptions
2023-04-25 20:31:52,804:INFO:Importing libraries
2023-04-25 20:31:52,804:INFO:Copying training dataset
2023-04-25 20:31:52,805:INFO:Defining folds
2023-04-25 20:31:52,805:INFO:Declaring metric variables
2023-04-25 20:31:52,813:INFO:Importing untrained model
2023-04-25 20:31:52,819:INFO:Elastic Net Imported successfully
2023-04-25 20:31:52,826:INFO:Starting cross validation
2023-04-25 20:31:52,831:INFO:Cross validating with ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), n_jobs=1
2023-04-25 20:31:52,831:ERROR:create_model() for en raised an exception or returned all 0.0:
2023-04-25 20:31:52,835:ERROR:Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 862, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in cross_validate
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1085, in __call__
    if self.dispatch_one_batch(iterator):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 873, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in <genexpr>
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1622, in split
    for train, test in self._iter_indices(X, y, groups):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1730, in _iter_indices
    n_train, n_test = _validate_shuffle_split(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 2126, in _validate_shuffle_split
    raise ValueError(
ValueError: With n_samples=1, test_size=None and train_size=0.9230769230769231, the resulting train set will be empty. Adjust any of the aforementioned parameters.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 862, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 810, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in cross_validate
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1085, in __call__
    if self.dispatch_one_batch(iterator):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 873, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in <genexpr>
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1622, in split
    for train, test in self._iter_indices(X, y, groups):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1730, in _iter_indices
    n_train, n_test = _validate_shuffle_split(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 2126, in _validate_shuffle_split
    raise ValueError(
ValueError: With n_samples=1, test_size=None and train_size=0.9230769230769231, the resulting train set will be empty. Adjust any of the aforementioned parameters.

2023-04-25 20:31:52,863:INFO:Initializing Huber Regressor
2023-04-25 20:31:52,863:INFO:Total runtime is 0.008018759886423745 minutes
2023-04-25 20:31:52,863:INFO:SubProcess create_model() called ==================================
2023-04-25 20:31:52,872:INFO:Initializing create_model()
2023-04-25 20:31:52,872:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A1868BC7F0>, estimator=huber, fold=ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A186E132B0>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 20:31:52,872:INFO:Checking exceptions
2023-04-25 20:31:52,872:INFO:Importing libraries
2023-04-25 20:31:52,872:INFO:Copying training dataset
2023-04-25 20:31:52,875:INFO:Defining folds
2023-04-25 20:31:52,875:INFO:Declaring metric variables
2023-04-25 20:31:52,881:INFO:Importing untrained model
2023-04-25 20:31:52,881:INFO:Huber Regressor Imported successfully
2023-04-25 20:31:52,897:INFO:Starting cross validation
2023-04-25 20:31:52,897:INFO:Cross validating with ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), n_jobs=1
2023-04-25 20:31:52,897:WARNING:create_model() for huber raised an exception or returned all 0.0, trying without fit_kwargs:
2023-04-25 20:31:52,901:WARNING:Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 862, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in cross_validate
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1085, in __call__
    if self.dispatch_one_batch(iterator):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 873, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in <genexpr>
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1622, in split
    for train, test in self._iter_indices(X, y, groups):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1730, in _iter_indices
    n_train, n_test = _validate_shuffle_split(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 2126, in _validate_shuffle_split
    raise ValueError(
ValueError: With n_samples=1, test_size=None and train_size=0.9230769230769231, the resulting train set will be empty. Adjust any of the aforementioned parameters.

2023-04-25 20:31:52,902:INFO:Initializing create_model()
2023-04-25 20:31:52,902:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A1868BC7F0>, estimator=huber, fold=ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A186E132B0>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 20:31:52,902:INFO:Checking exceptions
2023-04-25 20:31:52,902:INFO:Importing libraries
2023-04-25 20:31:52,902:INFO:Copying training dataset
2023-04-25 20:31:52,902:INFO:Defining folds
2023-04-25 20:31:52,902:INFO:Declaring metric variables
2023-04-25 20:31:52,910:INFO:Importing untrained model
2023-04-25 20:31:52,910:INFO:Huber Regressor Imported successfully
2023-04-25 20:31:52,926:INFO:Starting cross validation
2023-04-25 20:31:52,929:INFO:Cross validating with ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), n_jobs=1
2023-04-25 20:31:52,930:ERROR:create_model() for huber raised an exception or returned all 0.0:
2023-04-25 20:31:52,930:ERROR:Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 862, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in cross_validate
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1085, in __call__
    if self.dispatch_one_batch(iterator):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 873, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in <genexpr>
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1622, in split
    for train, test in self._iter_indices(X, y, groups):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1730, in _iter_indices
    n_train, n_test = _validate_shuffle_split(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 2126, in _validate_shuffle_split
    raise ValueError(
ValueError: With n_samples=1, test_size=None and train_size=0.9230769230769231, the resulting train set will be empty. Adjust any of the aforementioned parameters.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 862, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 810, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in cross_validate
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1085, in __call__
    if self.dispatch_one_batch(iterator):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 873, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in <genexpr>
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1622, in split
    for train, test in self._iter_indices(X, y, groups):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1730, in _iter_indices
    n_train, n_test = _validate_shuffle_split(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 2126, in _validate_shuffle_split
    raise ValueError(
ValueError: With n_samples=1, test_size=None and train_size=0.9230769230769231, the resulting train set will be empty. Adjust any of the aforementioned parameters.

2023-04-25 20:31:52,960:INFO:Initializing K Neighbors Regressor
2023-04-25 20:31:52,960:INFO:Total runtime is 0.009633286794026691 minutes
2023-04-25 20:31:52,960:INFO:SubProcess create_model() called ==================================
2023-04-25 20:31:52,960:INFO:Initializing create_model()
2023-04-25 20:31:52,960:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A1868BC7F0>, estimator=knn, fold=ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A186E132B0>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 20:31:52,960:INFO:Checking exceptions
2023-04-25 20:31:52,968:INFO:Importing libraries
2023-04-25 20:31:52,968:INFO:Copying training dataset
2023-04-25 20:31:52,972:INFO:Defining folds
2023-04-25 20:31:52,972:INFO:Declaring metric variables
2023-04-25 20:31:52,976:INFO:Importing untrained model
2023-04-25 20:31:52,979:INFO:K Neighbors Regressor Imported successfully
2023-04-25 20:31:52,987:INFO:Starting cross validation
2023-04-25 20:31:52,995:INFO:Cross validating with ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), n_jobs=1
2023-04-25 20:31:52,995:WARNING:create_model() for knn raised an exception or returned all 0.0, trying without fit_kwargs:
2023-04-25 20:31:52,995:WARNING:Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 862, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in cross_validate
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1085, in __call__
    if self.dispatch_one_batch(iterator):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 873, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in <genexpr>
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1622, in split
    for train, test in self._iter_indices(X, y, groups):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1730, in _iter_indices
    n_train, n_test = _validate_shuffle_split(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 2126, in _validate_shuffle_split
    raise ValueError(
ValueError: With n_samples=1, test_size=None and train_size=0.9230769230769231, the resulting train set will be empty. Adjust any of the aforementioned parameters.

2023-04-25 20:31:52,995:INFO:Initializing create_model()
2023-04-25 20:31:52,995:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A1868BC7F0>, estimator=knn, fold=ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A186E132B0>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 20:31:52,995:INFO:Checking exceptions
2023-04-25 20:31:52,995:INFO:Importing libraries
2023-04-25 20:31:52,995:INFO:Copying training dataset
2023-04-25 20:31:52,995:INFO:Defining folds
2023-04-25 20:31:52,995:INFO:Declaring metric variables
2023-04-25 20:31:53,007:INFO:Importing untrained model
2023-04-25 20:31:53,007:INFO:K Neighbors Regressor Imported successfully
2023-04-25 20:31:53,020:INFO:Starting cross validation
2023-04-25 20:31:53,020:INFO:Cross validating with ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), n_jobs=1
2023-04-25 20:31:53,020:ERROR:create_model() for knn raised an exception or returned all 0.0:
2023-04-25 20:31:53,025:ERROR:Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 862, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in cross_validate
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1085, in __call__
    if self.dispatch_one_batch(iterator):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 873, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in <genexpr>
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1622, in split
    for train, test in self._iter_indices(X, y, groups):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1730, in _iter_indices
    n_train, n_test = _validate_shuffle_split(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 2126, in _validate_shuffle_split
    raise ValueError(
ValueError: With n_samples=1, test_size=None and train_size=0.9230769230769231, the resulting train set will be empty. Adjust any of the aforementioned parameters.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 862, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 810, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in cross_validate
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1085, in __call__
    if self.dispatch_one_batch(iterator):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 873, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in <genexpr>
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1622, in split
    for train, test in self._iter_indices(X, y, groups):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1730, in _iter_indices
    n_train, n_test = _validate_shuffle_split(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 2126, in _validate_shuffle_split
    raise ValueError(
ValueError: With n_samples=1, test_size=None and train_size=0.9230769230769231, the resulting train set will be empty. Adjust any of the aforementioned parameters.

2023-04-25 20:31:53,050:INFO:Initializing AdaBoost Regressor
2023-04-25 20:31:53,050:INFO:Total runtime is 0.011141379674275715 minutes
2023-04-25 20:31:53,050:INFO:SubProcess create_model() called ==================================
2023-04-25 20:31:53,050:INFO:Initializing create_model()
2023-04-25 20:31:53,050:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A1868BC7F0>, estimator=ada, fold=ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A186E132B0>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 20:31:53,050:INFO:Checking exceptions
2023-04-25 20:31:53,050:INFO:Importing libraries
2023-04-25 20:31:53,050:INFO:Copying training dataset
2023-04-25 20:31:53,064:INFO:Defining folds
2023-04-25 20:31:53,064:INFO:Declaring metric variables
2023-04-25 20:31:53,072:INFO:Importing untrained model
2023-04-25 20:31:53,076:INFO:AdaBoost Regressor Imported successfully
2023-04-25 20:31:53,086:INFO:Starting cross validation
2023-04-25 20:31:53,090:INFO:Cross validating with ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), n_jobs=1
2023-04-25 20:31:53,090:WARNING:create_model() for ada raised an exception or returned all 0.0, trying without fit_kwargs:
2023-04-25 20:31:53,090:WARNING:Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 862, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in cross_validate
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1085, in __call__
    if self.dispatch_one_batch(iterator):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 873, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in <genexpr>
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1622, in split
    for train, test in self._iter_indices(X, y, groups):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1730, in _iter_indices
    n_train, n_test = _validate_shuffle_split(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 2126, in _validate_shuffle_split
    raise ValueError(
ValueError: With n_samples=1, test_size=None and train_size=0.9230769230769231, the resulting train set will be empty. Adjust any of the aforementioned parameters.

2023-04-25 20:31:53,090:INFO:Initializing create_model()
2023-04-25 20:31:53,090:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A1868BC7F0>, estimator=ada, fold=ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A186E132B0>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 20:31:53,090:INFO:Checking exceptions
2023-04-25 20:31:53,090:INFO:Importing libraries
2023-04-25 20:31:53,090:INFO:Copying training dataset
2023-04-25 20:31:53,097:INFO:Defining folds
2023-04-25 20:31:53,097:INFO:Declaring metric variables
2023-04-25 20:31:53,104:INFO:Importing untrained model
2023-04-25 20:31:53,104:INFO:AdaBoost Regressor Imported successfully
2023-04-25 20:31:53,117:INFO:Starting cross validation
2023-04-25 20:31:53,123:INFO:Cross validating with ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), n_jobs=1
2023-04-25 20:31:53,123:ERROR:create_model() for ada raised an exception or returned all 0.0:
2023-04-25 20:31:53,126:ERROR:Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 862, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in cross_validate
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1085, in __call__
    if self.dispatch_one_batch(iterator):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 873, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in <genexpr>
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1622, in split
    for train, test in self._iter_indices(X, y, groups):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1730, in _iter_indices
    n_train, n_test = _validate_shuffle_split(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 2126, in _validate_shuffle_split
    raise ValueError(
ValueError: With n_samples=1, test_size=None and train_size=0.9230769230769231, the resulting train set will be empty. Adjust any of the aforementioned parameters.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 862, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 810, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in cross_validate
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1085, in __call__
    if self.dispatch_one_batch(iterator):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 873, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in <genexpr>
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1622, in split
    for train, test in self._iter_indices(X, y, groups):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1730, in _iter_indices
    n_train, n_test = _validate_shuffle_split(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 2126, in _validate_shuffle_split
    raise ValueError(
ValueError: With n_samples=1, test_size=None and train_size=0.9230769230769231, the resulting train set will be empty. Adjust any of the aforementioned parameters.

2023-04-25 20:31:53,145:INFO:Initializing Gradient Boosting Regressor
2023-04-25 20:31:53,145:INFO:Total runtime is 0.012718923886617023 minutes
2023-04-25 20:31:53,161:INFO:SubProcess create_model() called ==================================
2023-04-25 20:31:53,161:INFO:Initializing create_model()
2023-04-25 20:31:53,161:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A1868BC7F0>, estimator=gbr, fold=ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A186E132B0>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 20:31:53,161:INFO:Checking exceptions
2023-04-25 20:31:53,161:INFO:Importing libraries
2023-04-25 20:31:53,161:INFO:Copying training dataset
2023-04-25 20:31:53,165:INFO:Defining folds
2023-04-25 20:31:53,165:INFO:Declaring metric variables
2023-04-25 20:31:53,172:INFO:Importing untrained model
2023-04-25 20:31:53,176:INFO:Gradient Boosting Regressor Imported successfully
2023-04-25 20:31:53,187:INFO:Starting cross validation
2023-04-25 20:31:53,187:INFO:Cross validating with ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), n_jobs=1
2023-04-25 20:31:53,187:WARNING:create_model() for gbr raised an exception or returned all 0.0, trying without fit_kwargs:
2023-04-25 20:31:53,194:WARNING:Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 862, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in cross_validate
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1085, in __call__
    if self.dispatch_one_batch(iterator):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 873, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in <genexpr>
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1622, in split
    for train, test in self._iter_indices(X, y, groups):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1730, in _iter_indices
    n_train, n_test = _validate_shuffle_split(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 2126, in _validate_shuffle_split
    raise ValueError(
ValueError: With n_samples=1, test_size=None and train_size=0.9230769230769231, the resulting train set will be empty. Adjust any of the aforementioned parameters.

2023-04-25 20:31:53,194:INFO:Initializing create_model()
2023-04-25 20:31:53,194:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A1868BC7F0>, estimator=gbr, fold=ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A186E132B0>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 20:31:53,194:INFO:Checking exceptions
2023-04-25 20:31:53,194:INFO:Importing libraries
2023-04-25 20:31:53,194:INFO:Copying training dataset
2023-04-25 20:31:53,201:INFO:Defining folds
2023-04-25 20:31:53,201:INFO:Declaring metric variables
2023-04-25 20:31:53,208:INFO:Importing untrained model
2023-04-25 20:31:53,208:INFO:Gradient Boosting Regressor Imported successfully
2023-04-25 20:31:53,221:INFO:Starting cross validation
2023-04-25 20:31:53,227:INFO:Cross validating with ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), n_jobs=1
2023-04-25 20:31:53,227:ERROR:create_model() for gbr raised an exception or returned all 0.0:
2023-04-25 20:31:53,227:ERROR:Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 862, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in cross_validate
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1085, in __call__
    if self.dispatch_one_batch(iterator):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 873, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in <genexpr>
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1622, in split
    for train, test in self._iter_indices(X, y, groups):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1730, in _iter_indices
    n_train, n_test = _validate_shuffle_split(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 2126, in _validate_shuffle_split
    raise ValueError(
ValueError: With n_samples=1, test_size=None and train_size=0.9230769230769231, the resulting train set will be empty. Adjust any of the aforementioned parameters.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 862, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 810, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in cross_validate
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1085, in __call__
    if self.dispatch_one_batch(iterator):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 873, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in <genexpr>
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1622, in split
    for train, test in self._iter_indices(X, y, groups):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1730, in _iter_indices
    n_train, n_test = _validate_shuffle_split(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 2126, in _validate_shuffle_split
    raise ValueError(
ValueError: With n_samples=1, test_size=None and train_size=0.9230769230769231, the resulting train set will be empty. Adjust any of the aforementioned parameters.

2023-04-25 20:31:53,273:INFO:_master_model_container: 0
2023-04-25 20:31:53,273:INFO:_display_container: 2
2023-04-25 20:31:53,273:INFO:[]
2023-04-25 20:31:53,273:INFO:compare_models() successfully completed......................................
2023-04-25 20:32:16,066:INFO:PyCaret RegressionExperiment
2023-04-25 20:32:16,066:INFO:Logging name: price_recomm_partial
2023-04-25 20:32:16,066:INFO:ML Usecase: MLUsecase.REGRESSION
2023-04-25 20:32:16,066:INFO:version 3.0.0
2023-04-25 20:32:16,066:INFO:Initializing setup()
2023-04-25 20:32:16,066:INFO:self.USI: ced3
2023-04-25 20:32:16,066:INFO:self._variable_keys: {'logging_param', 'seed', 'log_plots_param', 'exp_name_log', 'exp_id', 'y', 'gpu_param', 'X_test', 'X', '_available_plots', 'y_train', 'target_param', 'n_jobs_param', 'USI', 'pipeline', 'html_param', 'idx', 'X_train', '_ml_usecase', 'fold_groups_param', 'gpu_n_jobs_param', 'fold_generator', 'memory', 'data', 'fold_shuffle_param', 'y_test', 'transform_target_param'}
2023-04-25 20:32:16,066:INFO:Checking environment
2023-04-25 20:32:16,066:INFO:python_version: 3.10.5
2023-04-25 20:32:16,066:INFO:python_build: ('tags/v3.10.5:f377153', 'Jun  6 2022 16:14:13')
2023-04-25 20:32:16,066:INFO:machine: AMD64
2023-04-25 20:32:16,066:INFO:platform: Windows-10-10.0.22000-SP0
2023-04-25 20:32:16,066:INFO:Memory: svmem(total=16497119232, available=8723279872, percent=47.1, used=7773839360, free=8723279872)
2023-04-25 20:32:16,066:INFO:Physical Core: 8
2023-04-25 20:32:16,066:INFO:Logical Core: 16
2023-04-25 20:32:16,066:INFO:Checking libraries
2023-04-25 20:32:16,066:INFO:System:
2023-04-25 20:32:16,066:INFO:    python: 3.10.5 (tags/v3.10.5:f377153, Jun  6 2022, 16:14:13) [MSC v.1929 64 bit (AMD64)]
2023-04-25 20:32:16,066:INFO:executable: C:\Users\Hashif\AppData\Local\Programs\Python\Python310\python.exe
2023-04-25 20:32:16,066:INFO:   machine: Windows-10-10.0.22000-SP0
2023-04-25 20:32:16,074:INFO:PyCaret required dependencies:
2023-04-25 20:32:16,074:INFO:                 pip: 23.1.1
2023-04-25 20:32:16,074:INFO:          setuptools: 58.1.0
2023-04-25 20:32:16,074:INFO:             pycaret: 3.0.0
2023-04-25 20:32:16,074:INFO:             IPython: 8.4.0
2023-04-25 20:32:16,074:INFO:          ipywidgets: 7.7.0
2023-04-25 20:32:16,074:INFO:                tqdm: 4.65.0
2023-04-25 20:32:16,074:INFO:               numpy: 1.23.0
2023-04-25 20:32:16,074:INFO:              pandas: 1.4.3
2023-04-25 20:32:16,074:INFO:              jinja2: 3.1.2
2023-04-25 20:32:16,074:INFO:               scipy: 1.9.3
2023-04-25 20:32:16,074:INFO:              joblib: 1.2.0
2023-04-25 20:32:16,074:INFO:             sklearn: 1.1.2
2023-04-25 20:32:16,074:INFO:                pyod: 1.0.9
2023-04-25 20:32:16,074:INFO:            imblearn: 0.10.1
2023-04-25 20:32:16,074:INFO:   category_encoders: 2.6.0
2023-04-25 20:32:16,074:INFO:            lightgbm: 3.3.5
2023-04-25 20:32:16,074:INFO:               numba: 0.56.4
2023-04-25 20:32:16,074:INFO:            requests: 2.28.1
2023-04-25 20:32:16,074:INFO:          matplotlib: 3.6.2
2023-04-25 20:32:16,074:INFO:          scikitplot: 0.3.7
2023-04-25 20:32:16,074:INFO:         yellowbrick: 1.5
2023-04-25 20:32:16,074:INFO:              plotly: 5.14.1
2023-04-25 20:32:16,074:INFO:             kaleido: 0.2.1
2023-04-25 20:32:16,074:INFO:         statsmodels: 0.13.5
2023-04-25 20:32:16,074:INFO:              sktime: 0.17.1
2023-04-25 20:32:16,074:INFO:               tbats: 1.1.3
2023-04-25 20:32:16,074:INFO:            pmdarima: 2.0.3
2023-04-25 20:32:16,074:INFO:              psutil: 5.9.1
2023-04-25 20:32:16,074:INFO:PyCaret optional dependencies:
2023-04-25 20:32:16,074:INFO:                shap: Not installed
2023-04-25 20:32:16,074:INFO:           interpret: Not installed
2023-04-25 20:32:16,074:INFO:                umap: Not installed
2023-04-25 20:32:16,074:INFO:    pandas_profiling: Not installed
2023-04-25 20:32:16,074:INFO:  explainerdashboard: Not installed
2023-04-25 20:32:16,074:INFO:             autoviz: Not installed
2023-04-25 20:32:16,074:INFO:           fairlearn: Not installed
2023-04-25 20:32:16,074:INFO:             xgboost: Not installed
2023-04-25 20:32:16,074:INFO:            catboost: Not installed
2023-04-25 20:32:16,074:INFO:              kmodes: Not installed
2023-04-25 20:32:16,074:INFO:             mlxtend: Not installed
2023-04-25 20:32:16,074:INFO:       statsforecast: Not installed
2023-04-25 20:32:16,074:INFO:        tune_sklearn: Not installed
2023-04-25 20:32:16,074:INFO:                 ray: Not installed
2023-04-25 20:32:16,074:INFO:            hyperopt: Not installed
2023-04-25 20:32:16,074:INFO:              optuna: Not installed
2023-04-25 20:32:16,074:INFO:               skopt: Not installed
2023-04-25 20:32:16,074:INFO:              mlflow: 2.3.0
2023-04-25 20:32:16,074:INFO:              gradio: Not installed
2023-04-25 20:32:16,074:INFO:             fastapi: Not installed
2023-04-25 20:32:16,074:INFO:             uvicorn: Not installed
2023-04-25 20:32:16,074:INFO:              m2cgen: Not installed
2023-04-25 20:32:16,074:INFO:           evidently: Not installed
2023-04-25 20:32:16,074:INFO:               fugue: Not installed
2023-04-25 20:32:16,074:INFO:           streamlit: Not installed
2023-04-25 20:32:16,074:INFO:             prophet: Not installed
2023-04-25 20:32:16,074:INFO:None
2023-04-25 20:32:16,074:INFO:Set up GPU usage.
2023-04-25 20:32:16,074:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:32:16,074:WARNING:cuML is outdated or not found. Required version is >=22.10, got 3.0.0
2023-04-25 20:32:16,080:INFO:Set up data.
2023-04-25 20:32:16,085:INFO:Set up train/test split.
2023-04-25 20:32:16,090:INFO:Set up index.
2023-04-25 20:32:16,090:INFO:Set up folding strategy.
2023-04-25 20:32:16,090:INFO:Assigning column types.
2023-04-25 20:32:16,090:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-04-25 20:32:16,090:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:32:16,090:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-04-25 20:32:16,090:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:32:16,090:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-25 20:32:16,090:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:32:16,106:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-25 20:32:16,106:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:32:16,200:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-25 20:32:16,200:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:32:16,262:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-25 20:32:16,262:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:32:16,262:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:32:16,262:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 20:32:16,341:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 20:32:16,341:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:32:16,341:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-04-25 20:32:16,341:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:32:16,357:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-25 20:32:16,357:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:32:16,357:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-25 20:32:16,357:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:32:16,466:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-25 20:32:16,466:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:32:16,545:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-25 20:32:16,545:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:32:16,545:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:32:16,545:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 20:32:16,592:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 20:32:16,608:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-04-25 20:32:16,608:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:32:16,608:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:32:16,608:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-25 20:32:16,608:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:32:16,623:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-25 20:32:16,623:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:32:16,717:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-25 20:32:16,717:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:32:16,796:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-25 20:32:16,796:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:32:16,796:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:32:16,796:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 20:32:16,874:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 20:32:16,874:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:32:16,874:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:32:16,890:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-25 20:32:16,890:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:32:16,890:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-25 20:32:16,890:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:32:17,000:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-25 20:32:17,000:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:32:17,080:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-25 20:32:17,080:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:32:17,080:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:32:17,080:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 20:32:17,150:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 20:32:17,150:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-04-25 20:32:17,150:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:32:17,150:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:32:17,166:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:32:17,166:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-25 20:32:17,166:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:32:17,287:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-25 20:32:17,292:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:32:17,355:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-25 20:32:17,355:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:32:17,355:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:32:17,355:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 20:32:17,434:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 20:32:17,434:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:32:17,434:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:32:17,450:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:32:17,465:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-25 20:32:17,465:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:32:17,559:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-25 20:32:17,559:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:32:17,638:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-25 20:32:17,638:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:32:17,638:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:32:17,638:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 20:32:17,716:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 20:32:17,716:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-04-25 20:32:17,716:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:32:17,716:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:32:17,716:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:32:17,732:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:32:17,842:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-25 20:32:17,842:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:32:17,921:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-25 20:32:17,921:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:32:17,921:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:32:17,921:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 20:32:17,989:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 20:32:17,989:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:32:17,989:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:32:17,999:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:32:18,015:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:32:18,109:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-25 20:32:18,109:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:32:18,189:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-25 20:32:18,189:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:32:18,189:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:32:18,189:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 20:32:18,250:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 20:32:18,250:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-04-25 20:32:18,250:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:32:18,250:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:32:18,250:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:32:18,266:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:32:18,376:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-25 20:32:18,376:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:32:18,438:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:32:18,438:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:32:18,438:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 20:32:18,515:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 20:32:18,515:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:32:18,515:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:32:18,523:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:32:18,531:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:32:18,636:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-25 20:32:18,636:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:32:18,709:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:32:18,709:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:32:18,709:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 20:32:18,757:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 20:32:18,757:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-04-25 20:32:18,757:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:32:18,757:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:32:18,772:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:32:18,772:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:32:18,886:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:32:18,959:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:32:18,959:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:32:18,967:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 20:32:19,028:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 20:32:19,028:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:32:19,028:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:32:19,028:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:32:19,044:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:32:19,148:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:32:19,217:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:32:19,217:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:32:19,217:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 20:32:19,271:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 20:32:19,274:INFO:Set up custom pipeline.
2023-04-25 20:32:19,288:INFO:Finished creating preprocessing pipeline.
2023-04-25 20:32:19,392:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Hashif\AppData\Local\Temp\joblib),
         steps=[('custom_step',
                 TransformerWrapper(transformer=FeatureUnion(n_jobs=1,
                                                             transformer_list=[('pipeline-1',
                                                                                Pipeline(steps=[('functiontransformer',
                                                                                                 FunctionTransformer(func=operator.itemgetter('amneties'))),
                                                                                                ('tfidfvectorizer',
                                                                                                 TfidfVectorizer(max_features=10000,
                                                                                                                 ngram_range=(1,
                                                                                                                              2),
                                                                                                                 token_pattern='\\w+'))])),
                                                                               ('pipeline-2',
                                                                                Pipeline(steps=[('functiontransformer-1',
                                                                                                 FunctionTransformer(func=operator.itemgetter(['ratings', 'distance']))),
                                                                                                ('functiontransformer-2',
                                                                                                 FunctionTransformer(func=<function to_records at 0x000001A1ADE52D40>)),
                                                                                                ('dictvectorizer',
                                                                                                 DictVectorizer())]))])))])
2023-04-25 20:32:19,392:INFO:Creating final display dataframe.
2023-04-25 20:32:19,511:INFO:Setup _display_container:                    Description       Value
0                   Session id          42
1                       Target       price
2                  Target type  Regression
3          Original data shape      (2, 4)
4       Transformed data shape     (2, 12)
5  Transformed train set shape     (1, 12)
6   Transformed test set shape     (1, 12)
7             Numeric features           2
8         Categorical features           1
2023-04-25 20:32:19,519:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:32:19,519:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:32:19,526:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:32:19,535:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:32:19,627:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:32:19,711:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:32:19,711:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:32:19,715:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 20:32:19,770:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 20:32:19,770:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:32:19,774:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:32:19,784:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:32:19,793:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:32:19,905:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:32:19,975:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:32:19,975:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:32:19,975:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 20:32:20,020:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 20:32:20,020:INFO:Logging experiment in loggers
2023-04-25 20:32:20,167:INFO:SubProcess save_model() called ==================================
2023-04-25 20:32:20,333:INFO:Initializing save_model()
2023-04-25 20:32:20,333:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\Hashif\AppData\Local\Temp\joblib),
         steps=[('custom_step',
                 TransformerWrapper(transformer=FeatureUnion(n_jobs=1,
                                                             transformer_list=[('pipeline-1',
                                                                                Pipeline(steps=[('functiontransformer',
                                                                                                 FunctionTransformer(func=operator.itemgetter('amneties'))),
                                                                                                ('tfidfvectorizer',
                                                                                                 TfidfVectorizer(max_features=10000,
                                                                                                                 ngram_range=(1,
                                                                                                                              2),
                                                                                                                 token_pattern='\\w+'))])),
                                                                               ('pipeline-2',
                                                                                Pipeline(steps=[('functiontransformer-1',
                                                                                                 FunctionTransformer(func=operator.itemgetter(['ratings', 'distance']))),
                                                                                                ('functiontransformer-2',
                                                                                                 FunctionTransformer(func=<function to_records at 0x000001A1ADE52D40>)),
                                                                                                ('dictvectorizer',
                                                                                                 DictVectorizer())]))])))]), model_name=C:\Users\Hashif\AppData\Local\Temp\tmpdd27uu2x\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\Hashif\AppData\Local\Temp\joblib),
         steps=[('custom_step',
                 TransformerWrapper(transformer=FeatureUnion(n_jobs=1,
                                                             transformer_list=[('pipeline-1',
                                                                                Pipeline(steps=[('functiontransformer',
                                                                                                 FunctionTransformer(func=operator.itemgetter('amneties'))),
                                                                                                ('tfidfvectorizer',
                                                                                                 TfidfVectorizer(max_features=10000,
                                                                                                                 ngram_range=(1,
                                                                                                                              2),
                                                                                                                 token_pattern='\\w+'))])),
                                                                               ('pipeline-2',
                                                                                Pipeline(steps=[('functiontransformer-1',
                                                                                                 FunctionTransformer(func=operator.itemgetter(['ratings', 'distance']))),
                                                                                                ('functiontransformer-2',
                                                                                                 FunctionTransformer(func=<function to_records at 0x000001A1ADE52D40>)),
                                                                                                ('dictvectorizer',
                                                                                                 DictVectorizer())]))])))]), verbose=False, use_case=MLUsecase.REGRESSION, kwargs={})
2023-04-25 20:32:20,333:INFO:Adding model into prep_pipe
2023-04-25 20:32:20,333:WARNING:Only Model saved as it was a pipeline.
2023-04-25 20:32:20,339:INFO:C:\Users\Hashif\AppData\Local\Temp\tmpdd27uu2x\Transformation Pipeline.pkl saved in current working directory
2023-04-25 20:32:20,436:INFO:Pipeline(memory=FastMemory(location=C:\Users\Hashif\AppData\Local\Temp\joblib),
         steps=[('custom_step',
                 TransformerWrapper(transformer=FeatureUnion(n_jobs=1,
                                                             transformer_list=[('pipeline-1',
                                                                                Pipeline(steps=[('functiontransformer',
                                                                                                 FunctionTransformer(func=operator.itemgetter('amneties'))),
                                                                                                ('tfidfvectorizer',
                                                                                                 TfidfVectorizer(max_features=10000,
                                                                                                                 ngram_range=(1,
                                                                                                                              2),
                                                                                                                 token_pattern='\\w+'))])),
                                                                               ('pipeline-2',
                                                                                Pipeline(steps=[('functiontransformer-1',
                                                                                                 FunctionTransformer(func=operator.itemgetter(['ratings', 'distance']))),
                                                                                                ('functiontransformer-2',
                                                                                                 FunctionTransformer(func=<function to_records at 0x000001A1ADE52D40>)),
                                                                                                ('dictvectorizer',
                                                                                                 DictVectorizer())]))])))])
2023-04-25 20:32:20,436:INFO:save_model() successfully completed......................................
2023-04-25 20:32:20,624:INFO:SubProcess save_model() end ==================================
2023-04-25 20:32:20,668:INFO:setup() successfully completed in 3.99s...............
2023-04-25 20:32:20,687:INFO:Initializing compare_models()
2023-04-25 20:32:20,687:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A185082EF0>, include=['lr', 'lasso', 'ridge', 'en', 'huber', 'knn', 'ada', 'gbr'], fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001A185082EF0>, 'include': ['lr', 'lasso', 'ridge', 'en', 'huber', 'knn', 'ada', 'gbr'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-04-25 20:32:20,687:INFO:Checking exceptions
2023-04-25 20:32:20,687:INFO:Preparing display monitor
2023-04-25 20:32:20,729:INFO:Initializing Linear Regression
2023-04-25 20:32:20,729:INFO:Total runtime is 0.0 minutes
2023-04-25 20:32:20,735:INFO:SubProcess create_model() called ==================================
2023-04-25 20:32:20,735:INFO:Initializing create_model()
2023-04-25 20:32:20,735:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A185082EF0>, estimator=lr, fold=ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A1F38B7A00>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 20:32:20,742:INFO:Checking exceptions
2023-04-25 20:32:20,742:INFO:Importing libraries
2023-04-25 20:32:20,742:INFO:Copying training dataset
2023-04-25 20:32:20,750:INFO:Defining folds
2023-04-25 20:32:20,750:INFO:Declaring metric variables
2023-04-25 20:32:20,750:INFO:Importing untrained model
2023-04-25 20:32:20,758:INFO:Linear Regression Imported successfully
2023-04-25 20:32:20,769:INFO:Starting cross validation
2023-04-25 20:32:20,769:INFO:Cross validating with ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), n_jobs=1
2023-04-25 20:32:20,777:WARNING:create_model() for lr raised an exception or returned all 0.0, trying without fit_kwargs:
2023-04-25 20:32:20,777:WARNING:Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 862, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in cross_validate
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1085, in __call__
    if self.dispatch_one_batch(iterator):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 873, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in <genexpr>
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1622, in split
    for train, test in self._iter_indices(X, y, groups):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1730, in _iter_indices
    n_train, n_test = _validate_shuffle_split(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 2126, in _validate_shuffle_split
    raise ValueError(
ValueError: With n_samples=1, test_size=None and train_size=0.9230769230769231, the resulting train set will be empty. Adjust any of the aforementioned parameters.

2023-04-25 20:32:20,777:INFO:Initializing create_model()
2023-04-25 20:32:20,777:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A185082EF0>, estimator=lr, fold=ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A1F38B7A00>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 20:32:20,777:INFO:Checking exceptions
2023-04-25 20:32:20,777:INFO:Importing libraries
2023-04-25 20:32:20,777:INFO:Copying training dataset
2023-04-25 20:32:20,784:INFO:Defining folds
2023-04-25 20:32:20,784:INFO:Declaring metric variables
2023-04-25 20:32:20,792:INFO:Importing untrained model
2023-04-25 20:32:20,792:INFO:Linear Regression Imported successfully
2023-04-25 20:32:20,804:INFO:Starting cross validation
2023-04-25 20:32:20,808:INFO:Cross validating with ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), n_jobs=1
2023-04-25 20:32:20,808:ERROR:create_model() for lr raised an exception or returned all 0.0:
2023-04-25 20:32:20,808:ERROR:Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 862, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in cross_validate
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1085, in __call__
    if self.dispatch_one_batch(iterator):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 873, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in <genexpr>
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1622, in split
    for train, test in self._iter_indices(X, y, groups):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1730, in _iter_indices
    n_train, n_test = _validate_shuffle_split(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 2126, in _validate_shuffle_split
    raise ValueError(
ValueError: With n_samples=1, test_size=None and train_size=0.9230769230769231, the resulting train set will be empty. Adjust any of the aforementioned parameters.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 862, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 810, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in cross_validate
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1085, in __call__
    if self.dispatch_one_batch(iterator):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 873, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in <genexpr>
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1622, in split
    for train, test in self._iter_indices(X, y, groups):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1730, in _iter_indices
    n_train, n_test = _validate_shuffle_split(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 2126, in _validate_shuffle_split
    raise ValueError(
ValueError: With n_samples=1, test_size=None and train_size=0.9230769230769231, the resulting train set will be empty. Adjust any of the aforementioned parameters.

2023-04-25 20:32:20,841:INFO:Initializing Lasso Regression
2023-04-25 20:32:20,841:INFO:Total runtime is 0.0018627206484476725 minutes
2023-04-25 20:32:20,841:INFO:SubProcess create_model() called ==================================
2023-04-25 20:32:20,841:INFO:Initializing create_model()
2023-04-25 20:32:20,841:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A185082EF0>, estimator=lasso, fold=ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A1F38B7A00>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 20:32:20,841:INFO:Checking exceptions
2023-04-25 20:32:20,841:INFO:Importing libraries
2023-04-25 20:32:20,841:INFO:Copying training dataset
2023-04-25 20:32:20,851:INFO:Defining folds
2023-04-25 20:32:20,851:INFO:Declaring metric variables
2023-04-25 20:32:20,851:INFO:Importing untrained model
2023-04-25 20:32:20,859:INFO:Lasso Regression Imported successfully
2023-04-25 20:32:20,872:INFO:Starting cross validation
2023-04-25 20:32:20,873:INFO:Cross validating with ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), n_jobs=1
2023-04-25 20:32:20,873:WARNING:create_model() for lasso raised an exception or returned all 0.0, trying without fit_kwargs:
2023-04-25 20:32:20,873:WARNING:Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 862, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in cross_validate
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1085, in __call__
    if self.dispatch_one_batch(iterator):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 873, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in <genexpr>
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1622, in split
    for train, test in self._iter_indices(X, y, groups):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1730, in _iter_indices
    n_train, n_test = _validate_shuffle_split(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 2126, in _validate_shuffle_split
    raise ValueError(
ValueError: With n_samples=1, test_size=None and train_size=0.9230769230769231, the resulting train set will be empty. Adjust any of the aforementioned parameters.

2023-04-25 20:32:20,873:INFO:Initializing create_model()
2023-04-25 20:32:20,873:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A185082EF0>, estimator=lasso, fold=ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A1F38B7A00>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 20:32:20,873:INFO:Checking exceptions
2023-04-25 20:32:20,873:INFO:Importing libraries
2023-04-25 20:32:20,873:INFO:Copying training dataset
2023-04-25 20:32:20,887:INFO:Defining folds
2023-04-25 20:32:20,887:INFO:Declaring metric variables
2023-04-25 20:32:20,894:INFO:Importing untrained model
2023-04-25 20:32:20,900:INFO:Lasso Regression Imported successfully
2023-04-25 20:32:20,908:INFO:Starting cross validation
2023-04-25 20:32:20,915:INFO:Cross validating with ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), n_jobs=1
2023-04-25 20:32:20,915:ERROR:create_model() for lasso raised an exception or returned all 0.0:
2023-04-25 20:32:20,915:ERROR:Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 862, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in cross_validate
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1085, in __call__
    if self.dispatch_one_batch(iterator):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 873, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in <genexpr>
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1622, in split
    for train, test in self._iter_indices(X, y, groups):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1730, in _iter_indices
    n_train, n_test = _validate_shuffle_split(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 2126, in _validate_shuffle_split
    raise ValueError(
ValueError: With n_samples=1, test_size=None and train_size=0.9230769230769231, the resulting train set will be empty. Adjust any of the aforementioned parameters.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 862, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 810, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in cross_validate
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1085, in __call__
    if self.dispatch_one_batch(iterator):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 873, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in <genexpr>
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1622, in split
    for train, test in self._iter_indices(X, y, groups):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1730, in _iter_indices
    n_train, n_test = _validate_shuffle_split(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 2126, in _validate_shuffle_split
    raise ValueError(
ValueError: With n_samples=1, test_size=None and train_size=0.9230769230769231, the resulting train set will be empty. Adjust any of the aforementioned parameters.

2023-04-25 20:32:20,968:INFO:Initializing Ridge Regression
2023-04-25 20:32:20,968:INFO:Total runtime is 0.003976070880889892 minutes
2023-04-25 20:32:20,968:INFO:SubProcess create_model() called ==================================
2023-04-25 20:32:20,968:INFO:Initializing create_model()
2023-04-25 20:32:20,968:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A185082EF0>, estimator=ridge, fold=ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A1F38B7A00>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 20:32:20,968:INFO:Checking exceptions
2023-04-25 20:32:20,968:INFO:Importing libraries
2023-04-25 20:32:20,968:INFO:Copying training dataset
2023-04-25 20:32:20,980:INFO:Defining folds
2023-04-25 20:32:20,980:INFO:Declaring metric variables
2023-04-25 20:32:20,986:INFO:Importing untrained model
2023-04-25 20:32:20,992:INFO:Ridge Regression Imported successfully
2023-04-25 20:32:21,000:INFO:Starting cross validation
2023-04-25 20:32:21,006:INFO:Cross validating with ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), n_jobs=1
2023-04-25 20:32:21,006:WARNING:create_model() for ridge raised an exception or returned all 0.0, trying without fit_kwargs:
2023-04-25 20:32:21,006:WARNING:Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 862, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in cross_validate
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1085, in __call__
    if self.dispatch_one_batch(iterator):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 873, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in <genexpr>
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1622, in split
    for train, test in self._iter_indices(X, y, groups):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1730, in _iter_indices
    n_train, n_test = _validate_shuffle_split(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 2126, in _validate_shuffle_split
    raise ValueError(
ValueError: With n_samples=1, test_size=None and train_size=0.9230769230769231, the resulting train set will be empty. Adjust any of the aforementioned parameters.

2023-04-25 20:32:21,006:INFO:Initializing create_model()
2023-04-25 20:32:21,006:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A185082EF0>, estimator=ridge, fold=ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A1F38B7A00>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 20:32:21,006:INFO:Checking exceptions
2023-04-25 20:32:21,006:INFO:Importing libraries
2023-04-25 20:32:21,006:INFO:Copying training dataset
2023-04-25 20:32:21,014:INFO:Defining folds
2023-04-25 20:32:21,014:INFO:Declaring metric variables
2023-04-25 20:32:21,019:INFO:Importing untrained model
2023-04-25 20:32:21,019:INFO:Ridge Regression Imported successfully
2023-04-25 20:32:21,033:INFO:Starting cross validation
2023-04-25 20:32:21,038:INFO:Cross validating with ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), n_jobs=1
2023-04-25 20:32:21,038:ERROR:create_model() for ridge raised an exception or returned all 0.0:
2023-04-25 20:32:21,040:ERROR:Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 862, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in cross_validate
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1085, in __call__
    if self.dispatch_one_batch(iterator):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 873, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in <genexpr>
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1622, in split
    for train, test in self._iter_indices(X, y, groups):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1730, in _iter_indices
    n_train, n_test = _validate_shuffle_split(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 2126, in _validate_shuffle_split
    raise ValueError(
ValueError: With n_samples=1, test_size=None and train_size=0.9230769230769231, the resulting train set will be empty. Adjust any of the aforementioned parameters.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 862, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 810, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in cross_validate
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1085, in __call__
    if self.dispatch_one_batch(iterator):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 873, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in <genexpr>
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1622, in split
    for train, test in self._iter_indices(X, y, groups):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1730, in _iter_indices
    n_train, n_test = _validate_shuffle_split(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 2126, in _validate_shuffle_split
    raise ValueError(
ValueError: With n_samples=1, test_size=None and train_size=0.9230769230769231, the resulting train set will be empty. Adjust any of the aforementioned parameters.

2023-04-25 20:32:21,063:INFO:Initializing Elastic Net
2023-04-25 20:32:21,063:INFO:Total runtime is 0.005561677614847819 minutes
2023-04-25 20:32:21,063:INFO:SubProcess create_model() called ==================================
2023-04-25 20:32:21,063:INFO:Initializing create_model()
2023-04-25 20:32:21,063:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A185082EF0>, estimator=en, fold=ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A1F38B7A00>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 20:32:21,063:INFO:Checking exceptions
2023-04-25 20:32:21,063:INFO:Importing libraries
2023-04-25 20:32:21,063:INFO:Copying training dataset
2023-04-25 20:32:21,078:INFO:Defining folds
2023-04-25 20:32:21,078:INFO:Declaring metric variables
2023-04-25 20:32:21,084:INFO:Importing untrained model
2023-04-25 20:32:21,089:INFO:Elastic Net Imported successfully
2023-04-25 20:32:21,111:INFO:Starting cross validation
2023-04-25 20:32:21,119:INFO:Cross validating with ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), n_jobs=1
2023-04-25 20:32:21,119:WARNING:create_model() for en raised an exception or returned all 0.0, trying without fit_kwargs:
2023-04-25 20:32:21,119:WARNING:Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 862, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in cross_validate
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1085, in __call__
    if self.dispatch_one_batch(iterator):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 873, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in <genexpr>
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1622, in split
    for train, test in self._iter_indices(X, y, groups):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1730, in _iter_indices
    n_train, n_test = _validate_shuffle_split(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 2126, in _validate_shuffle_split
    raise ValueError(
ValueError: With n_samples=1, test_size=None and train_size=0.9230769230769231, the resulting train set will be empty. Adjust any of the aforementioned parameters.

2023-04-25 20:32:21,119:INFO:Initializing create_model()
2023-04-25 20:32:21,119:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A185082EF0>, estimator=en, fold=ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A1F38B7A00>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 20:32:21,119:INFO:Checking exceptions
2023-04-25 20:32:21,119:INFO:Importing libraries
2023-04-25 20:32:21,122:INFO:Copying training dataset
2023-04-25 20:32:21,123:INFO:Defining folds
2023-04-25 20:32:21,123:INFO:Declaring metric variables
2023-04-25 20:32:21,137:INFO:Importing untrained model
2023-04-25 20:32:21,145:INFO:Elastic Net Imported successfully
2023-04-25 20:32:21,158:INFO:Starting cross validation
2023-04-25 20:32:21,158:INFO:Cross validating with ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), n_jobs=1
2023-04-25 20:32:21,158:ERROR:create_model() for en raised an exception or returned all 0.0:
2023-04-25 20:32:21,158:ERROR:Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 862, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in cross_validate
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1085, in __call__
    if self.dispatch_one_batch(iterator):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 873, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in <genexpr>
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1622, in split
    for train, test in self._iter_indices(X, y, groups):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1730, in _iter_indices
    n_train, n_test = _validate_shuffle_split(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 2126, in _validate_shuffle_split
    raise ValueError(
ValueError: With n_samples=1, test_size=None and train_size=0.9230769230769231, the resulting train set will be empty. Adjust any of the aforementioned parameters.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 862, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 810, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in cross_validate
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1085, in __call__
    if self.dispatch_one_batch(iterator):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 873, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in <genexpr>
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1622, in split
    for train, test in self._iter_indices(X, y, groups):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1730, in _iter_indices
    n_train, n_test = _validate_shuffle_split(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 2126, in _validate_shuffle_split
    raise ValueError(
ValueError: With n_samples=1, test_size=None and train_size=0.9230769230769231, the resulting train set will be empty. Adjust any of the aforementioned parameters.

2023-04-25 20:32:21,195:INFO:Initializing Huber Regressor
2023-04-25 20:32:21,195:INFO:Total runtime is 0.007759324709574382 minutes
2023-04-25 20:32:21,200:INFO:SubProcess create_model() called ==================================
2023-04-25 20:32:21,200:INFO:Initializing create_model()
2023-04-25 20:32:21,200:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A185082EF0>, estimator=huber, fold=ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A1F38B7A00>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 20:32:21,200:INFO:Checking exceptions
2023-04-25 20:32:21,200:INFO:Importing libraries
2023-04-25 20:32:21,200:INFO:Copying training dataset
2023-04-25 20:32:21,204:INFO:Defining folds
2023-04-25 20:32:21,204:INFO:Declaring metric variables
2023-04-25 20:32:21,213:INFO:Importing untrained model
2023-04-25 20:32:21,213:INFO:Huber Regressor Imported successfully
2023-04-25 20:32:21,227:INFO:Starting cross validation
2023-04-25 20:32:21,227:INFO:Cross validating with ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), n_jobs=1
2023-04-25 20:32:21,233:WARNING:create_model() for huber raised an exception or returned all 0.0, trying without fit_kwargs:
2023-04-25 20:32:21,234:WARNING:Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 862, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in cross_validate
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1085, in __call__
    if self.dispatch_one_batch(iterator):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 873, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in <genexpr>
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1622, in split
    for train, test in self._iter_indices(X, y, groups):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1730, in _iter_indices
    n_train, n_test = _validate_shuffle_split(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 2126, in _validate_shuffle_split
    raise ValueError(
ValueError: With n_samples=1, test_size=None and train_size=0.9230769230769231, the resulting train set will be empty. Adjust any of the aforementioned parameters.

2023-04-25 20:32:21,234:INFO:Initializing create_model()
2023-04-25 20:32:21,234:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A185082EF0>, estimator=huber, fold=ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A1F38B7A00>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 20:32:21,234:INFO:Checking exceptions
2023-04-25 20:32:21,234:INFO:Importing libraries
2023-04-25 20:32:21,234:INFO:Copying training dataset
2023-04-25 20:32:21,241:INFO:Defining folds
2023-04-25 20:32:21,241:INFO:Declaring metric variables
2023-04-25 20:32:21,246:INFO:Importing untrained model
2023-04-25 20:32:21,249:INFO:Huber Regressor Imported successfully
2023-04-25 20:32:21,262:INFO:Starting cross validation
2023-04-25 20:32:21,262:INFO:Cross validating with ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), n_jobs=1
2023-04-25 20:32:21,262:ERROR:create_model() for huber raised an exception or returned all 0.0:
2023-04-25 20:32:21,268:ERROR:Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 862, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in cross_validate
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1085, in __call__
    if self.dispatch_one_batch(iterator):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 873, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in <genexpr>
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1622, in split
    for train, test in self._iter_indices(X, y, groups):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1730, in _iter_indices
    n_train, n_test = _validate_shuffle_split(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 2126, in _validate_shuffle_split
    raise ValueError(
ValueError: With n_samples=1, test_size=None and train_size=0.9230769230769231, the resulting train set will be empty. Adjust any of the aforementioned parameters.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 862, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 810, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in cross_validate
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1085, in __call__
    if self.dispatch_one_batch(iterator):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 873, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in <genexpr>
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1622, in split
    for train, test in self._iter_indices(X, y, groups):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1730, in _iter_indices
    n_train, n_test = _validate_shuffle_split(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 2126, in _validate_shuffle_split
    raise ValueError(
ValueError: With n_samples=1, test_size=None and train_size=0.9230769230769231, the resulting train set will be empty. Adjust any of the aforementioned parameters.

2023-04-25 20:32:21,294:INFO:Initializing K Neighbors Regressor
2023-04-25 20:32:21,294:INFO:Total runtime is 0.009412157535552978 minutes
2023-04-25 20:32:21,302:INFO:SubProcess create_model() called ==================================
2023-04-25 20:32:21,302:INFO:Initializing create_model()
2023-04-25 20:32:21,302:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A185082EF0>, estimator=knn, fold=ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A1F38B7A00>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 20:32:21,302:INFO:Checking exceptions
2023-04-25 20:32:21,302:INFO:Importing libraries
2023-04-25 20:32:21,302:INFO:Copying training dataset
2023-04-25 20:32:21,308:INFO:Defining folds
2023-04-25 20:32:21,308:INFO:Declaring metric variables
2023-04-25 20:32:21,313:INFO:Importing untrained model
2023-04-25 20:32:21,317:INFO:K Neighbors Regressor Imported successfully
2023-04-25 20:32:21,331:INFO:Starting cross validation
2023-04-25 20:32:21,331:INFO:Cross validating with ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), n_jobs=1
2023-04-25 20:32:21,331:WARNING:create_model() for knn raised an exception or returned all 0.0, trying without fit_kwargs:
2023-04-25 20:32:21,336:WARNING:Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 862, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in cross_validate
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1085, in __call__
    if self.dispatch_one_batch(iterator):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 873, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in <genexpr>
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1622, in split
    for train, test in self._iter_indices(X, y, groups):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1730, in _iter_indices
    n_train, n_test = _validate_shuffle_split(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 2126, in _validate_shuffle_split
    raise ValueError(
ValueError: With n_samples=1, test_size=None and train_size=0.9230769230769231, the resulting train set will be empty. Adjust any of the aforementioned parameters.

2023-04-25 20:32:21,336:INFO:Initializing create_model()
2023-04-25 20:32:21,336:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A185082EF0>, estimator=knn, fold=ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A1F38B7A00>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 20:32:21,336:INFO:Checking exceptions
2023-04-25 20:32:21,336:INFO:Importing libraries
2023-04-25 20:32:21,336:INFO:Copying training dataset
2023-04-25 20:32:21,338:INFO:Defining folds
2023-04-25 20:32:21,338:INFO:Declaring metric variables
2023-04-25 20:32:21,345:INFO:Importing untrained model
2023-04-25 20:32:21,345:INFO:K Neighbors Regressor Imported successfully
2023-04-25 20:32:21,359:INFO:Starting cross validation
2023-04-25 20:32:21,366:INFO:Cross validating with ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), n_jobs=1
2023-04-25 20:32:21,366:ERROR:create_model() for knn raised an exception or returned all 0.0:
2023-04-25 20:32:21,366:ERROR:Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 862, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in cross_validate
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1085, in __call__
    if self.dispatch_one_batch(iterator):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 873, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in <genexpr>
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1622, in split
    for train, test in self._iter_indices(X, y, groups):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1730, in _iter_indices
    n_train, n_test = _validate_shuffle_split(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 2126, in _validate_shuffle_split
    raise ValueError(
ValueError: With n_samples=1, test_size=None and train_size=0.9230769230769231, the resulting train set will be empty. Adjust any of the aforementioned parameters.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 862, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 810, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in cross_validate
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1085, in __call__
    if self.dispatch_one_batch(iterator):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 873, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in <genexpr>
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1622, in split
    for train, test in self._iter_indices(X, y, groups):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1730, in _iter_indices
    n_train, n_test = _validate_shuffle_split(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 2126, in _validate_shuffle_split
    raise ValueError(
ValueError: With n_samples=1, test_size=None and train_size=0.9230769230769231, the resulting train set will be empty. Adjust any of the aforementioned parameters.

2023-04-25 20:32:21,394:INFO:Initializing AdaBoost Regressor
2023-04-25 20:32:21,394:INFO:Total runtime is 0.011075456937154133 minutes
2023-04-25 20:32:21,404:INFO:SubProcess create_model() called ==================================
2023-04-25 20:32:21,404:INFO:Initializing create_model()
2023-04-25 20:32:21,404:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A185082EF0>, estimator=ada, fold=ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A1F38B7A00>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 20:32:21,404:INFO:Checking exceptions
2023-04-25 20:32:21,404:INFO:Importing libraries
2023-04-25 20:32:21,404:INFO:Copying training dataset
2023-04-25 20:32:21,408:INFO:Defining folds
2023-04-25 20:32:21,408:INFO:Declaring metric variables
2023-04-25 20:32:21,416:INFO:Importing untrained model
2023-04-25 20:32:21,421:INFO:AdaBoost Regressor Imported successfully
2023-04-25 20:32:21,433:INFO:Starting cross validation
2023-04-25 20:32:21,435:INFO:Cross validating with ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), n_jobs=1
2023-04-25 20:32:21,435:WARNING:create_model() for ada raised an exception or returned all 0.0, trying without fit_kwargs:
2023-04-25 20:32:21,435:WARNING:Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 862, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in cross_validate
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1085, in __call__
    if self.dispatch_one_batch(iterator):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 873, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in <genexpr>
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1622, in split
    for train, test in self._iter_indices(X, y, groups):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1730, in _iter_indices
    n_train, n_test = _validate_shuffle_split(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 2126, in _validate_shuffle_split
    raise ValueError(
ValueError: With n_samples=1, test_size=None and train_size=0.9230769230769231, the resulting train set will be empty. Adjust any of the aforementioned parameters.

2023-04-25 20:32:21,435:INFO:Initializing create_model()
2023-04-25 20:32:21,435:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A185082EF0>, estimator=ada, fold=ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A1F38B7A00>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 20:32:21,435:INFO:Checking exceptions
2023-04-25 20:32:21,435:INFO:Importing libraries
2023-04-25 20:32:21,435:INFO:Copying training dataset
2023-04-25 20:32:21,442:INFO:Defining folds
2023-04-25 20:32:21,442:INFO:Declaring metric variables
2023-04-25 20:32:21,447:INFO:Importing untrained model
2023-04-25 20:32:21,451:INFO:AdaBoost Regressor Imported successfully
2023-04-25 20:32:21,464:INFO:Starting cross validation
2023-04-25 20:32:21,466:INFO:Cross validating with ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), n_jobs=1
2023-04-25 20:32:21,466:ERROR:create_model() for ada raised an exception or returned all 0.0:
2023-04-25 20:32:21,466:ERROR:Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 862, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in cross_validate
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1085, in __call__
    if self.dispatch_one_batch(iterator):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 873, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in <genexpr>
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1622, in split
    for train, test in self._iter_indices(X, y, groups):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1730, in _iter_indices
    n_train, n_test = _validate_shuffle_split(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 2126, in _validate_shuffle_split
    raise ValueError(
ValueError: With n_samples=1, test_size=None and train_size=0.9230769230769231, the resulting train set will be empty. Adjust any of the aforementioned parameters.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 862, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 810, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in cross_validate
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1085, in __call__
    if self.dispatch_one_batch(iterator):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 873, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in <genexpr>
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1622, in split
    for train, test in self._iter_indices(X, y, groups):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1730, in _iter_indices
    n_train, n_test = _validate_shuffle_split(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 2126, in _validate_shuffle_split
    raise ValueError(
ValueError: With n_samples=1, test_size=None and train_size=0.9230769230769231, the resulting train set will be empty. Adjust any of the aforementioned parameters.

2023-04-25 20:32:21,496:INFO:Initializing Gradient Boosting Regressor
2023-04-25 20:32:21,496:INFO:Total runtime is 0.01277551253636678 minutes
2023-04-25 20:32:21,504:INFO:SubProcess create_model() called ==================================
2023-04-25 20:32:21,504:INFO:Initializing create_model()
2023-04-25 20:32:21,504:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A185082EF0>, estimator=gbr, fold=ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A1F38B7A00>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 20:32:21,504:INFO:Checking exceptions
2023-04-25 20:32:21,504:INFO:Importing libraries
2023-04-25 20:32:21,504:INFO:Copying training dataset
2023-04-25 20:32:21,508:INFO:Defining folds
2023-04-25 20:32:21,508:INFO:Declaring metric variables
2023-04-25 20:32:21,515:INFO:Importing untrained model
2023-04-25 20:32:21,518:INFO:Gradient Boosting Regressor Imported successfully
2023-04-25 20:32:21,539:INFO:Starting cross validation
2023-04-25 20:32:21,539:INFO:Cross validating with ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), n_jobs=1
2023-04-25 20:32:21,539:WARNING:create_model() for gbr raised an exception or returned all 0.0, trying without fit_kwargs:
2023-04-25 20:32:21,539:WARNING:Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 862, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in cross_validate
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1085, in __call__
    if self.dispatch_one_batch(iterator):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 873, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in <genexpr>
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1622, in split
    for train, test in self._iter_indices(X, y, groups):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1730, in _iter_indices
    n_train, n_test = _validate_shuffle_split(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 2126, in _validate_shuffle_split
    raise ValueError(
ValueError: With n_samples=1, test_size=None and train_size=0.9230769230769231, the resulting train set will be empty. Adjust any of the aforementioned parameters.

2023-04-25 20:32:21,539:INFO:Initializing create_model()
2023-04-25 20:32:21,539:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A185082EF0>, estimator=gbr, fold=ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A1F38B7A00>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 20:32:21,539:INFO:Checking exceptions
2023-04-25 20:32:21,539:INFO:Importing libraries
2023-04-25 20:32:21,539:INFO:Copying training dataset
2023-04-25 20:32:21,548:INFO:Defining folds
2023-04-25 20:32:21,548:INFO:Declaring metric variables
2023-04-25 20:32:21,554:INFO:Importing untrained model
2023-04-25 20:32:21,560:INFO:Gradient Boosting Regressor Imported successfully
2023-04-25 20:32:21,582:INFO:Starting cross validation
2023-04-25 20:32:21,582:INFO:Cross validating with ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), n_jobs=1
2023-04-25 20:32:21,582:ERROR:create_model() for gbr raised an exception or returned all 0.0:
2023-04-25 20:32:21,588:ERROR:Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 862, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in cross_validate
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1085, in __call__
    if self.dispatch_one_batch(iterator):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 873, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in <genexpr>
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1622, in split
    for train, test in self._iter_indices(X, y, groups):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1730, in _iter_indices
    n_train, n_test = _validate_shuffle_split(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 2126, in _validate_shuffle_split
    raise ValueError(
ValueError: With n_samples=1, test_size=None and train_size=0.9230769230769231, the resulting train set will be empty. Adjust any of the aforementioned parameters.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 862, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 810, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in cross_validate
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1085, in __call__
    if self.dispatch_one_batch(iterator):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 873, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in <genexpr>
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1622, in split
    for train, test in self._iter_indices(X, y, groups):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1730, in _iter_indices
    n_train, n_test = _validate_shuffle_split(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 2126, in _validate_shuffle_split
    raise ValueError(
ValueError: With n_samples=1, test_size=None and train_size=0.9230769230769231, the resulting train set will be empty. Adjust any of the aforementioned parameters.

2023-04-25 20:32:21,639:INFO:_master_model_container: 0
2023-04-25 20:32:21,639:INFO:_display_container: 2
2023-04-25 20:32:21,639:INFO:[]
2023-04-25 20:32:21,639:INFO:compare_models() successfully completed......................................
2023-04-25 20:41:40,981:INFO:Initializing compare_models()
2023-04-25 20:41:40,981:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A185082EF0>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001A185082EF0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-04-25 20:41:40,981:INFO:Checking exceptions
2023-04-25 20:41:40,989:INFO:Preparing display monitor
2023-04-25 20:41:41,029:INFO:Initializing Linear Regression
2023-04-25 20:41:41,029:INFO:Total runtime is 0.0 minutes
2023-04-25 20:41:41,037:INFO:SubProcess create_model() called ==================================
2023-04-25 20:41:41,037:INFO:Initializing create_model()
2023-04-25 20:41:41,037:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A185082EF0>, estimator=lr, fold=ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A1865D37C0>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 20:41:41,037:INFO:Checking exceptions
2023-04-25 20:41:41,037:INFO:Importing libraries
2023-04-25 20:41:41,037:INFO:Copying training dataset
2023-04-25 20:41:41,045:INFO:Defining folds
2023-04-25 20:41:41,045:INFO:Declaring metric variables
2023-04-25 20:41:41,057:INFO:Importing untrained model
2023-04-25 20:41:41,065:INFO:Linear Regression Imported successfully
2023-04-25 20:41:41,092:INFO:Starting cross validation
2023-04-25 20:41:41,098:INFO:Cross validating with ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), n_jobs=1
2023-04-25 20:41:41,098:WARNING:create_model() for lr raised an exception or returned all 0.0, trying without fit_kwargs:
2023-04-25 20:41:41,098:WARNING:Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 862, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in cross_validate
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1085, in __call__
    if self.dispatch_one_batch(iterator):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 873, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in <genexpr>
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1622, in split
    for train, test in self._iter_indices(X, y, groups):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1730, in _iter_indices
    n_train, n_test = _validate_shuffle_split(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 2126, in _validate_shuffle_split
    raise ValueError(
ValueError: With n_samples=1, test_size=None and train_size=0.9230769230769231, the resulting train set will be empty. Adjust any of the aforementioned parameters.

2023-04-25 20:41:41,098:INFO:Initializing create_model()
2023-04-25 20:41:41,098:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A185082EF0>, estimator=lr, fold=ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A1865D37C0>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 20:41:41,098:INFO:Checking exceptions
2023-04-25 20:41:41,098:INFO:Importing libraries
2023-04-25 20:41:41,098:INFO:Copying training dataset
2023-04-25 20:41:41,107:INFO:Defining folds
2023-04-25 20:41:41,107:INFO:Declaring metric variables
2023-04-25 20:41:41,107:INFO:Importing untrained model
2023-04-25 20:41:41,114:INFO:Linear Regression Imported successfully
2023-04-25 20:41:41,122:INFO:Starting cross validation
2023-04-25 20:41:41,130:INFO:Cross validating with ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), n_jobs=1
2023-04-25 20:41:41,130:ERROR:create_model() for lr raised an exception or returned all 0.0:
2023-04-25 20:41:41,130:ERROR:Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 862, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in cross_validate
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1085, in __call__
    if self.dispatch_one_batch(iterator):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 873, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in <genexpr>
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1622, in split
    for train, test in self._iter_indices(X, y, groups):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1730, in _iter_indices
    n_train, n_test = _validate_shuffle_split(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 2126, in _validate_shuffle_split
    raise ValueError(
ValueError: With n_samples=1, test_size=None and train_size=0.9230769230769231, the resulting train set will be empty. Adjust any of the aforementioned parameters.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 862, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 810, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in cross_validate
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1085, in __call__
    if self.dispatch_one_batch(iterator):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 873, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in <genexpr>
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1622, in split
    for train, test in self._iter_indices(X, y, groups):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1730, in _iter_indices
    n_train, n_test = _validate_shuffle_split(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 2126, in _validate_shuffle_split
    raise ValueError(
ValueError: With n_samples=1, test_size=None and train_size=0.9230769230769231, the resulting train set will be empty. Adjust any of the aforementioned parameters.

2023-04-25 20:41:41,181:INFO:Initializing Lasso Regression
2023-04-25 20:41:41,181:INFO:Total runtime is 0.002534512678782145 minutes
2023-04-25 20:41:41,181:INFO:SubProcess create_model() called ==================================
2023-04-25 20:41:41,181:INFO:Initializing create_model()
2023-04-25 20:41:41,181:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A185082EF0>, estimator=lasso, fold=ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A1865D37C0>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 20:41:41,181:INFO:Checking exceptions
2023-04-25 20:41:41,181:INFO:Importing libraries
2023-04-25 20:41:41,181:INFO:Copying training dataset
2023-04-25 20:41:41,195:INFO:Defining folds
2023-04-25 20:41:41,195:INFO:Declaring metric variables
2023-04-25 20:41:41,202:INFO:Importing untrained model
2023-04-25 20:41:41,210:INFO:Lasso Regression Imported successfully
2023-04-25 20:41:41,218:INFO:Starting cross validation
2023-04-25 20:41:41,227:INFO:Cross validating with ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), n_jobs=1
2023-04-25 20:41:41,227:WARNING:create_model() for lasso raised an exception or returned all 0.0, trying without fit_kwargs:
2023-04-25 20:41:41,227:WARNING:Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 862, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in cross_validate
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1085, in __call__
    if self.dispatch_one_batch(iterator):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 873, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in <genexpr>
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1622, in split
    for train, test in self._iter_indices(X, y, groups):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1730, in _iter_indices
    n_train, n_test = _validate_shuffle_split(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 2126, in _validate_shuffle_split
    raise ValueError(
ValueError: With n_samples=1, test_size=None and train_size=0.9230769230769231, the resulting train set will be empty. Adjust any of the aforementioned parameters.

2023-04-25 20:41:41,227:INFO:Initializing create_model()
2023-04-25 20:41:41,227:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A185082EF0>, estimator=lasso, fold=ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A1865D37C0>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 20:41:41,227:INFO:Checking exceptions
2023-04-25 20:41:41,227:INFO:Importing libraries
2023-04-25 20:41:41,227:INFO:Copying training dataset
2023-04-25 20:41:41,234:INFO:Defining folds
2023-04-25 20:41:41,234:INFO:Declaring metric variables
2023-04-25 20:41:41,242:INFO:Importing untrained model
2023-04-25 20:41:41,250:INFO:Lasso Regression Imported successfully
2023-04-25 20:41:41,264:INFO:Starting cross validation
2023-04-25 20:41:41,272:INFO:Cross validating with ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), n_jobs=1
2023-04-25 20:41:41,272:ERROR:create_model() for lasso raised an exception or returned all 0.0:
2023-04-25 20:41:41,272:ERROR:Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 862, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in cross_validate
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1085, in __call__
    if self.dispatch_one_batch(iterator):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 873, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in <genexpr>
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1622, in split
    for train, test in self._iter_indices(X, y, groups):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1730, in _iter_indices
    n_train, n_test = _validate_shuffle_split(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 2126, in _validate_shuffle_split
    raise ValueError(
ValueError: With n_samples=1, test_size=None and train_size=0.9230769230769231, the resulting train set will be empty. Adjust any of the aforementioned parameters.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 862, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 810, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in cross_validate
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1085, in __call__
    if self.dispatch_one_batch(iterator):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 873, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in <genexpr>
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1622, in split
    for train, test in self._iter_indices(X, y, groups):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1730, in _iter_indices
    n_train, n_test = _validate_shuffle_split(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 2126, in _validate_shuffle_split
    raise ValueError(
ValueError: With n_samples=1, test_size=None and train_size=0.9230769230769231, the resulting train set will be empty. Adjust any of the aforementioned parameters.

2023-04-25 20:41:41,308:INFO:Initializing Ridge Regression
2023-04-25 20:41:41,308:INFO:Total runtime is 0.004652043183644613 minutes
2023-04-25 20:41:41,308:INFO:SubProcess create_model() called ==================================
2023-04-25 20:41:41,308:INFO:Initializing create_model()
2023-04-25 20:41:41,308:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A185082EF0>, estimator=ridge, fold=ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A1865D37C0>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 20:41:41,308:INFO:Checking exceptions
2023-04-25 20:41:41,308:INFO:Importing libraries
2023-04-25 20:41:41,308:INFO:Copying training dataset
2023-04-25 20:41:41,323:INFO:Defining folds
2023-04-25 20:41:41,323:INFO:Declaring metric variables
2023-04-25 20:41:41,323:INFO:Importing untrained model
2023-04-25 20:41:41,334:INFO:Ridge Regression Imported successfully
2023-04-25 20:41:41,348:INFO:Starting cross validation
2023-04-25 20:41:41,348:INFO:Cross validating with ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), n_jobs=1
2023-04-25 20:41:41,348:WARNING:create_model() for ridge raised an exception or returned all 0.0, trying without fit_kwargs:
2023-04-25 20:41:41,356:WARNING:Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 862, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in cross_validate
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1085, in __call__
    if self.dispatch_one_batch(iterator):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 873, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in <genexpr>
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1622, in split
    for train, test in self._iter_indices(X, y, groups):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1730, in _iter_indices
    n_train, n_test = _validate_shuffle_split(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 2126, in _validate_shuffle_split
    raise ValueError(
ValueError: With n_samples=1, test_size=None and train_size=0.9230769230769231, the resulting train set will be empty. Adjust any of the aforementioned parameters.

2023-04-25 20:41:41,356:INFO:Initializing create_model()
2023-04-25 20:41:41,356:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A185082EF0>, estimator=ridge, fold=ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A1865D37C0>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 20:41:41,356:INFO:Checking exceptions
2023-04-25 20:41:41,356:INFO:Importing libraries
2023-04-25 20:41:41,356:INFO:Copying training dataset
2023-04-25 20:41:41,365:INFO:Defining folds
2023-04-25 20:41:41,365:INFO:Declaring metric variables
2023-04-25 20:41:41,369:INFO:Importing untrained model
2023-04-25 20:41:41,377:INFO:Ridge Regression Imported successfully
2023-04-25 20:41:41,390:INFO:Starting cross validation
2023-04-25 20:41:41,390:INFO:Cross validating with ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), n_jobs=1
2023-04-25 20:41:41,390:ERROR:create_model() for ridge raised an exception or returned all 0.0:
2023-04-25 20:41:41,390:ERROR:Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 862, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in cross_validate
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1085, in __call__
    if self.dispatch_one_batch(iterator):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 873, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in <genexpr>
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1622, in split
    for train, test in self._iter_indices(X, y, groups):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1730, in _iter_indices
    n_train, n_test = _validate_shuffle_split(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 2126, in _validate_shuffle_split
    raise ValueError(
ValueError: With n_samples=1, test_size=None and train_size=0.9230769230769231, the resulting train set will be empty. Adjust any of the aforementioned parameters.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 862, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 810, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in cross_validate
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1085, in __call__
    if self.dispatch_one_batch(iterator):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 873, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in <genexpr>
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1622, in split
    for train, test in self._iter_indices(X, y, groups):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1730, in _iter_indices
    n_train, n_test = _validate_shuffle_split(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 2126, in _validate_shuffle_split
    raise ValueError(
ValueError: With n_samples=1, test_size=None and train_size=0.9230769230769231, the resulting train set will be empty. Adjust any of the aforementioned parameters.

2023-04-25 20:41:41,425:INFO:Initializing Elastic Net
2023-04-25 20:41:41,425:INFO:Total runtime is 0.006589742501576742 minutes
2023-04-25 20:41:41,440:INFO:SubProcess create_model() called ==================================
2023-04-25 20:41:41,440:INFO:Initializing create_model()
2023-04-25 20:41:41,440:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A185082EF0>, estimator=en, fold=ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A1865D37C0>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 20:41:41,440:INFO:Checking exceptions
2023-04-25 20:41:41,440:INFO:Importing libraries
2023-04-25 20:41:41,440:INFO:Copying training dataset
2023-04-25 20:41:41,445:INFO:Defining folds
2023-04-25 20:41:41,445:INFO:Declaring metric variables
2023-04-25 20:41:41,450:INFO:Importing untrained model
2023-04-25 20:41:41,450:INFO:Elastic Net Imported successfully
2023-04-25 20:41:41,466:INFO:Starting cross validation
2023-04-25 20:41:41,472:INFO:Cross validating with ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), n_jobs=1
2023-04-25 20:41:41,473:WARNING:create_model() for en raised an exception or returned all 0.0, trying without fit_kwargs:
2023-04-25 20:41:41,473:WARNING:Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 862, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in cross_validate
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1085, in __call__
    if self.dispatch_one_batch(iterator):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 873, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in <genexpr>
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1622, in split
    for train, test in self._iter_indices(X, y, groups):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1730, in _iter_indices
    n_train, n_test = _validate_shuffle_split(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 2126, in _validate_shuffle_split
    raise ValueError(
ValueError: With n_samples=1, test_size=None and train_size=0.9230769230769231, the resulting train set will be empty. Adjust any of the aforementioned parameters.

2023-04-25 20:41:41,473:INFO:Initializing create_model()
2023-04-25 20:41:41,473:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A185082EF0>, estimator=en, fold=ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A1865D37C0>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 20:41:41,473:INFO:Checking exceptions
2023-04-25 20:41:41,473:INFO:Importing libraries
2023-04-25 20:41:41,473:INFO:Copying training dataset
2023-04-25 20:41:41,484:INFO:Defining folds
2023-04-25 20:41:41,484:INFO:Declaring metric variables
2023-04-25 20:41:41,493:INFO:Importing untrained model
2023-04-25 20:41:41,493:INFO:Elastic Net Imported successfully
2023-04-25 20:41:41,507:INFO:Starting cross validation
2023-04-25 20:41:41,507:INFO:Cross validating with ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), n_jobs=1
2023-04-25 20:41:41,515:ERROR:create_model() for en raised an exception or returned all 0.0:
2023-04-25 20:41:41,519:ERROR:Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 862, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in cross_validate
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1085, in __call__
    if self.dispatch_one_batch(iterator):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 873, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in <genexpr>
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1622, in split
    for train, test in self._iter_indices(X, y, groups):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1730, in _iter_indices
    n_train, n_test = _validate_shuffle_split(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 2126, in _validate_shuffle_split
    raise ValueError(
ValueError: With n_samples=1, test_size=None and train_size=0.9230769230769231, the resulting train set will be empty. Adjust any of the aforementioned parameters.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 862, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 810, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in cross_validate
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1085, in __call__
    if self.dispatch_one_batch(iterator):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 873, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in <genexpr>
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1622, in split
    for train, test in self._iter_indices(X, y, groups):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1730, in _iter_indices
    n_train, n_test = _validate_shuffle_split(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 2126, in _validate_shuffle_split
    raise ValueError(
ValueError: With n_samples=1, test_size=None and train_size=0.9230769230769231, the resulting train set will be empty. Adjust any of the aforementioned parameters.

2023-04-25 20:41:41,557:INFO:Initializing Least Angle Regression
2023-04-25 20:41:41,557:INFO:Total runtime is 0.008791176478068034 minutes
2023-04-25 20:41:41,557:INFO:SubProcess create_model() called ==================================
2023-04-25 20:41:41,557:INFO:Initializing create_model()
2023-04-25 20:41:41,557:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A185082EF0>, estimator=lar, fold=ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A1865D37C0>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 20:41:41,557:INFO:Checking exceptions
2023-04-25 20:41:41,557:INFO:Importing libraries
2023-04-25 20:41:41,564:INFO:Copying training dataset
2023-04-25 20:41:41,567:INFO:Defining folds
2023-04-25 20:41:41,567:INFO:Declaring metric variables
2023-04-25 20:41:41,567:INFO:Importing untrained model
2023-04-25 20:41:41,577:INFO:Least Angle Regression Imported successfully
2023-04-25 20:41:41,591:INFO:Starting cross validation
2023-04-25 20:41:41,599:INFO:Cross validating with ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), n_jobs=1
2023-04-25 20:41:41,599:WARNING:create_model() for lar raised an exception or returned all 0.0, trying without fit_kwargs:
2023-04-25 20:41:41,599:WARNING:Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 862, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in cross_validate
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1085, in __call__
    if self.dispatch_one_batch(iterator):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 873, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in <genexpr>
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1622, in split
    for train, test in self._iter_indices(X, y, groups):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1730, in _iter_indices
    n_train, n_test = _validate_shuffle_split(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 2126, in _validate_shuffle_split
    raise ValueError(
ValueError: With n_samples=1, test_size=None and train_size=0.9230769230769231, the resulting train set will be empty. Adjust any of the aforementioned parameters.

2023-04-25 20:41:41,599:INFO:Initializing create_model()
2023-04-25 20:41:41,599:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A185082EF0>, estimator=lar, fold=ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A1865D37C0>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 20:41:41,599:INFO:Checking exceptions
2023-04-25 20:41:41,599:INFO:Importing libraries
2023-04-25 20:41:41,599:INFO:Copying training dataset
2023-04-25 20:41:41,604:INFO:Defining folds
2023-04-25 20:41:41,604:INFO:Declaring metric variables
2023-04-25 20:41:41,615:INFO:Importing untrained model
2023-04-25 20:41:41,618:INFO:Least Angle Regression Imported successfully
2023-04-25 20:41:41,634:INFO:Starting cross validation
2023-04-25 20:41:41,634:INFO:Cross validating with ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), n_jobs=1
2023-04-25 20:41:41,642:ERROR:create_model() for lar raised an exception or returned all 0.0:
2023-04-25 20:41:41,642:ERROR:Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 862, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in cross_validate
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1085, in __call__
    if self.dispatch_one_batch(iterator):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 873, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in <genexpr>
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1622, in split
    for train, test in self._iter_indices(X, y, groups):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1730, in _iter_indices
    n_train, n_test = _validate_shuffle_split(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 2126, in _validate_shuffle_split
    raise ValueError(
ValueError: With n_samples=1, test_size=None and train_size=0.9230769230769231, the resulting train set will be empty. Adjust any of the aforementioned parameters.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 862, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 810, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in cross_validate
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1085, in __call__
    if self.dispatch_one_batch(iterator):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 873, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in <genexpr>
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1622, in split
    for train, test in self._iter_indices(X, y, groups):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1730, in _iter_indices
    n_train, n_test = _validate_shuffle_split(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 2126, in _validate_shuffle_split
    raise ValueError(
ValueError: With n_samples=1, test_size=None and train_size=0.9230769230769231, the resulting train set will be empty. Adjust any of the aforementioned parameters.

2023-04-25 20:41:41,679:INFO:Initializing Lasso Least Angle Regression
2023-04-25 20:41:41,679:INFO:Total runtime is 0.010831546783447266 minutes
2023-04-25 20:41:41,679:INFO:SubProcess create_model() called ==================================
2023-04-25 20:41:41,679:INFO:Initializing create_model()
2023-04-25 20:41:41,687:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A185082EF0>, estimator=llar, fold=ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A1865D37C0>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 20:41:41,687:INFO:Checking exceptions
2023-04-25 20:41:41,687:INFO:Importing libraries
2023-04-25 20:41:41,687:INFO:Copying training dataset
2023-04-25 20:41:41,687:INFO:Defining folds
2023-04-25 20:41:41,687:INFO:Declaring metric variables
2023-04-25 20:41:41,695:INFO:Importing untrained model
2023-04-25 20:41:41,703:INFO:Lasso Least Angle Regression Imported successfully
2023-04-25 20:41:41,715:INFO:Starting cross validation
2023-04-25 20:41:41,715:INFO:Cross validating with ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), n_jobs=1
2023-04-25 20:41:41,724:WARNING:create_model() for llar raised an exception or returned all 0.0, trying without fit_kwargs:
2023-04-25 20:41:41,724:WARNING:Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 862, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in cross_validate
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1085, in __call__
    if self.dispatch_one_batch(iterator):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 873, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in <genexpr>
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1622, in split
    for train, test in self._iter_indices(X, y, groups):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1730, in _iter_indices
    n_train, n_test = _validate_shuffle_split(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 2126, in _validate_shuffle_split
    raise ValueError(
ValueError: With n_samples=1, test_size=None and train_size=0.9230769230769231, the resulting train set will be empty. Adjust any of the aforementioned parameters.

2023-04-25 20:41:41,724:INFO:Initializing create_model()
2023-04-25 20:41:41,724:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A185082EF0>, estimator=llar, fold=ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A1865D37C0>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 20:41:41,724:INFO:Checking exceptions
2023-04-25 20:41:41,724:INFO:Importing libraries
2023-04-25 20:41:41,724:INFO:Copying training dataset
2023-04-25 20:41:41,729:INFO:Defining folds
2023-04-25 20:41:41,729:INFO:Declaring metric variables
2023-04-25 20:41:41,736:INFO:Importing untrained model
2023-04-25 20:41:41,743:INFO:Lasso Least Angle Regression Imported successfully
2023-04-25 20:41:41,760:INFO:Starting cross validation
2023-04-25 20:41:41,760:INFO:Cross validating with ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), n_jobs=1
2023-04-25 20:41:41,760:ERROR:create_model() for llar raised an exception or returned all 0.0:
2023-04-25 20:41:41,765:ERROR:Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 862, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in cross_validate
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1085, in __call__
    if self.dispatch_one_batch(iterator):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 873, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in <genexpr>
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1622, in split
    for train, test in self._iter_indices(X, y, groups):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1730, in _iter_indices
    n_train, n_test = _validate_shuffle_split(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 2126, in _validate_shuffle_split
    raise ValueError(
ValueError: With n_samples=1, test_size=None and train_size=0.9230769230769231, the resulting train set will be empty. Adjust any of the aforementioned parameters.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 862, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 810, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in cross_validate
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1085, in __call__
    if self.dispatch_one_batch(iterator):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 873, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in <genexpr>
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1622, in split
    for train, test in self._iter_indices(X, y, groups):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1730, in _iter_indices
    n_train, n_test = _validate_shuffle_split(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 2126, in _validate_shuffle_split
    raise ValueError(
ValueError: With n_samples=1, test_size=None and train_size=0.9230769230769231, the resulting train set will be empty. Adjust any of the aforementioned parameters.

2023-04-25 20:41:41,796:INFO:Initializing Orthogonal Matching Pursuit
2023-04-25 20:41:41,796:INFO:Total runtime is 0.01278280019760132 minutes
2023-04-25 20:41:41,804:INFO:SubProcess create_model() called ==================================
2023-04-25 20:41:41,804:INFO:Initializing create_model()
2023-04-25 20:41:41,804:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A185082EF0>, estimator=omp, fold=ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A1865D37C0>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 20:41:41,804:INFO:Checking exceptions
2023-04-25 20:41:41,804:INFO:Importing libraries
2023-04-25 20:41:41,804:INFO:Copying training dataset
2023-04-25 20:41:41,811:INFO:Defining folds
2023-04-25 20:41:41,811:INFO:Declaring metric variables
2023-04-25 20:41:41,819:INFO:Importing untrained model
2023-04-25 20:41:41,819:INFO:Orthogonal Matching Pursuit Imported successfully
2023-04-25 20:41:41,833:INFO:Starting cross validation
2023-04-25 20:41:41,833:INFO:Cross validating with ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), n_jobs=1
2023-04-25 20:41:41,843:WARNING:create_model() for omp raised an exception or returned all 0.0, trying without fit_kwargs:
2023-04-25 20:41:41,843:WARNING:Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 862, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in cross_validate
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1085, in __call__
    if self.dispatch_one_batch(iterator):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 873, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in <genexpr>
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1622, in split
    for train, test in self._iter_indices(X, y, groups):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1730, in _iter_indices
    n_train, n_test = _validate_shuffle_split(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 2126, in _validate_shuffle_split
    raise ValueError(
ValueError: With n_samples=1, test_size=None and train_size=0.9230769230769231, the resulting train set will be empty. Adjust any of the aforementioned parameters.

2023-04-25 20:41:41,843:INFO:Initializing create_model()
2023-04-25 20:41:41,843:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A185082EF0>, estimator=omp, fold=ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A1865D37C0>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 20:41:41,843:INFO:Checking exceptions
2023-04-25 20:41:41,843:INFO:Importing libraries
2023-04-25 20:41:41,843:INFO:Copying training dataset
2023-04-25 20:41:41,848:INFO:Defining folds
2023-04-25 20:41:41,848:INFO:Declaring metric variables
2023-04-25 20:41:41,859:INFO:Importing untrained model
2023-04-25 20:41:41,865:INFO:Orthogonal Matching Pursuit Imported successfully
2023-04-25 20:41:41,875:INFO:Starting cross validation
2023-04-25 20:41:41,875:INFO:Cross validating with ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), n_jobs=1
2023-04-25 20:41:41,875:ERROR:create_model() for omp raised an exception or returned all 0.0:
2023-04-25 20:41:41,875:ERROR:Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 862, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in cross_validate
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1085, in __call__
    if self.dispatch_one_batch(iterator):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 873, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in <genexpr>
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1622, in split
    for train, test in self._iter_indices(X, y, groups):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1730, in _iter_indices
    n_train, n_test = _validate_shuffle_split(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 2126, in _validate_shuffle_split
    raise ValueError(
ValueError: With n_samples=1, test_size=None and train_size=0.9230769230769231, the resulting train set will be empty. Adjust any of the aforementioned parameters.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 862, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 810, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in cross_validate
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1085, in __call__
    if self.dispatch_one_batch(iterator):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 873, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in <genexpr>
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1622, in split
    for train, test in self._iter_indices(X, y, groups):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1730, in _iter_indices
    n_train, n_test = _validate_shuffle_split(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 2126, in _validate_shuffle_split
    raise ValueError(
ValueError: With n_samples=1, test_size=None and train_size=0.9230769230769231, the resulting train set will be empty. Adjust any of the aforementioned parameters.

2023-04-25 20:41:41,912:INFO:Initializing Bayesian Ridge
2023-04-25 20:41:41,912:INFO:Total runtime is 0.014716609319051107 minutes
2023-04-25 20:41:41,912:INFO:SubProcess create_model() called ==================================
2023-04-25 20:41:41,912:INFO:Initializing create_model()
2023-04-25 20:41:41,912:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A185082EF0>, estimator=br, fold=ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A1865D37C0>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 20:41:41,912:INFO:Checking exceptions
2023-04-25 20:41:41,912:INFO:Importing libraries
2023-04-25 20:41:41,912:INFO:Copying training dataset
2023-04-25 20:41:41,929:INFO:Defining folds
2023-04-25 20:41:41,929:INFO:Declaring metric variables
2023-04-25 20:41:41,937:INFO:Importing untrained model
2023-04-25 20:41:41,937:INFO:Bayesian Ridge Imported successfully
2023-04-25 20:41:41,953:INFO:Starting cross validation
2023-04-25 20:41:41,953:INFO:Cross validating with ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), n_jobs=1
2023-04-25 20:41:41,953:WARNING:create_model() for br raised an exception or returned all 0.0, trying without fit_kwargs:
2023-04-25 20:41:41,961:WARNING:Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 862, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in cross_validate
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1085, in __call__
    if self.dispatch_one_batch(iterator):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 873, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in <genexpr>
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1622, in split
    for train, test in self._iter_indices(X, y, groups):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1730, in _iter_indices
    n_train, n_test = _validate_shuffle_split(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 2126, in _validate_shuffle_split
    raise ValueError(
ValueError: With n_samples=1, test_size=None and train_size=0.9230769230769231, the resulting train set will be empty. Adjust any of the aforementioned parameters.

2023-04-25 20:41:41,961:INFO:Initializing create_model()
2023-04-25 20:41:41,961:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A185082EF0>, estimator=br, fold=ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A1865D37C0>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 20:41:41,961:INFO:Checking exceptions
2023-04-25 20:41:41,961:INFO:Importing libraries
2023-04-25 20:41:41,961:INFO:Copying training dataset
2023-04-25 20:41:41,967:INFO:Defining folds
2023-04-25 20:41:41,967:INFO:Declaring metric variables
2023-04-25 20:41:41,975:INFO:Importing untrained model
2023-04-25 20:41:41,975:INFO:Bayesian Ridge Imported successfully
2023-04-25 20:41:41,991:INFO:Starting cross validation
2023-04-25 20:41:41,991:INFO:Cross validating with ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), n_jobs=1
2023-04-25 20:41:41,991:ERROR:create_model() for br raised an exception or returned all 0.0:
2023-04-25 20:41:41,999:ERROR:Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 862, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in cross_validate
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1085, in __call__
    if self.dispatch_one_batch(iterator):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 873, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in <genexpr>
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1622, in split
    for train, test in self._iter_indices(X, y, groups):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1730, in _iter_indices
    n_train, n_test = _validate_shuffle_split(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 2126, in _validate_shuffle_split
    raise ValueError(
ValueError: With n_samples=1, test_size=None and train_size=0.9230769230769231, the resulting train set will be empty. Adjust any of the aforementioned parameters.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 862, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 810, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in cross_validate
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1085, in __call__
    if self.dispatch_one_batch(iterator):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 873, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in <genexpr>
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1622, in split
    for train, test in self._iter_indices(X, y, groups):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1730, in _iter_indices
    n_train, n_test = _validate_shuffle_split(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 2126, in _validate_shuffle_split
    raise ValueError(
ValueError: With n_samples=1, test_size=None and train_size=0.9230769230769231, the resulting train set will be empty. Adjust any of the aforementioned parameters.

2023-04-25 20:41:42,031:INFO:Initializing Passive Aggressive Regressor
2023-04-25 20:41:42,031:INFO:Total runtime is 0.01670332352320353 minutes
2023-04-25 20:41:42,031:INFO:SubProcess create_model() called ==================================
2023-04-25 20:41:42,031:INFO:Initializing create_model()
2023-04-25 20:41:42,031:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A185082EF0>, estimator=par, fold=ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A1865D37C0>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 20:41:42,031:INFO:Checking exceptions
2023-04-25 20:41:42,031:INFO:Importing libraries
2023-04-25 20:41:42,031:INFO:Copying training dataset
2023-04-25 20:41:42,048:INFO:Defining folds
2023-04-25 20:41:42,048:INFO:Declaring metric variables
2023-04-25 20:41:42,053:INFO:Importing untrained model
2023-04-25 20:41:42,065:INFO:Passive Aggressive Regressor Imported successfully
2023-04-25 20:41:42,076:INFO:Starting cross validation
2023-04-25 20:41:42,076:INFO:Cross validating with ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), n_jobs=1
2023-04-25 20:41:42,076:WARNING:create_model() for par raised an exception or returned all 0.0, trying without fit_kwargs:
2023-04-25 20:41:42,084:WARNING:Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 862, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in cross_validate
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1085, in __call__
    if self.dispatch_one_batch(iterator):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 873, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in <genexpr>
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1622, in split
    for train, test in self._iter_indices(X, y, groups):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1730, in _iter_indices
    n_train, n_test = _validate_shuffle_split(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 2126, in _validate_shuffle_split
    raise ValueError(
ValueError: With n_samples=1, test_size=None and train_size=0.9230769230769231, the resulting train set will be empty. Adjust any of the aforementioned parameters.

2023-04-25 20:41:42,084:INFO:Initializing create_model()
2023-04-25 20:41:42,084:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A185082EF0>, estimator=par, fold=ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A1865D37C0>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 20:41:42,084:INFO:Checking exceptions
2023-04-25 20:41:42,084:INFO:Importing libraries
2023-04-25 20:41:42,084:INFO:Copying training dataset
2023-04-25 20:41:42,092:INFO:Defining folds
2023-04-25 20:41:42,092:INFO:Declaring metric variables
2023-04-25 20:41:42,101:INFO:Importing untrained model
2023-04-25 20:41:42,107:INFO:Passive Aggressive Regressor Imported successfully
2023-04-25 20:41:42,126:INFO:Starting cross validation
2023-04-25 20:41:42,126:INFO:Cross validating with ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), n_jobs=1
2023-04-25 20:41:42,136:ERROR:create_model() for par raised an exception or returned all 0.0:
2023-04-25 20:41:42,136:ERROR:Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 862, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in cross_validate
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1085, in __call__
    if self.dispatch_one_batch(iterator):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 873, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in <genexpr>
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1622, in split
    for train, test in self._iter_indices(X, y, groups):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1730, in _iter_indices
    n_train, n_test = _validate_shuffle_split(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 2126, in _validate_shuffle_split
    raise ValueError(
ValueError: With n_samples=1, test_size=None and train_size=0.9230769230769231, the resulting train set will be empty. Adjust any of the aforementioned parameters.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 862, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 810, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in cross_validate
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1085, in __call__
    if self.dispatch_one_batch(iterator):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 873, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in <genexpr>
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1622, in split
    for train, test in self._iter_indices(X, y, groups):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1730, in _iter_indices
    n_train, n_test = _validate_shuffle_split(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 2126, in _validate_shuffle_split
    raise ValueError(
ValueError: With n_samples=1, test_size=None and train_size=0.9230769230769231, the resulting train set will be empty. Adjust any of the aforementioned parameters.

2023-04-25 20:41:42,179:INFO:Initializing Huber Regressor
2023-04-25 20:41:42,179:INFO:Total runtime is 0.01916030248006185 minutes
2023-04-25 20:41:42,179:INFO:SubProcess create_model() called ==================================
2023-04-25 20:41:42,179:INFO:Initializing create_model()
2023-04-25 20:41:42,179:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A185082EF0>, estimator=huber, fold=ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A1865D37C0>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 20:41:42,179:INFO:Checking exceptions
2023-04-25 20:41:42,179:INFO:Importing libraries
2023-04-25 20:41:42,179:INFO:Copying training dataset
2023-04-25 20:41:42,191:INFO:Defining folds
2023-04-25 20:41:42,191:INFO:Declaring metric variables
2023-04-25 20:41:42,203:INFO:Importing untrained model
2023-04-25 20:41:42,208:INFO:Huber Regressor Imported successfully
2023-04-25 20:41:42,229:INFO:Starting cross validation
2023-04-25 20:41:42,229:INFO:Cross validating with ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), n_jobs=1
2023-04-25 20:41:42,229:WARNING:create_model() for huber raised an exception or returned all 0.0, trying without fit_kwargs:
2023-04-25 20:41:42,229:WARNING:Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 862, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in cross_validate
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1085, in __call__
    if self.dispatch_one_batch(iterator):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 873, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in <genexpr>
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1622, in split
    for train, test in self._iter_indices(X, y, groups):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1730, in _iter_indices
    n_train, n_test = _validate_shuffle_split(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 2126, in _validate_shuffle_split
    raise ValueError(
ValueError: With n_samples=1, test_size=None and train_size=0.9230769230769231, the resulting train set will be empty. Adjust any of the aforementioned parameters.

2023-04-25 20:41:42,229:INFO:Initializing create_model()
2023-04-25 20:41:42,229:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A185082EF0>, estimator=huber, fold=ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A1865D37C0>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 20:41:42,229:INFO:Checking exceptions
2023-04-25 20:41:42,229:INFO:Importing libraries
2023-04-25 20:41:42,229:INFO:Copying training dataset
2023-04-25 20:41:42,243:INFO:Defining folds
2023-04-25 20:41:42,243:INFO:Declaring metric variables
2023-04-25 20:41:42,251:INFO:Importing untrained model
2023-04-25 20:41:42,257:INFO:Huber Regressor Imported successfully
2023-04-25 20:41:42,272:INFO:Starting cross validation
2023-04-25 20:41:42,272:INFO:Cross validating with ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), n_jobs=1
2023-04-25 20:41:42,280:ERROR:create_model() for huber raised an exception or returned all 0.0:
2023-04-25 20:41:42,280:ERROR:Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 862, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in cross_validate
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1085, in __call__
    if self.dispatch_one_batch(iterator):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 873, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in <genexpr>
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1622, in split
    for train, test in self._iter_indices(X, y, groups):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1730, in _iter_indices
    n_train, n_test = _validate_shuffle_split(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 2126, in _validate_shuffle_split
    raise ValueError(
ValueError: With n_samples=1, test_size=None and train_size=0.9230769230769231, the resulting train set will be empty. Adjust any of the aforementioned parameters.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 862, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 810, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in cross_validate
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1085, in __call__
    if self.dispatch_one_batch(iterator):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 873, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in <genexpr>
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1622, in split
    for train, test in self._iter_indices(X, y, groups):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1730, in _iter_indices
    n_train, n_test = _validate_shuffle_split(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 2126, in _validate_shuffle_split
    raise ValueError(
ValueError: With n_samples=1, test_size=None and train_size=0.9230769230769231, the resulting train set will be empty. Adjust any of the aforementioned parameters.

2023-04-25 20:41:42,340:INFO:Initializing K Neighbors Regressor
2023-04-25 20:41:42,340:INFO:Total runtime is 0.02183998425801595 minutes
2023-04-25 20:41:42,348:INFO:SubProcess create_model() called ==================================
2023-04-25 20:41:42,348:INFO:Initializing create_model()
2023-04-25 20:41:42,348:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A185082EF0>, estimator=knn, fold=ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A1865D37C0>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 20:41:42,348:INFO:Checking exceptions
2023-04-25 20:41:42,348:INFO:Importing libraries
2023-04-25 20:41:42,348:INFO:Copying training dataset
2023-04-25 20:41:42,356:INFO:Defining folds
2023-04-25 20:41:42,356:INFO:Declaring metric variables
2023-04-25 20:41:42,368:INFO:Importing untrained model
2023-04-25 20:41:42,376:INFO:K Neighbors Regressor Imported successfully
2023-04-25 20:41:42,388:INFO:Starting cross validation
2023-04-25 20:41:42,388:INFO:Cross validating with ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), n_jobs=1
2023-04-25 20:41:42,396:WARNING:create_model() for knn raised an exception or returned all 0.0, trying without fit_kwargs:
2023-04-25 20:41:42,396:WARNING:Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 862, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in cross_validate
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1085, in __call__
    if self.dispatch_one_batch(iterator):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 873, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in <genexpr>
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1622, in split
    for train, test in self._iter_indices(X, y, groups):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1730, in _iter_indices
    n_train, n_test = _validate_shuffle_split(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 2126, in _validate_shuffle_split
    raise ValueError(
ValueError: With n_samples=1, test_size=None and train_size=0.9230769230769231, the resulting train set will be empty. Adjust any of the aforementioned parameters.

2023-04-25 20:41:42,396:INFO:Initializing create_model()
2023-04-25 20:41:42,396:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A185082EF0>, estimator=knn, fold=ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A1865D37C0>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 20:41:42,396:INFO:Checking exceptions
2023-04-25 20:41:42,396:INFO:Importing libraries
2023-04-25 20:41:42,396:INFO:Copying training dataset
2023-04-25 20:41:42,402:INFO:Defining folds
2023-04-25 20:41:42,402:INFO:Declaring metric variables
2023-04-25 20:41:42,409:INFO:Importing untrained model
2023-04-25 20:41:42,417:INFO:K Neighbors Regressor Imported successfully
2023-04-25 20:41:42,432:INFO:Starting cross validation
2023-04-25 20:41:42,432:INFO:Cross validating with ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), n_jobs=1
2023-04-25 20:41:42,437:ERROR:create_model() for knn raised an exception or returned all 0.0:
2023-04-25 20:41:42,438:ERROR:Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 862, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in cross_validate
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1085, in __call__
    if self.dispatch_one_batch(iterator):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 873, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in <genexpr>
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1622, in split
    for train, test in self._iter_indices(X, y, groups):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1730, in _iter_indices
    n_train, n_test = _validate_shuffle_split(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 2126, in _validate_shuffle_split
    raise ValueError(
ValueError: With n_samples=1, test_size=None and train_size=0.9230769230769231, the resulting train set will be empty. Adjust any of the aforementioned parameters.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 862, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 810, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in cross_validate
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1085, in __call__
    if self.dispatch_one_batch(iterator):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 873, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in <genexpr>
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1622, in split
    for train, test in self._iter_indices(X, y, groups):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1730, in _iter_indices
    n_train, n_test = _validate_shuffle_split(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 2126, in _validate_shuffle_split
    raise ValueError(
ValueError: With n_samples=1, test_size=None and train_size=0.9230769230769231, the resulting train set will be empty. Adjust any of the aforementioned parameters.

2023-04-25 20:41:42,475:INFO:Initializing Decision Tree Regressor
2023-04-25 20:41:42,475:INFO:Total runtime is 0.02409935394922892 minutes
2023-04-25 20:41:42,475:INFO:SubProcess create_model() called ==================================
2023-04-25 20:41:42,475:INFO:Initializing create_model()
2023-04-25 20:41:42,475:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A185082EF0>, estimator=dt, fold=ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A1865D37C0>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 20:41:42,475:INFO:Checking exceptions
2023-04-25 20:41:42,475:INFO:Importing libraries
2023-04-25 20:41:42,475:INFO:Copying training dataset
2023-04-25 20:41:42,486:INFO:Defining folds
2023-04-25 20:41:42,486:INFO:Declaring metric variables
2023-04-25 20:41:42,493:INFO:Importing untrained model
2023-04-25 20:41:42,499:INFO:Decision Tree Regressor Imported successfully
2023-04-25 20:41:42,515:INFO:Starting cross validation
2023-04-25 20:41:42,515:INFO:Cross validating with ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), n_jobs=1
2023-04-25 20:41:42,515:WARNING:create_model() for dt raised an exception or returned all 0.0, trying without fit_kwargs:
2023-04-25 20:41:42,515:WARNING:Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 862, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in cross_validate
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1085, in __call__
    if self.dispatch_one_batch(iterator):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 873, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in <genexpr>
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1622, in split
    for train, test in self._iter_indices(X, y, groups):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1730, in _iter_indices
    n_train, n_test = _validate_shuffle_split(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 2126, in _validate_shuffle_split
    raise ValueError(
ValueError: With n_samples=1, test_size=None and train_size=0.9230769230769231, the resulting train set will be empty. Adjust any of the aforementioned parameters.

2023-04-25 20:41:42,515:INFO:Initializing create_model()
2023-04-25 20:41:42,515:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A185082EF0>, estimator=dt, fold=ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A1865D37C0>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 20:41:42,522:INFO:Checking exceptions
2023-04-25 20:41:42,522:INFO:Importing libraries
2023-04-25 20:41:42,522:INFO:Copying training dataset
2023-04-25 20:41:42,527:INFO:Defining folds
2023-04-25 20:41:42,527:INFO:Declaring metric variables
2023-04-25 20:41:42,527:INFO:Importing untrained model
2023-04-25 20:41:42,535:INFO:Decision Tree Regressor Imported successfully
2023-04-25 20:41:42,548:INFO:Starting cross validation
2023-04-25 20:41:42,548:INFO:Cross validating with ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), n_jobs=1
2023-04-25 20:41:42,557:ERROR:create_model() for dt raised an exception or returned all 0.0:
2023-04-25 20:41:42,557:ERROR:Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 862, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in cross_validate
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1085, in __call__
    if self.dispatch_one_batch(iterator):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 873, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in <genexpr>
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1622, in split
    for train, test in self._iter_indices(X, y, groups):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1730, in _iter_indices
    n_train, n_test = _validate_shuffle_split(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 2126, in _validate_shuffle_split
    raise ValueError(
ValueError: With n_samples=1, test_size=None and train_size=0.9230769230769231, the resulting train set will be empty. Adjust any of the aforementioned parameters.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 862, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 810, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in cross_validate
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1085, in __call__
    if self.dispatch_one_batch(iterator):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 873, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in <genexpr>
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1622, in split
    for train, test in self._iter_indices(X, y, groups):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1730, in _iter_indices
    n_train, n_test = _validate_shuffle_split(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 2126, in _validate_shuffle_split
    raise ValueError(
ValueError: With n_samples=1, test_size=None and train_size=0.9230769230769231, the resulting train set will be empty. Adjust any of the aforementioned parameters.

2023-04-25 20:41:42,604:INFO:Initializing Random Forest Regressor
2023-04-25 20:41:42,604:INFO:Total runtime is 0.026245780785878497 minutes
2023-04-25 20:41:42,620:INFO:SubProcess create_model() called ==================================
2023-04-25 20:41:42,620:INFO:Initializing create_model()
2023-04-25 20:41:42,620:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A185082EF0>, estimator=rf, fold=ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A1865D37C0>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 20:41:42,620:INFO:Checking exceptions
2023-04-25 20:41:42,620:INFO:Importing libraries
2023-04-25 20:41:42,620:INFO:Copying training dataset
2023-04-25 20:41:42,626:INFO:Defining folds
2023-04-25 20:41:42,626:INFO:Declaring metric variables
2023-04-25 20:41:42,634:INFO:Importing untrained model
2023-04-25 20:41:42,640:INFO:Random Forest Regressor Imported successfully
2023-04-25 20:41:42,656:INFO:Starting cross validation
2023-04-25 20:41:42,660:INFO:Cross validating with ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), n_jobs=1
2023-04-25 20:41:42,660:WARNING:create_model() for rf raised an exception or returned all 0.0, trying without fit_kwargs:
2023-04-25 20:41:42,664:WARNING:Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 862, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in cross_validate
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1085, in __call__
    if self.dispatch_one_batch(iterator):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 873, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in <genexpr>
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1622, in split
    for train, test in self._iter_indices(X, y, groups):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1730, in _iter_indices
    n_train, n_test = _validate_shuffle_split(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 2126, in _validate_shuffle_split
    raise ValueError(
ValueError: With n_samples=1, test_size=None and train_size=0.9230769230769231, the resulting train set will be empty. Adjust any of the aforementioned parameters.

2023-04-25 20:41:42,664:INFO:Initializing create_model()
2023-04-25 20:41:42,664:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A185082EF0>, estimator=rf, fold=ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A1865D37C0>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 20:41:42,664:INFO:Checking exceptions
2023-04-25 20:41:42,664:INFO:Importing libraries
2023-04-25 20:41:42,664:INFO:Copying training dataset
2023-04-25 20:41:42,666:INFO:Defining folds
2023-04-25 20:41:42,666:INFO:Declaring metric variables
2023-04-25 20:41:42,675:INFO:Importing untrained model
2023-04-25 20:41:42,675:INFO:Random Forest Regressor Imported successfully
2023-04-25 20:41:42,694:INFO:Starting cross validation
2023-04-25 20:41:42,694:INFO:Cross validating with ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), n_jobs=1
2023-04-25 20:41:42,694:ERROR:create_model() for rf raised an exception or returned all 0.0:
2023-04-25 20:41:42,694:ERROR:Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 862, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in cross_validate
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1085, in __call__
    if self.dispatch_one_batch(iterator):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 873, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in <genexpr>
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1622, in split
    for train, test in self._iter_indices(X, y, groups):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1730, in _iter_indices
    n_train, n_test = _validate_shuffle_split(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 2126, in _validate_shuffle_split
    raise ValueError(
ValueError: With n_samples=1, test_size=None and train_size=0.9230769230769231, the resulting train set will be empty. Adjust any of the aforementioned parameters.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 862, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 810, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in cross_validate
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1085, in __call__
    if self.dispatch_one_batch(iterator):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 873, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in <genexpr>
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1622, in split
    for train, test in self._iter_indices(X, y, groups):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1730, in _iter_indices
    n_train, n_test = _validate_shuffle_split(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 2126, in _validate_shuffle_split
    raise ValueError(
ValueError: With n_samples=1, test_size=None and train_size=0.9230769230769231, the resulting train set will be empty. Adjust any of the aforementioned parameters.

2023-04-25 20:41:42,737:INFO:Initializing Extra Trees Regressor
2023-04-25 20:41:42,737:INFO:Total runtime is 0.028470945358276364 minutes
2023-04-25 20:41:42,737:INFO:SubProcess create_model() called ==================================
2023-04-25 20:41:42,737:INFO:Initializing create_model()
2023-04-25 20:41:42,737:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A185082EF0>, estimator=et, fold=ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A1865D37C0>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 20:41:42,737:INFO:Checking exceptions
2023-04-25 20:41:42,737:INFO:Importing libraries
2023-04-25 20:41:42,737:INFO:Copying training dataset
2023-04-25 20:41:42,750:INFO:Defining folds
2023-04-25 20:41:42,750:INFO:Declaring metric variables
2023-04-25 20:41:42,758:INFO:Importing untrained model
2023-04-25 20:41:42,772:INFO:Extra Trees Regressor Imported successfully
2023-04-25 20:41:42,785:INFO:Starting cross validation
2023-04-25 20:41:42,785:INFO:Cross validating with ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), n_jobs=1
2023-04-25 20:41:42,785:WARNING:create_model() for et raised an exception or returned all 0.0, trying without fit_kwargs:
2023-04-25 20:41:42,791:WARNING:Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 862, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in cross_validate
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1085, in __call__
    if self.dispatch_one_batch(iterator):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 873, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in <genexpr>
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1622, in split
    for train, test in self._iter_indices(X, y, groups):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1730, in _iter_indices
    n_train, n_test = _validate_shuffle_split(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 2126, in _validate_shuffle_split
    raise ValueError(
ValueError: With n_samples=1, test_size=None and train_size=0.9230769230769231, the resulting train set will be empty. Adjust any of the aforementioned parameters.

2023-04-25 20:41:42,791:INFO:Initializing create_model()
2023-04-25 20:41:42,791:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A185082EF0>, estimator=et, fold=ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A1865D37C0>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 20:41:42,791:INFO:Checking exceptions
2023-04-25 20:41:42,791:INFO:Importing libraries
2023-04-25 20:41:42,791:INFO:Copying training dataset
2023-04-25 20:41:42,799:INFO:Defining folds
2023-04-25 20:41:42,799:INFO:Declaring metric variables
2023-04-25 20:41:42,799:INFO:Importing untrained model
2023-04-25 20:41:42,813:INFO:Extra Trees Regressor Imported successfully
2023-04-25 20:41:42,823:INFO:Starting cross validation
2023-04-25 20:41:42,823:INFO:Cross validating with ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), n_jobs=1
2023-04-25 20:41:42,829:ERROR:create_model() for et raised an exception or returned all 0.0:
2023-04-25 20:41:42,829:ERROR:Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 862, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in cross_validate
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1085, in __call__
    if self.dispatch_one_batch(iterator):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 873, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in <genexpr>
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1622, in split
    for train, test in self._iter_indices(X, y, groups):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1730, in _iter_indices
    n_train, n_test = _validate_shuffle_split(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 2126, in _validate_shuffle_split
    raise ValueError(
ValueError: With n_samples=1, test_size=None and train_size=0.9230769230769231, the resulting train set will be empty. Adjust any of the aforementioned parameters.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 862, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 810, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in cross_validate
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1085, in __call__
    if self.dispatch_one_batch(iterator):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 873, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in <genexpr>
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1622, in split
    for train, test in self._iter_indices(X, y, groups):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1730, in _iter_indices
    n_train, n_test = _validate_shuffle_split(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 2126, in _validate_shuffle_split
    raise ValueError(
ValueError: With n_samples=1, test_size=None and train_size=0.9230769230769231, the resulting train set will be empty. Adjust any of the aforementioned parameters.

2023-04-25 20:41:42,874:INFO:Initializing AdaBoost Regressor
2023-04-25 20:41:42,874:INFO:Total runtime is 0.030745180447896318 minutes
2023-04-25 20:41:42,883:INFO:SubProcess create_model() called ==================================
2023-04-25 20:41:42,884:INFO:Initializing create_model()
2023-04-25 20:41:42,884:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A185082EF0>, estimator=ada, fold=ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A1865D37C0>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 20:41:42,885:INFO:Checking exceptions
2023-04-25 20:41:42,885:INFO:Importing libraries
2023-04-25 20:41:42,885:INFO:Copying training dataset
2023-04-25 20:41:42,886:INFO:Defining folds
2023-04-25 20:41:42,886:INFO:Declaring metric variables
2023-04-25 20:41:42,899:INFO:Importing untrained model
2023-04-25 20:41:42,899:INFO:AdaBoost Regressor Imported successfully
2023-04-25 20:41:42,923:INFO:Starting cross validation
2023-04-25 20:41:42,926:INFO:Cross validating with ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), n_jobs=1
2023-04-25 20:41:42,926:WARNING:create_model() for ada raised an exception or returned all 0.0, trying without fit_kwargs:
2023-04-25 20:41:42,926:WARNING:Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 862, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in cross_validate
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1085, in __call__
    if self.dispatch_one_batch(iterator):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 873, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in <genexpr>
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1622, in split
    for train, test in self._iter_indices(X, y, groups):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1730, in _iter_indices
    n_train, n_test = _validate_shuffle_split(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 2126, in _validate_shuffle_split
    raise ValueError(
ValueError: With n_samples=1, test_size=None and train_size=0.9230769230769231, the resulting train set will be empty. Adjust any of the aforementioned parameters.

2023-04-25 20:41:42,926:INFO:Initializing create_model()
2023-04-25 20:41:42,926:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A185082EF0>, estimator=ada, fold=ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A1865D37C0>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 20:41:42,926:INFO:Checking exceptions
2023-04-25 20:41:42,926:INFO:Importing libraries
2023-04-25 20:41:42,926:INFO:Copying training dataset
2023-04-25 20:41:42,944:INFO:Defining folds
2023-04-25 20:41:42,944:INFO:Declaring metric variables
2023-04-25 20:41:42,950:INFO:Importing untrained model
2023-04-25 20:41:42,964:INFO:AdaBoost Regressor Imported successfully
2023-04-25 20:41:42,978:INFO:Starting cross validation
2023-04-25 20:41:42,978:INFO:Cross validating with ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), n_jobs=1
2023-04-25 20:41:42,978:ERROR:create_model() for ada raised an exception or returned all 0.0:
2023-04-25 20:41:42,987:ERROR:Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 862, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in cross_validate
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1085, in __call__
    if self.dispatch_one_batch(iterator):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 873, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in <genexpr>
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1622, in split
    for train, test in self._iter_indices(X, y, groups):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1730, in _iter_indices
    n_train, n_test = _validate_shuffle_split(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 2126, in _validate_shuffle_split
    raise ValueError(
ValueError: With n_samples=1, test_size=None and train_size=0.9230769230769231, the resulting train set will be empty. Adjust any of the aforementioned parameters.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 862, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 810, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in cross_validate
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1085, in __call__
    if self.dispatch_one_batch(iterator):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 873, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in <genexpr>
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1622, in split
    for train, test in self._iter_indices(X, y, groups):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1730, in _iter_indices
    n_train, n_test = _validate_shuffle_split(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 2126, in _validate_shuffle_split
    raise ValueError(
ValueError: With n_samples=1, test_size=None and train_size=0.9230769230769231, the resulting train set will be empty. Adjust any of the aforementioned parameters.

2023-04-25 20:41:43,038:INFO:Initializing Gradient Boosting Regressor
2023-04-25 20:41:43,038:INFO:Total runtime is 0.033480163415273025 minutes
2023-04-25 20:41:43,047:INFO:SubProcess create_model() called ==================================
2023-04-25 20:41:43,047:INFO:Initializing create_model()
2023-04-25 20:41:43,047:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A185082EF0>, estimator=gbr, fold=ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A1865D37C0>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 20:41:43,047:INFO:Checking exceptions
2023-04-25 20:41:43,049:INFO:Importing libraries
2023-04-25 20:41:43,049:INFO:Copying training dataset
2023-04-25 20:41:43,058:INFO:Defining folds
2023-04-25 20:41:43,058:INFO:Declaring metric variables
2023-04-25 20:41:43,068:INFO:Importing untrained model
2023-04-25 20:41:43,078:INFO:Gradient Boosting Regressor Imported successfully
2023-04-25 20:41:43,096:INFO:Starting cross validation
2023-04-25 20:41:43,096:INFO:Cross validating with ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), n_jobs=1
2023-04-25 20:41:43,096:WARNING:create_model() for gbr raised an exception or returned all 0.0, trying without fit_kwargs:
2023-04-25 20:41:43,096:WARNING:Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 862, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in cross_validate
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1085, in __call__
    if self.dispatch_one_batch(iterator):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 873, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in <genexpr>
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1622, in split
    for train, test in self._iter_indices(X, y, groups):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1730, in _iter_indices
    n_train, n_test = _validate_shuffle_split(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 2126, in _validate_shuffle_split
    raise ValueError(
ValueError: With n_samples=1, test_size=None and train_size=0.9230769230769231, the resulting train set will be empty. Adjust any of the aforementioned parameters.

2023-04-25 20:41:43,096:INFO:Initializing create_model()
2023-04-25 20:41:43,104:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A185082EF0>, estimator=gbr, fold=ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A1865D37C0>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 20:41:43,104:INFO:Checking exceptions
2023-04-25 20:41:43,104:INFO:Importing libraries
2023-04-25 20:41:43,104:INFO:Copying training dataset
2023-04-25 20:41:43,112:INFO:Defining folds
2023-04-25 20:41:43,115:INFO:Declaring metric variables
2023-04-25 20:41:43,124:INFO:Importing untrained model
2023-04-25 20:41:43,132:INFO:Gradient Boosting Regressor Imported successfully
2023-04-25 20:41:43,152:INFO:Starting cross validation
2023-04-25 20:41:43,152:INFO:Cross validating with ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), n_jobs=1
2023-04-25 20:41:43,152:ERROR:create_model() for gbr raised an exception or returned all 0.0:
2023-04-25 20:41:43,152:ERROR:Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 862, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in cross_validate
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1085, in __call__
    if self.dispatch_one_batch(iterator):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 873, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in <genexpr>
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1622, in split
    for train, test in self._iter_indices(X, y, groups):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1730, in _iter_indices
    n_train, n_test = _validate_shuffle_split(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 2126, in _validate_shuffle_split
    raise ValueError(
ValueError: With n_samples=1, test_size=None and train_size=0.9230769230769231, the resulting train set will be empty. Adjust any of the aforementioned parameters.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 862, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 810, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in cross_validate
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1085, in __call__
    if self.dispatch_one_batch(iterator):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 873, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in <genexpr>
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1622, in split
    for train, test in self._iter_indices(X, y, groups):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1730, in _iter_indices
    n_train, n_test = _validate_shuffle_split(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 2126, in _validate_shuffle_split
    raise ValueError(
ValueError: With n_samples=1, test_size=None and train_size=0.9230769230769231, the resulting train set will be empty. Adjust any of the aforementioned parameters.

2023-04-25 20:41:43,200:INFO:Initializing Light Gradient Boosting Machine
2023-04-25 20:41:43,200:INFO:Total runtime is 0.036184875170389805 minutes
2023-04-25 20:41:43,200:INFO:SubProcess create_model() called ==================================
2023-04-25 20:41:43,200:INFO:Initializing create_model()
2023-04-25 20:41:43,200:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A185082EF0>, estimator=lightgbm, fold=ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A1865D37C0>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 20:41:43,200:INFO:Checking exceptions
2023-04-25 20:41:43,200:INFO:Importing libraries
2023-04-25 20:41:43,200:INFO:Copying training dataset
2023-04-25 20:41:43,214:INFO:Defining folds
2023-04-25 20:41:43,214:INFO:Declaring metric variables
2023-04-25 20:41:43,222:INFO:Importing untrained model
2023-04-25 20:41:43,232:INFO:Light Gradient Boosting Machine Imported successfully
2023-04-25 20:41:43,250:INFO:Starting cross validation
2023-04-25 20:41:43,250:INFO:Cross validating with ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), n_jobs=1
2023-04-25 20:41:43,250:WARNING:create_model() for lightgbm raised an exception or returned all 0.0, trying without fit_kwargs:
2023-04-25 20:41:43,258:WARNING:Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 862, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in cross_validate
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1085, in __call__
    if self.dispatch_one_batch(iterator):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 873, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in <genexpr>
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1622, in split
    for train, test in self._iter_indices(X, y, groups):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1730, in _iter_indices
    n_train, n_test = _validate_shuffle_split(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 2126, in _validate_shuffle_split
    raise ValueError(
ValueError: With n_samples=1, test_size=None and train_size=0.9230769230769231, the resulting train set will be empty. Adjust any of the aforementioned parameters.

2023-04-25 20:41:43,258:INFO:Initializing create_model()
2023-04-25 20:41:43,258:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A185082EF0>, estimator=lightgbm, fold=ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A1865D37C0>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 20:41:43,258:INFO:Checking exceptions
2023-04-25 20:41:43,258:INFO:Importing libraries
2023-04-25 20:41:43,258:INFO:Copying training dataset
2023-04-25 20:41:43,258:INFO:Defining folds
2023-04-25 20:41:43,266:INFO:Declaring metric variables
2023-04-25 20:41:43,273:INFO:Importing untrained model
2023-04-25 20:41:43,276:INFO:Light Gradient Boosting Machine Imported successfully
2023-04-25 20:41:43,290:INFO:Starting cross validation
2023-04-25 20:41:43,290:INFO:Cross validating with ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), n_jobs=1
2023-04-25 20:41:43,290:ERROR:create_model() for lightgbm raised an exception or returned all 0.0:
2023-04-25 20:41:43,298:ERROR:Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 862, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in cross_validate
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1085, in __call__
    if self.dispatch_one_batch(iterator):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 873, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in <genexpr>
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1622, in split
    for train, test in self._iter_indices(X, y, groups):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1730, in _iter_indices
    n_train, n_test = _validate_shuffle_split(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 2126, in _validate_shuffle_split
    raise ValueError(
ValueError: With n_samples=1, test_size=None and train_size=0.9230769230769231, the resulting train set will be empty. Adjust any of the aforementioned parameters.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 862, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 810, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in cross_validate
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1085, in __call__
    if self.dispatch_one_batch(iterator):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 873, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in <genexpr>
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1622, in split
    for train, test in self._iter_indices(X, y, groups):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1730, in _iter_indices
    n_train, n_test = _validate_shuffle_split(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 2126, in _validate_shuffle_split
    raise ValueError(
ValueError: With n_samples=1, test_size=None and train_size=0.9230769230769231, the resulting train set will be empty. Adjust any of the aforementioned parameters.

2023-04-25 20:41:43,334:INFO:Initializing Dummy Regressor
2023-04-25 20:41:43,334:INFO:Total runtime is 0.03841288884480794 minutes
2023-04-25 20:41:43,334:INFO:SubProcess create_model() called ==================================
2023-04-25 20:41:43,334:INFO:Initializing create_model()
2023-04-25 20:41:43,334:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A185082EF0>, estimator=dummy, fold=ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A1865D37C0>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 20:41:43,334:INFO:Checking exceptions
2023-04-25 20:41:43,334:INFO:Importing libraries
2023-04-25 20:41:43,334:INFO:Copying training dataset
2023-04-25 20:41:43,350:INFO:Defining folds
2023-04-25 20:41:43,350:INFO:Declaring metric variables
2023-04-25 20:41:43,361:INFO:Importing untrained model
2023-04-25 20:41:43,367:INFO:Dummy Regressor Imported successfully
2023-04-25 20:41:43,385:INFO:Starting cross validation
2023-04-25 20:41:43,385:INFO:Cross validating with ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), n_jobs=1
2023-04-25 20:41:43,385:WARNING:create_model() for dummy raised an exception or returned all 0.0, trying without fit_kwargs:
2023-04-25 20:41:43,390:WARNING:Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 862, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in cross_validate
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1085, in __call__
    if self.dispatch_one_batch(iterator):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 873, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in <genexpr>
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1622, in split
    for train, test in self._iter_indices(X, y, groups):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1730, in _iter_indices
    n_train, n_test = _validate_shuffle_split(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 2126, in _validate_shuffle_split
    raise ValueError(
ValueError: With n_samples=1, test_size=None and train_size=0.9230769230769231, the resulting train set will be empty. Adjust any of the aforementioned parameters.

2023-04-25 20:41:43,390:INFO:Initializing create_model()
2023-04-25 20:41:43,390:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A185082EF0>, estimator=dummy, fold=ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A1865D37C0>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 20:41:43,390:INFO:Checking exceptions
2023-04-25 20:41:43,390:INFO:Importing libraries
2023-04-25 20:41:43,390:INFO:Copying training dataset
2023-04-25 20:41:43,400:INFO:Defining folds
2023-04-25 20:41:43,400:INFO:Declaring metric variables
2023-04-25 20:41:43,401:INFO:Importing untrained model
2023-04-25 20:41:43,409:INFO:Dummy Regressor Imported successfully
2023-04-25 20:41:43,420:INFO:Starting cross validation
2023-04-25 20:41:43,424:INFO:Cross validating with ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), n_jobs=1
2023-04-25 20:41:43,424:ERROR:create_model() for dummy raised an exception or returned all 0.0:
2023-04-25 20:41:43,429:ERROR:Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 862, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in cross_validate
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1085, in __call__
    if self.dispatch_one_batch(iterator):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 873, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in <genexpr>
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1622, in split
    for train, test in self._iter_indices(X, y, groups):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1730, in _iter_indices
    n_train, n_test = _validate_shuffle_split(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 2126, in _validate_shuffle_split
    raise ValueError(
ValueError: With n_samples=1, test_size=None and train_size=0.9230769230769231, the resulting train set will be empty. Adjust any of the aforementioned parameters.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 862, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 810, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in cross_validate
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1085, in __call__
    if self.dispatch_one_batch(iterator):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 873, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in <genexpr>
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1622, in split
    for train, test in self._iter_indices(X, y, groups):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1730, in _iter_indices
    n_train, n_test = _validate_shuffle_split(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 2126, in _validate_shuffle_split
    raise ValueError(
ValueError: With n_samples=1, test_size=None and train_size=0.9230769230769231, the resulting train set will be empty. Adjust any of the aforementioned parameters.

2023-04-25 20:41:43,472:INFO:_master_model_container: 0
2023-04-25 20:41:43,472:INFO:_display_container: 3
2023-04-25 20:41:43,472:INFO:[]
2023-04-25 20:41:43,472:INFO:compare_models() successfully completed......................................
2023-04-25 20:41:56,943:INFO:PyCaret RegressionExperiment
2023-04-25 20:41:56,943:INFO:Logging name: price_recomm_partial
2023-04-25 20:41:56,943:INFO:ML Usecase: MLUsecase.REGRESSION
2023-04-25 20:41:56,943:INFO:version 3.0.0
2023-04-25 20:41:56,943:INFO:Initializing setup()
2023-04-25 20:41:56,943:INFO:self.USI: fa73
2023-04-25 20:41:56,943:INFO:self._variable_keys: {'logging_param', 'seed', 'log_plots_param', 'exp_name_log', 'exp_id', 'y', 'gpu_param', 'X_test', 'X', '_available_plots', 'y_train', 'target_param', 'n_jobs_param', 'USI', 'pipeline', 'html_param', 'idx', 'X_train', '_ml_usecase', 'fold_groups_param', 'gpu_n_jobs_param', 'fold_generator', 'memory', 'data', 'fold_shuffle_param', 'y_test', 'transform_target_param'}
2023-04-25 20:41:56,943:INFO:Checking environment
2023-04-25 20:41:56,943:INFO:python_version: 3.10.5
2023-04-25 20:41:56,943:INFO:python_build: ('tags/v3.10.5:f377153', 'Jun  6 2022 16:14:13')
2023-04-25 20:41:56,943:INFO:machine: AMD64
2023-04-25 20:41:56,943:INFO:platform: Windows-10-10.0.22000-SP0
2023-04-25 20:41:56,943:INFO:Memory: svmem(total=16497119232, available=8704765952, percent=47.2, used=7792353280, free=8704765952)
2023-04-25 20:41:56,943:INFO:Physical Core: 8
2023-04-25 20:41:56,943:INFO:Logical Core: 16
2023-04-25 20:41:56,943:INFO:Checking libraries
2023-04-25 20:41:56,943:INFO:System:
2023-04-25 20:41:56,943:INFO:    python: 3.10.5 (tags/v3.10.5:f377153, Jun  6 2022, 16:14:13) [MSC v.1929 64 bit (AMD64)]
2023-04-25 20:41:56,943:INFO:executable: C:\Users\Hashif\AppData\Local\Programs\Python\Python310\python.exe
2023-04-25 20:41:56,943:INFO:   machine: Windows-10-10.0.22000-SP0
2023-04-25 20:41:56,943:INFO:PyCaret required dependencies:
2023-04-25 20:41:56,943:INFO:                 pip: 23.1.1
2023-04-25 20:41:56,943:INFO:          setuptools: 58.1.0
2023-04-25 20:41:56,943:INFO:             pycaret: 3.0.0
2023-04-25 20:41:56,943:INFO:             IPython: 8.4.0
2023-04-25 20:41:56,943:INFO:          ipywidgets: 7.7.0
2023-04-25 20:41:56,943:INFO:                tqdm: 4.65.0
2023-04-25 20:41:56,943:INFO:               numpy: 1.23.0
2023-04-25 20:41:56,943:INFO:              pandas: 1.4.3
2023-04-25 20:41:56,943:INFO:              jinja2: 3.1.2
2023-04-25 20:41:56,943:INFO:               scipy: 1.9.3
2023-04-25 20:41:56,943:INFO:              joblib: 1.2.0
2023-04-25 20:41:56,943:INFO:             sklearn: 1.1.2
2023-04-25 20:41:56,943:INFO:                pyod: 1.0.9
2023-04-25 20:41:56,943:INFO:            imblearn: 0.10.1
2023-04-25 20:41:56,943:INFO:   category_encoders: 2.6.0
2023-04-25 20:41:56,943:INFO:            lightgbm: 3.3.5
2023-04-25 20:41:56,943:INFO:               numba: 0.56.4
2023-04-25 20:41:56,943:INFO:            requests: 2.28.1
2023-04-25 20:41:56,943:INFO:          matplotlib: 3.6.2
2023-04-25 20:41:56,943:INFO:          scikitplot: 0.3.7
2023-04-25 20:41:56,943:INFO:         yellowbrick: 1.5
2023-04-25 20:41:56,943:INFO:              plotly: 5.14.1
2023-04-25 20:41:56,943:INFO:             kaleido: 0.2.1
2023-04-25 20:41:56,943:INFO:         statsmodels: 0.13.5
2023-04-25 20:41:56,943:INFO:              sktime: 0.17.1
2023-04-25 20:41:56,943:INFO:               tbats: 1.1.3
2023-04-25 20:41:56,943:INFO:            pmdarima: 2.0.3
2023-04-25 20:41:56,943:INFO:              psutil: 5.9.1
2023-04-25 20:41:56,943:INFO:PyCaret optional dependencies:
2023-04-25 20:41:56,943:INFO:                shap: Not installed
2023-04-25 20:41:56,943:INFO:           interpret: Not installed
2023-04-25 20:41:56,943:INFO:                umap: Not installed
2023-04-25 20:41:56,943:INFO:    pandas_profiling: Not installed
2023-04-25 20:41:56,943:INFO:  explainerdashboard: Not installed
2023-04-25 20:41:56,943:INFO:             autoviz: Not installed
2023-04-25 20:41:56,943:INFO:           fairlearn: Not installed
2023-04-25 20:41:56,943:INFO:             xgboost: Not installed
2023-04-25 20:41:56,943:INFO:            catboost: Not installed
2023-04-25 20:41:56,943:INFO:              kmodes: Not installed
2023-04-25 20:41:56,943:INFO:             mlxtend: Not installed
2023-04-25 20:41:56,943:INFO:       statsforecast: Not installed
2023-04-25 20:41:56,943:INFO:        tune_sklearn: Not installed
2023-04-25 20:41:56,943:INFO:                 ray: Not installed
2023-04-25 20:41:56,943:INFO:            hyperopt: Not installed
2023-04-25 20:41:56,943:INFO:              optuna: Not installed
2023-04-25 20:41:56,943:INFO:               skopt: Not installed
2023-04-25 20:41:56,943:INFO:              mlflow: 2.3.0
2023-04-25 20:41:56,943:INFO:              gradio: Not installed
2023-04-25 20:41:56,943:INFO:             fastapi: Not installed
2023-04-25 20:41:56,943:INFO:             uvicorn: Not installed
2023-04-25 20:41:56,943:INFO:              m2cgen: Not installed
2023-04-25 20:41:56,943:INFO:           evidently: Not installed
2023-04-25 20:41:56,943:INFO:               fugue: Not installed
2023-04-25 20:41:56,943:INFO:           streamlit: Not installed
2023-04-25 20:41:56,943:INFO:             prophet: Not installed
2023-04-25 20:41:56,943:INFO:None
2023-04-25 20:41:56,943:INFO:Set up GPU usage.
2023-04-25 20:41:56,951:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:41:56,951:WARNING:cuML is outdated or not found. Required version is >=22.10, got 3.0.0
2023-04-25 20:41:56,951:INFO:Set up data.
2023-04-25 20:41:56,951:INFO:Set up train/test split.
2023-04-25 20:41:56,959:INFO:Set up index.
2023-04-25 20:41:56,959:INFO:Set up folding strategy.
2023-04-25 20:41:56,959:INFO:Assigning column types.
2023-04-25 20:41:56,959:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-04-25 20:41:56,959:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:41:56,959:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-04-25 20:41:56,959:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:41:56,959:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-25 20:41:56,975:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:41:56,975:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-25 20:41:56,975:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:41:57,068:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-25 20:41:57,068:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:41:57,133:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-25 20:41:57,133:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:41:57,133:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:41:57,133:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 20:41:57,225:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 20:41:57,233:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:41:57,233:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-04-25 20:41:57,233:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:41:57,241:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-25 20:41:57,241:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:41:57,241:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-25 20:41:57,241:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:41:57,351:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-25 20:41:57,351:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:41:57,413:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-25 20:41:57,413:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:41:57,413:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:41:57,413:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 20:41:57,477:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 20:41:57,477:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-04-25 20:41:57,477:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:41:57,477:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:41:57,492:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-25 20:41:57,492:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:41:57,508:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-25 20:41:57,508:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:41:57,602:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-25 20:41:57,602:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:41:57,680:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-25 20:41:57,680:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:41:57,680:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:41:57,680:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 20:41:57,775:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 20:41:57,775:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:41:57,775:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:41:57,775:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-25 20:41:57,775:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:41:57,790:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-25 20:41:57,790:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:41:57,900:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-25 20:41:57,900:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:41:57,970:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-25 20:41:57,970:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:41:57,970:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:41:57,970:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 20:41:58,035:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 20:41:58,035:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-04-25 20:41:58,035:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:41:58,035:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:41:58,035:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:41:58,048:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-25 20:41:58,048:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:41:58,158:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-25 20:41:58,158:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:41:58,233:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-25 20:41:58,233:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:41:58,235:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:41:58,235:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 20:41:58,296:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 20:41:58,296:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:41:58,296:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:41:58,312:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:41:58,328:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-25 20:41:58,328:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:41:58,422:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-25 20:41:58,422:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:41:58,500:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-25 20:41:58,500:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:41:58,500:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:41:58,500:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 20:41:58,563:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 20:41:58,563:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-04-25 20:41:58,563:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:41:58,563:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:41:58,563:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:41:58,579:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:41:58,689:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-25 20:41:58,689:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:41:58,751:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-25 20:41:58,751:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:41:58,767:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:41:58,767:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 20:41:58,830:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 20:41:58,830:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:41:58,830:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:41:58,836:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:41:58,846:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:41:58,955:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-25 20:41:58,955:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:41:59,018:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-25 20:41:59,018:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:41:59,018:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:41:59,018:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 20:41:59,096:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 20:41:59,096:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-04-25 20:41:59,096:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:41:59,096:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:41:59,096:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:41:59,112:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:41:59,223:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-25 20:41:59,223:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:41:59,287:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:41:59,287:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:41:59,287:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 20:41:59,339:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 20:41:59,339:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:41:59,339:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:41:59,343:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:41:59,358:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:41:59,452:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-25 20:41:59,452:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:41:59,534:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:41:59,539:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:41:59,539:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 20:41:59,600:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 20:41:59,600:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-04-25 20:41:59,600:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:41:59,600:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:41:59,610:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:41:59,619:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:41:59,728:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:41:59,794:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:41:59,794:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:41:59,794:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 20:41:59,846:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 20:41:59,846:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:41:59,846:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:41:59,856:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:41:59,872:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:41:59,982:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:42:00,057:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:42:00,057:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:42:00,057:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 20:42:00,106:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 20:42:00,106:INFO:Set up custom pipeline.
2023-04-25 20:42:00,122:INFO:Finished creating preprocessing pipeline.
2023-04-25 20:42:00,232:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Hashif\AppData\Local\Temp\joblib),
         steps=[('custom_step',
                 TransformerWrapper(transformer=FeatureUnion(n_jobs=1,
                                                             transformer_list=[('pipeline-1',
                                                                                Pipeline(steps=[('functiontransformer',
                                                                                                 FunctionTransformer(func=operator.itemgetter('amneties'))),
                                                                                                ('tfidfvectorizer',
                                                                                                 TfidfVectorizer(max_features=10000,
                                                                                                                 ngram_range=(1,
                                                                                                                              2),
                                                                                                                 token_pattern='\\w+'))])),
                                                                               ('pipeline-2',
                                                                                Pipeline(steps=[('functiontransformer-1',
                                                                                                 FunctionTransformer(func=operator.itemgetter(['ratings', 'distance']))),
                                                                                                ('functiontransformer-2',
                                                                                                 FunctionTransformer(func=<function to_records at 0x000001A1F41D4160>)),
                                                                                                ('dictvectorizer',
                                                                                                 DictVectorizer())]))])))])
2023-04-25 20:42:00,232:INFO:Creating final display dataframe.
2023-04-25 20:42:00,363:INFO:Setup _display_container:                    Description       Value
0                   Session id          42
1                       Target       price
2                  Target type  Regression
3          Original data shape      (2, 4)
4       Transformed data shape     (2, 12)
5  Transformed train set shape     (1, 12)
6   Transformed test set shape     (1, 12)
7             Numeric features           2
8         Categorical features           1
2023-04-25 20:42:00,370:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:42:00,374:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:42:00,377:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:42:00,390:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:42:00,494:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:42:00,572:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:42:00,572:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:42:00,572:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 20:42:00,626:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 20:42:00,626:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:42:00,626:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:42:00,640:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:42:00,656:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:42:00,768:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:42:00,837:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:42:00,840:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:42:00,841:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 20:42:00,897:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 20:42:00,897:INFO:Logging experiment in loggers
2023-04-25 20:42:01,004:INFO:SubProcess save_model() called ==================================
2023-04-25 20:42:01,188:INFO:Initializing save_model()
2023-04-25 20:42:01,188:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\Hashif\AppData\Local\Temp\joblib),
         steps=[('custom_step',
                 TransformerWrapper(transformer=FeatureUnion(n_jobs=1,
                                                             transformer_list=[('pipeline-1',
                                                                                Pipeline(steps=[('functiontransformer',
                                                                                                 FunctionTransformer(func=operator.itemgetter('amneties'))),
                                                                                                ('tfidfvectorizer',
                                                                                                 TfidfVectorizer(max_features=10000,
                                                                                                                 ngram_range=(1,
                                                                                                                              2),
                                                                                                                 token_pattern='\\w+'))])),
                                                                               ('pipeline-2',
                                                                                Pipeline(steps=[('functiontransformer-1',
                                                                                                 FunctionTransformer(func=operator.itemgetter(['ratings', 'distance']))),
                                                                                                ('functiontransformer-2',
                                                                                                 FunctionTransformer(func=<function to_records at 0x000001A1F41D4160>)),
                                                                                                ('dictvectorizer',
                                                                                                 DictVectorizer())]))])))]), model_name=C:\Users\Hashif\AppData\Local\Temp\tmpdc79qm3b\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\Hashif\AppData\Local\Temp\joblib),
         steps=[('custom_step',
                 TransformerWrapper(transformer=FeatureUnion(n_jobs=1,
                                                             transformer_list=[('pipeline-1',
                                                                                Pipeline(steps=[('functiontransformer',
                                                                                                 FunctionTransformer(func=operator.itemgetter('amneties'))),
                                                                                                ('tfidfvectorizer',
                                                                                                 TfidfVectorizer(max_features=10000,
                                                                                                                 ngram_range=(1,
                                                                                                                              2),
                                                                                                                 token_pattern='\\w+'))])),
                                                                               ('pipeline-2',
                                                                                Pipeline(steps=[('functiontransformer-1',
                                                                                                 FunctionTransformer(func=operator.itemgetter(['ratings', 'distance']))),
                                                                                                ('functiontransformer-2',
                                                                                                 FunctionTransformer(func=<function to_records at 0x000001A1F41D4160>)),
                                                                                                ('dictvectorizer',
                                                                                                 DictVectorizer())]))])))]), verbose=False, use_case=MLUsecase.REGRESSION, kwargs={})
2023-04-25 20:42:01,188:INFO:Adding model into prep_pipe
2023-04-25 20:42:01,188:WARNING:Only Model saved as it was a pipeline.
2023-04-25 20:42:01,188:INFO:C:\Users\Hashif\AppData\Local\Temp\tmpdc79qm3b\Transformation Pipeline.pkl saved in current working directory
2023-04-25 20:42:01,271:INFO:Pipeline(memory=FastMemory(location=C:\Users\Hashif\AppData\Local\Temp\joblib),
         steps=[('custom_step',
                 TransformerWrapper(transformer=FeatureUnion(n_jobs=1,
                                                             transformer_list=[('pipeline-1',
                                                                                Pipeline(steps=[('functiontransformer',
                                                                                                 FunctionTransformer(func=operator.itemgetter('amneties'))),
                                                                                                ('tfidfvectorizer',
                                                                                                 TfidfVectorizer(max_features=10000,
                                                                                                                 ngram_range=(1,
                                                                                                                              2),
                                                                                                                 token_pattern='\\w+'))])),
                                                                               ('pipeline-2',
                                                                                Pipeline(steps=[('functiontransformer-1',
                                                                                                 FunctionTransformer(func=operator.itemgetter(['ratings', 'distance']))),
                                                                                                ('functiontransformer-2',
                                                                                                 FunctionTransformer(func=<function to_records at 0x000001A1F41D4160>)),
                                                                                                ('dictvectorizer',
                                                                                                 DictVectorizer())]))])))])
2023-04-25 20:42:01,271:INFO:save_model() successfully completed......................................
2023-04-25 20:42:01,439:INFO:SubProcess save_model() end ==================================
2023-04-25 20:42:01,466:INFO:setup() successfully completed in 3.98s...............
2023-04-25 20:42:01,488:INFO:Initializing compare_models()
2023-04-25 20:42:01,488:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A185083970>, include=['lr', 'lasso', 'ridge', 'en', 'huber', 'knn', 'ada', 'gbr'], fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001A185083970>, 'include': ['lr', 'lasso', 'ridge', 'en', 'huber', 'knn', 'ada', 'gbr'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-04-25 20:42:01,488:INFO:Checking exceptions
2023-04-25 20:42:01,488:INFO:Preparing display monitor
2023-04-25 20:42:01,529:INFO:Initializing Linear Regression
2023-04-25 20:42:01,529:INFO:Total runtime is 0.0 minutes
2023-04-25 20:42:01,529:INFO:SubProcess create_model() called ==================================
2023-04-25 20:42:01,535:INFO:Initializing create_model()
2023-04-25 20:42:01,535:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A185083970>, estimator=lr, fold=ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A185FC0D00>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 20:42:01,535:INFO:Checking exceptions
2023-04-25 20:42:01,535:INFO:Importing libraries
2023-04-25 20:42:01,535:INFO:Copying training dataset
2023-04-25 20:42:01,542:INFO:Defining folds
2023-04-25 20:42:01,542:INFO:Declaring metric variables
2023-04-25 20:42:01,551:INFO:Importing untrained model
2023-04-25 20:42:01,556:INFO:Linear Regression Imported successfully
2023-04-25 20:42:01,563:INFO:Starting cross validation
2023-04-25 20:42:01,570:INFO:Cross validating with ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), n_jobs=1
2023-04-25 20:42:01,570:WARNING:create_model() for lr raised an exception or returned all 0.0, trying without fit_kwargs:
2023-04-25 20:42:01,570:WARNING:Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 862, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in cross_validate
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1085, in __call__
    if self.dispatch_one_batch(iterator):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 873, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in <genexpr>
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1622, in split
    for train, test in self._iter_indices(X, y, groups):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1730, in _iter_indices
    n_train, n_test = _validate_shuffle_split(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 2126, in _validate_shuffle_split
    raise ValueError(
ValueError: With n_samples=1, test_size=None and train_size=0.9230769230769231, the resulting train set will be empty. Adjust any of the aforementioned parameters.

2023-04-25 20:42:01,570:INFO:Initializing create_model()
2023-04-25 20:42:01,570:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A185083970>, estimator=lr, fold=ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A185FC0D00>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 20:42:01,570:INFO:Checking exceptions
2023-04-25 20:42:01,570:INFO:Importing libraries
2023-04-25 20:42:01,570:INFO:Copying training dataset
2023-04-25 20:42:01,577:INFO:Defining folds
2023-04-25 20:42:01,577:INFO:Declaring metric variables
2023-04-25 20:42:01,585:INFO:Importing untrained model
2023-04-25 20:42:01,585:INFO:Linear Regression Imported successfully
2023-04-25 20:42:01,602:INFO:Starting cross validation
2023-04-25 20:42:01,604:INFO:Cross validating with ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), n_jobs=1
2023-04-25 20:42:01,604:ERROR:create_model() for lr raised an exception or returned all 0.0:
2023-04-25 20:42:01,604:ERROR:Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 862, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in cross_validate
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1085, in __call__
    if self.dispatch_one_batch(iterator):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 873, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in <genexpr>
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1622, in split
    for train, test in self._iter_indices(X, y, groups):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1730, in _iter_indices
    n_train, n_test = _validate_shuffle_split(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 2126, in _validate_shuffle_split
    raise ValueError(
ValueError: With n_samples=1, test_size=None and train_size=0.9230769230769231, the resulting train set will be empty. Adjust any of the aforementioned parameters.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 862, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 810, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in cross_validate
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1085, in __call__
    if self.dispatch_one_batch(iterator):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 873, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in <genexpr>
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1622, in split
    for train, test in self._iter_indices(X, y, groups):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1730, in _iter_indices
    n_train, n_test = _validate_shuffle_split(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 2126, in _validate_shuffle_split
    raise ValueError(
ValueError: With n_samples=1, test_size=None and train_size=0.9230769230769231, the resulting train set will be empty. Adjust any of the aforementioned parameters.

2023-04-25 20:42:01,634:INFO:Initializing Lasso Regression
2023-04-25 20:42:01,634:INFO:Total runtime is 0.0017516136169433594 minutes
2023-04-25 20:42:01,634:INFO:SubProcess create_model() called ==================================
2023-04-25 20:42:01,634:INFO:Initializing create_model()
2023-04-25 20:42:01,634:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A185083970>, estimator=lasso, fold=ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A185FC0D00>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 20:42:01,634:INFO:Checking exceptions
2023-04-25 20:42:01,634:INFO:Importing libraries
2023-04-25 20:42:01,634:INFO:Copying training dataset
2023-04-25 20:42:01,648:INFO:Defining folds
2023-04-25 20:42:01,648:INFO:Declaring metric variables
2023-04-25 20:42:01,648:INFO:Importing untrained model
2023-04-25 20:42:01,656:INFO:Lasso Regression Imported successfully
2023-04-25 20:42:01,667:INFO:Starting cross validation
2023-04-25 20:42:01,667:INFO:Cross validating with ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), n_jobs=1
2023-04-25 20:42:01,674:WARNING:create_model() for lasso raised an exception or returned all 0.0, trying without fit_kwargs:
2023-04-25 20:42:01,674:WARNING:Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 862, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in cross_validate
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1085, in __call__
    if self.dispatch_one_batch(iterator):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 873, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in <genexpr>
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1622, in split
    for train, test in self._iter_indices(X, y, groups):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1730, in _iter_indices
    n_train, n_test = _validate_shuffle_split(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 2126, in _validate_shuffle_split
    raise ValueError(
ValueError: With n_samples=1, test_size=None and train_size=0.9230769230769231, the resulting train set will be empty. Adjust any of the aforementioned parameters.

2023-04-25 20:42:01,674:INFO:Initializing create_model()
2023-04-25 20:42:01,674:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A185083970>, estimator=lasso, fold=ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A185FC0D00>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 20:42:01,674:INFO:Checking exceptions
2023-04-25 20:42:01,674:INFO:Importing libraries
2023-04-25 20:42:01,674:INFO:Copying training dataset
2023-04-25 20:42:01,680:INFO:Defining folds
2023-04-25 20:42:01,680:INFO:Declaring metric variables
2023-04-25 20:42:01,686:INFO:Importing untrained model
2023-04-25 20:42:01,688:INFO:Lasso Regression Imported successfully
2023-04-25 20:42:01,702:INFO:Starting cross validation
2023-04-25 20:42:01,708:INFO:Cross validating with ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), n_jobs=1
2023-04-25 20:42:01,708:ERROR:create_model() for lasso raised an exception or returned all 0.0:
2023-04-25 20:42:01,708:ERROR:Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 862, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in cross_validate
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1085, in __call__
    if self.dispatch_one_batch(iterator):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 873, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in <genexpr>
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1622, in split
    for train, test in self._iter_indices(X, y, groups):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1730, in _iter_indices
    n_train, n_test = _validate_shuffle_split(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 2126, in _validate_shuffle_split
    raise ValueError(
ValueError: With n_samples=1, test_size=None and train_size=0.9230769230769231, the resulting train set will be empty. Adjust any of the aforementioned parameters.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 862, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 810, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in cross_validate
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1085, in __call__
    if self.dispatch_one_batch(iterator):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 873, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in <genexpr>
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1622, in split
    for train, test in self._iter_indices(X, y, groups):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1730, in _iter_indices
    n_train, n_test = _validate_shuffle_split(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 2126, in _validate_shuffle_split
    raise ValueError(
ValueError: With n_samples=1, test_size=None and train_size=0.9230769230769231, the resulting train set will be empty. Adjust any of the aforementioned parameters.

2023-04-25 20:42:01,741:INFO:Initializing Ridge Regression
2023-04-25 20:42:01,741:INFO:Total runtime is 0.0035215139389038084 minutes
2023-04-25 20:42:01,749:INFO:SubProcess create_model() called ==================================
2023-04-25 20:42:01,749:INFO:Initializing create_model()
2023-04-25 20:42:01,749:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A185083970>, estimator=ridge, fold=ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A185FC0D00>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 20:42:01,749:INFO:Checking exceptions
2023-04-25 20:42:01,749:INFO:Importing libraries
2023-04-25 20:42:01,749:INFO:Copying training dataset
2023-04-25 20:42:01,756:INFO:Defining folds
2023-04-25 20:42:01,756:INFO:Declaring metric variables
2023-04-25 20:42:01,759:INFO:Importing untrained model
2023-04-25 20:42:01,764:INFO:Ridge Regression Imported successfully
2023-04-25 20:42:01,775:INFO:Starting cross validation
2023-04-25 20:42:01,779:INFO:Cross validating with ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), n_jobs=1
2023-04-25 20:42:01,779:WARNING:create_model() for ridge raised an exception or returned all 0.0, trying without fit_kwargs:
2023-04-25 20:42:01,779:WARNING:Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 862, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in cross_validate
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1085, in __call__
    if self.dispatch_one_batch(iterator):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 873, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in <genexpr>
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1622, in split
    for train, test in self._iter_indices(X, y, groups):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1730, in _iter_indices
    n_train, n_test = _validate_shuffle_split(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 2126, in _validate_shuffle_split
    raise ValueError(
ValueError: With n_samples=1, test_size=None and train_size=0.9230769230769231, the resulting train set will be empty. Adjust any of the aforementioned parameters.

2023-04-25 20:42:01,779:INFO:Initializing create_model()
2023-04-25 20:42:01,779:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A185083970>, estimator=ridge, fold=ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A185FC0D00>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 20:42:01,779:INFO:Checking exceptions
2023-04-25 20:42:01,783:INFO:Importing libraries
2023-04-25 20:42:01,783:INFO:Copying training dataset
2023-04-25 20:42:01,785:INFO:Defining folds
2023-04-25 20:42:01,785:INFO:Declaring metric variables
2023-04-25 20:42:01,793:INFO:Importing untrained model
2023-04-25 20:42:01,793:INFO:Ridge Regression Imported successfully
2023-04-25 20:42:01,801:INFO:Starting cross validation
2023-04-25 20:42:01,809:INFO:Cross validating with ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), n_jobs=1
2023-04-25 20:42:01,811:ERROR:create_model() for ridge raised an exception or returned all 0.0:
2023-04-25 20:42:01,813:ERROR:Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 862, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in cross_validate
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1085, in __call__
    if self.dispatch_one_batch(iterator):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 873, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in <genexpr>
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1622, in split
    for train, test in self._iter_indices(X, y, groups):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1730, in _iter_indices
    n_train, n_test = _validate_shuffle_split(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 2126, in _validate_shuffle_split
    raise ValueError(
ValueError: With n_samples=1, test_size=None and train_size=0.9230769230769231, the resulting train set will be empty. Adjust any of the aforementioned parameters.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 862, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 810, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in cross_validate
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1085, in __call__
    if self.dispatch_one_batch(iterator):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 873, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in <genexpr>
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1622, in split
    for train, test in self._iter_indices(X, y, groups):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1730, in _iter_indices
    n_train, n_test = _validate_shuffle_split(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 2126, in _validate_shuffle_split
    raise ValueError(
ValueError: With n_samples=1, test_size=None and train_size=0.9230769230769231, the resulting train set will be empty. Adjust any of the aforementioned parameters.

2023-04-25 20:42:01,842:INFO:Initializing Elastic Net
2023-04-25 20:42:01,842:INFO:Total runtime is 0.005218903223673502 minutes
2023-04-25 20:42:01,850:INFO:SubProcess create_model() called ==================================
2023-04-25 20:42:01,850:INFO:Initializing create_model()
2023-04-25 20:42:01,850:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A185083970>, estimator=en, fold=ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A185FC0D00>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 20:42:01,850:INFO:Checking exceptions
2023-04-25 20:42:01,850:INFO:Importing libraries
2023-04-25 20:42:01,850:INFO:Copying training dataset
2023-04-25 20:42:01,854:INFO:Defining folds
2023-04-25 20:42:01,854:INFO:Declaring metric variables
2023-04-25 20:42:01,858:INFO:Importing untrained model
2023-04-25 20:42:01,858:INFO:Elastic Net Imported successfully
2023-04-25 20:42:01,882:INFO:Starting cross validation
2023-04-25 20:42:01,882:INFO:Cross validating with ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), n_jobs=1
2023-04-25 20:42:01,887:WARNING:create_model() for en raised an exception or returned all 0.0, trying without fit_kwargs:
2023-04-25 20:42:01,889:WARNING:Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 862, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in cross_validate
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1085, in __call__
    if self.dispatch_one_batch(iterator):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 873, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in <genexpr>
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1622, in split
    for train, test in self._iter_indices(X, y, groups):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1730, in _iter_indices
    n_train, n_test = _validate_shuffle_split(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 2126, in _validate_shuffle_split
    raise ValueError(
ValueError: With n_samples=1, test_size=None and train_size=0.9230769230769231, the resulting train set will be empty. Adjust any of the aforementioned parameters.

2023-04-25 20:42:01,889:INFO:Initializing create_model()
2023-04-25 20:42:01,889:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A185083970>, estimator=en, fold=ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A185FC0D00>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 20:42:01,889:INFO:Checking exceptions
2023-04-25 20:42:01,889:INFO:Importing libraries
2023-04-25 20:42:01,889:INFO:Copying training dataset
2023-04-25 20:42:01,894:INFO:Defining folds
2023-04-25 20:42:01,894:INFO:Declaring metric variables
2023-04-25 20:42:01,896:INFO:Importing untrained model
2023-04-25 20:42:01,904:INFO:Elastic Net Imported successfully
2023-04-25 20:42:01,910:INFO:Starting cross validation
2023-04-25 20:42:01,910:INFO:Cross validating with ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), n_jobs=1
2023-04-25 20:42:01,917:ERROR:create_model() for en raised an exception or returned all 0.0:
2023-04-25 20:42:01,917:ERROR:Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 862, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in cross_validate
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1085, in __call__
    if self.dispatch_one_batch(iterator):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 873, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in <genexpr>
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1622, in split
    for train, test in self._iter_indices(X, y, groups):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1730, in _iter_indices
    n_train, n_test = _validate_shuffle_split(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 2126, in _validate_shuffle_split
    raise ValueError(
ValueError: With n_samples=1, test_size=None and train_size=0.9230769230769231, the resulting train set will be empty. Adjust any of the aforementioned parameters.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 862, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 810, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in cross_validate
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1085, in __call__
    if self.dispatch_one_batch(iterator):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 873, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in <genexpr>
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1622, in split
    for train, test in self._iter_indices(X, y, groups):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1730, in _iter_indices
    n_train, n_test = _validate_shuffle_split(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 2126, in _validate_shuffle_split
    raise ValueError(
ValueError: With n_samples=1, test_size=None and train_size=0.9230769230769231, the resulting train set will be empty. Adjust any of the aforementioned parameters.

2023-04-25 20:42:01,951:INFO:Initializing Huber Regressor
2023-04-25 20:42:01,951:INFO:Total runtime is 0.007022015253702799 minutes
2023-04-25 20:42:01,951:INFO:SubProcess create_model() called ==================================
2023-04-25 20:42:01,951:INFO:Initializing create_model()
2023-04-25 20:42:01,951:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A185083970>, estimator=huber, fold=ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A185FC0D00>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 20:42:01,951:INFO:Checking exceptions
2023-04-25 20:42:01,951:INFO:Importing libraries
2023-04-25 20:42:01,951:INFO:Copying training dataset
2023-04-25 20:42:01,962:INFO:Defining folds
2023-04-25 20:42:01,962:INFO:Declaring metric variables
2023-04-25 20:42:01,972:INFO:Importing untrained model
2023-04-25 20:42:01,972:INFO:Huber Regressor Imported successfully
2023-04-25 20:42:01,986:INFO:Starting cross validation
2023-04-25 20:42:01,986:INFO:Cross validating with ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), n_jobs=1
2023-04-25 20:42:01,986:WARNING:create_model() for huber raised an exception or returned all 0.0, trying without fit_kwargs:
2023-04-25 20:42:01,992:WARNING:Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 862, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in cross_validate
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1085, in __call__
    if self.dispatch_one_batch(iterator):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 873, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in <genexpr>
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1622, in split
    for train, test in self._iter_indices(X, y, groups):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1730, in _iter_indices
    n_train, n_test = _validate_shuffle_split(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 2126, in _validate_shuffle_split
    raise ValueError(
ValueError: With n_samples=1, test_size=None and train_size=0.9230769230769231, the resulting train set will be empty. Adjust any of the aforementioned parameters.

2023-04-25 20:42:01,992:INFO:Initializing create_model()
2023-04-25 20:42:01,993:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A185083970>, estimator=huber, fold=ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A185FC0D00>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 20:42:01,993:INFO:Checking exceptions
2023-04-25 20:42:01,993:INFO:Importing libraries
2023-04-25 20:42:01,993:INFO:Copying training dataset
2023-04-25 20:42:01,993:INFO:Defining folds
2023-04-25 20:42:01,993:INFO:Declaring metric variables
2023-04-25 20:42:02,001:INFO:Importing untrained model
2023-04-25 20:42:02,001:INFO:Huber Regressor Imported successfully
2023-04-25 20:42:02,017:INFO:Starting cross validation
2023-04-25 20:42:02,019:INFO:Cross validating with ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), n_jobs=1
2023-04-25 20:42:02,019:ERROR:create_model() for huber raised an exception or returned all 0.0:
2023-04-25 20:42:02,022:ERROR:Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 862, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in cross_validate
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1085, in __call__
    if self.dispatch_one_batch(iterator):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 873, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in <genexpr>
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1622, in split
    for train, test in self._iter_indices(X, y, groups):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1730, in _iter_indices
    n_train, n_test = _validate_shuffle_split(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 2126, in _validate_shuffle_split
    raise ValueError(
ValueError: With n_samples=1, test_size=None and train_size=0.9230769230769231, the resulting train set will be empty. Adjust any of the aforementioned parameters.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 862, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 810, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in cross_validate
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1085, in __call__
    if self.dispatch_one_batch(iterator):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 873, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in <genexpr>
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1622, in split
    for train, test in self._iter_indices(X, y, groups):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1730, in _iter_indices
    n_train, n_test = _validate_shuffle_split(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 2126, in _validate_shuffle_split
    raise ValueError(
ValueError: With n_samples=1, test_size=None and train_size=0.9230769230769231, the resulting train set will be empty. Adjust any of the aforementioned parameters.

2023-04-25 20:42:02,051:INFO:Initializing K Neighbors Regressor
2023-04-25 20:42:02,051:INFO:Total runtime is 0.00868786573410034 minutes
2023-04-25 20:42:02,051:INFO:SubProcess create_model() called ==================================
2023-04-25 20:42:02,051:INFO:Initializing create_model()
2023-04-25 20:42:02,051:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A185083970>, estimator=knn, fold=ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A185FC0D00>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 20:42:02,051:INFO:Checking exceptions
2023-04-25 20:42:02,059:INFO:Importing libraries
2023-04-25 20:42:02,059:INFO:Copying training dataset
2023-04-25 20:42:02,061:INFO:Defining folds
2023-04-25 20:42:02,061:INFO:Declaring metric variables
2023-04-25 20:42:02,066:INFO:Importing untrained model
2023-04-25 20:42:02,069:INFO:K Neighbors Regressor Imported successfully
2023-04-25 20:42:02,083:INFO:Starting cross validation
2023-04-25 20:42:02,083:INFO:Cross validating with ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), n_jobs=1
2023-04-25 20:42:02,083:WARNING:create_model() for knn raised an exception or returned all 0.0, trying without fit_kwargs:
2023-04-25 20:42:02,083:WARNING:Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 862, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in cross_validate
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1085, in __call__
    if self.dispatch_one_batch(iterator):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 873, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in <genexpr>
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1622, in split
    for train, test in self._iter_indices(X, y, groups):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1730, in _iter_indices
    n_train, n_test = _validate_shuffle_split(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 2126, in _validate_shuffle_split
    raise ValueError(
ValueError: With n_samples=1, test_size=None and train_size=0.9230769230769231, the resulting train set will be empty. Adjust any of the aforementioned parameters.

2023-04-25 20:42:02,089:INFO:Initializing create_model()
2023-04-25 20:42:02,089:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A185083970>, estimator=knn, fold=ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A185FC0D00>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 20:42:02,089:INFO:Checking exceptions
2023-04-25 20:42:02,089:INFO:Importing libraries
2023-04-25 20:42:02,089:INFO:Copying training dataset
2023-04-25 20:42:02,096:INFO:Defining folds
2023-04-25 20:42:02,096:INFO:Declaring metric variables
2023-04-25 20:42:02,099:INFO:Importing untrained model
2023-04-25 20:42:02,106:INFO:K Neighbors Regressor Imported successfully
2023-04-25 20:42:02,114:INFO:Starting cross validation
2023-04-25 20:42:02,114:INFO:Cross validating with ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), n_jobs=1
2023-04-25 20:42:02,123:ERROR:create_model() for knn raised an exception or returned all 0.0:
2023-04-25 20:42:02,123:ERROR:Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 862, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in cross_validate
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1085, in __call__
    if self.dispatch_one_batch(iterator):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 873, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in <genexpr>
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1622, in split
    for train, test in self._iter_indices(X, y, groups):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1730, in _iter_indices
    n_train, n_test = _validate_shuffle_split(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 2126, in _validate_shuffle_split
    raise ValueError(
ValueError: With n_samples=1, test_size=None and train_size=0.9230769230769231, the resulting train set will be empty. Adjust any of the aforementioned parameters.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 862, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 810, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in cross_validate
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1085, in __call__
    if self.dispatch_one_batch(iterator):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 873, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in <genexpr>
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1622, in split
    for train, test in self._iter_indices(X, y, groups):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1730, in _iter_indices
    n_train, n_test = _validate_shuffle_split(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 2126, in _validate_shuffle_split
    raise ValueError(
ValueError: With n_samples=1, test_size=None and train_size=0.9230769230769231, the resulting train set will be empty. Adjust any of the aforementioned parameters.

2023-04-25 20:42:02,151:INFO:Initializing AdaBoost Regressor
2023-04-25 20:42:02,151:INFO:Total runtime is 0.010358146826426187 minutes
2023-04-25 20:42:02,164:INFO:SubProcess create_model() called ==================================
2023-04-25 20:42:02,164:INFO:Initializing create_model()
2023-04-25 20:42:02,164:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A185083970>, estimator=ada, fold=ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A185FC0D00>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 20:42:02,164:INFO:Checking exceptions
2023-04-25 20:42:02,164:INFO:Importing libraries
2023-04-25 20:42:02,164:INFO:Copying training dataset
2023-04-25 20:42:02,170:INFO:Defining folds
2023-04-25 20:42:02,170:INFO:Declaring metric variables
2023-04-25 20:42:02,175:INFO:Importing untrained model
2023-04-25 20:42:02,180:INFO:AdaBoost Regressor Imported successfully
2023-04-25 20:42:02,195:INFO:Starting cross validation
2023-04-25 20:42:02,195:INFO:Cross validating with ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), n_jobs=1
2023-04-25 20:42:02,195:WARNING:create_model() for ada raised an exception or returned all 0.0, trying without fit_kwargs:
2023-04-25 20:42:02,195:WARNING:Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 862, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in cross_validate
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1085, in __call__
    if self.dispatch_one_batch(iterator):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 873, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in <genexpr>
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1622, in split
    for train, test in self._iter_indices(X, y, groups):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1730, in _iter_indices
    n_train, n_test = _validate_shuffle_split(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 2126, in _validate_shuffle_split
    raise ValueError(
ValueError: With n_samples=1, test_size=None and train_size=0.9230769230769231, the resulting train set will be empty. Adjust any of the aforementioned parameters.

2023-04-25 20:42:02,195:INFO:Initializing create_model()
2023-04-25 20:42:02,195:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A185083970>, estimator=ada, fold=ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A185FC0D00>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 20:42:02,201:INFO:Checking exceptions
2023-04-25 20:42:02,201:INFO:Importing libraries
2023-04-25 20:42:02,201:INFO:Copying training dataset
2023-04-25 20:42:02,201:INFO:Defining folds
2023-04-25 20:42:02,201:INFO:Declaring metric variables
2023-04-25 20:42:02,208:INFO:Importing untrained model
2023-04-25 20:42:02,208:INFO:AdaBoost Regressor Imported successfully
2023-04-25 20:42:02,224:INFO:Starting cross validation
2023-04-25 20:42:02,227:INFO:Cross validating with ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), n_jobs=1
2023-04-25 20:42:02,227:ERROR:create_model() for ada raised an exception or returned all 0.0:
2023-04-25 20:42:02,227:ERROR:Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 862, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in cross_validate
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1085, in __call__
    if self.dispatch_one_batch(iterator):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 873, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in <genexpr>
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1622, in split
    for train, test in self._iter_indices(X, y, groups):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1730, in _iter_indices
    n_train, n_test = _validate_shuffle_split(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 2126, in _validate_shuffle_split
    raise ValueError(
ValueError: With n_samples=1, test_size=None and train_size=0.9230769230769231, the resulting train set will be empty. Adjust any of the aforementioned parameters.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 862, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 810, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in cross_validate
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1085, in __call__
    if self.dispatch_one_batch(iterator):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 873, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in <genexpr>
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1622, in split
    for train, test in self._iter_indices(X, y, groups):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1730, in _iter_indices
    n_train, n_test = _validate_shuffle_split(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 2126, in _validate_shuffle_split
    raise ValueError(
ValueError: With n_samples=1, test_size=None and train_size=0.9230769230769231, the resulting train set will be empty. Adjust any of the aforementioned parameters.

2023-04-25 20:42:02,257:INFO:Initializing Gradient Boosting Regressor
2023-04-25 20:42:02,257:INFO:Total runtime is 0.012124574184417723 minutes
2023-04-25 20:42:02,257:INFO:SubProcess create_model() called ==================================
2023-04-25 20:42:02,257:INFO:Initializing create_model()
2023-04-25 20:42:02,257:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A185083970>, estimator=gbr, fold=ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A185FC0D00>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 20:42:02,257:INFO:Checking exceptions
2023-04-25 20:42:02,257:INFO:Importing libraries
2023-04-25 20:42:02,257:INFO:Copying training dataset
2023-04-25 20:42:02,271:INFO:Defining folds
2023-04-25 20:42:02,271:INFO:Declaring metric variables
2023-04-25 20:42:02,277:INFO:Importing untrained model
2023-04-25 20:42:02,277:INFO:Gradient Boosting Regressor Imported successfully
2023-04-25 20:42:02,298:INFO:Starting cross validation
2023-04-25 20:42:02,298:INFO:Cross validating with ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), n_jobs=1
2023-04-25 20:42:02,298:WARNING:create_model() for gbr raised an exception or returned all 0.0, trying without fit_kwargs:
2023-04-25 20:42:02,306:WARNING:Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 862, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in cross_validate
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1085, in __call__
    if self.dispatch_one_batch(iterator):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 873, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in <genexpr>
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1622, in split
    for train, test in self._iter_indices(X, y, groups):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1730, in _iter_indices
    n_train, n_test = _validate_shuffle_split(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 2126, in _validate_shuffle_split
    raise ValueError(
ValueError: With n_samples=1, test_size=None and train_size=0.9230769230769231, the resulting train set will be empty. Adjust any of the aforementioned parameters.

2023-04-25 20:42:02,306:INFO:Initializing create_model()
2023-04-25 20:42:02,306:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A185083970>, estimator=gbr, fold=ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A185FC0D00>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 20:42:02,306:INFO:Checking exceptions
2023-04-25 20:42:02,306:INFO:Importing libraries
2023-04-25 20:42:02,306:INFO:Copying training dataset
2023-04-25 20:42:02,312:INFO:Defining folds
2023-04-25 20:42:02,312:INFO:Declaring metric variables
2023-04-25 20:42:02,326:INFO:Importing untrained model
2023-04-25 20:42:02,326:INFO:Gradient Boosting Regressor Imported successfully
2023-04-25 20:42:02,352:INFO:Starting cross validation
2023-04-25 20:42:02,354:INFO:Cross validating with ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), n_jobs=1
2023-04-25 20:42:02,354:ERROR:create_model() for gbr raised an exception or returned all 0.0:
2023-04-25 20:42:02,358:ERROR:Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 862, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in cross_validate
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1085, in __call__
    if self.dispatch_one_batch(iterator):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 873, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in <genexpr>
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1622, in split
    for train, test in self._iter_indices(X, y, groups):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1730, in _iter_indices
    n_train, n_test = _validate_shuffle_split(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 2126, in _validate_shuffle_split
    raise ValueError(
ValueError: With n_samples=1, test_size=None and train_size=0.9230769230769231, the resulting train set will be empty. Adjust any of the aforementioned parameters.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 862, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 810, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in cross_validate
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1085, in __call__
    if self.dispatch_one_batch(iterator):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 873, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in <genexpr>
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1622, in split
    for train, test in self._iter_indices(X, y, groups):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1730, in _iter_indices
    n_train, n_test = _validate_shuffle_split(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 2126, in _validate_shuffle_split
    raise ValueError(
ValueError: With n_samples=1, test_size=None and train_size=0.9230769230769231, the resulting train set will be empty. Adjust any of the aforementioned parameters.

2023-04-25 20:42:02,437:INFO:_master_model_container: 0
2023-04-25 20:42:02,445:INFO:_display_container: 2
2023-04-25 20:42:02,445:INFO:[]
2023-04-25 20:42:02,445:INFO:compare_models() successfully completed......................................
2023-04-25 20:42:11,731:INFO:Initializing compare_models()
2023-04-25 20:42:11,731:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A185083970>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001A185083970>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-04-25 20:42:11,731:INFO:Checking exceptions
2023-04-25 20:42:11,741:INFO:Preparing display monitor
2023-04-25 20:42:11,781:INFO:Initializing Linear Regression
2023-04-25 20:42:11,781:INFO:Total runtime is 0.0 minutes
2023-04-25 20:42:11,789:INFO:SubProcess create_model() called ==================================
2023-04-25 20:42:11,789:INFO:Initializing create_model()
2023-04-25 20:42:11,789:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A185083970>, estimator=lr, fold=ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A1F38B5660>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 20:42:11,789:INFO:Checking exceptions
2023-04-25 20:42:11,789:INFO:Importing libraries
2023-04-25 20:42:11,789:INFO:Copying training dataset
2023-04-25 20:42:11,804:INFO:Defining folds
2023-04-25 20:42:11,804:INFO:Declaring metric variables
2023-04-25 20:42:11,814:INFO:Importing untrained model
2023-04-25 20:42:11,820:INFO:Linear Regression Imported successfully
2023-04-25 20:42:11,830:INFO:Starting cross validation
2023-04-25 20:42:11,830:INFO:Cross validating with ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), n_jobs=1
2023-04-25 20:42:11,830:WARNING:create_model() for lr raised an exception or returned all 0.0, trying without fit_kwargs:
2023-04-25 20:42:11,838:WARNING:Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 862, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in cross_validate
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1085, in __call__
    if self.dispatch_one_batch(iterator):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 873, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in <genexpr>
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1622, in split
    for train, test in self._iter_indices(X, y, groups):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1730, in _iter_indices
    n_train, n_test = _validate_shuffle_split(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 2126, in _validate_shuffle_split
    raise ValueError(
ValueError: With n_samples=1, test_size=None and train_size=0.9230769230769231, the resulting train set will be empty. Adjust any of the aforementioned parameters.

2023-04-25 20:42:11,838:INFO:Initializing create_model()
2023-04-25 20:42:11,838:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A185083970>, estimator=lr, fold=ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A1F38B5660>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 20:42:11,838:INFO:Checking exceptions
2023-04-25 20:42:11,838:INFO:Importing libraries
2023-04-25 20:42:11,838:INFO:Copying training dataset
2023-04-25 20:42:11,846:INFO:Defining folds
2023-04-25 20:42:11,846:INFO:Declaring metric variables
2023-04-25 20:42:11,854:INFO:Importing untrained model
2023-04-25 20:42:11,862:INFO:Linear Regression Imported successfully
2023-04-25 20:42:11,872:INFO:Starting cross validation
2023-04-25 20:42:11,872:INFO:Cross validating with ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), n_jobs=1
2023-04-25 20:42:11,880:ERROR:create_model() for lr raised an exception or returned all 0.0:
2023-04-25 20:42:11,880:ERROR:Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 862, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in cross_validate
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1085, in __call__
    if self.dispatch_one_batch(iterator):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 873, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in <genexpr>
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1622, in split
    for train, test in self._iter_indices(X, y, groups):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1730, in _iter_indices
    n_train, n_test = _validate_shuffle_split(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 2126, in _validate_shuffle_split
    raise ValueError(
ValueError: With n_samples=1, test_size=None and train_size=0.9230769230769231, the resulting train set will be empty. Adjust any of the aforementioned parameters.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 862, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 810, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in cross_validate
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1085, in __call__
    if self.dispatch_one_batch(iterator):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 873, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in <genexpr>
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1622, in split
    for train, test in self._iter_indices(X, y, groups):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1730, in _iter_indices
    n_train, n_test = _validate_shuffle_split(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 2126, in _validate_shuffle_split
    raise ValueError(
ValueError: With n_samples=1, test_size=None and train_size=0.9230769230769231, the resulting train set will be empty. Adjust any of the aforementioned parameters.

2023-04-25 20:42:11,918:INFO:Initializing Lasso Regression
2023-04-25 20:42:11,918:INFO:Total runtime is 0.0022704601287841797 minutes
2023-04-25 20:42:11,918:INFO:SubProcess create_model() called ==================================
2023-04-25 20:42:11,918:INFO:Initializing create_model()
2023-04-25 20:42:11,918:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A185083970>, estimator=lasso, fold=ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A1F38B5660>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 20:42:11,918:INFO:Checking exceptions
2023-04-25 20:42:11,918:INFO:Importing libraries
2023-04-25 20:42:11,918:INFO:Copying training dataset
2023-04-25 20:42:11,931:INFO:Defining folds
2023-04-25 20:42:11,931:INFO:Declaring metric variables
2023-04-25 20:42:11,939:INFO:Importing untrained model
2023-04-25 20:42:11,947:INFO:Lasso Regression Imported successfully
2023-04-25 20:42:11,962:INFO:Starting cross validation
2023-04-25 20:42:11,962:INFO:Cross validating with ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), n_jobs=1
2023-04-25 20:42:11,962:WARNING:create_model() for lasso raised an exception or returned all 0.0, trying without fit_kwargs:
2023-04-25 20:42:11,962:WARNING:Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 862, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in cross_validate
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1085, in __call__
    if self.dispatch_one_batch(iterator):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 873, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in <genexpr>
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1622, in split
    for train, test in self._iter_indices(X, y, groups):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1730, in _iter_indices
    n_train, n_test = _validate_shuffle_split(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 2126, in _validate_shuffle_split
    raise ValueError(
ValueError: With n_samples=1, test_size=None and train_size=0.9230769230769231, the resulting train set will be empty. Adjust any of the aforementioned parameters.

2023-04-25 20:42:11,970:INFO:Initializing create_model()
2023-04-25 20:42:11,970:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A185083970>, estimator=lasso, fold=ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A1F38B5660>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 20:42:11,970:INFO:Checking exceptions
2023-04-25 20:42:11,970:INFO:Importing libraries
2023-04-25 20:42:11,970:INFO:Copying training dataset
2023-04-25 20:42:11,976:INFO:Defining folds
2023-04-25 20:42:11,976:INFO:Declaring metric variables
2023-04-25 20:42:11,976:INFO:Importing untrained model
2023-04-25 20:42:11,984:INFO:Lasso Regression Imported successfully
2023-04-25 20:42:11,997:INFO:Starting cross validation
2023-04-25 20:42:12,005:INFO:Cross validating with ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), n_jobs=1
2023-04-25 20:42:12,006:ERROR:create_model() for lasso raised an exception or returned all 0.0:
2023-04-25 20:42:12,010:ERROR:Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 862, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in cross_validate
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1085, in __call__
    if self.dispatch_one_batch(iterator):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 873, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in <genexpr>
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1622, in split
    for train, test in self._iter_indices(X, y, groups):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1730, in _iter_indices
    n_train, n_test = _validate_shuffle_split(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 2126, in _validate_shuffle_split
    raise ValueError(
ValueError: With n_samples=1, test_size=None and train_size=0.9230769230769231, the resulting train set will be empty. Adjust any of the aforementioned parameters.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 862, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 810, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in cross_validate
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1085, in __call__
    if self.dispatch_one_batch(iterator):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 873, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in <genexpr>
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1622, in split
    for train, test in self._iter_indices(X, y, groups):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1730, in _iter_indices
    n_train, n_test = _validate_shuffle_split(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 2126, in _validate_shuffle_split
    raise ValueError(
ValueError: With n_samples=1, test_size=None and train_size=0.9230769230769231, the resulting train set will be empty. Adjust any of the aforementioned parameters.

2023-04-25 20:42:12,040:INFO:Initializing Ridge Regression
2023-04-25 20:42:12,040:INFO:Total runtime is 0.004315177599589029 minutes
2023-04-25 20:42:12,056:INFO:SubProcess create_model() called ==================================
2023-04-25 20:42:12,056:INFO:Initializing create_model()
2023-04-25 20:42:12,056:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A185083970>, estimator=ridge, fold=ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A1F38B5660>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 20:42:12,056:INFO:Checking exceptions
2023-04-25 20:42:12,056:INFO:Importing libraries
2023-04-25 20:42:12,056:INFO:Copying training dataset
2023-04-25 20:42:12,063:INFO:Defining folds
2023-04-25 20:42:12,063:INFO:Declaring metric variables
2023-04-25 20:42:12,063:INFO:Importing untrained model
2023-04-25 20:42:12,073:INFO:Ridge Regression Imported successfully
2023-04-25 20:42:12,083:INFO:Starting cross validation
2023-04-25 20:42:12,087:INFO:Cross validating with ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), n_jobs=1
2023-04-25 20:42:12,087:WARNING:create_model() for ridge raised an exception or returned all 0.0, trying without fit_kwargs:
2023-04-25 20:42:12,087:WARNING:Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 862, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in cross_validate
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1085, in __call__
    if self.dispatch_one_batch(iterator):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 873, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in <genexpr>
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1622, in split
    for train, test in self._iter_indices(X, y, groups):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1730, in _iter_indices
    n_train, n_test = _validate_shuffle_split(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 2126, in _validate_shuffle_split
    raise ValueError(
ValueError: With n_samples=1, test_size=None and train_size=0.9230769230769231, the resulting train set will be empty. Adjust any of the aforementioned parameters.

2023-04-25 20:42:12,087:INFO:Initializing create_model()
2023-04-25 20:42:12,087:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A185083970>, estimator=ridge, fold=ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A1F38B5660>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 20:42:12,087:INFO:Checking exceptions
2023-04-25 20:42:12,087:INFO:Importing libraries
2023-04-25 20:42:12,087:INFO:Copying training dataset
2023-04-25 20:42:12,098:INFO:Defining folds
2023-04-25 20:42:12,098:INFO:Declaring metric variables
2023-04-25 20:42:12,103:INFO:Importing untrained model
2023-04-25 20:42:12,108:INFO:Ridge Regression Imported successfully
2023-04-25 20:42:12,124:INFO:Starting cross validation
2023-04-25 20:42:12,124:INFO:Cross validating with ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), n_jobs=1
2023-04-25 20:42:12,132:ERROR:create_model() for ridge raised an exception or returned all 0.0:
2023-04-25 20:42:12,132:ERROR:Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 862, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in cross_validate
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1085, in __call__
    if self.dispatch_one_batch(iterator):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 873, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in <genexpr>
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1622, in split
    for train, test in self._iter_indices(X, y, groups):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1730, in _iter_indices
    n_train, n_test = _validate_shuffle_split(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 2126, in _validate_shuffle_split
    raise ValueError(
ValueError: With n_samples=1, test_size=None and train_size=0.9230769230769231, the resulting train set will be empty. Adjust any of the aforementioned parameters.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 862, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 810, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in cross_validate
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1085, in __call__
    if self.dispatch_one_batch(iterator):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 873, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in <genexpr>
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1622, in split
    for train, test in self._iter_indices(X, y, groups):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1730, in _iter_indices
    n_train, n_test = _validate_shuffle_split(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 2126, in _validate_shuffle_split
    raise ValueError(
ValueError: With n_samples=1, test_size=None and train_size=0.9230769230769231, the resulting train set will be empty. Adjust any of the aforementioned parameters.

2023-04-25 20:42:12,163:INFO:Initializing Elastic Net
2023-04-25 20:42:12,163:INFO:Total runtime is 0.00636528730392456 minutes
2023-04-25 20:42:12,163:INFO:SubProcess create_model() called ==================================
2023-04-25 20:42:12,163:INFO:Initializing create_model()
2023-04-25 20:42:12,163:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A185083970>, estimator=en, fold=ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A1F38B5660>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 20:42:12,163:INFO:Checking exceptions
2023-04-25 20:42:12,163:INFO:Importing libraries
2023-04-25 20:42:12,163:INFO:Copying training dataset
2023-04-25 20:42:12,181:INFO:Defining folds
2023-04-25 20:42:12,181:INFO:Declaring metric variables
2023-04-25 20:42:12,189:INFO:Importing untrained model
2023-04-25 20:42:12,191:INFO:Elastic Net Imported successfully
2023-04-25 20:42:12,205:INFO:Starting cross validation
2023-04-25 20:42:12,213:INFO:Cross validating with ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), n_jobs=1
2023-04-25 20:42:12,215:WARNING:create_model() for en raised an exception or returned all 0.0, trying without fit_kwargs:
2023-04-25 20:42:12,216:WARNING:Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 862, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in cross_validate
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1085, in __call__
    if self.dispatch_one_batch(iterator):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 873, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in <genexpr>
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1622, in split
    for train, test in self._iter_indices(X, y, groups):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1730, in _iter_indices
    n_train, n_test = _validate_shuffle_split(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 2126, in _validate_shuffle_split
    raise ValueError(
ValueError: With n_samples=1, test_size=None and train_size=0.9230769230769231, the resulting train set will be empty. Adjust any of the aforementioned parameters.

2023-04-25 20:42:12,216:INFO:Initializing create_model()
2023-04-25 20:42:12,216:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A185083970>, estimator=en, fold=ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A1F38B5660>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 20:42:12,216:INFO:Checking exceptions
2023-04-25 20:42:12,216:INFO:Importing libraries
2023-04-25 20:42:12,216:INFO:Copying training dataset
2023-04-25 20:42:12,221:INFO:Defining folds
2023-04-25 20:42:12,221:INFO:Declaring metric variables
2023-04-25 20:42:12,229:INFO:Importing untrained model
2023-04-25 20:42:12,229:INFO:Elastic Net Imported successfully
2023-04-25 20:42:12,247:INFO:Starting cross validation
2023-04-25 20:42:12,247:INFO:Cross validating with ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), n_jobs=1
2023-04-25 20:42:12,247:ERROR:create_model() for en raised an exception or returned all 0.0:
2023-04-25 20:42:12,253:ERROR:Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 862, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in cross_validate
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1085, in __call__
    if self.dispatch_one_batch(iterator):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 873, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in <genexpr>
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1622, in split
    for train, test in self._iter_indices(X, y, groups):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1730, in _iter_indices
    n_train, n_test = _validate_shuffle_split(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 2126, in _validate_shuffle_split
    raise ValueError(
ValueError: With n_samples=1, test_size=None and train_size=0.9230769230769231, the resulting train set will be empty. Adjust any of the aforementioned parameters.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 862, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 810, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in cross_validate
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1085, in __call__
    if self.dispatch_one_batch(iterator):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 873, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in <genexpr>
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1622, in split
    for train, test in self._iter_indices(X, y, groups):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1730, in _iter_indices
    n_train, n_test = _validate_shuffle_split(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 2126, in _validate_shuffle_split
    raise ValueError(
ValueError: With n_samples=1, test_size=None and train_size=0.9230769230769231, the resulting train set will be empty. Adjust any of the aforementioned parameters.

2023-04-25 20:42:12,290:INFO:Initializing Least Angle Regression
2023-04-25 20:42:12,290:INFO:Total runtime is 0.008471421400705972 minutes
2023-04-25 20:42:12,290:INFO:SubProcess create_model() called ==================================
2023-04-25 20:42:12,290:INFO:Initializing create_model()
2023-04-25 20:42:12,290:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A185083970>, estimator=lar, fold=ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A1F38B5660>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 20:42:12,290:INFO:Checking exceptions
2023-04-25 20:42:12,290:INFO:Importing libraries
2023-04-25 20:42:12,290:INFO:Copying training dataset
2023-04-25 20:42:12,299:INFO:Defining folds
2023-04-25 20:42:12,299:INFO:Declaring metric variables
2023-04-25 20:42:12,307:INFO:Importing untrained model
2023-04-25 20:42:12,309:INFO:Least Angle Regression Imported successfully
2023-04-25 20:42:12,323:INFO:Starting cross validation
2023-04-25 20:42:12,331:INFO:Cross validating with ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), n_jobs=1
2023-04-25 20:42:12,332:WARNING:create_model() for lar raised an exception or returned all 0.0, trying without fit_kwargs:
2023-04-25 20:42:12,333:WARNING:Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 862, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in cross_validate
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1085, in __call__
    if self.dispatch_one_batch(iterator):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 873, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in <genexpr>
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1622, in split
    for train, test in self._iter_indices(X, y, groups):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1730, in _iter_indices
    n_train, n_test = _validate_shuffle_split(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 2126, in _validate_shuffle_split
    raise ValueError(
ValueError: With n_samples=1, test_size=None and train_size=0.9230769230769231, the resulting train set will be empty. Adjust any of the aforementioned parameters.

2023-04-25 20:42:12,333:INFO:Initializing create_model()
2023-04-25 20:42:12,333:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A185083970>, estimator=lar, fold=ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A1F38B5660>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 20:42:12,333:INFO:Checking exceptions
2023-04-25 20:42:12,333:INFO:Importing libraries
2023-04-25 20:42:12,333:INFO:Copying training dataset
2023-04-25 20:42:12,339:INFO:Defining folds
2023-04-25 20:42:12,339:INFO:Declaring metric variables
2023-04-25 20:42:12,345:INFO:Importing untrained model
2023-04-25 20:42:12,350:INFO:Least Angle Regression Imported successfully
2023-04-25 20:42:12,364:INFO:Starting cross validation
2023-04-25 20:42:12,364:INFO:Cross validating with ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), n_jobs=1
2023-04-25 20:42:12,364:ERROR:create_model() for lar raised an exception or returned all 0.0:
2023-04-25 20:42:12,373:ERROR:Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 862, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in cross_validate
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1085, in __call__
    if self.dispatch_one_batch(iterator):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 873, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in <genexpr>
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1622, in split
    for train, test in self._iter_indices(X, y, groups):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1730, in _iter_indices
    n_train, n_test = _validate_shuffle_split(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 2126, in _validate_shuffle_split
    raise ValueError(
ValueError: With n_samples=1, test_size=None and train_size=0.9230769230769231, the resulting train set will be empty. Adjust any of the aforementioned parameters.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 862, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 810, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in cross_validate
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1085, in __call__
    if self.dispatch_one_batch(iterator):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 873, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in <genexpr>
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1622, in split
    for train, test in self._iter_indices(X, y, groups):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1730, in _iter_indices
    n_train, n_test = _validate_shuffle_split(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 2126, in _validate_shuffle_split
    raise ValueError(
ValueError: With n_samples=1, test_size=None and train_size=0.9230769230769231, the resulting train set will be empty. Adjust any of the aforementioned parameters.

2023-04-25 20:42:12,399:INFO:Initializing Lasso Least Angle Regression
2023-04-25 20:42:12,399:INFO:Total runtime is 0.010292255878448484 minutes
2023-04-25 20:42:12,416:INFO:SubProcess create_model() called ==================================
2023-04-25 20:42:12,416:INFO:Initializing create_model()
2023-04-25 20:42:12,416:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A185083970>, estimator=llar, fold=ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A1F38B5660>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 20:42:12,416:INFO:Checking exceptions
2023-04-25 20:42:12,416:INFO:Importing libraries
2023-04-25 20:42:12,416:INFO:Copying training dataset
2023-04-25 20:42:12,424:INFO:Defining folds
2023-04-25 20:42:12,424:INFO:Declaring metric variables
2023-04-25 20:42:12,431:INFO:Importing untrained model
2023-04-25 20:42:12,434:INFO:Lasso Least Angle Regression Imported successfully
2023-04-25 20:42:12,449:INFO:Starting cross validation
2023-04-25 20:42:12,454:INFO:Cross validating with ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), n_jobs=1
2023-04-25 20:42:12,454:WARNING:create_model() for llar raised an exception or returned all 0.0, trying without fit_kwargs:
2023-04-25 20:42:12,454:WARNING:Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 862, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in cross_validate
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1085, in __call__
    if self.dispatch_one_batch(iterator):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 873, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in <genexpr>
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1622, in split
    for train, test in self._iter_indices(X, y, groups):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1730, in _iter_indices
    n_train, n_test = _validate_shuffle_split(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 2126, in _validate_shuffle_split
    raise ValueError(
ValueError: With n_samples=1, test_size=None and train_size=0.9230769230769231, the resulting train set will be empty. Adjust any of the aforementioned parameters.

2023-04-25 20:42:12,454:INFO:Initializing create_model()
2023-04-25 20:42:12,454:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A185083970>, estimator=llar, fold=ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A1F38B5660>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 20:42:12,454:INFO:Checking exceptions
2023-04-25 20:42:12,454:INFO:Importing libraries
2023-04-25 20:42:12,454:INFO:Copying training dataset
2023-04-25 20:42:12,464:INFO:Defining folds
2023-04-25 20:42:12,464:INFO:Declaring metric variables
2023-04-25 20:42:12,471:INFO:Importing untrained model
2023-04-25 20:42:12,471:INFO:Lasso Least Angle Regression Imported successfully
2023-04-25 20:42:12,491:INFO:Starting cross validation
2023-04-25 20:42:12,491:INFO:Cross validating with ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), n_jobs=1
2023-04-25 20:42:12,496:ERROR:create_model() for llar raised an exception or returned all 0.0:
2023-04-25 20:42:12,496:ERROR:Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 862, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in cross_validate
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1085, in __call__
    if self.dispatch_one_batch(iterator):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 873, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in <genexpr>
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1622, in split
    for train, test in self._iter_indices(X, y, groups):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1730, in _iter_indices
    n_train, n_test = _validate_shuffle_split(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 2126, in _validate_shuffle_split
    raise ValueError(
ValueError: With n_samples=1, test_size=None and train_size=0.9230769230769231, the resulting train set will be empty. Adjust any of the aforementioned parameters.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 862, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 810, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in cross_validate
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1085, in __call__
    if self.dispatch_one_batch(iterator):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 873, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in <genexpr>
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1622, in split
    for train, test in self._iter_indices(X, y, groups):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1730, in _iter_indices
    n_train, n_test = _validate_shuffle_split(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 2126, in _validate_shuffle_split
    raise ValueError(
ValueError: With n_samples=1, test_size=None and train_size=0.9230769230769231, the resulting train set will be empty. Adjust any of the aforementioned parameters.

2023-04-25 20:42:12,531:INFO:Initializing Orthogonal Matching Pursuit
2023-04-25 20:42:12,531:INFO:Total runtime is 0.012485957145690917 minutes
2023-04-25 20:42:12,531:INFO:SubProcess create_model() called ==================================
2023-04-25 20:42:12,546:INFO:Initializing create_model()
2023-04-25 20:42:12,546:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A185083970>, estimator=omp, fold=ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A1F38B5660>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 20:42:12,546:INFO:Checking exceptions
2023-04-25 20:42:12,546:INFO:Importing libraries
2023-04-25 20:42:12,546:INFO:Copying training dataset
2023-04-25 20:42:12,549:INFO:Defining folds
2023-04-25 20:42:12,549:INFO:Declaring metric variables
2023-04-25 20:42:12,559:INFO:Importing untrained model
2023-04-25 20:42:12,567:INFO:Orthogonal Matching Pursuit Imported successfully
2023-04-25 20:42:12,573:INFO:Starting cross validation
2023-04-25 20:42:12,579:INFO:Cross validating with ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), n_jobs=1
2023-04-25 20:42:12,579:WARNING:create_model() for omp raised an exception or returned all 0.0, trying without fit_kwargs:
2023-04-25 20:42:12,579:WARNING:Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 862, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in cross_validate
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1085, in __call__
    if self.dispatch_one_batch(iterator):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 873, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in <genexpr>
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1622, in split
    for train, test in self._iter_indices(X, y, groups):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1730, in _iter_indices
    n_train, n_test = _validate_shuffle_split(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 2126, in _validate_shuffle_split
    raise ValueError(
ValueError: With n_samples=1, test_size=None and train_size=0.9230769230769231, the resulting train set will be empty. Adjust any of the aforementioned parameters.

2023-04-25 20:42:12,579:INFO:Initializing create_model()
2023-04-25 20:42:12,579:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A185083970>, estimator=omp, fold=ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A1F38B5660>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 20:42:12,579:INFO:Checking exceptions
2023-04-25 20:42:12,579:INFO:Importing libraries
2023-04-25 20:42:12,579:INFO:Copying training dataset
2023-04-25 20:42:12,593:INFO:Defining folds
2023-04-25 20:42:12,593:INFO:Declaring metric variables
2023-04-25 20:42:12,593:INFO:Importing untrained model
2023-04-25 20:42:12,607:INFO:Orthogonal Matching Pursuit Imported successfully
2023-04-25 20:42:12,615:INFO:Starting cross validation
2023-04-25 20:42:12,623:INFO:Cross validating with ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), n_jobs=1
2023-04-25 20:42:12,625:ERROR:create_model() for omp raised an exception or returned all 0.0:
2023-04-25 20:42:12,625:ERROR:Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 862, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in cross_validate
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1085, in __call__
    if self.dispatch_one_batch(iterator):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 873, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in <genexpr>
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1622, in split
    for train, test in self._iter_indices(X, y, groups):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1730, in _iter_indices
    n_train, n_test = _validate_shuffle_split(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 2126, in _validate_shuffle_split
    raise ValueError(
ValueError: With n_samples=1, test_size=None and train_size=0.9230769230769231, the resulting train set will be empty. Adjust any of the aforementioned parameters.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 862, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 810, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in cross_validate
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1085, in __call__
    if self.dispatch_one_batch(iterator):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 873, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in <genexpr>
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1622, in split
    for train, test in self._iter_indices(X, y, groups):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1730, in _iter_indices
    n_train, n_test = _validate_shuffle_split(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 2126, in _validate_shuffle_split
    raise ValueError(
ValueError: With n_samples=1, test_size=None and train_size=0.9230769230769231, the resulting train set will be empty. Adjust any of the aforementioned parameters.

2023-04-25 20:42:12,663:INFO:Initializing Bayesian Ridge
2023-04-25 20:42:12,663:INFO:Total runtime is 0.014694138367970783 minutes
2023-04-25 20:42:12,663:INFO:SubProcess create_model() called ==================================
2023-04-25 20:42:12,663:INFO:Initializing create_model()
2023-04-25 20:42:12,663:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A185083970>, estimator=br, fold=ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A1F38B5660>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 20:42:12,663:INFO:Checking exceptions
2023-04-25 20:42:12,663:INFO:Importing libraries
2023-04-25 20:42:12,663:INFO:Copying training dataset
2023-04-25 20:42:12,673:INFO:Defining folds
2023-04-25 20:42:12,673:INFO:Declaring metric variables
2023-04-25 20:42:12,681:INFO:Importing untrained model
2023-04-25 20:42:12,683:INFO:Bayesian Ridge Imported successfully
2023-04-25 20:42:12,697:INFO:Starting cross validation
2023-04-25 20:42:12,697:INFO:Cross validating with ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), n_jobs=1
2023-04-25 20:42:12,697:WARNING:create_model() for br raised an exception or returned all 0.0, trying without fit_kwargs:
2023-04-25 20:42:12,705:WARNING:Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 862, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in cross_validate
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1085, in __call__
    if self.dispatch_one_batch(iterator):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 873, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in <genexpr>
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1622, in split
    for train, test in self._iter_indices(X, y, groups):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1730, in _iter_indices
    n_train, n_test = _validate_shuffle_split(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 2126, in _validate_shuffle_split
    raise ValueError(
ValueError: With n_samples=1, test_size=None and train_size=0.9230769230769231, the resulting train set will be empty. Adjust any of the aforementioned parameters.

2023-04-25 20:42:12,706:INFO:Initializing create_model()
2023-04-25 20:42:12,706:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A185083970>, estimator=br, fold=ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A1F38B5660>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 20:42:12,706:INFO:Checking exceptions
2023-04-25 20:42:12,706:INFO:Importing libraries
2023-04-25 20:42:12,706:INFO:Copying training dataset
2023-04-25 20:42:12,711:INFO:Defining folds
2023-04-25 20:42:12,711:INFO:Declaring metric variables
2023-04-25 20:42:12,711:INFO:Importing untrained model
2023-04-25 20:42:12,719:INFO:Bayesian Ridge Imported successfully
2023-04-25 20:42:12,740:INFO:Starting cross validation
2023-04-25 20:42:12,740:INFO:Cross validating with ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), n_jobs=1
2023-04-25 20:42:12,745:ERROR:create_model() for br raised an exception or returned all 0.0:
2023-04-25 20:42:12,746:ERROR:Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 862, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in cross_validate
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1085, in __call__
    if self.dispatch_one_batch(iterator):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 873, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in <genexpr>
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1622, in split
    for train, test in self._iter_indices(X, y, groups):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1730, in _iter_indices
    n_train, n_test = _validate_shuffle_split(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 2126, in _validate_shuffle_split
    raise ValueError(
ValueError: With n_samples=1, test_size=None and train_size=0.9230769230769231, the resulting train set will be empty. Adjust any of the aforementioned parameters.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 862, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 810, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in cross_validate
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1085, in __call__
    if self.dispatch_one_batch(iterator):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 873, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in <genexpr>
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1622, in split
    for train, test in self._iter_indices(X, y, groups):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1730, in _iter_indices
    n_train, n_test = _validate_shuffle_split(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 2126, in _validate_shuffle_split
    raise ValueError(
ValueError: With n_samples=1, test_size=None and train_size=0.9230769230769231, the resulting train set will be empty. Adjust any of the aforementioned parameters.

2023-04-25 20:42:12,784:INFO:Initializing Passive Aggressive Regressor
2023-04-25 20:42:12,784:INFO:Total runtime is 0.01670473019282023 minutes
2023-04-25 20:42:12,792:INFO:SubProcess create_model() called ==================================
2023-04-25 20:42:12,795:INFO:Initializing create_model()
2023-04-25 20:42:12,795:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A185083970>, estimator=par, fold=ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A1F38B5660>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 20:42:12,795:INFO:Checking exceptions
2023-04-25 20:42:12,795:INFO:Importing libraries
2023-04-25 20:42:12,795:INFO:Copying training dataset
2023-04-25 20:42:12,795:INFO:Defining folds
2023-04-25 20:42:12,802:INFO:Declaring metric variables
2023-04-25 20:42:12,802:INFO:Importing untrained model
2023-04-25 20:42:12,815:INFO:Passive Aggressive Regressor Imported successfully
2023-04-25 20:42:12,823:INFO:Starting cross validation
2023-04-25 20:42:12,831:INFO:Cross validating with ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), n_jobs=1
2023-04-25 20:42:12,831:WARNING:create_model() for par raised an exception or returned all 0.0, trying without fit_kwargs:
2023-04-25 20:42:12,831:WARNING:Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 862, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in cross_validate
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1085, in __call__
    if self.dispatch_one_batch(iterator):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 873, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in <genexpr>
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1622, in split
    for train, test in self._iter_indices(X, y, groups):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1730, in _iter_indices
    n_train, n_test = _validate_shuffle_split(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 2126, in _validate_shuffle_split
    raise ValueError(
ValueError: With n_samples=1, test_size=None and train_size=0.9230769230769231, the resulting train set will be empty. Adjust any of the aforementioned parameters.

2023-04-25 20:42:12,831:INFO:Initializing create_model()
2023-04-25 20:42:12,831:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A185083970>, estimator=par, fold=ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A1F38B5660>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 20:42:12,831:INFO:Checking exceptions
2023-04-25 20:42:12,831:INFO:Importing libraries
2023-04-25 20:42:12,831:INFO:Copying training dataset
2023-04-25 20:42:12,839:INFO:Defining folds
2023-04-25 20:42:12,839:INFO:Declaring metric variables
2023-04-25 20:42:12,844:INFO:Importing untrained model
2023-04-25 20:42:12,850:INFO:Passive Aggressive Regressor Imported successfully
2023-04-25 20:42:12,864:INFO:Starting cross validation
2023-04-25 20:42:12,871:INFO:Cross validating with ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), n_jobs=1
2023-04-25 20:42:12,871:ERROR:create_model() for par raised an exception or returned all 0.0:
2023-04-25 20:42:12,871:ERROR:Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 862, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in cross_validate
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1085, in __call__
    if self.dispatch_one_batch(iterator):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 873, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in <genexpr>
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1622, in split
    for train, test in self._iter_indices(X, y, groups):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1730, in _iter_indices
    n_train, n_test = _validate_shuffle_split(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 2126, in _validate_shuffle_split
    raise ValueError(
ValueError: With n_samples=1, test_size=None and train_size=0.9230769230769231, the resulting train set will be empty. Adjust any of the aforementioned parameters.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 862, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 810, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in cross_validate
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1085, in __call__
    if self.dispatch_one_batch(iterator):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 873, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in <genexpr>
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1622, in split
    for train, test in self._iter_indices(X, y, groups):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1730, in _iter_indices
    n_train, n_test = _validate_shuffle_split(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 2126, in _validate_shuffle_split
    raise ValueError(
ValueError: With n_samples=1, test_size=None and train_size=0.9230769230769231, the resulting train set will be empty. Adjust any of the aforementioned parameters.

2023-04-25 20:42:12,905:INFO:Initializing Huber Regressor
2023-04-25 20:42:12,905:INFO:Total runtime is 0.01872988939285278 minutes
2023-04-25 20:42:12,905:INFO:SubProcess create_model() called ==================================
2023-04-25 20:42:12,921:INFO:Initializing create_model()
2023-04-25 20:42:12,921:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A185083970>, estimator=huber, fold=ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A1F38B5660>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 20:42:12,921:INFO:Checking exceptions
2023-04-25 20:42:12,921:INFO:Importing libraries
2023-04-25 20:42:12,921:INFO:Copying training dataset
2023-04-25 20:42:12,935:INFO:Defining folds
2023-04-25 20:42:12,935:INFO:Declaring metric variables
2023-04-25 20:42:12,942:INFO:Importing untrained model
2023-04-25 20:42:12,954:INFO:Huber Regressor Imported successfully
2023-04-25 20:42:12,969:INFO:Starting cross validation
2023-04-25 20:42:12,969:INFO:Cross validating with ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), n_jobs=1
2023-04-25 20:42:12,969:WARNING:create_model() for huber raised an exception or returned all 0.0, trying without fit_kwargs:
2023-04-25 20:42:12,977:WARNING:Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 862, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in cross_validate
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1085, in __call__
    if self.dispatch_one_batch(iterator):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 873, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in <genexpr>
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1622, in split
    for train, test in self._iter_indices(X, y, groups):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1730, in _iter_indices
    n_train, n_test = _validate_shuffle_split(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 2126, in _validate_shuffle_split
    raise ValueError(
ValueError: With n_samples=1, test_size=None and train_size=0.9230769230769231, the resulting train set will be empty. Adjust any of the aforementioned parameters.

2023-04-25 20:42:12,977:INFO:Initializing create_model()
2023-04-25 20:42:12,977:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A185083970>, estimator=huber, fold=ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A1F38B5660>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 20:42:12,977:INFO:Checking exceptions
2023-04-25 20:42:12,977:INFO:Importing libraries
2023-04-25 20:42:12,977:INFO:Copying training dataset
2023-04-25 20:42:12,985:INFO:Defining folds
2023-04-25 20:42:12,985:INFO:Declaring metric variables
2023-04-25 20:42:13,001:INFO:Importing untrained model
2023-04-25 20:42:13,012:INFO:Huber Regressor Imported successfully
2023-04-25 20:42:13,031:INFO:Starting cross validation
2023-04-25 20:42:13,031:INFO:Cross validating with ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), n_jobs=1
2023-04-25 20:42:13,031:ERROR:create_model() for huber raised an exception or returned all 0.0:
2023-04-25 20:42:13,037:ERROR:Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 862, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in cross_validate
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1085, in __call__
    if self.dispatch_one_batch(iterator):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 873, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in <genexpr>
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1622, in split
    for train, test in self._iter_indices(X, y, groups):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1730, in _iter_indices
    n_train, n_test = _validate_shuffle_split(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 2126, in _validate_shuffle_split
    raise ValueError(
ValueError: With n_samples=1, test_size=None and train_size=0.9230769230769231, the resulting train set will be empty. Adjust any of the aforementioned parameters.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 862, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 810, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in cross_validate
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1085, in __call__
    if self.dispatch_one_batch(iterator):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 873, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in <genexpr>
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1622, in split
    for train, test in self._iter_indices(X, y, groups):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1730, in _iter_indices
    n_train, n_test = _validate_shuffle_split(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 2126, in _validate_shuffle_split
    raise ValueError(
ValueError: With n_samples=1, test_size=None and train_size=0.9230769230769231, the resulting train set will be empty. Adjust any of the aforementioned parameters.

2023-04-25 20:42:13,081:INFO:Initializing K Neighbors Regressor
2023-04-25 20:42:13,081:INFO:Total runtime is 0.021657474835713703 minutes
2023-04-25 20:42:13,081:INFO:SubProcess create_model() called ==================================
2023-04-25 20:42:13,081:INFO:Initializing create_model()
2023-04-25 20:42:13,081:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A185083970>, estimator=knn, fold=ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A1F38B5660>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 20:42:13,081:INFO:Checking exceptions
2023-04-25 20:42:13,081:INFO:Importing libraries
2023-04-25 20:42:13,081:INFO:Copying training dataset
2023-04-25 20:42:13,098:INFO:Defining folds
2023-04-25 20:42:13,098:INFO:Declaring metric variables
2023-04-25 20:42:13,099:INFO:Importing untrained model
2023-04-25 20:42:13,107:INFO:K Neighbors Regressor Imported successfully
2023-04-25 20:42:13,114:INFO:Starting cross validation
2023-04-25 20:42:13,119:INFO:Cross validating with ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), n_jobs=1
2023-04-25 20:42:13,120:WARNING:create_model() for knn raised an exception or returned all 0.0, trying without fit_kwargs:
2023-04-25 20:42:13,120:WARNING:Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 862, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in cross_validate
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1085, in __call__
    if self.dispatch_one_batch(iterator):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 873, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in <genexpr>
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1622, in split
    for train, test in self._iter_indices(X, y, groups):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1730, in _iter_indices
    n_train, n_test = _validate_shuffle_split(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 2126, in _validate_shuffle_split
    raise ValueError(
ValueError: With n_samples=1, test_size=None and train_size=0.9230769230769231, the resulting train set will be empty. Adjust any of the aforementioned parameters.

2023-04-25 20:42:13,120:INFO:Initializing create_model()
2023-04-25 20:42:13,120:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A185083970>, estimator=knn, fold=ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A1F38B5660>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 20:42:13,120:INFO:Checking exceptions
2023-04-25 20:42:13,120:INFO:Importing libraries
2023-04-25 20:42:13,120:INFO:Copying training dataset
2023-04-25 20:42:13,127:INFO:Defining folds
2023-04-25 20:42:13,127:INFO:Declaring metric variables
2023-04-25 20:42:13,132:INFO:Importing untrained model
2023-04-25 20:42:13,137:INFO:K Neighbors Regressor Imported successfully
2023-04-25 20:42:13,145:INFO:Starting cross validation
2023-04-25 20:42:13,150:INFO:Cross validating with ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), n_jobs=1
2023-04-25 20:42:13,150:ERROR:create_model() for knn raised an exception or returned all 0.0:
2023-04-25 20:42:13,150:ERROR:Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 862, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in cross_validate
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1085, in __call__
    if self.dispatch_one_batch(iterator):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 873, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in <genexpr>
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1622, in split
    for train, test in self._iter_indices(X, y, groups):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1730, in _iter_indices
    n_train, n_test = _validate_shuffle_split(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 2126, in _validate_shuffle_split
    raise ValueError(
ValueError: With n_samples=1, test_size=None and train_size=0.9230769230769231, the resulting train set will be empty. Adjust any of the aforementioned parameters.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 862, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 810, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in cross_validate
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1085, in __call__
    if self.dispatch_one_batch(iterator):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 873, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in <genexpr>
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1622, in split
    for train, test in self._iter_indices(X, y, groups):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1730, in _iter_indices
    n_train, n_test = _validate_shuffle_split(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 2126, in _validate_shuffle_split
    raise ValueError(
ValueError: With n_samples=1, test_size=None and train_size=0.9230769230769231, the resulting train set will be empty. Adjust any of the aforementioned parameters.

2023-04-25 20:42:13,178:INFO:Initializing Decision Tree Regressor
2023-04-25 20:42:13,178:INFO:Total runtime is 0.023274000485738116 minutes
2023-04-25 20:42:13,178:INFO:SubProcess create_model() called ==================================
2023-04-25 20:42:13,178:INFO:Initializing create_model()
2023-04-25 20:42:13,178:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A185083970>, estimator=dt, fold=ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A1F38B5660>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 20:42:13,178:INFO:Checking exceptions
2023-04-25 20:42:13,178:INFO:Importing libraries
2023-04-25 20:42:13,178:INFO:Copying training dataset
2023-04-25 20:42:13,192:INFO:Defining folds
2023-04-25 20:42:13,192:INFO:Declaring metric variables
2023-04-25 20:42:13,204:INFO:Importing untrained model
2023-04-25 20:42:13,212:INFO:Decision Tree Regressor Imported successfully
2023-04-25 20:42:13,226:INFO:Starting cross validation
2023-04-25 20:42:13,233:INFO:Cross validating with ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), n_jobs=1
2023-04-25 20:42:13,233:WARNING:create_model() for dt raised an exception or returned all 0.0, trying without fit_kwargs:
2023-04-25 20:42:13,238:WARNING:Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 862, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in cross_validate
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1085, in __call__
    if self.dispatch_one_batch(iterator):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 873, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in <genexpr>
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1622, in split
    for train, test in self._iter_indices(X, y, groups):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1730, in _iter_indices
    n_train, n_test = _validate_shuffle_split(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 2126, in _validate_shuffle_split
    raise ValueError(
ValueError: With n_samples=1, test_size=None and train_size=0.9230769230769231, the resulting train set will be empty. Adjust any of the aforementioned parameters.

2023-04-25 20:42:13,238:INFO:Initializing create_model()
2023-04-25 20:42:13,238:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A185083970>, estimator=dt, fold=ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A1F38B5660>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 20:42:13,238:INFO:Checking exceptions
2023-04-25 20:42:13,238:INFO:Importing libraries
2023-04-25 20:42:13,238:INFO:Copying training dataset
2023-04-25 20:42:13,246:INFO:Defining folds
2023-04-25 20:42:13,246:INFO:Declaring metric variables
2023-04-25 20:42:13,259:INFO:Importing untrained model
2023-04-25 20:42:13,267:INFO:Decision Tree Regressor Imported successfully
2023-04-25 20:42:13,281:INFO:Starting cross validation
2023-04-25 20:42:13,281:INFO:Cross validating with ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), n_jobs=1
2023-04-25 20:42:13,281:ERROR:create_model() for dt raised an exception or returned all 0.0:
2023-04-25 20:42:13,289:ERROR:Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 862, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in cross_validate
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1085, in __call__
    if self.dispatch_one_batch(iterator):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 873, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in <genexpr>
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1622, in split
    for train, test in self._iter_indices(X, y, groups):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1730, in _iter_indices
    n_train, n_test = _validate_shuffle_split(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 2126, in _validate_shuffle_split
    raise ValueError(
ValueError: With n_samples=1, test_size=None and train_size=0.9230769230769231, the resulting train set will be empty. Adjust any of the aforementioned parameters.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 862, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 810, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in cross_validate
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1085, in __call__
    if self.dispatch_one_batch(iterator):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 873, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in <genexpr>
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1622, in split
    for train, test in self._iter_indices(X, y, groups):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1730, in _iter_indices
    n_train, n_test = _validate_shuffle_split(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 2126, in _validate_shuffle_split
    raise ValueError(
ValueError: With n_samples=1, test_size=None and train_size=0.9230769230769231, the resulting train set will be empty. Adjust any of the aforementioned parameters.

2023-04-25 20:42:13,332:INFO:Initializing Random Forest Regressor
2023-04-25 20:42:13,332:INFO:Total runtime is 0.025835585594177243 minutes
2023-04-25 20:42:13,335:INFO:SubProcess create_model() called ==================================
2023-04-25 20:42:13,338:INFO:Initializing create_model()
2023-04-25 20:42:13,338:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A185083970>, estimator=rf, fold=ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A1F38B5660>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 20:42:13,338:INFO:Checking exceptions
2023-04-25 20:42:13,338:INFO:Importing libraries
2023-04-25 20:42:13,338:INFO:Copying training dataset
2023-04-25 20:42:13,342:INFO:Defining folds
2023-04-25 20:42:13,342:INFO:Declaring metric variables
2023-04-25 20:42:13,350:INFO:Importing untrained model
2023-04-25 20:42:13,357:INFO:Random Forest Regressor Imported successfully
2023-04-25 20:42:13,364:INFO:Starting cross validation
2023-04-25 20:42:13,371:INFO:Cross validating with ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), n_jobs=1
2023-04-25 20:42:13,371:WARNING:create_model() for rf raised an exception or returned all 0.0, trying without fit_kwargs:
2023-04-25 20:42:13,371:WARNING:Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 862, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in cross_validate
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1085, in __call__
    if self.dispatch_one_batch(iterator):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 873, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in <genexpr>
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1622, in split
    for train, test in self._iter_indices(X, y, groups):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1730, in _iter_indices
    n_train, n_test = _validate_shuffle_split(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 2126, in _validate_shuffle_split
    raise ValueError(
ValueError: With n_samples=1, test_size=None and train_size=0.9230769230769231, the resulting train set will be empty. Adjust any of the aforementioned parameters.

2023-04-25 20:42:13,371:INFO:Initializing create_model()
2023-04-25 20:42:13,371:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A185083970>, estimator=rf, fold=ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A1F38B5660>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 20:42:13,371:INFO:Checking exceptions
2023-04-25 20:42:13,371:INFO:Importing libraries
2023-04-25 20:42:13,371:INFO:Copying training dataset
2023-04-25 20:42:13,378:INFO:Defining folds
2023-04-25 20:42:13,378:INFO:Declaring metric variables
2023-04-25 20:42:13,385:INFO:Importing untrained model
2023-04-25 20:42:13,393:INFO:Random Forest Regressor Imported successfully
2023-04-25 20:42:13,405:INFO:Starting cross validation
2023-04-25 20:42:13,405:INFO:Cross validating with ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), n_jobs=1
2023-04-25 20:42:13,405:ERROR:create_model() for rf raised an exception or returned all 0.0:
2023-04-25 20:42:13,405:ERROR:Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 862, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in cross_validate
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1085, in __call__
    if self.dispatch_one_batch(iterator):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 873, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in <genexpr>
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1622, in split
    for train, test in self._iter_indices(X, y, groups):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1730, in _iter_indices
    n_train, n_test = _validate_shuffle_split(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 2126, in _validate_shuffle_split
    raise ValueError(
ValueError: With n_samples=1, test_size=None and train_size=0.9230769230769231, the resulting train set will be empty. Adjust any of the aforementioned parameters.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 862, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 810, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in cross_validate
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1085, in __call__
    if self.dispatch_one_batch(iterator):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 873, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in <genexpr>
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1622, in split
    for train, test in self._iter_indices(X, y, groups):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1730, in _iter_indices
    n_train, n_test = _validate_shuffle_split(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 2126, in _validate_shuffle_split
    raise ValueError(
ValueError: With n_samples=1, test_size=None and train_size=0.9230769230769231, the resulting train set will be empty. Adjust any of the aforementioned parameters.

2023-04-25 20:42:13,447:INFO:Initializing Extra Trees Regressor
2023-04-25 20:42:13,447:INFO:Total runtime is 0.027764205137888586 minutes
2023-04-25 20:42:13,447:INFO:SubProcess create_model() called ==================================
2023-04-25 20:42:13,453:INFO:Initializing create_model()
2023-04-25 20:42:13,453:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A185083970>, estimator=et, fold=ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A1F38B5660>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 20:42:13,453:INFO:Checking exceptions
2023-04-25 20:42:13,453:INFO:Importing libraries
2023-04-25 20:42:13,453:INFO:Copying training dataset
2023-04-25 20:42:13,460:INFO:Defining folds
2023-04-25 20:42:13,460:INFO:Declaring metric variables
2023-04-25 20:42:13,463:INFO:Importing untrained model
2023-04-25 20:42:13,472:INFO:Extra Trees Regressor Imported successfully
2023-04-25 20:42:13,489:INFO:Starting cross validation
2023-04-25 20:42:13,489:INFO:Cross validating with ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), n_jobs=1
2023-04-25 20:42:13,489:WARNING:create_model() for et raised an exception or returned all 0.0, trying without fit_kwargs:
2023-04-25 20:42:13,494:WARNING:Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 862, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in cross_validate
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1085, in __call__
    if self.dispatch_one_batch(iterator):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 873, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in <genexpr>
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1622, in split
    for train, test in self._iter_indices(X, y, groups):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1730, in _iter_indices
    n_train, n_test = _validate_shuffle_split(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 2126, in _validate_shuffle_split
    raise ValueError(
ValueError: With n_samples=1, test_size=None and train_size=0.9230769230769231, the resulting train set will be empty. Adjust any of the aforementioned parameters.

2023-04-25 20:42:13,495:INFO:Initializing create_model()
2023-04-25 20:42:13,495:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A185083970>, estimator=et, fold=ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A1F38B5660>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 20:42:13,495:INFO:Checking exceptions
2023-04-25 20:42:13,495:INFO:Importing libraries
2023-04-25 20:42:13,495:INFO:Copying training dataset
2023-04-25 20:42:13,502:INFO:Defining folds
2023-04-25 20:42:13,502:INFO:Declaring metric variables
2023-04-25 20:42:13,502:INFO:Importing untrained model
2023-04-25 20:42:13,517:INFO:Extra Trees Regressor Imported successfully
2023-04-25 20:42:13,530:INFO:Starting cross validation
2023-04-25 20:42:13,530:INFO:Cross validating with ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), n_jobs=1
2023-04-25 20:42:13,530:ERROR:create_model() for et raised an exception or returned all 0.0:
2023-04-25 20:42:13,533:ERROR:Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 862, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in cross_validate
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1085, in __call__
    if self.dispatch_one_batch(iterator):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 873, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in <genexpr>
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1622, in split
    for train, test in self._iter_indices(X, y, groups):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1730, in _iter_indices
    n_train, n_test = _validate_shuffle_split(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 2126, in _validate_shuffle_split
    raise ValueError(
ValueError: With n_samples=1, test_size=None and train_size=0.9230769230769231, the resulting train set will be empty. Adjust any of the aforementioned parameters.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 862, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 810, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in cross_validate
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1085, in __call__
    if self.dispatch_one_batch(iterator):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 873, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in <genexpr>
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1622, in split
    for train, test in self._iter_indices(X, y, groups):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1730, in _iter_indices
    n_train, n_test = _validate_shuffle_split(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 2126, in _validate_shuffle_split
    raise ValueError(
ValueError: With n_samples=1, test_size=None and train_size=0.9230769230769231, the resulting train set will be empty. Adjust any of the aforementioned parameters.

2023-04-25 20:42:13,560:INFO:Initializing AdaBoost Regressor
2023-04-25 20:42:13,560:INFO:Total runtime is 0.02964542706807454 minutes
2023-04-25 20:42:13,560:INFO:SubProcess create_model() called ==================================
2023-04-25 20:42:13,560:INFO:Initializing create_model()
2023-04-25 20:42:13,560:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A185083970>, estimator=ada, fold=ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A1F38B5660>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 20:42:13,560:INFO:Checking exceptions
2023-04-25 20:42:13,560:INFO:Importing libraries
2023-04-25 20:42:13,560:INFO:Copying training dataset
2023-04-25 20:42:13,572:INFO:Defining folds
2023-04-25 20:42:13,572:INFO:Declaring metric variables
2023-04-25 20:42:13,578:INFO:Importing untrained model
2023-04-25 20:42:13,582:INFO:AdaBoost Regressor Imported successfully
2023-04-25 20:42:13,592:INFO:Starting cross validation
2023-04-25 20:42:13,592:INFO:Cross validating with ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), n_jobs=1
2023-04-25 20:42:13,592:WARNING:create_model() for ada raised an exception or returned all 0.0, trying without fit_kwargs:
2023-04-25 20:42:13,592:WARNING:Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 862, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in cross_validate
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1085, in __call__
    if self.dispatch_one_batch(iterator):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 873, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in <genexpr>
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1622, in split
    for train, test in self._iter_indices(X, y, groups):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1730, in _iter_indices
    n_train, n_test = _validate_shuffle_split(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 2126, in _validate_shuffle_split
    raise ValueError(
ValueError: With n_samples=1, test_size=None and train_size=0.9230769230769231, the resulting train set will be empty. Adjust any of the aforementioned parameters.

2023-04-25 20:42:13,592:INFO:Initializing create_model()
2023-04-25 20:42:13,592:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A185083970>, estimator=ada, fold=ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A1F38B5660>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 20:42:13,592:INFO:Checking exceptions
2023-04-25 20:42:13,592:INFO:Importing libraries
2023-04-25 20:42:13,592:INFO:Copying training dataset
2023-04-25 20:42:13,599:INFO:Defining folds
2023-04-25 20:42:13,599:INFO:Declaring metric variables
2023-04-25 20:42:13,599:INFO:Importing untrained model
2023-04-25 20:42:13,606:INFO:AdaBoost Regressor Imported successfully
2023-04-25 20:42:13,617:INFO:Starting cross validation
2023-04-25 20:42:13,617:INFO:Cross validating with ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), n_jobs=1
2023-04-25 20:42:13,617:ERROR:create_model() for ada raised an exception or returned all 0.0:
2023-04-25 20:42:13,620:ERROR:Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 862, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in cross_validate
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1085, in __call__
    if self.dispatch_one_batch(iterator):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 873, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in <genexpr>
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1622, in split
    for train, test in self._iter_indices(X, y, groups):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1730, in _iter_indices
    n_train, n_test = _validate_shuffle_split(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 2126, in _validate_shuffle_split
    raise ValueError(
ValueError: With n_samples=1, test_size=None and train_size=0.9230769230769231, the resulting train set will be empty. Adjust any of the aforementioned parameters.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 862, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 810, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in cross_validate
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1085, in __call__
    if self.dispatch_one_batch(iterator):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 873, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in <genexpr>
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1622, in split
    for train, test in self._iter_indices(X, y, groups):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1730, in _iter_indices
    n_train, n_test = _validate_shuffle_split(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 2126, in _validate_shuffle_split
    raise ValueError(
ValueError: With n_samples=1, test_size=None and train_size=0.9230769230769231, the resulting train set will be empty. Adjust any of the aforementioned parameters.

2023-04-25 20:42:13,643:INFO:Initializing Gradient Boosting Regressor
2023-04-25 20:42:13,651:INFO:Total runtime is 0.03116581837336222 minutes
2023-04-25 20:42:13,651:INFO:SubProcess create_model() called ==================================
2023-04-25 20:42:13,651:INFO:Initializing create_model()
2023-04-25 20:42:13,651:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A185083970>, estimator=gbr, fold=ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A1F38B5660>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 20:42:13,651:INFO:Checking exceptions
2023-04-25 20:42:13,651:INFO:Importing libraries
2023-04-25 20:42:13,651:INFO:Copying training dataset
2023-04-25 20:42:13,659:INFO:Defining folds
2023-04-25 20:42:13,659:INFO:Declaring metric variables
2023-04-25 20:42:13,666:INFO:Importing untrained model
2023-04-25 20:42:13,670:INFO:Gradient Boosting Regressor Imported successfully
2023-04-25 20:42:13,679:INFO:Starting cross validation
2023-04-25 20:42:13,679:INFO:Cross validating with ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), n_jobs=1
2023-04-25 20:42:13,682:WARNING:create_model() for gbr raised an exception or returned all 0.0, trying without fit_kwargs:
2023-04-25 20:42:13,682:WARNING:Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 862, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in cross_validate
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1085, in __call__
    if self.dispatch_one_batch(iterator):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 873, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in <genexpr>
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1622, in split
    for train, test in self._iter_indices(X, y, groups):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1730, in _iter_indices
    n_train, n_test = _validate_shuffle_split(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 2126, in _validate_shuffle_split
    raise ValueError(
ValueError: With n_samples=1, test_size=None and train_size=0.9230769230769231, the resulting train set will be empty. Adjust any of the aforementioned parameters.

2023-04-25 20:42:13,682:INFO:Initializing create_model()
2023-04-25 20:42:13,682:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A185083970>, estimator=gbr, fold=ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A1F38B5660>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 20:42:13,682:INFO:Checking exceptions
2023-04-25 20:42:13,682:INFO:Importing libraries
2023-04-25 20:42:13,682:INFO:Copying training dataset
2023-04-25 20:42:13,684:INFO:Defining folds
2023-04-25 20:42:13,684:INFO:Declaring metric variables
2023-04-25 20:42:13,692:INFO:Importing untrained model
2023-04-25 20:42:13,696:INFO:Gradient Boosting Regressor Imported successfully
2023-04-25 20:42:13,703:INFO:Starting cross validation
2023-04-25 20:42:13,703:INFO:Cross validating with ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), n_jobs=1
2023-04-25 20:42:13,703:ERROR:create_model() for gbr raised an exception or returned all 0.0:
2023-04-25 20:42:13,708:ERROR:Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 862, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in cross_validate
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1085, in __call__
    if self.dispatch_one_batch(iterator):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 873, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in <genexpr>
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1622, in split
    for train, test in self._iter_indices(X, y, groups):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1730, in _iter_indices
    n_train, n_test = _validate_shuffle_split(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 2126, in _validate_shuffle_split
    raise ValueError(
ValueError: With n_samples=1, test_size=None and train_size=0.9230769230769231, the resulting train set will be empty. Adjust any of the aforementioned parameters.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 862, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 810, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in cross_validate
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1085, in __call__
    if self.dispatch_one_batch(iterator):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 873, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in <genexpr>
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1622, in split
    for train, test in self._iter_indices(X, y, groups):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1730, in _iter_indices
    n_train, n_test = _validate_shuffle_split(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 2126, in _validate_shuffle_split
    raise ValueError(
ValueError: With n_samples=1, test_size=None and train_size=0.9230769230769231, the resulting train set will be empty. Adjust any of the aforementioned parameters.

2023-04-25 20:42:13,732:INFO:Initializing Light Gradient Boosting Machine
2023-04-25 20:42:13,732:INFO:Total runtime is 0.032513340314229325 minutes
2023-04-25 20:42:13,741:INFO:SubProcess create_model() called ==================================
2023-04-25 20:42:13,741:INFO:Initializing create_model()
2023-04-25 20:42:13,741:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A185083970>, estimator=lightgbm, fold=ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A1F38B5660>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 20:42:13,741:INFO:Checking exceptions
2023-04-25 20:42:13,741:INFO:Importing libraries
2023-04-25 20:42:13,741:INFO:Copying training dataset
2023-04-25 20:42:13,746:INFO:Defining folds
2023-04-25 20:42:13,746:INFO:Declaring metric variables
2023-04-25 20:42:13,752:INFO:Importing untrained model
2023-04-25 20:42:13,752:INFO:Light Gradient Boosting Machine Imported successfully
2023-04-25 20:42:13,765:INFO:Starting cross validation
2023-04-25 20:42:13,769:INFO:Cross validating with ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), n_jobs=1
2023-04-25 20:42:13,769:WARNING:create_model() for lightgbm raised an exception or returned all 0.0, trying without fit_kwargs:
2023-04-25 20:42:13,769:WARNING:Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 862, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in cross_validate
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1085, in __call__
    if self.dispatch_one_batch(iterator):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 873, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in <genexpr>
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1622, in split
    for train, test in self._iter_indices(X, y, groups):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1730, in _iter_indices
    n_train, n_test = _validate_shuffle_split(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 2126, in _validate_shuffle_split
    raise ValueError(
ValueError: With n_samples=1, test_size=None and train_size=0.9230769230769231, the resulting train set will be empty. Adjust any of the aforementioned parameters.

2023-04-25 20:42:13,769:INFO:Initializing create_model()
2023-04-25 20:42:13,769:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A185083970>, estimator=lightgbm, fold=ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A1F38B5660>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 20:42:13,769:INFO:Checking exceptions
2023-04-25 20:42:13,769:INFO:Importing libraries
2023-04-25 20:42:13,769:INFO:Copying training dataset
2023-04-25 20:42:13,772:INFO:Defining folds
2023-04-25 20:42:13,772:INFO:Declaring metric variables
2023-04-25 20:42:13,779:INFO:Importing untrained model
2023-04-25 20:42:13,781:INFO:Light Gradient Boosting Machine Imported successfully
2023-04-25 20:42:13,789:INFO:Starting cross validation
2023-04-25 20:42:13,789:INFO:Cross validating with ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), n_jobs=1
2023-04-25 20:42:13,789:ERROR:create_model() for lightgbm raised an exception or returned all 0.0:
2023-04-25 20:42:13,797:ERROR:Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 862, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in cross_validate
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1085, in __call__
    if self.dispatch_one_batch(iterator):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 873, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in <genexpr>
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1622, in split
    for train, test in self._iter_indices(X, y, groups):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1730, in _iter_indices
    n_train, n_test = _validate_shuffle_split(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 2126, in _validate_shuffle_split
    raise ValueError(
ValueError: With n_samples=1, test_size=None and train_size=0.9230769230769231, the resulting train set will be empty. Adjust any of the aforementioned parameters.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 862, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 810, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in cross_validate
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1085, in __call__
    if self.dispatch_one_batch(iterator):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 873, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in <genexpr>
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1622, in split
    for train, test in self._iter_indices(X, y, groups):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1730, in _iter_indices
    n_train, n_test = _validate_shuffle_split(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 2126, in _validate_shuffle_split
    raise ValueError(
ValueError: With n_samples=1, test_size=None and train_size=0.9230769230769231, the resulting train set will be empty. Adjust any of the aforementioned parameters.

2023-04-25 20:42:13,830:INFO:Initializing Dummy Regressor
2023-04-25 20:42:13,830:INFO:Total runtime is 0.03414602279663086 minutes
2023-04-25 20:42:13,830:INFO:SubProcess create_model() called ==================================
2023-04-25 20:42:13,830:INFO:Initializing create_model()
2023-04-25 20:42:13,830:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A185083970>, estimator=dummy, fold=ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A1F38B5660>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 20:42:13,830:INFO:Checking exceptions
2023-04-25 20:42:13,830:INFO:Importing libraries
2023-04-25 20:42:13,830:INFO:Copying training dataset
2023-04-25 20:42:13,845:INFO:Defining folds
2023-04-25 20:42:13,845:INFO:Declaring metric variables
2023-04-25 20:42:13,850:INFO:Importing untrained model
2023-04-25 20:42:13,856:INFO:Dummy Regressor Imported successfully
2023-04-25 20:42:13,865:INFO:Starting cross validation
2023-04-25 20:42:13,865:INFO:Cross validating with ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), n_jobs=1
2023-04-25 20:42:13,869:WARNING:create_model() for dummy raised an exception or returned all 0.0, trying without fit_kwargs:
2023-04-25 20:42:13,869:WARNING:Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 862, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in cross_validate
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1085, in __call__
    if self.dispatch_one_batch(iterator):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 873, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in <genexpr>
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1622, in split
    for train, test in self._iter_indices(X, y, groups):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1730, in _iter_indices
    n_train, n_test = _validate_shuffle_split(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 2126, in _validate_shuffle_split
    raise ValueError(
ValueError: With n_samples=1, test_size=None and train_size=0.9230769230769231, the resulting train set will be empty. Adjust any of the aforementioned parameters.

2023-04-25 20:42:13,869:INFO:Initializing create_model()
2023-04-25 20:42:13,869:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A185083970>, estimator=dummy, fold=ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A1F38B5660>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 20:42:13,869:INFO:Checking exceptions
2023-04-25 20:42:13,869:INFO:Importing libraries
2023-04-25 20:42:13,869:INFO:Copying training dataset
2023-04-25 20:42:13,878:INFO:Defining folds
2023-04-25 20:42:13,878:INFO:Declaring metric variables
2023-04-25 20:42:13,883:INFO:Importing untrained model
2023-04-25 20:42:13,883:INFO:Dummy Regressor Imported successfully
2023-04-25 20:42:13,902:INFO:Starting cross validation
2023-04-25 20:42:13,902:INFO:Cross validating with ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), n_jobs=1
2023-04-25 20:42:13,902:ERROR:create_model() for dummy raised an exception or returned all 0.0:
2023-04-25 20:42:13,905:ERROR:Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 862, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in cross_validate
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1085, in __call__
    if self.dispatch_one_batch(iterator):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 873, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in <genexpr>
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1622, in split
    for train, test in self._iter_indices(X, y, groups):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1730, in _iter_indices
    n_train, n_test = _validate_shuffle_split(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 2126, in _validate_shuffle_split
    raise ValueError(
ValueError: With n_samples=1, test_size=None and train_size=0.9230769230769231, the resulting train set will be empty. Adjust any of the aforementioned parameters.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 862, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 810, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in cross_validate
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1085, in __call__
    if self.dispatch_one_batch(iterator):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 873, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 266, in <genexpr>
    results = parallel(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1622, in split
    for train, test in self._iter_indices(X, y, groups):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 1730, in _iter_indices
    n_train, n_test = _validate_shuffle_split(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 2126, in _validate_shuffle_split
    raise ValueError(
ValueError: With n_samples=1, test_size=None and train_size=0.9230769230769231, the resulting train set will be empty. Adjust any of the aforementioned parameters.

2023-04-25 20:42:13,946:INFO:_master_model_container: 0
2023-04-25 20:42:13,946:INFO:_display_container: 3
2023-04-25 20:42:13,946:INFO:[]
2023-04-25 20:42:13,946:INFO:compare_models() successfully completed......................................
2023-04-25 20:53:01,691:INFO:PyCaret RegressionExperiment
2023-04-25 20:53:01,691:INFO:Logging name: price_recomm_partial
2023-04-25 20:53:01,691:INFO:ML Usecase: MLUsecase.REGRESSION
2023-04-25 20:53:01,691:INFO:version 3.0.0
2023-04-25 20:53:01,691:INFO:Initializing setup()
2023-04-25 20:53:01,691:INFO:self.USI: 2eeb
2023-04-25 20:53:01,691:INFO:self._variable_keys: {'logging_param', 'seed', 'log_plots_param', 'exp_name_log', 'exp_id', 'y', 'gpu_param', 'X_test', 'X', '_available_plots', 'y_train', 'target_param', 'n_jobs_param', 'USI', 'pipeline', 'html_param', 'idx', 'X_train', '_ml_usecase', 'fold_groups_param', 'gpu_n_jobs_param', 'fold_generator', 'memory', 'data', 'fold_shuffle_param', 'y_test', 'transform_target_param'}
2023-04-25 20:53:01,691:INFO:Checking environment
2023-04-25 20:53:01,691:INFO:python_version: 3.10.5
2023-04-25 20:53:01,691:INFO:python_build: ('tags/v3.10.5:f377153', 'Jun  6 2022 16:14:13')
2023-04-25 20:53:01,691:INFO:machine: AMD64
2023-04-25 20:53:01,691:INFO:platform: Windows-10-10.0.22000-SP0
2023-04-25 20:53:01,691:INFO:Memory: svmem(total=16497119232, available=8402747392, percent=49.1, used=8094371840, free=8402747392)
2023-04-25 20:53:01,691:INFO:Physical Core: 8
2023-04-25 20:53:01,691:INFO:Logical Core: 16
2023-04-25 20:53:01,691:INFO:Checking libraries
2023-04-25 20:53:01,691:INFO:System:
2023-04-25 20:53:01,691:INFO:    python: 3.10.5 (tags/v3.10.5:f377153, Jun  6 2022, 16:14:13) [MSC v.1929 64 bit (AMD64)]
2023-04-25 20:53:01,691:INFO:executable: C:\Users\Hashif\AppData\Local\Programs\Python\Python310\python.exe
2023-04-25 20:53:01,691:INFO:   machine: Windows-10-10.0.22000-SP0
2023-04-25 20:53:01,691:INFO:PyCaret required dependencies:
2023-04-25 20:53:01,691:INFO:                 pip: 23.1.1
2023-04-25 20:53:01,691:INFO:          setuptools: 58.1.0
2023-04-25 20:53:01,691:INFO:             pycaret: 3.0.0
2023-04-25 20:53:01,691:INFO:             IPython: 8.4.0
2023-04-25 20:53:01,691:INFO:          ipywidgets: 7.7.0
2023-04-25 20:53:01,691:INFO:                tqdm: 4.65.0
2023-04-25 20:53:01,691:INFO:               numpy: 1.23.0
2023-04-25 20:53:01,691:INFO:              pandas: 1.4.3
2023-04-25 20:53:01,691:INFO:              jinja2: 3.1.2
2023-04-25 20:53:01,691:INFO:               scipy: 1.9.3
2023-04-25 20:53:01,691:INFO:              joblib: 1.2.0
2023-04-25 20:53:01,691:INFO:             sklearn: 1.1.2
2023-04-25 20:53:01,691:INFO:                pyod: 1.0.9
2023-04-25 20:53:01,691:INFO:            imblearn: 0.10.1
2023-04-25 20:53:01,691:INFO:   category_encoders: 2.6.0
2023-04-25 20:53:01,691:INFO:            lightgbm: 3.3.5
2023-04-25 20:53:01,691:INFO:               numba: 0.56.4
2023-04-25 20:53:01,691:INFO:            requests: 2.28.1
2023-04-25 20:53:01,691:INFO:          matplotlib: 3.6.2
2023-04-25 20:53:01,691:INFO:          scikitplot: 0.3.7
2023-04-25 20:53:01,691:INFO:         yellowbrick: 1.5
2023-04-25 20:53:01,691:INFO:              plotly: 5.14.1
2023-04-25 20:53:01,691:INFO:             kaleido: 0.2.1
2023-04-25 20:53:01,691:INFO:         statsmodels: 0.13.5
2023-04-25 20:53:01,691:INFO:              sktime: 0.17.1
2023-04-25 20:53:01,691:INFO:               tbats: 1.1.3
2023-04-25 20:53:01,691:INFO:            pmdarima: 2.0.3
2023-04-25 20:53:01,691:INFO:              psutil: 5.9.1
2023-04-25 20:53:01,691:INFO:PyCaret optional dependencies:
2023-04-25 20:53:01,691:INFO:                shap: Not installed
2023-04-25 20:53:01,691:INFO:           interpret: Not installed
2023-04-25 20:53:01,691:INFO:                umap: Not installed
2023-04-25 20:53:01,691:INFO:    pandas_profiling: Not installed
2023-04-25 20:53:01,691:INFO:  explainerdashboard: Not installed
2023-04-25 20:53:01,691:INFO:             autoviz: Not installed
2023-04-25 20:53:01,691:INFO:           fairlearn: Not installed
2023-04-25 20:53:01,691:INFO:             xgboost: Not installed
2023-04-25 20:53:01,691:INFO:            catboost: Not installed
2023-04-25 20:53:01,691:INFO:              kmodes: Not installed
2023-04-25 20:53:01,691:INFO:             mlxtend: Not installed
2023-04-25 20:53:01,691:INFO:       statsforecast: Not installed
2023-04-25 20:53:01,691:INFO:        tune_sklearn: Not installed
2023-04-25 20:53:01,691:INFO:                 ray: Not installed
2023-04-25 20:53:01,691:INFO:            hyperopt: Not installed
2023-04-25 20:53:01,691:INFO:              optuna: Not installed
2023-04-25 20:53:01,691:INFO:               skopt: Not installed
2023-04-25 20:53:01,691:INFO:              mlflow: 2.3.0
2023-04-25 20:53:01,691:INFO:              gradio: Not installed
2023-04-25 20:53:01,691:INFO:             fastapi: Not installed
2023-04-25 20:53:01,691:INFO:             uvicorn: Not installed
2023-04-25 20:53:01,691:INFO:              m2cgen: Not installed
2023-04-25 20:53:01,691:INFO:           evidently: Not installed
2023-04-25 20:53:01,691:INFO:               fugue: Not installed
2023-04-25 20:53:01,691:INFO:           streamlit: Not installed
2023-04-25 20:53:01,691:INFO:             prophet: Not installed
2023-04-25 20:53:01,691:INFO:None
2023-04-25 20:53:01,691:INFO:Set up GPU usage.
2023-04-25 20:53:01,691:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:53:01,691:WARNING:cuML is outdated or not found. Required version is >=22.10, got 3.0.0
2023-04-25 20:53:01,691:INFO:Set up data.
2023-04-25 20:53:01,699:INFO:Set up train/test split.
2023-04-25 20:53:01,705:INFO:Set up index.
2023-04-25 20:53:01,705:INFO:Set up folding strategy.
2023-04-25 20:53:01,705:INFO:Assigning column types.
2023-04-25 20:53:01,705:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-04-25 20:53:01,705:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:53:01,705:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-04-25 20:53:01,705:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:53:01,720:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-25 20:53:01,720:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:53:01,724:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-25 20:53:01,724:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:53:01,815:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-25 20:53:01,815:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:53:01,878:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-25 20:53:01,878:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:53:01,878:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:53:01,878:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 20:53:01,940:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 20:53:01,956:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:53:01,956:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-04-25 20:53:01,956:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:53:01,956:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-25 20:53:01,956:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:53:01,972:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-25 20:53:01,972:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:53:02,066:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-25 20:53:02,066:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:53:02,145:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-25 20:53:02,145:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:53:02,145:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:53:02,145:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 20:53:02,207:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 20:53:02,207:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-04-25 20:53:02,207:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:53:02,207:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:53:02,225:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-25 20:53:02,225:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:53:02,225:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-25 20:53:02,225:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:53:02,334:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-25 20:53:02,334:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:53:02,411:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-25 20:53:02,411:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:53:02,411:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:53:02,411:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 20:53:02,489:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 20:53:02,489:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:53:02,489:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:53:02,489:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-04-25 20:53:02,489:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:53:02,505:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-25 20:53:02,505:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:53:02,614:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-25 20:53:02,614:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:53:02,686:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-25 20:53:02,686:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:53:02,686:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:53:02,686:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 20:53:02,749:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 20:53:02,749:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-04-25 20:53:02,749:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:53:02,749:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:53:02,765:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:53:02,765:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-25 20:53:02,765:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:53:02,875:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-25 20:53:02,875:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:53:02,952:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-25 20:53:02,952:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:53:02,952:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:53:02,952:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 20:53:03,030:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 20:53:03,036:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:53:03,036:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:53:03,041:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:53:03,049:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-04-25 20:53:03,049:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:53:03,152:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-25 20:53:03,152:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:53:03,230:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-25 20:53:03,230:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:53:03,230:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:53:03,231:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 20:53:03,293:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 20:53:03,293:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-04-25 20:53:03,293:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:53:03,293:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:53:03,293:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:53:03,308:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:53:03,402:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-25 20:53:03,402:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:53:03,481:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-25 20:53:03,481:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:53:03,481:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:53:03,481:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 20:53:03,550:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 20:53:03,550:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:53:03,550:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:53:03,566:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:53:03,584:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:53:03,676:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-25 20:53:03,676:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:53:03,756:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-25 20:53:03,756:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:53:03,756:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:53:03,756:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 20:53:03,834:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 20:53:03,834:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-04-25 20:53:03,834:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:53:03,834:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:53:03,850:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:53:03,865:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:53:03,966:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-25 20:53:03,966:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:53:04,049:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:53:04,049:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:53:04,049:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 20:53:04,122:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 20:53:04,122:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:53:04,122:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:53:04,133:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:53:04,140:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:53:04,244:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-04-25 20:53:04,244:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:53:04,313:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:53:04,313:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:53:04,313:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 20:53:04,366:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 20:53:04,369:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-04-25 20:53:04,369:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:53:04,369:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:53:04,377:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:53:04,386:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:53:04,489:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:53:04,566:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:53:04,566:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:53:04,566:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 20:53:04,629:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 20:53:04,629:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:53:04,629:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:53:04,639:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:53:04,646:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:53:04,739:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:53:04,809:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:53:04,809:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:53:04,825:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 20:53:04,870:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 20:53:04,870:INFO:Set up custom pipeline.
2023-04-25 20:53:04,892:INFO:Finished creating preprocessing pipeline.
2023-04-25 20:53:04,993:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Hashif\AppData\Local\Temp\joblib),
         steps=[('custom_step',
                 TransformerWrapper(transformer=FeatureUnion(n_jobs=1,
                                                             transformer_list=[('pipeline-1',
                                                                                Pipeline(steps=[('functiontransformer',
                                                                                                 FunctionTransformer(func=operator.itemgetter('amneties'))),
                                                                                                ('tfidfvectorizer',
                                                                                                 TfidfVectorizer(max_features=10000,
                                                                                                                 ngram_range=(1,
                                                                                                                              2),
                                                                                                                 token_pattern='\\w+'))])),
                                                                               ('pipeline-2',
                                                                                Pipeline(steps=[('functiontransformer-1',
                                                                                                 FunctionTransformer(func=operator.itemgetter(['ratings', 'distance']))),
                                                                                                ('functiontransformer-2',
                                                                                                 FunctionTransformer(func=<function to_records at 0x000001A1F41D40D0>)),
                                                                                                ('dictvectorizer',
                                                                                                 DictVectorizer())]))])))])
2023-04-25 20:53:04,993:INFO:Creating final display dataframe.
2023-04-25 20:53:05,250:INFO:Setup _display_container:                    Description       Value
0                   Session id          42
1                       Target       price
2                  Target type  Regression
3          Original data shape     (10, 4)
4       Transformed data shape    (10, 47)
5  Transformed train set shape     (9, 47)
6   Transformed test set shape     (1, 47)
7             Numeric features           2
8         Categorical features           1
2023-04-25 20:53:05,260:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:53:05,260:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:53:05,263:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:53:05,274:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:53:05,367:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:53:05,440:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:53:05,440:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:53:05,440:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 20:53:05,491:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 20:53:05,507:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:53:05,507:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:53:05,507:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:53:05,522:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:53:05,617:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:53:05,695:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:53:05,695:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-25 20:53:05,695:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 20:53:05,742:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-25 20:53:05,742:INFO:Logging experiment in loggers
2023-04-25 20:53:05,837:INFO:SubProcess save_model() called ==================================
2023-04-25 20:53:06,041:INFO:Initializing save_model()
2023-04-25 20:53:06,041:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\Hashif\AppData\Local\Temp\joblib),
         steps=[('custom_step',
                 TransformerWrapper(transformer=FeatureUnion(n_jobs=1,
                                                             transformer_list=[('pipeline-1',
                                                                                Pipeline(steps=[('functiontransformer',
                                                                                                 FunctionTransformer(func=operator.itemgetter('amneties'))),
                                                                                                ('tfidfvectorizer',
                                                                                                 TfidfVectorizer(max_features=10000,
                                                                                                                 ngram_range=(1,
                                                                                                                              2),
                                                                                                                 token_pattern='\\w+'))])),
                                                                               ('pipeline-2',
                                                                                Pipeline(steps=[('functiontransformer-1',
                                                                                                 FunctionTransformer(func=operator.itemgetter(['ratings', 'distance']))),
                                                                                                ('functiontransformer-2',
                                                                                                 FunctionTransformer(func=<function to_records at 0x000001A1F41D40D0>)),
                                                                                                ('dictvectorizer',
                                                                                                 DictVectorizer())]))])))]), model_name=C:\Users\Hashif\AppData\Local\Temp\tmpnpz9zecl\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\Hashif\AppData\Local\Temp\joblib),
         steps=[('custom_step',
                 TransformerWrapper(transformer=FeatureUnion(n_jobs=1,
                                                             transformer_list=[('pipeline-1',
                                                                                Pipeline(steps=[('functiontransformer',
                                                                                                 FunctionTransformer(func=operator.itemgetter('amneties'))),
                                                                                                ('tfidfvectorizer',
                                                                                                 TfidfVectorizer(max_features=10000,
                                                                                                                 ngram_range=(1,
                                                                                                                              2),
                                                                                                                 token_pattern='\\w+'))])),
                                                                               ('pipeline-2',
                                                                                Pipeline(steps=[('functiontransformer-1',
                                                                                                 FunctionTransformer(func=operator.itemgetter(['ratings', 'distance']))),
                                                                                                ('functiontransformer-2',
                                                                                                 FunctionTransformer(func=<function to_records at 0x000001A1F41D40D0>)),
                                                                                                ('dictvectorizer',
                                                                                                 DictVectorizer())]))])))]), verbose=False, use_case=MLUsecase.REGRESSION, kwargs={})
2023-04-25 20:53:06,041:INFO:Adding model into prep_pipe
2023-04-25 20:53:06,041:WARNING:Only Model saved as it was a pipeline.
2023-04-25 20:53:06,041:INFO:C:\Users\Hashif\AppData\Local\Temp\tmpnpz9zecl\Transformation Pipeline.pkl saved in current working directory
2023-04-25 20:53:06,120:INFO:Pipeline(memory=FastMemory(location=C:\Users\Hashif\AppData\Local\Temp\joblib),
         steps=[('custom_step',
                 TransformerWrapper(transformer=FeatureUnion(n_jobs=1,
                                                             transformer_list=[('pipeline-1',
                                                                                Pipeline(steps=[('functiontransformer',
                                                                                                 FunctionTransformer(func=operator.itemgetter('amneties'))),
                                                                                                ('tfidfvectorizer',
                                                                                                 TfidfVectorizer(max_features=10000,
                                                                                                                 ngram_range=(1,
                                                                                                                              2),
                                                                                                                 token_pattern='\\w+'))])),
                                                                               ('pipeline-2',
                                                                                Pipeline(steps=[('functiontransformer-1',
                                                                                                 FunctionTransformer(func=operator.itemgetter(['ratings', 'distance']))),
                                                                                                ('functiontransformer-2',
                                                                                                 FunctionTransformer(func=<function to_records at 0x000001A1F41D40D0>)),
                                                                                                ('dictvectorizer',
                                                                                                 DictVectorizer())]))])))])
2023-04-25 20:53:06,120:INFO:save_model() successfully completed......................................
2023-04-25 20:53:06,260:INFO:SubProcess save_model() end ==================================
2023-04-25 20:53:06,311:INFO:setup() successfully completed in 4.07s...............
2023-04-25 20:53:06,339:INFO:Initializing compare_models()
2023-04-25 20:53:06,339:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A186E128F0>, include=['lr', 'lasso', 'ridge', 'en', 'huber', 'knn', 'ada', 'gbr'], fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001A186E128F0>, 'include': ['lr', 'lasso', 'ridge', 'en', 'huber', 'knn', 'ada', 'gbr'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-04-25 20:53:06,339:INFO:Checking exceptions
2023-04-25 20:53:06,339:INFO:Preparing display monitor
2023-04-25 20:53:06,394:INFO:Initializing Linear Regression
2023-04-25 20:53:06,394:INFO:Total runtime is 0.0 minutes
2023-04-25 20:53:06,402:INFO:SubProcess create_model() called ==================================
2023-04-25 20:53:06,402:INFO:Initializing create_model()
2023-04-25 20:53:06,402:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A186E128F0>, estimator=lr, fold=ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A185C1EEF0>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 20:53:06,402:INFO:Checking exceptions
2023-04-25 20:53:06,402:INFO:Importing libraries
2023-04-25 20:53:06,402:INFO:Copying training dataset
2023-04-25 20:53:06,410:INFO:Defining folds
2023-04-25 20:53:06,410:INFO:Declaring metric variables
2023-04-25 20:53:06,415:INFO:Importing untrained model
2023-04-25 20:53:06,415:INFO:Linear Regression Imported successfully
2023-04-25 20:53:06,434:INFO:Starting cross validation
2023-04-25 20:53:06,436:INFO:Cross validating with ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), n_jobs=1
2023-04-25 20:53:06,591:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-04-25 20:53:06,607:INFO:Calculating mean and std
2023-04-25 20:53:06,607:INFO:Creating metrics dataframe
2023-04-25 20:53:06,634:INFO:Uploading results into container
2023-04-25 20:53:06,639:INFO:Uploading model into container now
2023-04-25 20:53:06,639:INFO:_master_model_container: 1
2023-04-25 20:53:06,639:INFO:_display_container: 2
2023-04-25 20:53:06,639:INFO:LinearRegression(n_jobs=-1)
2023-04-25 20:53:06,639:INFO:create_model() successfully completed......................................
2023-04-25 20:53:06,761:INFO:SubProcess create_model() end ==================================
2023-04-25 20:53:06,765:INFO:Creating metrics dataframe
2023-04-25 20:53:06,769:INFO:Initializing Lasso Regression
2023-04-25 20:53:06,769:INFO:Total runtime is 0.006246495246887207 minutes
2023-04-25 20:53:06,779:INFO:SubProcess create_model() called ==================================
2023-04-25 20:53:06,779:INFO:Initializing create_model()
2023-04-25 20:53:06,779:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A186E128F0>, estimator=lasso, fold=ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A185C1EEF0>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 20:53:06,779:INFO:Checking exceptions
2023-04-25 20:53:06,779:INFO:Importing libraries
2023-04-25 20:53:06,779:INFO:Copying training dataset
2023-04-25 20:53:06,784:INFO:Defining folds
2023-04-25 20:53:06,784:INFO:Declaring metric variables
2023-04-25 20:53:06,784:INFO:Importing untrained model
2023-04-25 20:53:06,797:INFO:Lasso Regression Imported successfully
2023-04-25 20:53:06,810:INFO:Starting cross validation
2023-04-25 20:53:06,810:INFO:Cross validating with ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), n_jobs=1
2023-04-25 20:53:06,971:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-04-25 20:53:06,987:INFO:Calculating mean and std
2023-04-25 20:53:06,987:INFO:Creating metrics dataframe
2023-04-25 20:53:07,018:INFO:Uploading results into container
2023-04-25 20:53:07,018:INFO:Uploading model into container now
2023-04-25 20:53:07,018:INFO:_master_model_container: 2
2023-04-25 20:53:07,018:INFO:_display_container: 2
2023-04-25 20:53:07,018:INFO:Lasso(random_state=42)
2023-04-25 20:53:07,018:INFO:create_model() successfully completed......................................
2023-04-25 20:53:07,144:INFO:SubProcess create_model() end ==================================
2023-04-25 20:53:07,144:INFO:Creating metrics dataframe
2023-04-25 20:53:07,144:INFO:Initializing Ridge Regression
2023-04-25 20:53:07,144:INFO:Total runtime is 0.012491663297017416 minutes
2023-04-25 20:53:07,161:INFO:SubProcess create_model() called ==================================
2023-04-25 20:53:07,161:INFO:Initializing create_model()
2023-04-25 20:53:07,161:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A186E128F0>, estimator=ridge, fold=ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A185C1EEF0>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 20:53:07,161:INFO:Checking exceptions
2023-04-25 20:53:07,161:INFO:Importing libraries
2023-04-25 20:53:07,161:INFO:Copying training dataset
2023-04-25 20:53:07,171:INFO:Defining folds
2023-04-25 20:53:07,171:INFO:Declaring metric variables
2023-04-25 20:53:07,171:INFO:Importing untrained model
2023-04-25 20:53:07,193:INFO:Ridge Regression Imported successfully
2023-04-25 20:53:07,200:INFO:Starting cross validation
2023-04-25 20:53:07,206:INFO:Cross validating with ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), n_jobs=1
2023-04-25 20:53:07,335:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-04-25 20:53:07,340:INFO:Calculating mean and std
2023-04-25 20:53:07,356:INFO:Creating metrics dataframe
2023-04-25 20:53:07,366:INFO:Uploading results into container
2023-04-25 20:53:07,366:INFO:Uploading model into container now
2023-04-25 20:53:07,366:INFO:_master_model_container: 3
2023-04-25 20:53:07,366:INFO:_display_container: 2
2023-04-25 20:53:07,366:INFO:Ridge(random_state=42)
2023-04-25 20:53:07,366:INFO:create_model() successfully completed......................................
2023-04-25 20:53:07,488:INFO:SubProcess create_model() end ==================================
2023-04-25 20:53:07,488:INFO:Creating metrics dataframe
2023-04-25 20:53:07,503:INFO:Initializing Elastic Net
2023-04-25 20:53:07,503:INFO:Total runtime is 0.01848516861597697 minutes
2023-04-25 20:53:07,515:INFO:SubProcess create_model() called ==================================
2023-04-25 20:53:07,515:INFO:Initializing create_model()
2023-04-25 20:53:07,515:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A186E128F0>, estimator=en, fold=ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A185C1EEF0>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 20:53:07,515:INFO:Checking exceptions
2023-04-25 20:53:07,515:INFO:Importing libraries
2023-04-25 20:53:07,515:INFO:Copying training dataset
2023-04-25 20:53:07,531:INFO:Defining folds
2023-04-25 20:53:07,531:INFO:Declaring metric variables
2023-04-25 20:53:07,540:INFO:Importing untrained model
2023-04-25 20:53:07,547:INFO:Elastic Net Imported successfully
2023-04-25 20:53:07,575:INFO:Starting cross validation
2023-04-25 20:53:07,575:INFO:Cross validating with ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), n_jobs=1
2023-04-25 20:53:07,689:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-04-25 20:53:07,705:INFO:Calculating mean and std
2023-04-25 20:53:07,720:INFO:Creating metrics dataframe
2023-04-25 20:53:07,736:INFO:Uploading results into container
2023-04-25 20:53:07,736:INFO:Uploading model into container now
2023-04-25 20:53:07,736:INFO:_master_model_container: 4
2023-04-25 20:53:07,736:INFO:_display_container: 2
2023-04-25 20:53:07,736:INFO:ElasticNet(random_state=42)
2023-04-25 20:53:07,736:INFO:create_model() successfully completed......................................
2023-04-25 20:53:07,864:INFO:SubProcess create_model() end ==================================
2023-04-25 20:53:07,864:INFO:Creating metrics dataframe
2023-04-25 20:53:07,864:INFO:Initializing Huber Regressor
2023-04-25 20:53:07,864:INFO:Total runtime is 0.024497572580973306 minutes
2023-04-25 20:53:07,882:INFO:SubProcess create_model() called ==================================
2023-04-25 20:53:07,882:INFO:Initializing create_model()
2023-04-25 20:53:07,882:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A186E128F0>, estimator=huber, fold=ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A185C1EEF0>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 20:53:07,882:INFO:Checking exceptions
2023-04-25 20:53:07,882:INFO:Importing libraries
2023-04-25 20:53:07,882:INFO:Copying training dataset
2023-04-25 20:53:07,887:INFO:Defining folds
2023-04-25 20:53:07,887:INFO:Declaring metric variables
2023-04-25 20:53:07,887:INFO:Importing untrained model
2023-04-25 20:53:07,900:INFO:Huber Regressor Imported successfully
2023-04-25 20:53:07,907:INFO:Starting cross validation
2023-04-25 20:53:07,914:INFO:Cross validating with ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), n_jobs=1
2023-04-25 20:53:08,123:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-04-25 20:53:08,202:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-04-25 20:53:08,217:INFO:Calculating mean and std
2023-04-25 20:53:08,217:INFO:Creating metrics dataframe
2023-04-25 20:53:08,254:INFO:Uploading results into container
2023-04-25 20:53:08,254:INFO:Uploading model into container now
2023-04-25 20:53:08,254:INFO:_master_model_container: 5
2023-04-25 20:53:08,254:INFO:_display_container: 2
2023-04-25 20:53:08,254:INFO:HuberRegressor()
2023-04-25 20:53:08,254:INFO:create_model() successfully completed......................................
2023-04-25 20:53:08,371:INFO:SubProcess create_model() end ==================================
2023-04-25 20:53:08,371:INFO:Creating metrics dataframe
2023-04-25 20:53:08,371:INFO:Initializing K Neighbors Regressor
2023-04-25 20:53:08,371:INFO:Total runtime is 0.03293828964233399 minutes
2023-04-25 20:53:08,388:INFO:SubProcess create_model() called ==================================
2023-04-25 20:53:08,388:INFO:Initializing create_model()
2023-04-25 20:53:08,388:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A186E128F0>, estimator=knn, fold=ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A185C1EEF0>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 20:53:08,388:INFO:Checking exceptions
2023-04-25 20:53:08,388:INFO:Importing libraries
2023-04-25 20:53:08,388:INFO:Copying training dataset
2023-04-25 20:53:08,394:INFO:Defining folds
2023-04-25 20:53:08,394:INFO:Declaring metric variables
2023-04-25 20:53:08,394:INFO:Importing untrained model
2023-04-25 20:53:08,407:INFO:K Neighbors Regressor Imported successfully
2023-04-25 20:53:08,420:INFO:Starting cross validation
2023-04-25 20:53:08,420:INFO:Cross validating with ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), n_jobs=1
2023-04-25 20:53:08,584:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-04-25 20:53:08,615:INFO:Calculating mean and std
2023-04-25 20:53:08,615:INFO:Creating metrics dataframe
2023-04-25 20:53:08,644:INFO:Uploading results into container
2023-04-25 20:53:08,644:INFO:Uploading model into container now
2023-04-25 20:53:08,644:INFO:_master_model_container: 6
2023-04-25 20:53:08,644:INFO:_display_container: 2
2023-04-25 20:53:08,644:INFO:KNeighborsRegressor(n_jobs=-1)
2023-04-25 20:53:08,644:INFO:create_model() successfully completed......................................
2023-04-25 20:53:08,773:INFO:SubProcess create_model() end ==================================
2023-04-25 20:53:08,773:INFO:Creating metrics dataframe
2023-04-25 20:53:08,788:INFO:Initializing AdaBoost Regressor
2023-04-25 20:53:08,788:INFO:Total runtime is 0.039902579784393315 minutes
2023-04-25 20:53:08,795:INFO:SubProcess create_model() called ==================================
2023-04-25 20:53:08,795:INFO:Initializing create_model()
2023-04-25 20:53:08,795:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A186E128F0>, estimator=ada, fold=ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A185C1EEF0>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 20:53:08,795:INFO:Checking exceptions
2023-04-25 20:53:08,795:INFO:Importing libraries
2023-04-25 20:53:08,795:INFO:Copying training dataset
2023-04-25 20:53:08,803:INFO:Defining folds
2023-04-25 20:53:08,803:INFO:Declaring metric variables
2023-04-25 20:53:08,809:INFO:Importing untrained model
2023-04-25 20:53:08,815:INFO:AdaBoost Regressor Imported successfully
2023-04-25 20:53:08,823:INFO:Starting cross validation
2023-04-25 20:53:08,829:INFO:Cross validating with ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), n_jobs=1
2023-04-25 20:53:09,110:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-04-25 20:53:09,136:INFO:Calculating mean and std
2023-04-25 20:53:09,142:INFO:Creating metrics dataframe
2023-04-25 20:53:09,169:INFO:Uploading results into container
2023-04-25 20:53:09,169:INFO:Uploading model into container now
2023-04-25 20:53:09,169:INFO:_master_model_container: 7
2023-04-25 20:53:09,169:INFO:_display_container: 2
2023-04-25 20:53:09,169:INFO:AdaBoostRegressor(random_state=42)
2023-04-25 20:53:09,169:INFO:create_model() successfully completed......................................
2023-04-25 20:53:09,295:INFO:SubProcess create_model() end ==================================
2023-04-25 20:53:09,295:INFO:Creating metrics dataframe
2023-04-25 20:53:09,295:INFO:Initializing Gradient Boosting Regressor
2023-04-25 20:53:09,295:INFO:Total runtime is 0.04834118286768596 minutes
2023-04-25 20:53:09,311:INFO:SubProcess create_model() called ==================================
2023-04-25 20:53:09,311:INFO:Initializing create_model()
2023-04-25 20:53:09,311:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A186E128F0>, estimator=gbr, fold=ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A185C1EEF0>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 20:53:09,311:INFO:Checking exceptions
2023-04-25 20:53:09,311:INFO:Importing libraries
2023-04-25 20:53:09,311:INFO:Copying training dataset
2023-04-25 20:53:09,317:INFO:Defining folds
2023-04-25 20:53:09,317:INFO:Declaring metric variables
2023-04-25 20:53:09,317:INFO:Importing untrained model
2023-04-25 20:53:09,330:INFO:Gradient Boosting Regressor Imported successfully
2023-04-25 20:53:09,343:INFO:Starting cross validation
2023-04-25 20:53:09,343:INFO:Cross validating with ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), n_jobs=1
2023-04-25 20:53:09,558:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-04-25 20:53:09,568:INFO:Calculating mean and std
2023-04-25 20:53:09,568:INFO:Creating metrics dataframe
2023-04-25 20:53:09,601:INFO:Uploading results into container
2023-04-25 20:53:09,601:INFO:Uploading model into container now
2023-04-25 20:53:09,601:INFO:_master_model_container: 8
2023-04-25 20:53:09,601:INFO:_display_container: 2
2023-04-25 20:53:09,601:INFO:GradientBoostingRegressor(random_state=42)
2023-04-25 20:53:09,601:INFO:create_model() successfully completed......................................
2023-04-25 20:53:09,724:INFO:SubProcess create_model() end ==================================
2023-04-25 20:53:09,724:INFO:Creating metrics dataframe
2023-04-25 20:53:09,766:INFO:Initializing create_model()
2023-04-25 20:53:09,766:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A186E128F0>, estimator=LinearRegression(n_jobs=-1), fold=ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-25 20:53:09,766:INFO:Checking exceptions
2023-04-25 20:53:09,766:INFO:Importing libraries
2023-04-25 20:53:09,766:INFO:Copying training dataset
2023-04-25 20:53:09,775:INFO:Defining folds
2023-04-25 20:53:09,775:INFO:Declaring metric variables
2023-04-25 20:53:09,780:INFO:Importing untrained model
2023-04-25 20:53:09,780:INFO:Declaring custom model
2023-04-25 20:53:09,780:INFO:Linear Regression Imported successfully
2023-04-25 20:53:09,780:INFO:Cross validation set to False
2023-04-25 20:53:09,780:INFO:Fitting Model
2023-04-25 20:53:09,850:INFO:LinearRegression(n_jobs=-1)
2023-04-25 20:53:09,850:INFO:create_model() successfully completed......................................
2023-04-25 20:53:09,960:INFO:Creating Dashboard logs
2023-04-25 20:53:09,978:INFO:Model: Linear Regression
2023-04-25 20:53:10,047:INFO:Logged params: {'copy_X': True, 'fit_intercept': True, 'n_jobs': -1, 'normalize': 'deprecated', 'positive': False}
2023-04-25 20:53:10,157:INFO:Initializing predict_model()
2023-04-25 20:53:10,157:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A186E128F0>, estimator=LinearRegression(n_jobs=-1), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000001A1870E41F0>)
2023-04-25 20:53:10,157:INFO:Checking exceptions
2023-04-25 20:53:10,157:INFO:Preloading libraries
2023-04-25 20:53:10,252:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-04-25 20:53:10,644:INFO:Creating Dashboard logs
2023-04-25 20:53:10,644:INFO:Model: Lasso Regression
2023-04-25 20:53:10,698:INFO:Logged params: {'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'max_iter': 1000, 'normalize': 'deprecated', 'positive': False, 'precompute': False, 'random_state': 42, 'selection': 'cyclic', 'tol': 0.0001, 'warm_start': False}
2023-04-25 20:53:10,934:INFO:Creating Dashboard logs
2023-04-25 20:53:10,939:INFO:Model: Ridge Regression
2023-04-25 20:53:10,982:INFO:Logged params: {'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'normalize': 'deprecated', 'positive': False, 'random_state': 42, 'solver': 'auto', 'tol': 0.001}
2023-04-25 20:53:11,203:INFO:Creating Dashboard logs
2023-04-25 20:53:11,203:INFO:Model: Elastic Net
2023-04-25 20:53:11,256:INFO:Logged params: {'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'l1_ratio': 0.5, 'max_iter': 1000, 'normalize': 'deprecated', 'positive': False, 'precompute': False, 'random_state': 42, 'selection': 'cyclic', 'tol': 0.0001, 'warm_start': False}
2023-04-25 20:53:11,492:INFO:Creating Dashboard logs
2023-04-25 20:53:11,492:INFO:Model: Huber Regressor
2023-04-25 20:53:11,544:INFO:Logged params: {'alpha': 0.0001, 'epsilon': 1.35, 'fit_intercept': True, 'max_iter': 100, 'tol': 1e-05, 'warm_start': False}
2023-04-25 20:53:11,881:INFO:Creating Dashboard logs
2023-04-25 20:53:11,881:INFO:Model: K Neighbors Regressor
2023-04-25 20:53:11,927:INFO:Logged params: {'algorithm': 'auto', 'leaf_size': 30, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': -1, 'n_neighbors': 5, 'p': 2, 'weights': 'uniform'}
2023-04-25 20:53:12,162:INFO:Creating Dashboard logs
2023-04-25 20:53:12,162:INFO:Model: AdaBoost Regressor
2023-04-25 20:53:12,226:INFO:Logged params: {'base_estimator': None, 'learning_rate': 1.0, 'loss': 'linear', 'n_estimators': 50, 'random_state': 42}
2023-04-25 20:53:12,446:INFO:Creating Dashboard logs
2023-04-25 20:53:12,446:INFO:Model: Gradient Boosting Regressor
2023-04-25 20:53:12,510:INFO:Logged params: {'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': None, 'random_state': 42, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2023-04-25 20:53:12,777:INFO:_master_model_container: 8
2023-04-25 20:53:12,777:INFO:_display_container: 2
2023-04-25 20:53:12,777:INFO:LinearRegression(n_jobs=-1)
2023-04-25 20:53:12,777:INFO:compare_models() successfully completed......................................
2023-04-25 20:54:32,125:INFO:Initializing compare_models()
2023-04-25 20:54:32,125:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A186E128F0>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001A186E128F0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-04-25 20:54:32,129:INFO:Checking exceptions
2023-04-25 20:54:32,132:INFO:Preparing display monitor
2023-04-25 20:54:32,172:INFO:Initializing Linear Regression
2023-04-25 20:54:32,172:INFO:Total runtime is 0.0 minutes
2023-04-25 20:54:32,186:INFO:SubProcess create_model() called ==================================
2023-04-25 20:54:32,188:INFO:Initializing create_model()
2023-04-25 20:54:32,188:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A186E128F0>, estimator=lr, fold=ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A1F3741E70>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 20:54:32,188:INFO:Checking exceptions
2023-04-25 20:54:32,188:INFO:Importing libraries
2023-04-25 20:54:32,188:INFO:Copying training dataset
2023-04-25 20:54:32,197:INFO:Defining folds
2023-04-25 20:54:32,197:INFO:Declaring metric variables
2023-04-25 20:54:32,201:INFO:Importing untrained model
2023-04-25 20:54:32,209:INFO:Linear Regression Imported successfully
2023-04-25 20:54:32,225:INFO:Starting cross validation
2023-04-25 20:54:32,225:INFO:Cross validating with ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), n_jobs=1
2023-04-25 20:54:32,358:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-04-25 20:54:32,374:INFO:Calculating mean and std
2023-04-25 20:54:32,374:INFO:Creating metrics dataframe
2023-04-25 20:54:32,390:INFO:Uploading results into container
2023-04-25 20:54:32,390:INFO:Uploading model into container now
2023-04-25 20:54:32,390:INFO:_master_model_container: 9
2023-04-25 20:54:32,390:INFO:_display_container: 3
2023-04-25 20:54:32,390:INFO:LinearRegression(n_jobs=-1)
2023-04-25 20:54:32,390:INFO:create_model() successfully completed......................................
2023-04-25 20:54:32,626:INFO:SubProcess create_model() end ==================================
2023-04-25 20:54:32,626:INFO:Creating metrics dataframe
2023-04-25 20:54:32,641:INFO:Initializing Lasso Regression
2023-04-25 20:54:32,641:INFO:Total runtime is 0.007808522383371989 minutes
2023-04-25 20:54:32,656:INFO:SubProcess create_model() called ==================================
2023-04-25 20:54:32,656:INFO:Initializing create_model()
2023-04-25 20:54:32,656:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A186E128F0>, estimator=lasso, fold=ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A1F3741E70>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 20:54:32,656:INFO:Checking exceptions
2023-04-25 20:54:32,656:INFO:Importing libraries
2023-04-25 20:54:32,656:INFO:Copying training dataset
2023-04-25 20:54:32,665:INFO:Defining folds
2023-04-25 20:54:32,665:INFO:Declaring metric variables
2023-04-25 20:54:32,665:INFO:Importing untrained model
2023-04-25 20:54:32,683:INFO:Lasso Regression Imported successfully
2023-04-25 20:54:32,703:INFO:Starting cross validation
2023-04-25 20:54:32,703:INFO:Cross validating with ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), n_jobs=1
2023-04-25 20:54:32,899:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-04-25 20:54:32,915:INFO:Calculating mean and std
2023-04-25 20:54:32,915:INFO:Creating metrics dataframe
2023-04-25 20:54:32,941:INFO:Uploading results into container
2023-04-25 20:54:32,941:INFO:Uploading model into container now
2023-04-25 20:54:32,941:INFO:_master_model_container: 10
2023-04-25 20:54:32,941:INFO:_display_container: 3
2023-04-25 20:54:32,949:INFO:Lasso(random_state=42)
2023-04-25 20:54:32,949:INFO:create_model() successfully completed......................................
2023-04-25 20:54:33,186:INFO:SubProcess create_model() end ==================================
2023-04-25 20:54:33,186:INFO:Creating metrics dataframe
2023-04-25 20:54:33,200:INFO:Initializing Ridge Regression
2023-04-25 20:54:33,200:INFO:Total runtime is 0.01712138255437215 minutes
2023-04-25 20:54:33,215:INFO:SubProcess create_model() called ==================================
2023-04-25 20:54:33,215:INFO:Initializing create_model()
2023-04-25 20:54:33,215:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A186E128F0>, estimator=ridge, fold=ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A1F3741E70>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 20:54:33,215:INFO:Checking exceptions
2023-04-25 20:54:33,215:INFO:Importing libraries
2023-04-25 20:54:33,215:INFO:Copying training dataset
2023-04-25 20:54:33,228:INFO:Defining folds
2023-04-25 20:54:33,228:INFO:Declaring metric variables
2023-04-25 20:54:33,232:INFO:Importing untrained model
2023-04-25 20:54:33,245:INFO:Ridge Regression Imported successfully
2023-04-25 20:54:33,263:INFO:Starting cross validation
2023-04-25 20:54:33,263:INFO:Cross validating with ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), n_jobs=1
2023-04-25 20:54:33,394:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-04-25 20:54:33,429:INFO:Calculating mean and std
2023-04-25 20:54:33,434:INFO:Creating metrics dataframe
2023-04-25 20:54:33,471:INFO:Uploading results into container
2023-04-25 20:54:33,471:INFO:Uploading model into container now
2023-04-25 20:54:33,471:INFO:_master_model_container: 11
2023-04-25 20:54:33,471:INFO:_display_container: 3
2023-04-25 20:54:33,476:INFO:Ridge(random_state=42)
2023-04-25 20:54:33,476:INFO:create_model() successfully completed......................................
2023-04-25 20:54:33,805:INFO:SubProcess create_model() end ==================================
2023-04-25 20:54:33,805:INFO:Creating metrics dataframe
2023-04-25 20:54:33,817:INFO:Initializing Elastic Net
2023-04-25 20:54:33,817:INFO:Total runtime is 0.02741845448811849 minutes
2023-04-25 20:54:33,823:INFO:SubProcess create_model() called ==================================
2023-04-25 20:54:33,823:INFO:Initializing create_model()
2023-04-25 20:54:33,823:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A186E128F0>, estimator=en, fold=ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A1F3741E70>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 20:54:33,823:INFO:Checking exceptions
2023-04-25 20:54:33,823:INFO:Importing libraries
2023-04-25 20:54:33,825:INFO:Copying training dataset
2023-04-25 20:54:33,826:INFO:Defining folds
2023-04-25 20:54:33,826:INFO:Declaring metric variables
2023-04-25 20:54:33,835:INFO:Importing untrained model
2023-04-25 20:54:33,846:INFO:Elastic Net Imported successfully
2023-04-25 20:54:33,854:INFO:Starting cross validation
2023-04-25 20:54:33,854:INFO:Cross validating with ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), n_jobs=1
2023-04-25 20:54:33,991:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-04-25 20:54:34,007:INFO:Calculating mean and std
2023-04-25 20:54:34,012:INFO:Creating metrics dataframe
2023-04-25 20:54:34,036:INFO:Uploading results into container
2023-04-25 20:54:34,036:INFO:Uploading model into container now
2023-04-25 20:54:34,036:INFO:_master_model_container: 12
2023-04-25 20:54:34,036:INFO:_display_container: 3
2023-04-25 20:54:34,036:INFO:ElasticNet(random_state=42)
2023-04-25 20:54:34,036:INFO:create_model() successfully completed......................................
2023-04-25 20:54:34,238:INFO:SubProcess create_model() end ==================================
2023-04-25 20:54:34,238:INFO:Creating metrics dataframe
2023-04-25 20:54:34,254:INFO:Initializing Least Angle Regression
2023-04-25 20:54:34,254:INFO:Total runtime is 0.034692994753519696 minutes
2023-04-25 20:54:34,254:INFO:SubProcess create_model() called ==================================
2023-04-25 20:54:34,254:INFO:Initializing create_model()
2023-04-25 20:54:34,254:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A186E128F0>, estimator=lar, fold=ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A1F3741E70>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 20:54:34,254:INFO:Checking exceptions
2023-04-25 20:54:34,254:INFO:Importing libraries
2023-04-25 20:54:34,254:INFO:Copying training dataset
2023-04-25 20:54:34,273:INFO:Defining folds
2023-04-25 20:54:34,273:INFO:Declaring metric variables
2023-04-25 20:54:34,281:INFO:Importing untrained model
2023-04-25 20:54:34,289:INFO:Least Angle Regression Imported successfully
2023-04-25 20:54:34,306:INFO:Starting cross validation
2023-04-25 20:54:34,310:INFO:Cross validating with ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), n_jobs=1
2023-04-25 20:54:34,455:WARNING:create_model() for lar raised an exception or returned all 0.0, trying without fit_kwargs:
2023-04-25 20:54:34,455:WARNING:Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 285, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 367, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 1 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 260, in fit
    fitted_estimator = self._memory_fit(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 66, in _fit_one
    transformer.fit(*args, **fit_params)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py", line 1109, in fit
    X, y = self._validate_data(X, y, y_numeric=True, multi_output=True)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\base.py", line 596, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\validation.py", line 1074, in check_X_y
    X = check_array(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\validation.py", line 822, in check_array
    array = _ensure_sparse_format(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\validation.py", line 512, in _ensure_sparse_format
    raise TypeError(
TypeError: A sparse matrix was passed, but dense data is required. Use X.toarray() to convert to a dense numpy array.


2023-04-25 20:54:34,455:INFO:Initializing create_model()
2023-04-25 20:54:34,455:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A186E128F0>, estimator=lar, fold=ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A1F3741E70>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 20:54:34,455:INFO:Checking exceptions
2023-04-25 20:54:34,455:INFO:Importing libraries
2023-04-25 20:54:34,455:INFO:Copying training dataset
2023-04-25 20:54:34,455:INFO:Defining folds
2023-04-25 20:54:34,455:INFO:Declaring metric variables
2023-04-25 20:54:34,470:INFO:Importing untrained model
2023-04-25 20:54:34,470:INFO:Least Angle Regression Imported successfully
2023-04-25 20:54:34,491:INFO:Starting cross validation
2023-04-25 20:54:34,491:INFO:Cross validating with ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), n_jobs=1
2023-04-25 20:54:34,578:ERROR:create_model() for lar raised an exception or returned all 0.0:
2023-04-25 20:54:34,578:ERROR:Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 285, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 367, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 1 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 260, in fit
    fitted_estimator = self._memory_fit(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 66, in _fit_one
    transformer.fit(*args, **fit_params)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py", line 1109, in fit
    X, y = self._validate_data(X, y, y_numeric=True, multi_output=True)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\base.py", line 596, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\validation.py", line 1074, in check_X_y
    X = check_array(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\validation.py", line 822, in check_array
    array = _ensure_sparse_format(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\validation.py", line 512, in _ensure_sparse_format
    raise TypeError(
TypeError: A sparse matrix was passed, but dense data is required. Use X.toarray() to convert to a dense numpy array.


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 810, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 285, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 367, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 1 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 285, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 367, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 1 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 260, in fit
    fitted_estimator = self._memory_fit(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 66, in _fit_one
    transformer.fit(*args, **fit_params)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py", line 1109, in fit
    X, y = self._validate_data(X, y, y_numeric=True, multi_output=True)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\base.py", line 596, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\validation.py", line 1074, in check_X_y
    X = check_array(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\validation.py", line 822, in check_array
    array = _ensure_sparse_format(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\validation.py", line 512, in _ensure_sparse_format
    raise TypeError(
TypeError: A sparse matrix was passed, but dense data is required. Use X.toarray() to convert to a dense numpy array.


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 260, in fit
    fitted_estimator = self._memory_fit(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 66, in _fit_one
    transformer.fit(*args, **fit_params)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py", line 1109, in fit
    X, y = self._validate_data(X, y, y_numeric=True, multi_output=True)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\base.py", line 596, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\validation.py", line 1074, in check_X_y
    X = check_array(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\validation.py", line 822, in check_array
    array = _ensure_sparse_format(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\validation.py", line 512, in _ensure_sparse_format
    raise TypeError(
TypeError: A sparse matrix was passed, but dense data is required. Use X.toarray() to convert to a dense numpy array.


2023-04-25 20:54:34,603:INFO:Initializing Lasso Least Angle Regression
2023-04-25 20:54:34,603:INFO:Total runtime is 0.040505572160085046 minutes
2023-04-25 20:54:34,618:INFO:SubProcess create_model() called ==================================
2023-04-25 20:54:34,618:INFO:Initializing create_model()
2023-04-25 20:54:34,618:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A186E128F0>, estimator=llar, fold=ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A1F3741E70>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 20:54:34,618:INFO:Checking exceptions
2023-04-25 20:54:34,618:INFO:Importing libraries
2023-04-25 20:54:34,618:INFO:Copying training dataset
2023-04-25 20:54:34,624:INFO:Defining folds
2023-04-25 20:54:34,624:INFO:Declaring metric variables
2023-04-25 20:54:34,629:INFO:Importing untrained model
2023-04-25 20:54:34,634:INFO:Lasso Least Angle Regression Imported successfully
2023-04-25 20:54:34,638:INFO:Starting cross validation
2023-04-25 20:54:34,638:INFO:Cross validating with ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), n_jobs=1
2023-04-25 20:54:34,766:WARNING:create_model() for llar raised an exception or returned all 0.0, trying without fit_kwargs:
2023-04-25 20:54:34,766:WARNING:Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 285, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 367, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 1 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 260, in fit
    fitted_estimator = self._memory_fit(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 66, in _fit_one
    transformer.fit(*args, **fit_params)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py", line 1109, in fit
    X, y = self._validate_data(X, y, y_numeric=True, multi_output=True)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\base.py", line 596, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\validation.py", line 1074, in check_X_y
    X = check_array(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\validation.py", line 822, in check_array
    array = _ensure_sparse_format(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\validation.py", line 512, in _ensure_sparse_format
    raise TypeError(
TypeError: A sparse matrix was passed, but dense data is required. Use X.toarray() to convert to a dense numpy array.


2023-04-25 20:54:34,766:INFO:Initializing create_model()
2023-04-25 20:54:34,766:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A186E128F0>, estimator=llar, fold=ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A1F3741E70>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 20:54:34,766:INFO:Checking exceptions
2023-04-25 20:54:34,766:INFO:Importing libraries
2023-04-25 20:54:34,766:INFO:Copying training dataset
2023-04-25 20:54:34,766:INFO:Defining folds
2023-04-25 20:54:34,766:INFO:Declaring metric variables
2023-04-25 20:54:34,766:INFO:Importing untrained model
2023-04-25 20:54:34,786:INFO:Lasso Least Angle Regression Imported successfully
2023-04-25 20:54:34,786:INFO:Starting cross validation
2023-04-25 20:54:34,786:INFO:Cross validating with ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), n_jobs=1
2023-04-25 20:54:34,888:ERROR:create_model() for llar raised an exception or returned all 0.0:
2023-04-25 20:54:34,888:ERROR:Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 285, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 367, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 1 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 260, in fit
    fitted_estimator = self._memory_fit(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 66, in _fit_one
    transformer.fit(*args, **fit_params)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py", line 1109, in fit
    X, y = self._validate_data(X, y, y_numeric=True, multi_output=True)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\base.py", line 596, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\validation.py", line 1074, in check_X_y
    X = check_array(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\validation.py", line 822, in check_array
    array = _ensure_sparse_format(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\validation.py", line 512, in _ensure_sparse_format
    raise TypeError(
TypeError: A sparse matrix was passed, but dense data is required. Use X.toarray() to convert to a dense numpy array.


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 810, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 285, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 367, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 1 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 285, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 367, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 1 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 260, in fit
    fitted_estimator = self._memory_fit(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 66, in _fit_one
    transformer.fit(*args, **fit_params)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py", line 1109, in fit
    X, y = self._validate_data(X, y, y_numeric=True, multi_output=True)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\base.py", line 596, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\validation.py", line 1074, in check_X_y
    X = check_array(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\validation.py", line 822, in check_array
    array = _ensure_sparse_format(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\validation.py", line 512, in _ensure_sparse_format
    raise TypeError(
TypeError: A sparse matrix was passed, but dense data is required. Use X.toarray() to convert to a dense numpy array.


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 260, in fit
    fitted_estimator = self._memory_fit(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 66, in _fit_one
    transformer.fit(*args, **fit_params)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py", line 1109, in fit
    X, y = self._validate_data(X, y, y_numeric=True, multi_output=True)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\base.py", line 596, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\validation.py", line 1074, in check_X_y
    X = check_array(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\validation.py", line 822, in check_array
    array = _ensure_sparse_format(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\validation.py", line 512, in _ensure_sparse_format
    raise TypeError(
TypeError: A sparse matrix was passed, but dense data is required. Use X.toarray() to convert to a dense numpy array.


2023-04-25 20:54:34,919:INFO:Initializing Orthogonal Matching Pursuit
2023-04-25 20:54:34,919:INFO:Total runtime is 0.04578130642573039 minutes
2023-04-25 20:54:34,935:INFO:SubProcess create_model() called ==================================
2023-04-25 20:54:34,938:INFO:Initializing create_model()
2023-04-25 20:54:34,938:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A186E128F0>, estimator=omp, fold=ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A1F3741E70>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 20:54:34,938:INFO:Checking exceptions
2023-04-25 20:54:34,938:INFO:Importing libraries
2023-04-25 20:54:34,938:INFO:Copying training dataset
2023-04-25 20:54:34,943:INFO:Defining folds
2023-04-25 20:54:34,943:INFO:Declaring metric variables
2023-04-25 20:54:34,949:INFO:Importing untrained model
2023-04-25 20:54:34,949:INFO:Orthogonal Matching Pursuit Imported successfully
2023-04-25 20:54:34,970:INFO:Starting cross validation
2023-04-25 20:54:34,970:INFO:Cross validating with ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), n_jobs=1
2023-04-25 20:54:35,069:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-25 20:54:35,100:WARNING:create_model() for omp raised an exception or returned all 0.0, trying without fit_kwargs:
2023-04-25 20:54:35,100:WARNING:Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 285, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 367, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 1 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 260, in fit
    fitted_estimator = self._memory_fit(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 66, in _fit_one
    transformer.fit(*args, **fit_params)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_omp.py", line 727, in fit
    X, y = self._validate_data(X, y, multi_output=True, y_numeric=True)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\base.py", line 596, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\validation.py", line 1074, in check_X_y
    X = check_array(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\validation.py", line 822, in check_array
    array = _ensure_sparse_format(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\validation.py", line 512, in _ensure_sparse_format
    raise TypeError(
TypeError: A sparse matrix was passed, but dense data is required. Use X.toarray() to convert to a dense numpy array.


2023-04-25 20:54:35,100:INFO:Initializing create_model()
2023-04-25 20:54:35,100:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A186E128F0>, estimator=omp, fold=ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A1F3741E70>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 20:54:35,100:INFO:Checking exceptions
2023-04-25 20:54:35,100:INFO:Importing libraries
2023-04-25 20:54:35,100:INFO:Copying training dataset
2023-04-25 20:54:35,100:INFO:Defining folds
2023-04-25 20:54:35,100:INFO:Declaring metric variables
2023-04-25 20:54:35,122:INFO:Importing untrained model
2023-04-25 20:54:35,129:INFO:Orthogonal Matching Pursuit Imported successfully
2023-04-25 20:54:35,137:INFO:Starting cross validation
2023-04-25 20:54:35,137:INFO:Cross validating with ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), n_jobs=1
2023-04-25 20:54:35,217:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-04-25 20:54:35,233:ERROR:create_model() for omp raised an exception or returned all 0.0:
2023-04-25 20:54:35,233:ERROR:Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 285, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 367, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 1 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 260, in fit
    fitted_estimator = self._memory_fit(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 66, in _fit_one
    transformer.fit(*args, **fit_params)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_omp.py", line 727, in fit
    X, y = self._validate_data(X, y, multi_output=True, y_numeric=True)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\base.py", line 596, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\validation.py", line 1074, in check_X_y
    X = check_array(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\validation.py", line 822, in check_array
    array = _ensure_sparse_format(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\validation.py", line 512, in _ensure_sparse_format
    raise TypeError(
TypeError: A sparse matrix was passed, but dense data is required. Use X.toarray() to convert to a dense numpy array.


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 810, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 285, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 367, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 1 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 285, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 367, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 1 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 260, in fit
    fitted_estimator = self._memory_fit(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 66, in _fit_one
    transformer.fit(*args, **fit_params)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_omp.py", line 727, in fit
    X, y = self._validate_data(X, y, multi_output=True, y_numeric=True)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\base.py", line 596, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\validation.py", line 1074, in check_X_y
    X = check_array(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\validation.py", line 822, in check_array
    array = _ensure_sparse_format(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\validation.py", line 512, in _ensure_sparse_format
    raise TypeError(
TypeError: A sparse matrix was passed, but dense data is required. Use X.toarray() to convert to a dense numpy array.


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 260, in fit
    fitted_estimator = self._memory_fit(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 66, in _fit_one
    transformer.fit(*args, **fit_params)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_omp.py", line 727, in fit
    X, y = self._validate_data(X, y, multi_output=True, y_numeric=True)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\base.py", line 596, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\validation.py", line 1074, in check_X_y
    X = check_array(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\validation.py", line 822, in check_array
    array = _ensure_sparse_format(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\validation.py", line 512, in _ensure_sparse_format
    raise TypeError(
TypeError: A sparse matrix was passed, but dense data is required. Use X.toarray() to convert to a dense numpy array.


2023-04-25 20:54:35,265:INFO:Initializing Bayesian Ridge
2023-04-25 20:54:35,265:INFO:Total runtime is 0.05154095490773519 minutes
2023-04-25 20:54:35,265:INFO:SubProcess create_model() called ==================================
2023-04-25 20:54:35,265:INFO:Initializing create_model()
2023-04-25 20:54:35,265:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A186E128F0>, estimator=br, fold=ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A1F3741E70>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 20:54:35,265:INFO:Checking exceptions
2023-04-25 20:54:35,265:INFO:Importing libraries
2023-04-25 20:54:35,265:INFO:Copying training dataset
2023-04-25 20:54:35,280:INFO:Defining folds
2023-04-25 20:54:35,280:INFO:Declaring metric variables
2023-04-25 20:54:35,280:INFO:Importing untrained model
2023-04-25 20:54:35,289:INFO:Bayesian Ridge Imported successfully
2023-04-25 20:54:35,295:INFO:Starting cross validation
2023-04-25 20:54:35,295:INFO:Cross validating with ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), n_jobs=1
2023-04-25 20:54:35,409:WARNING:create_model() for br raised an exception or returned all 0.0, trying without fit_kwargs:
2023-04-25 20:54:35,425:WARNING:Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 285, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 367, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 1 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 260, in fit
    fitted_estimator = self._memory_fit(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 66, in _fit_one
    transformer.fit(*args, **fit_params)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_bayes.py", line 240, in fit
    X, y = self._validate_data(X, y, dtype=[np.float64, np.float32], y_numeric=True)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\base.py", line 596, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\validation.py", line 1074, in check_X_y
    X = check_array(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\validation.py", line 822, in check_array
    array = _ensure_sparse_format(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\validation.py", line 512, in _ensure_sparse_format
    raise TypeError(
TypeError: A sparse matrix was passed, but dense data is required. Use X.toarray() to convert to a dense numpy array.


2023-04-25 20:54:35,425:INFO:Initializing create_model()
2023-04-25 20:54:35,425:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A186E128F0>, estimator=br, fold=ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A1F3741E70>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 20:54:35,425:INFO:Checking exceptions
2023-04-25 20:54:35,425:INFO:Importing libraries
2023-04-25 20:54:35,425:INFO:Copying training dataset
2023-04-25 20:54:35,425:INFO:Defining folds
2023-04-25 20:54:35,425:INFO:Declaring metric variables
2023-04-25 20:54:35,435:INFO:Importing untrained model
2023-04-25 20:54:35,438:INFO:Bayesian Ridge Imported successfully
2023-04-25 20:54:35,444:INFO:Starting cross validation
2023-04-25 20:54:35,450:INFO:Cross validating with ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), n_jobs=1
2023-04-25 20:54:35,532:ERROR:create_model() for br raised an exception or returned all 0.0:
2023-04-25 20:54:35,532:ERROR:Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 285, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 367, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 1 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 260, in fit
    fitted_estimator = self._memory_fit(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 66, in _fit_one
    transformer.fit(*args, **fit_params)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_bayes.py", line 240, in fit
    X, y = self._validate_data(X, y, dtype=[np.float64, np.float32], y_numeric=True)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\base.py", line 596, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\validation.py", line 1074, in check_X_y
    X = check_array(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\validation.py", line 822, in check_array
    array = _ensure_sparse_format(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\validation.py", line 512, in _ensure_sparse_format
    raise TypeError(
TypeError: A sparse matrix was passed, but dense data is required. Use X.toarray() to convert to a dense numpy array.


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 810, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 285, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 367, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 1 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 285, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 367, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 1 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 260, in fit
    fitted_estimator = self._memory_fit(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 66, in _fit_one
    transformer.fit(*args, **fit_params)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_bayes.py", line 240, in fit
    X, y = self._validate_data(X, y, dtype=[np.float64, np.float32], y_numeric=True)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\base.py", line 596, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\validation.py", line 1074, in check_X_y
    X = check_array(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\validation.py", line 822, in check_array
    array = _ensure_sparse_format(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\validation.py", line 512, in _ensure_sparse_format
    raise TypeError(
TypeError: A sparse matrix was passed, but dense data is required. Use X.toarray() to convert to a dense numpy array.


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 260, in fit
    fitted_estimator = self._memory_fit(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 66, in _fit_one
    transformer.fit(*args, **fit_params)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_bayes.py", line 240, in fit
    X, y = self._validate_data(X, y, dtype=[np.float64, np.float32], y_numeric=True)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\base.py", line 596, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\validation.py", line 1074, in check_X_y
    X = check_array(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\validation.py", line 822, in check_array
    array = _ensure_sparse_format(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\validation.py", line 512, in _ensure_sparse_format
    raise TypeError(
TypeError: A sparse matrix was passed, but dense data is required. Use X.toarray() to convert to a dense numpy array.


2023-04-25 20:54:35,563:INFO:Initializing Passive Aggressive Regressor
2023-04-25 20:54:35,563:INFO:Total runtime is 0.0565155029296875 minutes
2023-04-25 20:54:35,569:INFO:SubProcess create_model() called ==================================
2023-04-25 20:54:35,569:INFO:Initializing create_model()
2023-04-25 20:54:35,569:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A186E128F0>, estimator=par, fold=ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A1F3741E70>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 20:54:35,569:INFO:Checking exceptions
2023-04-25 20:54:35,569:INFO:Importing libraries
2023-04-25 20:54:35,569:INFO:Copying training dataset
2023-04-25 20:54:35,573:INFO:Defining folds
2023-04-25 20:54:35,573:INFO:Declaring metric variables
2023-04-25 20:54:35,582:INFO:Importing untrained model
2023-04-25 20:54:35,586:INFO:Passive Aggressive Regressor Imported successfully
2023-04-25 20:54:35,593:INFO:Starting cross validation
2023-04-25 20:54:35,603:INFO:Cross validating with ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), n_jobs=1
2023-04-25 20:54:35,773:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-04-25 20:54:35,804:INFO:Calculating mean and std
2023-04-25 20:54:35,804:INFO:Creating metrics dataframe
2023-04-25 20:54:35,837:INFO:Uploading results into container
2023-04-25 20:54:35,837:INFO:Uploading model into container now
2023-04-25 20:54:35,837:INFO:_master_model_container: 13
2023-04-25 20:54:35,837:INFO:_display_container: 3
2023-04-25 20:54:35,837:INFO:PassiveAggressiveRegressor(random_state=42)
2023-04-25 20:54:35,837:INFO:create_model() successfully completed......................................
2023-04-25 20:54:35,953:INFO:SubProcess create_model() end ==================================
2023-04-25 20:54:35,953:INFO:Creating metrics dataframe
2023-04-25 20:54:35,967:INFO:Initializing Huber Regressor
2023-04-25 20:54:35,967:INFO:Total runtime is 0.06324413617451986 minutes
2023-04-25 20:54:35,986:INFO:SubProcess create_model() called ==================================
2023-04-25 20:54:35,989:INFO:Initializing create_model()
2023-04-25 20:54:35,989:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A186E128F0>, estimator=huber, fold=ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A1F3741E70>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 20:54:35,989:INFO:Checking exceptions
2023-04-25 20:54:35,989:INFO:Importing libraries
2023-04-25 20:54:35,989:INFO:Copying training dataset
2023-04-25 20:54:36,010:INFO:Defining folds
2023-04-25 20:54:36,010:INFO:Declaring metric variables
2023-04-25 20:54:36,019:INFO:Importing untrained model
2023-04-25 20:54:36,027:INFO:Huber Regressor Imported successfully
2023-04-25 20:54:36,037:INFO:Starting cross validation
2023-04-25 20:54:36,037:INFO:Cross validating with ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), n_jobs=1
2023-04-25 20:54:36,167:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-04-25 20:54:36,183:INFO:Calculating mean and std
2023-04-25 20:54:36,183:INFO:Creating metrics dataframe
2023-04-25 20:54:36,211:INFO:Uploading results into container
2023-04-25 20:54:36,219:INFO:Uploading model into container now
2023-04-25 20:54:36,219:INFO:_master_model_container: 14
2023-04-25 20:54:36,219:INFO:_display_container: 3
2023-04-25 20:54:36,219:INFO:HuberRegressor()
2023-04-25 20:54:36,219:INFO:create_model() successfully completed......................................
2023-04-25 20:54:36,354:INFO:SubProcess create_model() end ==================================
2023-04-25 20:54:36,354:INFO:Creating metrics dataframe
2023-04-25 20:54:36,354:INFO:Initializing K Neighbors Regressor
2023-04-25 20:54:36,354:INFO:Total runtime is 0.06969910065333049 minutes
2023-04-25 20:54:36,370:INFO:SubProcess create_model() called ==================================
2023-04-25 20:54:36,370:INFO:Initializing create_model()
2023-04-25 20:54:36,370:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A186E128F0>, estimator=knn, fold=ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A1F3741E70>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 20:54:36,370:INFO:Checking exceptions
2023-04-25 20:54:36,370:INFO:Importing libraries
2023-04-25 20:54:36,370:INFO:Copying training dataset
2023-04-25 20:54:36,375:INFO:Defining folds
2023-04-25 20:54:36,375:INFO:Declaring metric variables
2023-04-25 20:54:36,375:INFO:Importing untrained model
2023-04-25 20:54:36,375:INFO:K Neighbors Regressor Imported successfully
2023-04-25 20:54:36,399:INFO:Starting cross validation
2023-04-25 20:54:36,399:INFO:Cross validating with ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), n_jobs=1
2023-04-25 20:54:36,530:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-04-25 20:54:36,545:INFO:Calculating mean and std
2023-04-25 20:54:36,554:INFO:Creating metrics dataframe
2023-04-25 20:54:36,581:INFO:Uploading results into container
2023-04-25 20:54:36,581:INFO:Uploading model into container now
2023-04-25 20:54:36,586:INFO:_master_model_container: 15
2023-04-25 20:54:36,586:INFO:_display_container: 3
2023-04-25 20:54:36,586:INFO:KNeighborsRegressor(n_jobs=-1)
2023-04-25 20:54:36,586:INFO:create_model() successfully completed......................................
2023-04-25 20:54:36,702:INFO:SubProcess create_model() end ==================================
2023-04-25 20:54:36,702:INFO:Creating metrics dataframe
2023-04-25 20:54:36,718:INFO:Initializing Decision Tree Regressor
2023-04-25 20:54:36,718:INFO:Total runtime is 0.07576222022374471 minutes
2023-04-25 20:54:36,722:INFO:SubProcess create_model() called ==================================
2023-04-25 20:54:36,722:INFO:Initializing create_model()
2023-04-25 20:54:36,722:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A186E128F0>, estimator=dt, fold=ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A1F3741E70>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 20:54:36,722:INFO:Checking exceptions
2023-04-25 20:54:36,722:INFO:Importing libraries
2023-04-25 20:54:36,722:INFO:Copying training dataset
2023-04-25 20:54:36,728:INFO:Defining folds
2023-04-25 20:54:36,728:INFO:Declaring metric variables
2023-04-25 20:54:36,728:INFO:Importing untrained model
2023-04-25 20:54:36,746:INFO:Decision Tree Regressor Imported successfully
2023-04-25 20:54:36,755:INFO:Starting cross validation
2023-04-25 20:54:36,759:INFO:Cross validating with ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), n_jobs=1
2023-04-25 20:54:36,896:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-04-25 20:54:36,912:INFO:Calculating mean and std
2023-04-25 20:54:36,912:INFO:Creating metrics dataframe
2023-04-25 20:54:36,940:INFO:Uploading results into container
2023-04-25 20:54:36,942:INFO:Uploading model into container now
2023-04-25 20:54:36,942:INFO:_master_model_container: 16
2023-04-25 20:54:36,942:INFO:_display_container: 3
2023-04-25 20:54:36,942:INFO:DecisionTreeRegressor(random_state=42)
2023-04-25 20:54:36,942:INFO:create_model() successfully completed......................................
2023-04-25 20:54:37,055:INFO:SubProcess create_model() end ==================================
2023-04-25 20:54:37,055:INFO:Creating metrics dataframe
2023-04-25 20:54:37,065:INFO:Initializing Random Forest Regressor
2023-04-25 20:54:37,065:INFO:Total runtime is 0.08154198328653971 minutes
2023-04-25 20:54:37,080:INFO:SubProcess create_model() called ==================================
2023-04-25 20:54:37,080:INFO:Initializing create_model()
2023-04-25 20:54:37,080:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A186E128F0>, estimator=rf, fold=ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A1F3741E70>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 20:54:37,080:INFO:Checking exceptions
2023-04-25 20:54:37,080:INFO:Importing libraries
2023-04-25 20:54:37,080:INFO:Copying training dataset
2023-04-25 20:54:37,086:INFO:Defining folds
2023-04-25 20:54:37,086:INFO:Declaring metric variables
2023-04-25 20:54:37,086:INFO:Importing untrained model
2023-04-25 20:54:37,100:INFO:Random Forest Regressor Imported successfully
2023-04-25 20:54:37,113:INFO:Starting cross validation
2023-04-25 20:54:37,113:INFO:Cross validating with ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), n_jobs=1
2023-04-25 20:54:40,326:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-04-25 20:54:40,341:INFO:Calculating mean and std
2023-04-25 20:54:40,341:INFO:Creating metrics dataframe
2023-04-25 20:54:40,359:INFO:Uploading results into container
2023-04-25 20:54:40,359:INFO:Uploading model into container now
2023-04-25 20:54:40,359:INFO:_master_model_container: 17
2023-04-25 20:54:40,359:INFO:_display_container: 3
2023-04-25 20:54:40,359:INFO:RandomForestRegressor(n_jobs=-1, random_state=42)
2023-04-25 20:54:40,359:INFO:create_model() successfully completed......................................
2023-04-25 20:54:40,486:INFO:SubProcess create_model() end ==================================
2023-04-25 20:54:40,486:INFO:Creating metrics dataframe
2023-04-25 20:54:40,502:INFO:Initializing Extra Trees Regressor
2023-04-25 20:54:40,502:INFO:Total runtime is 0.1388225793838501 minutes
2023-04-25 20:54:40,502:INFO:SubProcess create_model() called ==================================
2023-04-25 20:54:40,502:INFO:Initializing create_model()
2023-04-25 20:54:40,502:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A186E128F0>, estimator=et, fold=ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A1F3741E70>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 20:54:40,502:INFO:Checking exceptions
2023-04-25 20:54:40,502:INFO:Importing libraries
2023-04-25 20:54:40,502:INFO:Copying training dataset
2023-04-25 20:54:40,502:INFO:Defining folds
2023-04-25 20:54:40,502:INFO:Declaring metric variables
2023-04-25 20:54:40,517:INFO:Importing untrained model
2023-04-25 20:54:40,517:INFO:Extra Trees Regressor Imported successfully
2023-04-25 20:54:40,533:INFO:Starting cross validation
2023-04-25 20:54:40,533:INFO:Cross validating with ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), n_jobs=1
2023-04-25 20:54:40,941:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-04-25 20:54:40,957:INFO:Calculating mean and std
2023-04-25 20:54:40,958:INFO:Creating metrics dataframe
2023-04-25 20:54:40,972:INFO:Uploading results into container
2023-04-25 20:54:40,972:INFO:Uploading model into container now
2023-04-25 20:54:40,972:INFO:_master_model_container: 18
2023-04-25 20:54:40,972:INFO:_display_container: 3
2023-04-25 20:54:40,972:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=42)
2023-04-25 20:54:40,972:INFO:create_model() successfully completed......................................
2023-04-25 20:54:41,098:INFO:SubProcess create_model() end ==================================
2023-04-25 20:54:41,098:INFO:Creating metrics dataframe
2023-04-25 20:54:41,098:INFO:Initializing AdaBoost Regressor
2023-04-25 20:54:41,098:INFO:Total runtime is 0.14876269102096557 minutes
2023-04-25 20:54:41,114:INFO:SubProcess create_model() called ==================================
2023-04-25 20:54:41,114:INFO:Initializing create_model()
2023-04-25 20:54:41,114:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A186E128F0>, estimator=ada, fold=ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A1F3741E70>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 20:54:41,114:INFO:Checking exceptions
2023-04-25 20:54:41,114:INFO:Importing libraries
2023-04-25 20:54:41,114:INFO:Copying training dataset
2023-04-25 20:54:41,114:INFO:Defining folds
2023-04-25 20:54:41,114:INFO:Declaring metric variables
2023-04-25 20:54:41,114:INFO:Importing untrained model
2023-04-25 20:54:41,129:INFO:AdaBoost Regressor Imported successfully
2023-04-25 20:54:41,129:INFO:Starting cross validation
2023-04-25 20:54:41,145:INFO:Cross validating with ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), n_jobs=1
2023-04-25 20:54:41,348:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-04-25 20:54:41,348:INFO:Calculating mean and std
2023-04-25 20:54:41,364:INFO:Creating metrics dataframe
2023-04-25 20:54:41,379:INFO:Uploading results into container
2023-04-25 20:54:41,379:INFO:Uploading model into container now
2023-04-25 20:54:41,379:INFO:_master_model_container: 19
2023-04-25 20:54:41,379:INFO:_display_container: 3
2023-04-25 20:54:41,379:INFO:AdaBoostRegressor(random_state=42)
2023-04-25 20:54:41,379:INFO:create_model() successfully completed......................................
2023-04-25 20:54:41,486:INFO:SubProcess create_model() end ==================================
2023-04-25 20:54:41,486:INFO:Creating metrics dataframe
2023-04-25 20:54:41,497:INFO:Initializing Gradient Boosting Regressor
2023-04-25 20:54:41,497:INFO:Total runtime is 0.15541210174560546 minutes
2023-04-25 20:54:41,504:INFO:SubProcess create_model() called ==================================
2023-04-25 20:54:41,504:INFO:Initializing create_model()
2023-04-25 20:54:41,504:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A186E128F0>, estimator=gbr, fold=ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A1F3741E70>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 20:54:41,504:INFO:Checking exceptions
2023-04-25 20:54:41,504:INFO:Importing libraries
2023-04-25 20:54:41,504:INFO:Copying training dataset
2023-04-25 20:54:41,504:INFO:Defining folds
2023-04-25 20:54:41,504:INFO:Declaring metric variables
2023-04-25 20:54:41,512:INFO:Importing untrained model
2023-04-25 20:54:41,512:INFO:Gradient Boosting Regressor Imported successfully
2023-04-25 20:54:41,518:INFO:Starting cross validation
2023-04-25 20:54:41,525:INFO:Cross validating with ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), n_jobs=1
2023-04-25 20:54:41,643:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-04-25 20:54:41,659:INFO:Calculating mean and std
2023-04-25 20:54:41,659:INFO:Creating metrics dataframe
2023-04-25 20:54:41,680:INFO:Uploading results into container
2023-04-25 20:54:41,680:INFO:Uploading model into container now
2023-04-25 20:54:41,680:INFO:_master_model_container: 20
2023-04-25 20:54:41,680:INFO:_display_container: 3
2023-04-25 20:54:41,680:INFO:GradientBoostingRegressor(random_state=42)
2023-04-25 20:54:41,680:INFO:create_model() successfully completed......................................
2023-04-25 20:54:41,790:INFO:SubProcess create_model() end ==================================
2023-04-25 20:54:41,790:INFO:Creating metrics dataframe
2023-04-25 20:54:41,804:INFO:Initializing Light Gradient Boosting Machine
2023-04-25 20:54:41,804:INFO:Total runtime is 0.16053145726521809 minutes
2023-04-25 20:54:41,804:INFO:SubProcess create_model() called ==================================
2023-04-25 20:54:41,809:INFO:Initializing create_model()
2023-04-25 20:54:41,809:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A186E128F0>, estimator=lightgbm, fold=ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A1F3741E70>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 20:54:41,809:INFO:Checking exceptions
2023-04-25 20:54:41,809:INFO:Importing libraries
2023-04-25 20:54:41,809:INFO:Copying training dataset
2023-04-25 20:54:41,811:INFO:Defining folds
2023-04-25 20:54:41,811:INFO:Declaring metric variables
2023-04-25 20:54:41,818:INFO:Importing untrained model
2023-04-25 20:54:41,818:INFO:Light Gradient Boosting Machine Imported successfully
2023-04-25 20:54:41,824:INFO:Starting cross validation
2023-04-25 20:54:41,824:INFO:Cross validating with ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), n_jobs=1
2023-04-25 20:54:41,963:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-04-25 20:54:41,971:INFO:Calculating mean and std
2023-04-25 20:54:41,979:INFO:Creating metrics dataframe
2023-04-25 20:54:41,995:INFO:Uploading results into container
2023-04-25 20:54:41,995:INFO:Uploading model into container now
2023-04-25 20:54:41,995:INFO:_master_model_container: 21
2023-04-25 20:54:41,995:INFO:_display_container: 3
2023-04-25 20:54:41,995:INFO:LGBMRegressor(device='gpu', random_state=42)
2023-04-25 20:54:41,995:INFO:create_model() successfully completed......................................
2023-04-25 20:54:42,104:INFO:SubProcess create_model() end ==================================
2023-04-25 20:54:42,104:INFO:Creating metrics dataframe
2023-04-25 20:54:42,120:INFO:Initializing Dummy Regressor
2023-04-25 20:54:42,120:INFO:Total runtime is 0.1657959222793579 minutes
2023-04-25 20:54:42,120:INFO:SubProcess create_model() called ==================================
2023-04-25 20:54:42,120:INFO:Initializing create_model()
2023-04-25 20:54:42,120:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A186E128F0>, estimator=dummy, fold=ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A1F3741E70>, model_only=True, return_train_score=False, kwargs={})
2023-04-25 20:54:42,120:INFO:Checking exceptions
2023-04-25 20:54:42,120:INFO:Importing libraries
2023-04-25 20:54:42,120:INFO:Copying training dataset
2023-04-25 20:54:42,120:INFO:Defining folds
2023-04-25 20:54:42,120:INFO:Declaring metric variables
2023-04-25 20:54:42,120:INFO:Importing untrained model
2023-04-25 20:54:42,136:INFO:Dummy Regressor Imported successfully
2023-04-25 20:54:42,136:INFO:Starting cross validation
2023-04-25 20:54:42,136:INFO:Cross validating with ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), n_jobs=1
2023-04-25 20:54:42,214:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-04-25 20:54:42,214:INFO:Calculating mean and std
2023-04-25 20:54:42,214:INFO:Creating metrics dataframe
2023-04-25 20:54:42,230:INFO:Uploading results into container
2023-04-25 20:54:42,230:INFO:Uploading model into container now
2023-04-25 20:54:42,230:INFO:_master_model_container: 22
2023-04-25 20:54:42,230:INFO:_display_container: 3
2023-04-25 20:54:42,230:INFO:DummyRegressor()
2023-04-25 20:54:42,230:INFO:create_model() successfully completed......................................
2023-04-25 20:54:42,372:INFO:SubProcess create_model() end ==================================
2023-04-25 20:54:42,372:INFO:Creating metrics dataframe
2023-04-25 20:54:42,388:INFO:Initializing create_model()
2023-04-25 20:54:42,388:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A186E128F0>, estimator=LinearRegression(n_jobs=-1), fold=ShuffleSplit(n_splits=1, random_state=42, test_size=None,
       train_size=0.9230769230769231), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-25 20:54:42,388:INFO:Checking exceptions
2023-04-25 20:54:42,388:INFO:Importing libraries
2023-04-25 20:54:42,388:INFO:Copying training dataset
2023-04-25 20:54:42,396:INFO:Defining folds
2023-04-25 20:54:42,396:INFO:Declaring metric variables
2023-04-25 20:54:42,396:INFO:Importing untrained model
2023-04-25 20:54:42,396:INFO:Declaring custom model
2023-04-25 20:54:42,396:INFO:Linear Regression Imported successfully
2023-04-25 20:54:42,399:INFO:Cross validation set to False
2023-04-25 20:54:42,399:INFO:Fitting Model
2023-04-25 20:54:42,447:INFO:LinearRegression(n_jobs=-1)
2023-04-25 20:54:42,447:INFO:create_model() successfully completed......................................
2023-04-25 20:54:42,559:INFO:Creating Dashboard logs
2023-04-25 20:54:42,559:INFO:Model: Linear Regression
2023-04-25 20:54:42,599:INFO:Logged params: {'copy_X': True, 'fit_intercept': True, 'n_jobs': -1, 'normalize': 'deprecated', 'positive': False}
2023-04-25 20:54:42,677:INFO:Initializing predict_model()
2023-04-25 20:54:42,677:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A186E128F0>, estimator=LinearRegression(n_jobs=-1), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000001A186DB0C10>)
2023-04-25 20:54:42,677:INFO:Checking exceptions
2023-04-25 20:54:42,677:INFO:Preloading libraries
2023-04-25 20:54:42,788:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)

2023-04-25 20:54:43,067:INFO:Creating Dashboard logs
2023-04-25 20:54:43,067:INFO:Model: Lasso Regression
2023-04-25 20:54:43,123:INFO:Logged params: {'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'max_iter': 1000, 'normalize': 'deprecated', 'positive': False, 'precompute': False, 'random_state': 42, 'selection': 'cyclic', 'tol': 0.0001, 'warm_start': False}
2023-04-25 20:54:43,356:INFO:Creating Dashboard logs
2023-04-25 20:54:43,356:INFO:Model: Ridge Regression
2023-04-25 20:54:43,404:INFO:Logged params: {'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'normalize': 'deprecated', 'positive': False, 'random_state': 42, 'solver': 'auto', 'tol': 0.001}
2023-04-25 20:54:43,623:INFO:Creating Dashboard logs
2023-04-25 20:54:43,641:INFO:Model: Elastic Net
2023-04-25 20:54:43,679:INFO:Logged params: {'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'l1_ratio': 0.5, 'max_iter': 1000, 'normalize': 'deprecated', 'positive': False, 'precompute': False, 'random_state': 42, 'selection': 'cyclic', 'tol': 0.0001, 'warm_start': False}
2023-04-25 20:54:43,914:INFO:Creating Dashboard logs
2023-04-25 20:54:43,914:INFO:Model: Passive Aggressive Regressor
2023-04-25 20:54:43,961:INFO:Logged params: {'C': 1.0, 'average': False, 'early_stopping': False, 'epsilon': 0.1, 'fit_intercept': True, 'loss': 'epsilon_insensitive', 'max_iter': 1000, 'n_iter_no_change': 5, 'random_state': 42, 'shuffle': True, 'tol': 0.001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2023-04-25 20:54:44,246:INFO:Creating Dashboard logs
2023-04-25 20:54:44,260:INFO:Model: Huber Regressor
2023-04-25 20:54:44,304:INFO:Logged params: {'alpha': 0.0001, 'epsilon': 1.35, 'fit_intercept': True, 'max_iter': 100, 'tol': 1e-05, 'warm_start': False}
2023-04-25 20:54:44,528:INFO:Creating Dashboard logs
2023-04-25 20:54:44,528:INFO:Model: K Neighbors Regressor
2023-04-25 20:54:44,574:INFO:Logged params: {'algorithm': 'auto', 'leaf_size': 30, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': -1, 'n_neighbors': 5, 'p': 2, 'weights': 'uniform'}
2023-04-25 20:54:44,787:INFO:Creating Dashboard logs
2023-04-25 20:54:44,787:INFO:Model: Decision Tree Regressor
2023-04-25 20:54:44,848:INFO:Logged params: {'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'random_state': 42, 'splitter': 'best'}
2023-04-25 20:54:45,243:INFO:Creating Dashboard logs
2023-04-25 20:54:45,243:INFO:Model: Random Forest Regressor
2023-04-25 20:54:45,306:INFO:Logged params: {'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': 1.0, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 42, 'verbose': 0, 'warm_start': False}
2023-04-25 20:54:45,576:INFO:Creating Dashboard logs
2023-04-25 20:54:45,576:INFO:Model: Extra Trees Regressor
2023-04-25 20:54:45,623:INFO:Logged params: {'bootstrap': False, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': 1.0, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 42, 'verbose': 0, 'warm_start': False}
2023-04-25 20:54:45,874:INFO:Creating Dashboard logs
2023-04-25 20:54:45,874:INFO:Model: AdaBoost Regressor
2023-04-25 20:54:45,921:INFO:Logged params: {'base_estimator': None, 'learning_rate': 1.0, 'loss': 'linear', 'n_estimators': 50, 'random_state': 42}
2023-04-25 20:54:46,130:INFO:Creating Dashboard logs
2023-04-25 20:54:46,144:INFO:Model: Gradient Boosting Regressor
2023-04-25 20:54:46,175:INFO:Logged params: {'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': None, 'random_state': 42, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2023-04-25 20:54:46,413:INFO:Creating Dashboard logs
2023-04-25 20:54:46,413:INFO:Model: Light Gradient Boosting Machine
2023-04-25 20:54:46,474:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 42, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'device': 'gpu'}
2023-04-25 20:54:46,716:INFO:Creating Dashboard logs
2023-04-25 20:54:46,716:INFO:Model: Dummy Regressor
2023-04-25 20:54:46,763:INFO:Logged params: {'constant': None, 'quantile': None, 'strategy': 'mean'}
2023-04-25 20:54:46,998:INFO:_master_model_container: 22
2023-04-25 20:54:46,998:INFO:_display_container: 3
2023-04-25 20:54:46,998:INFO:LinearRegression(n_jobs=-1)
2023-04-25 20:54:46,998:INFO:compare_models() successfully completed......................................
2023-06-05 23:06:57,485:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-05 23:06:57,486:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-05 23:06:57,486:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-05 23:06:57,486:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-05 23:06:58,868:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-06-05 23:06:59,226:INFO:PyCaret RegressionExperiment
2023-06-05 23:06:59,226:INFO:Logging name: your_experiment_name
2023-06-05 23:06:59,226:INFO:ML Usecase: MLUsecase.REGRESSION
2023-06-05 23:06:59,226:INFO:version 3.0.0
2023-06-05 23:06:59,226:INFO:Initializing setup()
2023-06-05 23:06:59,226:INFO:self.USI: ba11
2023-06-05 23:06:59,226:INFO:self._variable_keys: {'pipeline', 'fold_shuffle_param', 'n_jobs_param', 'data', 'transform_target_param', 'exp_name_log', 'y', 'target_param', 'idx', '_ml_usecase', 'html_param', '_available_plots', 'y_test', 'USI', 'logging_param', 'gpu_param', 'X_train', 'gpu_n_jobs_param', 'seed', 'fold_groups_param', 'X', 'y_train', 'X_test', 'memory', 'log_plots_param', 'exp_id', 'fold_generator'}
2023-06-05 23:06:59,226:INFO:Checking environment
2023-06-05 23:06:59,226:INFO:python_version: 3.10.5
2023-06-05 23:06:59,226:INFO:python_build: ('tags/v3.10.5:f377153', 'Jun  6 2022 16:14:13')
2023-06-05 23:06:59,226:INFO:machine: AMD64
2023-06-05 23:06:59,226:INFO:platform: Windows-10-10.0.22621-SP0
2023-06-05 23:06:59,226:INFO:Memory: svmem(total=16497119232, available=8722927616, percent=47.1, used=7774191616, free=8722927616)
2023-06-05 23:06:59,226:INFO:Physical Core: 8
2023-06-05 23:06:59,227:INFO:Logical Core: 16
2023-06-05 23:06:59,227:INFO:Checking libraries
2023-06-05 23:06:59,227:INFO:System:
2023-06-05 23:06:59,227:INFO:    python: 3.10.5 (tags/v3.10.5:f377153, Jun  6 2022, 16:14:13) [MSC v.1929 64 bit (AMD64)]
2023-06-05 23:06:59,227:INFO:executable: C:\Users\Hashif\AppData\Local\Programs\Python\Python310\python.exe
2023-06-05 23:06:59,227:INFO:   machine: Windows-10-10.0.22621-SP0
2023-06-05 23:06:59,227:INFO:PyCaret required dependencies:
2023-06-05 23:06:59,227:INFO:                 pip: 23.1.1
2023-06-05 23:06:59,227:INFO:          setuptools: 58.1.0
2023-06-05 23:06:59,227:INFO:             pycaret: 3.0.0
2023-06-05 23:06:59,227:INFO:             IPython: 8.4.0
2023-06-05 23:06:59,227:INFO:          ipywidgets: 7.7.0
2023-06-05 23:06:59,227:INFO:                tqdm: 4.65.0
2023-06-05 23:06:59,227:INFO:               numpy: 1.23.0
2023-06-05 23:06:59,227:INFO:              pandas: 1.4.3
2023-06-05 23:06:59,227:INFO:              jinja2: 3.1.2
2023-06-05 23:06:59,227:INFO:               scipy: 1.9.3
2023-06-05 23:06:59,227:INFO:              joblib: 1.2.0
2023-06-05 23:06:59,227:INFO:             sklearn: 1.1.2
2023-06-05 23:06:59,227:INFO:                pyod: 1.0.9
2023-06-05 23:06:59,227:INFO:            imblearn: 0.10.1
2023-06-05 23:06:59,227:INFO:   category_encoders: 2.6.0
2023-06-05 23:06:59,227:INFO:            lightgbm: 3.3.5
2023-06-05 23:06:59,227:INFO:               numba: 0.56.4
2023-06-05 23:06:59,227:INFO:            requests: 2.28.1
2023-06-05 23:06:59,227:INFO:          matplotlib: 3.6.2
2023-06-05 23:06:59,227:INFO:          scikitplot: 0.3.7
2023-06-05 23:06:59,227:INFO:         yellowbrick: 1.5
2023-06-05 23:06:59,227:INFO:              plotly: 5.14.1
2023-06-05 23:06:59,227:INFO:             kaleido: 0.2.1
2023-06-05 23:06:59,227:INFO:         statsmodels: 0.13.5
2023-06-05 23:06:59,228:INFO:              sktime: 0.17.1
2023-06-05 23:06:59,228:INFO:               tbats: 1.1.3
2023-06-05 23:06:59,228:INFO:            pmdarima: 2.0.3
2023-06-05 23:06:59,228:INFO:              psutil: 5.9.1
2023-06-05 23:06:59,228:INFO:PyCaret optional dependencies:
2023-06-05 23:06:59,231:INFO:                shap: Not installed
2023-06-05 23:06:59,231:INFO:           interpret: Not installed
2023-06-05 23:06:59,231:INFO:                umap: Not installed
2023-06-05 23:06:59,231:INFO:    pandas_profiling: Not installed
2023-06-05 23:06:59,231:INFO:  explainerdashboard: Not installed
2023-06-05 23:06:59,231:INFO:             autoviz: Not installed
2023-06-05 23:06:59,231:INFO:           fairlearn: Not installed
2023-06-05 23:06:59,231:INFO:             xgboost: Not installed
2023-06-05 23:06:59,231:INFO:            catboost: Not installed
2023-06-05 23:06:59,231:INFO:              kmodes: Not installed
2023-06-05 23:06:59,231:INFO:             mlxtend: Not installed
2023-06-05 23:06:59,231:INFO:       statsforecast: Not installed
2023-06-05 23:06:59,231:INFO:        tune_sklearn: Not installed
2023-06-05 23:06:59,231:INFO:                 ray: Not installed
2023-06-05 23:06:59,231:INFO:            hyperopt: Not installed
2023-06-05 23:06:59,231:INFO:              optuna: Not installed
2023-06-05 23:06:59,231:INFO:               skopt: Not installed
2023-06-05 23:06:59,231:INFO:              mlflow: 2.3.0
2023-06-05 23:06:59,231:INFO:              gradio: Not installed
2023-06-05 23:06:59,231:INFO:             fastapi: Not installed
2023-06-05 23:06:59,231:INFO:             uvicorn: Not installed
2023-06-05 23:06:59,231:INFO:              m2cgen: Not installed
2023-06-05 23:06:59,231:INFO:           evidently: Not installed
2023-06-05 23:06:59,231:INFO:               fugue: Not installed
2023-06-05 23:06:59,231:INFO:           streamlit: Not installed
2023-06-05 23:06:59,231:INFO:             prophet: Not installed
2023-06-05 23:06:59,231:INFO:None
2023-06-05 23:06:59,231:INFO:Set up data.
2023-06-05 23:06:59,278:INFO:Set up train/test split.
2023-06-05 23:06:59,278:INFO:Set up index.
2023-06-05 23:06:59,278:INFO:Set up folding strategy.
2023-06-05 23:06:59,278:INFO:Assigning column types.
2023-06-05 23:06:59,278:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-06-05 23:06:59,278:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-06-05 23:06:59,294:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-06-05 23:06:59,294:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-05 23:06:59,361:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-05 23:06:59,404:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-05 23:06:59,404:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 23:06:59,433:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 23:06:59,433:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-06-05 23:06:59,448:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-06-05 23:06:59,448:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-05 23:06:59,516:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-05 23:06:59,559:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-05 23:06:59,560:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 23:06:59,561:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 23:06:59,561:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-06-05 23:06:59,565:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-06-05 23:06:59,565:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-05 23:06:59,620:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-05 23:06:59,651:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-05 23:06:59,667:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 23:06:59,667:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 23:06:59,667:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-06-05 23:06:59,667:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-05 23:06:59,730:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-05 23:06:59,761:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-05 23:06:59,761:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 23:06:59,761:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 23:06:59,761:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-06-05 23:06:59,777:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-05 23:06:59,824:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-05 23:06:59,888:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-05 23:06:59,888:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 23:06:59,889:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 23:06:59,897:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-05 23:06:59,946:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-05 23:06:59,993:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-05 23:06:59,993:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 23:06:59,993:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 23:06:59,993:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-06-05 23:07:00,056:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-05 23:07:00,103:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-05 23:07:00,103:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 23:07:00,103:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 23:07:00,165:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-05 23:07:00,213:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-05 23:07:00,213:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 23:07:00,213:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 23:07:00,213:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-06-05 23:07:00,276:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-05 23:07:00,322:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 23:07:00,322:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 23:07:00,385:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-05 23:07:00,434:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 23:07:00,434:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 23:07:00,434:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-06-05 23:07:00,542:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 23:07:00,542:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 23:07:00,651:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 23:07:00,651:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 23:07:00,675:INFO:Preparing preprocessing pipeline...
2023-06-05 23:07:00,675:INFO:Set up simple imputation.
2023-06-05 23:07:00,675:INFO:Set up feature normalization.
2023-06-05 23:07:00,675:INFO:Set up column name cleaning.
2023-06-05 23:07:00,715:INFO:Finished creating preprocessing pipeline.
2023-06-05 23:07:00,715:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Hashif\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['location', 'ratings', 'type',
                                             '( free', '( temporarily',
                                             ') exceptional', ') fitness',
                                             ') free', ') good',
                                             ') non-smoking', ') room', ') spa',
                                             '2 swimming', '24-hour front',
                                             'air conditioning',
                                             'airport shuttle', 'bar (',
                                             'bar air', 'bar breakfast'...
                                             'centre (', 'centre 24-hour',
                                             'centre daily',
                                             'centre facilities', 'centre free', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-06-05 23:07:00,715:INFO:Creating final display dataframe.
2023-06-05 23:07:00,841:INFO:Setup _display_container:                     Description                 Value
0                    Session id                   123
1                        Target                 price
2                   Target type            Regression
3           Original data shape            (735, 214)
4        Transformed data shape            (735, 214)
5   Transformed train set shape            (588, 214)
6    Transformed test set shape            (147, 214)
7              Numeric features                   213
8                    Preprocess                  True
9               Imputation type                simple
10           Numeric imputation                  mean
11       Categorical imputation                  mode
12                    Normalize                  True
13             Normalize method                zscore
14               Fold Generator                 KFold
15                  Fold Number                    10
16                     CPU Jobs                    -1
17                      Use GPU                 False
18               Log Experiment          MlflowLogger
19              Experiment Name  your_experiment_name
20                          USI                  ba11
2023-06-05 23:07:00,984:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 23:07:00,984:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 23:07:01,093:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 23:07:01,093:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 23:07:01,093:INFO:Logging experiment in loggers
2023-06-05 23:07:01,369:INFO:SubProcess save_model() called ==================================
2023-06-05 23:07:01,381:INFO:Initializing save_model()
2023-06-05 23:07:01,381:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\Hashif\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['location', 'ratings', 'type',
                                             '( free', '( temporarily',
                                             ') exceptional', ') fitness',
                                             ') free', ') good',
                                             ') non-smoking', ') room', ') spa',
                                             '2 swimming', '24-hour front',
                                             'air conditioning',
                                             'airport shuttle', 'bar (',
                                             'bar air', 'bar breakfast'...
                                             'centre (', 'centre 24-hour',
                                             'centre daily',
                                             'centre facilities', 'centre free', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), model_name=C:\Users\Hashif\AppData\Local\Temp\tmpl7tq7idj\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\Hashif\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['location', 'ratings', 'type',
                                             '( free', '( temporarily',
                                             ') exceptional', ') fitness',
                                             ') free', ') good',
                                             ') non-smoking', ') room', ') spa',
                                             '2 swimming', '24-hour front',
                                             'air conditioning',
                                             'airport shuttle', 'bar (',
                                             'bar air', 'bar breakfast'...
                                             'centre (', 'centre 24-hour',
                                             'centre daily',
                                             'centre facilities', 'centre free', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=False, use_case=MLUsecase.REGRESSION, kwargs={})
2023-06-05 23:07:01,381:INFO:Adding model into prep_pipe
2023-06-05 23:07:01,381:WARNING:Only Model saved as it was a pipeline.
2023-06-05 23:07:01,381:INFO:C:\Users\Hashif\AppData\Local\Temp\tmpl7tq7idj\Transformation Pipeline.pkl saved in current working directory
2023-06-05 23:07:01,381:INFO:Pipeline(memory=FastMemory(location=C:\Users\Hashif\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['location', 'ratings', 'type',
                                             '( free', '( temporarily',
                                             ') exceptional', ') fitness',
                                             ') free', ') good',
                                             ') non-smoking', ') room', ') spa',
                                             '2 swimming', '24-hour front',
                                             'air conditioning',
                                             'airport shuttle', 'bar (',
                                             'bar air', 'bar breakfast'...
                                             'centre (', 'centre 24-hour',
                                             'centre daily',
                                             'centre facilities', 'centre free', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-06-05 23:07:01,381:INFO:save_model() successfully completed......................................
2023-06-05 23:07:01,494:INFO:SubProcess save_model() end ==================================
2023-06-05 23:07:01,548:INFO:setup() successfully completed in 1.87s...............
2023-06-05 23:07:01,548:INFO:Initializing compare_models()
2023-06-05 23:07:01,548:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020E25C03C70>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x0000020E25C03C70>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-06-05 23:07:01,548:INFO:Checking exceptions
2023-06-05 23:07:01,548:INFO:Preparing display monitor
2023-06-05 23:07:01,590:INFO:Initializing Linear Regression
2023-06-05 23:07:01,590:INFO:Total runtime is 1.2365976969401042e-05 minutes
2023-06-05 23:07:01,594:INFO:SubProcess create_model() called ==================================
2023-06-05 23:07:01,594:INFO:Initializing create_model()
2023-06-05 23:07:01,595:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020E25C03C70>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020E295358A0>, model_only=True, return_train_score=False, kwargs={})
2023-06-05 23:07:01,595:INFO:Checking exceptions
2023-06-05 23:07:01,595:INFO:Importing libraries
2023-06-05 23:07:01,595:INFO:Copying training dataset
2023-06-05 23:07:01,602:INFO:Defining folds
2023-06-05 23:07:01,603:INFO:Declaring metric variables
2023-06-05 23:07:01,606:INFO:Importing untrained model
2023-06-05 23:07:01,612:INFO:Linear Regression Imported successfully
2023-06-05 23:07:01,622:INFO:Starting cross validation
2023-06-05 23:07:01,635:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-05 23:07:07,652:INFO:Calculating mean and std
2023-06-05 23:07:07,655:INFO:Creating metrics dataframe
2023-06-05 23:07:07,655:INFO:Uploading results into container
2023-06-05 23:07:07,655:INFO:Uploading model into container now
2023-06-05 23:07:07,665:INFO:_master_model_container: 1
2023-06-05 23:07:07,665:INFO:_display_container: 2
2023-06-05 23:07:07,666:INFO:LinearRegression(n_jobs=-1)
2023-06-05 23:07:07,666:INFO:create_model() successfully completed......................................
2023-06-05 23:07:07,788:INFO:SubProcess create_model() end ==================================
2023-06-05 23:07:07,788:INFO:Creating metrics dataframe
2023-06-05 23:07:07,788:INFO:Initializing Lasso Regression
2023-06-05 23:07:07,788:INFO:Total runtime is 0.10330822865168253 minutes
2023-06-05 23:07:07,808:INFO:SubProcess create_model() called ==================================
2023-06-05 23:07:07,808:INFO:Initializing create_model()
2023-06-05 23:07:07,808:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020E25C03C70>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020E295358A0>, model_only=True, return_train_score=False, kwargs={})
2023-06-05 23:07:07,808:INFO:Checking exceptions
2023-06-05 23:07:07,808:INFO:Importing libraries
2023-06-05 23:07:07,808:INFO:Copying training dataset
2023-06-05 23:07:07,814:INFO:Defining folds
2023-06-05 23:07:07,814:INFO:Declaring metric variables
2023-06-05 23:07:07,819:INFO:Importing untrained model
2023-06-05 23:07:07,825:INFO:Lasso Regression Imported successfully
2023-06-05 23:07:07,837:INFO:Starting cross validation
2023-06-05 23:07:07,839:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-05 23:07:08,069:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.104e+06, tolerance: 2.354e+05
  model = cd_fast.enet_coordinate_descent(

2023-06-05 23:07:08,069:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.326e+06, tolerance: 2.501e+05
  model = cd_fast.enet_coordinate_descent(

2023-06-05 23:07:10,098:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.463e+05, tolerance: 2.492e+05
  model = cd_fast.enet_coordinate_descent(

2023-06-05 23:07:10,115:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.728e+05, tolerance: 2.388e+05
  model = cd_fast.enet_coordinate_descent(

2023-06-05 23:07:10,146:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.425e+05, tolerance: 2.126e+05
  model = cd_fast.enet_coordinate_descent(

2023-06-05 23:07:10,146:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.427e+05, tolerance: 2.238e+05
  model = cd_fast.enet_coordinate_descent(

2023-06-05 23:07:10,161:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.588e+05, tolerance: 2.437e+05
  model = cd_fast.enet_coordinate_descent(

2023-06-05 23:07:10,193:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.602e+06, tolerance: 2.377e+05
  model = cd_fast.enet_coordinate_descent(

2023-06-05 23:07:10,255:INFO:Calculating mean and std
2023-06-05 23:07:10,256:INFO:Creating metrics dataframe
2023-06-05 23:07:10,260:INFO:Uploading results into container
2023-06-05 23:07:10,260:INFO:Uploading model into container now
2023-06-05 23:07:10,260:INFO:_master_model_container: 2
2023-06-05 23:07:10,260:INFO:_display_container: 2
2023-06-05 23:07:10,260:INFO:Lasso(random_state=123)
2023-06-05 23:07:10,260:INFO:create_model() successfully completed......................................
2023-06-05 23:07:10,362:INFO:SubProcess create_model() end ==================================
2023-06-05 23:07:10,362:INFO:Creating metrics dataframe
2023-06-05 23:07:10,362:INFO:Initializing Ridge Regression
2023-06-05 23:07:10,362:INFO:Total runtime is 0.14620773792266845 minutes
2023-06-05 23:07:10,362:INFO:SubProcess create_model() called ==================================
2023-06-05 23:07:10,378:INFO:Initializing create_model()
2023-06-05 23:07:10,378:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020E25C03C70>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020E295358A0>, model_only=True, return_train_score=False, kwargs={})
2023-06-05 23:07:10,378:INFO:Checking exceptions
2023-06-05 23:07:10,378:INFO:Importing libraries
2023-06-05 23:07:10,378:INFO:Copying training dataset
2023-06-05 23:07:10,381:INFO:Defining folds
2023-06-05 23:07:10,381:INFO:Declaring metric variables
2023-06-05 23:07:10,381:INFO:Importing untrained model
2023-06-05 23:07:10,381:INFO:Ridge Regression Imported successfully
2023-06-05 23:07:10,409:INFO:Starting cross validation
2023-06-05 23:07:10,409:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-05 23:07:10,611:INFO:Calculating mean and std
2023-06-05 23:07:10,611:INFO:Creating metrics dataframe
2023-06-05 23:07:10,618:INFO:Uploading results into container
2023-06-05 23:07:10,618:INFO:Uploading model into container now
2023-06-05 23:07:10,618:INFO:_master_model_container: 3
2023-06-05 23:07:10,619:INFO:_display_container: 2
2023-06-05 23:07:10,619:INFO:Ridge(random_state=123)
2023-06-05 23:07:10,619:INFO:create_model() successfully completed......................................
2023-06-05 23:07:10,716:INFO:SubProcess create_model() end ==================================
2023-06-05 23:07:10,717:INFO:Creating metrics dataframe
2023-06-05 23:07:10,717:INFO:Initializing Elastic Net
2023-06-05 23:07:10,717:INFO:Total runtime is 0.15211611191431682 minutes
2023-06-05 23:07:10,727:INFO:SubProcess create_model() called ==================================
2023-06-05 23:07:10,727:INFO:Initializing create_model()
2023-06-05 23:07:10,727:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020E25C03C70>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020E295358A0>, model_only=True, return_train_score=False, kwargs={})
2023-06-05 23:07:10,729:INFO:Checking exceptions
2023-06-05 23:07:10,729:INFO:Importing libraries
2023-06-05 23:07:10,729:INFO:Copying training dataset
2023-06-05 23:07:10,729:INFO:Defining folds
2023-06-05 23:07:10,729:INFO:Declaring metric variables
2023-06-05 23:07:10,729:INFO:Importing untrained model
2023-06-05 23:07:10,744:INFO:Elastic Net Imported successfully
2023-06-05 23:07:10,748:INFO:Starting cross validation
2023-06-05 23:07:10,756:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-05 23:07:10,991:INFO:Calculating mean and std
2023-06-05 23:07:10,992:INFO:Creating metrics dataframe
2023-06-05 23:07:10,996:INFO:Uploading results into container
2023-06-05 23:07:10,996:INFO:Uploading model into container now
2023-06-05 23:07:10,996:INFO:_master_model_container: 4
2023-06-05 23:07:10,996:INFO:_display_container: 2
2023-06-05 23:07:10,997:INFO:ElasticNet(random_state=123)
2023-06-05 23:07:10,997:INFO:create_model() successfully completed......................................
2023-06-05 23:07:11,088:INFO:SubProcess create_model() end ==================================
2023-06-05 23:07:11,088:INFO:Creating metrics dataframe
2023-06-05 23:07:11,088:INFO:Initializing Least Angle Regression
2023-06-05 23:07:11,088:INFO:Total runtime is 0.15830149253209433 minutes
2023-06-05 23:07:11,103:INFO:SubProcess create_model() called ==================================
2023-06-05 23:07:11,103:INFO:Initializing create_model()
2023-06-05 23:07:11,103:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020E25C03C70>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020E295358A0>, model_only=True, return_train_score=False, kwargs={})
2023-06-05 23:07:11,103:INFO:Checking exceptions
2023-06-05 23:07:11,103:INFO:Importing libraries
2023-06-05 23:07:11,103:INFO:Copying training dataset
2023-06-05 23:07:11,117:INFO:Defining folds
2023-06-05 23:07:11,117:INFO:Declaring metric variables
2023-06-05 23:07:11,117:INFO:Importing untrained model
2023-06-05 23:07:11,117:INFO:Least Angle Regression Imported successfully
2023-06-05 23:07:11,133:INFO:Starting cross validation
2023-06-05 23:07:11,133:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-05 23:07:11,267:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-06-05 23:07:11,267:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-06-05 23:07:11,283:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-06-05 23:07:11,283:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-06-05 23:07:11,283:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-06-05 23:07:11,298:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=9.299e+00, with an active set of 18 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:07:11,298:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:741: RuntimeWarning: overflow encountered in divide
  z = -coef[active] / (least_squares + tiny32)

2023-06-05 23:07:11,298:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=1.850e+01, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:07:11,298:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 30 iterations, i.e. alpha=5.165e+00, with an active set of 27 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:07:11,298:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 30 iterations, i.e. alpha=5.103e+00, with an active set of 27 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:07:11,298:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=9.988e+00, with an active set of 17 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:07:11,298:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=9.248e+00, with an active set of 18 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:07:11,298:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=3.014e+01, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:07:11,298:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=6.161e+00, with an active set of 24 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:07:11,298:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=6.097e+00, with an active set of 25 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:07:11,298:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:732: RuntimeWarning: overflow encountered in divide
  g1 = arrayfuncs.min_pos((C - Cov) / (AA - corr_eq_dir + tiny32))

2023-06-05 23:07:11,298:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:732: RuntimeWarning: overflow encountered in divide
  g1 = arrayfuncs.min_pos((C - Cov) / (AA - corr_eq_dir + tiny32))

2023-06-05 23:07:11,298:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=1.843e+01, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:07:11,298:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=1.513e+01, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:07:11,298:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 27 iterations, i.e. alpha=6.078e+00, with an active set of 27 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:07:11,298:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 48 iterations, i.e. alpha=4.082e+00, with an active set of 45 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:07:11,298:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=9.745e+00, with an active set of 16 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:07:11,298:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=8.894e+00, with an active set of 17 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:07:11,298:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 34 iterations, i.e. alpha=4.844e+00, with an active set of 33 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:07:11,298:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=7.859e+00, with an active set of 20 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:07:11,298:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-06-05 23:07:11,314:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=4.230e+00, with an active set of 40 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:07:11,314:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-06-05 23:07:11,314:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 45 iterations, i.e. alpha=4.070e+00, with an active set of 43 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:07:11,316:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-06-05 23:07:11,316:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 50 iterations, i.e. alpha=3.811e+00, with an active set of 49 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:07:11,316:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=1.874e+01, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:07:11,316:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 52 iterations, i.e. alpha=3.694e+00, with an active set of 51 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:07:11,316:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:732: RuntimeWarning: overflow encountered in divide
  g1 = arrayfuncs.min_pos((C - Cov) / (AA - corr_eq_dir + tiny32))

2023-06-05 23:07:11,316:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=2.417e+01, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:07:11,316:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 55 iterations, i.e. alpha=3.570e+00, with an active set of 53 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:07:11,316:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=1.655e+01, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:07:11,316:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=1.005e+01, with an active set of 16 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:07:11,316:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 61 iterations, i.e. alpha=2.925e+00, with an active set of 60 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:07:11,316:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=1.209e+01, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:07:11,316:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 63 iterations, i.e. alpha=2.943e+00, with an active set of 61 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:07:11,316:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:741: RuntimeWarning: overflow encountered in divide
  z = -coef[active] / (least_squares + tiny32)

2023-06-05 23:07:11,316:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=7.426e+00, with an active set of 23 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:07:11,316:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=6.933e+00, with an active set of 20 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:07:11,316:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 78 iterations, i.e. alpha=2.411e+00, with an active set of 75 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:07:11,316:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 27 iterations, i.e. alpha=5.755e+00, with an active set of 27 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:07:11,316:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=8.139e+00, with an active set of 18 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:07:11,316:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 70 iterations, i.e. alpha=3.115e+00, with an active set of 65 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:07:11,316:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 71 iterations, i.e. alpha=3.103e+00, with an active set of 66 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:07:11,316:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 35 iterations, i.e. alpha=5.792e+00, with an active set of 31 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:07:11,316:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 73 iterations, i.e. alpha=3.037e+00, with an active set of 68 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:07:11,316:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 81 iterations, i.e. alpha=2.722e+00, with an active set of 75 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:07:11,316:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 45 iterations, i.e. alpha=3.298e+00, with an active set of 45 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:07:11,316:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 101 iterations, i.e. alpha=2.216e+00, with an active set of 93 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:07:11,316:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 50 iterations, i.e. alpha=4.428e+00, with an active set of 45 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:07:11,330:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=1.346e+01, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:07:11,330:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:732: RuntimeWarning: overflow encountered in divide
  g1 = arrayfuncs.min_pos((C - Cov) / (AA - corr_eq_dir + tiny32))

2023-06-05 23:07:11,330:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 99 iterations, i.e. alpha=2.683e+02, with an active set of 78 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:07:11,330:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:732: RuntimeWarning: overflow encountered in divide
  g1 = arrayfuncs.min_pos((C - Cov) / (AA - corr_eq_dir + tiny32))

2023-06-05 23:07:11,330:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 97 iterations, i.e. alpha=2.127e+00, with an active set of 89 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:07:11,330:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=6.475e+00, with an active set of 21 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:07:11,330:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:736: RuntimeWarning: overflow encountered in divide
  g2 = arrayfuncs.min_pos((C + Cov) / (AA + corr_eq_dir + tiny32))

2023-06-05 23:07:11,330:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=6.270e+00, with an active set of 23 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:07:11,330:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=6.730e+00, with an active set of 23 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:07:11,330:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=6.576e+00, with an active set of 23 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:07:11,330:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 44 iterations, i.e. alpha=3.967e+00, with an active set of 43 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:07:11,330:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 55 iterations, i.e. alpha=2.878e+00, with an active set of 55 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:07:11,330:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=6.362e+00, with an active set of 24 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:07:11,330:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 44 iterations, i.e. alpha=3.603e+00, with an active set of 44 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:07:11,330:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 63 iterations, i.e. alpha=2.469e+00, with an active set of 63 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:07:11,330:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 65 iterations, i.e. alpha=2.435e+00, with an active set of 65 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:07:11,330:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 48 iterations, i.e. alpha=3.241e+00, with an active set of 48 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:07:11,330:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:732: RuntimeWarning: overflow encountered in divide
  g1 = arrayfuncs.min_pos((C - Cov) / (AA - corr_eq_dir + tiny32))

2023-06-05 23:07:11,330:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:736: RuntimeWarning: overflow encountered in divide
  g2 = arrayfuncs.min_pos((C + Cov) / (AA + corr_eq_dir + tiny32))

2023-06-05 23:07:11,330:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 67 iterations, i.e. alpha=2.417e+00, with an active set of 67 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:07:11,330:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 70 iterations, i.e. alpha=2.607e+00, with an active set of 68 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:07:11,330:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-06-05 23:07:11,346:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 83 iterations, i.e. alpha=1.926e+00, with an active set of 79 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:07:11,346:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 90 iterations, i.e. alpha=1.695e+00, with an active set of 86 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:07:11,346:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 57 iterations, i.e. alpha=3.336e+00, with an active set of 54 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:07:11,346:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 180 iterations, i.e. alpha=7.884e+03, with an active set of 144 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:07:11,346:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 94 iterations, i.e. alpha=1.611e+00, with an active set of 89 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(


2023-06-05 23:07:11,346:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 58 iterations, i.e. alpha=3.219e+00, with an active set of 55 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:07:11,346:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 79 iterations, i.e. alpha=3.028e+00, with an active set of 74 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:07:11,346:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 79 iterations, i.e. alpha=3.026e+00, with an active set of 74 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:07:11,346:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 101 iterations, i.e. alpha=1.481e+00, with an active set of 94 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:07:11,346:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 64 iterations, i.e. alpha=3.097e+00, with an active set of 59 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(


2023-06-05 23:07:11,346:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 102 iterations, i.e. alpha=1.444e+00, with an active set of 95 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:07:11,346:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=1.570e+01, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:07:11,346:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:741: RuntimeWarning: overflow encountered in divide
  z = -coef[active] / (least_squares + tiny32)

2023-06-05 23:07:11,346:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-06-05 23:07:11,346:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 109 iterations, i.e. alpha=2.367e+00, with an active set of 99 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:07:11,346:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 109 iterations, i.e. alpha=2.267e+00, with an active set of 99 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:07:11,346:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 75 iterations, i.e. alpha=2.881e+00, with an active set of 68 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:07:11,346:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=8.286e+00, with an active set of 21 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:07:11,346:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 109 iterations, i.e. alpha=2.260e+00, with an active set of 99 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:07:11,346:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 110 iterations, i.e. alpha=2.194e+00, with an active set of 100 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:07:11,346:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 110 iterations, i.e. alpha=2.154e+00, with an active set of 100 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:07:11,346:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 79 iterations, i.e. alpha=2.763e+00, with an active set of 72 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:07:11,346:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 29 iterations, i.e. alpha=6.550e+00, with an active set of 28 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:07:11,346:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 30 iterations, i.e. alpha=6.385e+00, with an active set of 29 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:07:11,346:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 31 iterations, i.e. alpha=6.166e+00, with an active set of 30 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:07:11,346:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 86 iterations, i.e. alpha=2.640e+00, with an active set of 78 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:07:11,346:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 122 iterations, i.e. alpha=2.617e+00, with an active set of 106 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:07:11,346:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=3.020e+01, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:07:11,346:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 218 iterations, i.e. alpha=4.695e+03, with an active set of 162 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:07:11,362:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=1.506e+01, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(


2023-06-05 23:07:11,363:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:732: RuntimeWarning: overflow encountered in divide
  g1 = arrayfuncs.min_pos((C - Cov) / (AA - corr_eq_dir + tiny32))

2023-06-05 23:07:11,364:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=9.367e+00, with an active set of 18 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:07:11,364:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 102 iterations, i.e. alpha=2.337e+00, with an active set of 92 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:07:11,366:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=7.452e+00, with an active set of 20 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:07:11,370:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 265 iterations, i.e. alpha=6.479e+04, with an active set of 194 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:07:11,370:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 37 iterations, i.e. alpha=4.818e+00, with an active set of 36 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:07:11,370:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 265 iterations, i.e. alpha=6.469e+04, with an active set of 194 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:07:11,370:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 37 iterations, i.e. alpha=4.813e+00, with an active set of 36 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:07:11,371:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 268 iterations, i.e. alpha=4.444e+04, with an active set of 197 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:07:11,372:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 269 iterations, i.e. alpha=2.260e+04, with an active set of 198 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:07:11,372:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 270 iterations, i.e. alpha=7.142e+03, with an active set of 199 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:07:11,373:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 270 iterations, i.e. alpha=1.964e+02, with an active set of 199 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:07:11,373:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 184 iterations, i.e. alpha=3.470e+03, with an active set of 139 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:07:11,374:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 49 iterations, i.e. alpha=3.714e+00, with an active set of 48 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:07:11,375:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 96 iterations, i.e. alpha=2.661e+03, with an active set of 73 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:07:11,375:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:773: RuntimeWarning: overflow encountered in add
  coef[active] = prev_coef[active] + gamma_ * least_squares

2023-06-05 23:07:11,376:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:773: RuntimeWarning: overflow encountered in multiply
  coef[active] = prev_coef[active] + gamma_ * least_squares

2023-06-05 23:07:11,377:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 139 iterations, i.e. alpha=6.009e+00, with an active set of 117 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:07:11,378:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:741: RuntimeWarning: overflow encountered in divide
  z = -coef[active] / (least_squares + tiny32)

2023-06-05 23:07:11,378:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 66 iterations, i.e. alpha=2.761e+00, with an active set of 62 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:07:11,380:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:773: RuntimeWarning: invalid value encountered in add
  coef[active] = prev_coef[active] + gamma_ * least_squares

2023-06-05 23:07:11,380:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 70 iterations, i.e. alpha=2.612e+00, with an active set of 66 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:07:11,384:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 216 iterations, i.e. alpha=6.197e+04, with an active set of 159 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:07:11,385:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 126 iterations, i.e. alpha=2.573e+03, with an active set of 103 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:07:11,385:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 85 iterations, i.e. alpha=2.675e+00, with an active set of 75 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:07:11,389:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 101 iterations, i.e. alpha=2.590e+00, with an active set of 88 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:07:11,391:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 145 iterations, i.e. alpha=2.529e+03, with an active set of 120 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:07:11,391:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 111 iterations, i.e. alpha=2.420e+00, with an active set of 97 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:07:11,391:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 118 iterations, i.e. alpha=2.289e+00, with an active set of 103 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:07:11,398:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 272 iterations, i.e. alpha=6.535e+06, with an active set of 196 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:07:11,398:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 274 iterations, i.e. alpha=1.631e+06, with an active set of 198 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:07:11,398:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 276 iterations, i.e. alpha=1.435e+06, with an active set of 200 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:07:11,398:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:732: RuntimeWarning: overflow encountered in subtract
  g1 = arrayfuncs.min_pos((C - Cov) / (AA - corr_eq_dir + tiny32))

2023-06-05 23:07:11,398:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:736: RuntimeWarning: overflow encountered in add
  g2 = arrayfuncs.min_pos((C + Cov) / (AA + corr_eq_dir + tiny32))

2023-06-05 23:07:11,428:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:776: RuntimeWarning: overflow encountered in multiply
  Cov -= gamma_ * corr_eq_dir

2023-06-05 23:07:11,428:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 239 iterations, i.e. alpha=5.432e+06, with an active set of 184 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:07:11,428:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:776: RuntimeWarning: overflow encountered in subtract
  Cov -= gamma_ * corr_eq_dir

2023-06-05 23:07:11,430:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:732: RuntimeWarning: invalid value encountered in subtract
  g1 = arrayfuncs.min_pos((C - Cov) / (AA - corr_eq_dir + tiny32))

2023-06-05 23:07:11,430:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 241 iterations, i.e. alpha=5.008e+06, with an active set of 185 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:07:11,430:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:736: RuntimeWarning: invalid value encountered in add
  g2 = arrayfuncs.min_pos((C + Cov) / (AA + corr_eq_dir + tiny32))

2023-06-05 23:07:11,430:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 243 iterations, i.e. alpha=4.947e+06, with an active set of 187 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:07:11,430:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 247 iterations, i.e. alpha=4.793e+06, with an active set of 191 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:07:11,430:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 248 iterations, i.e. alpha=4.754e+06, with an active set of 192 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:07:11,430:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 252 iterations, i.e. alpha=6.003e+06, with an active set of 196 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:07:11,430:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 252 iterations, i.e. alpha=3.277e+06, with an active set of 196 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:07:11,430:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 253 iterations, i.e. alpha=2.137e+06, with an active set of 197 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:07:11,430:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 253 iterations, i.e. alpha=9.225e+05, with an active set of 197 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:07:11,445:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 249 iterations, i.e. alpha=1.130e+04, with an active set of 188 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:07:11,650:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\extmath.py:152: RuntimeWarning: invalid value encountered in matmul
  ret = a @ b

2023-06-05 23:07:11,690:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 267, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_regression.py", line 196, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\validation.py", line 899, in check_array
    _assert_all_finite(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\validation.py", line 146, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-06-05 23:07:11,690:INFO:Calculating mean and std
2023-06-05 23:07:11,690:INFO:Creating metrics dataframe
2023-06-05 23:07:11,696:INFO:Uploading results into container
2023-06-05 23:07:11,696:INFO:Uploading model into container now
2023-06-05 23:07:11,696:INFO:_master_model_container: 5
2023-06-05 23:07:11,696:INFO:_display_container: 2
2023-06-05 23:07:11,696:INFO:Lars(random_state=123)
2023-06-05 23:07:11,696:INFO:create_model() successfully completed......................................
2023-06-05 23:07:11,798:INFO:SubProcess create_model() end ==================================
2023-06-05 23:07:11,798:INFO:Creating metrics dataframe
2023-06-05 23:07:11,798:INFO:Initializing Lasso Least Angle Regression
2023-06-05 23:07:11,798:INFO:Total runtime is 0.1701378067334493 minutes
2023-06-05 23:07:11,815:INFO:SubProcess create_model() called ==================================
2023-06-05 23:07:11,815:INFO:Initializing create_model()
2023-06-05 23:07:11,817:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020E25C03C70>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020E295358A0>, model_only=True, return_train_score=False, kwargs={})
2023-06-05 23:07:11,817:INFO:Checking exceptions
2023-06-05 23:07:11,817:INFO:Importing libraries
2023-06-05 23:07:11,817:INFO:Copying training dataset
2023-06-05 23:07:11,823:INFO:Defining folds
2023-06-05 23:07:11,823:INFO:Declaring metric variables
2023-06-05 23:07:11,828:INFO:Importing untrained model
2023-06-05 23:07:11,831:INFO:Lasso Least Angle Regression Imported successfully
2023-06-05 23:07:11,838:INFO:Starting cross validation
2023-06-05 23:07:11,844:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-05 23:07:11,936:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-06-05 23:07:11,951:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=1.346e+01, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:07:11,951:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:732: RuntimeWarning: overflow encountered in divide
  g1 = arrayfuncs.min_pos((C - Cov) / (AA - corr_eq_dir + tiny32))

2023-06-05 23:07:11,951:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=6.730e+00, with an active set of 23 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:07:11,951:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:679: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 27 iterations, alpha=6.117e+00, previous alpha=6.116e+00, with an active set of 28 regressors.
  warnings.warn(

2023-06-05 23:07:11,951:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-06-05 23:07:11,967:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-06-05 23:07:11,967:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 44 iterations, i.e. alpha=4.414e+00, with an active set of 36 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:07:11,967:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:732: RuntimeWarning: overflow encountered in divide
  g1 = arrayfuncs.min_pos((C - Cov) / (AA - corr_eq_dir + tiny32))

2023-06-05 23:07:11,967:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-06-05 23:07:11,967:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=6.475e+00, with an active set of 21 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:07:11,967:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:736: RuntimeWarning: overflow encountered in divide
  g2 = arrayfuncs.min_pos((C + Cov) / (AA + corr_eq_dir + tiny32))

2023-06-05 23:07:11,967:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=6.270e+00, with an active set of 23 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:07:11,983:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-06-05 23:07:11,983:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:741: RuntimeWarning: overflow encountered in divide
  z = -coef[active] / (least_squares + tiny32)

2023-06-05 23:07:11,983:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=1.850e+01, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:07:11,983:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=9.988e+00, with an active set of 17 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:07:11,983:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=3.014e+01, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:07:11,983:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=9.248e+00, with an active set of 18 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:07:11,983:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:732: RuntimeWarning: overflow encountered in divide
  g1 = arrayfuncs.min_pos((C - Cov) / (AA - corr_eq_dir + tiny32))

2023-06-05 23:07:11,983:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:679: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 86 iterations, alpha=2.465e+00, previous alpha=2.412e+00, with an active set of 69 regressors.
  warnings.warn(

2023-06-05 23:07:11,983:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=1.843e+01, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(


2023-06-05 23:07:11,983:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=6.097e+00, with an active set of 25 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:07:11,983:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:732: RuntimeWarning: overflow encountered in divide
  g1 = arrayfuncs.min_pos((C - Cov) / (AA - corr_eq_dir + tiny32))

2023-06-05 23:07:11,983:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=1.513e+01, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:07:11,983:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 27 iterations, i.e. alpha=6.078e+00, with an active set of 27 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:07:11,983:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 62 iterations, i.e. alpha=2.647e+00, with an active set of 60 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:07:11,983:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=9.745e+00, with an active set of 16 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:07:11,983:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=8.894e+00, with an active set of 17 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:07:11,983:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=7.859e+00, with an active set of 20 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:07:11,983:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:679: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 38 iterations, alpha=4.580e+00, previous alpha=4.415e+00, with an active set of 35 regressors.
  warnings.warn(

2023-06-05 23:07:11,998:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:679: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 86 iterations, alpha=1.770e+00, previous alpha=1.692e+00, with an active set of 83 regressors.
  warnings.warn(

2023-06-05 23:07:11,998:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 43 iterations, i.e. alpha=5.133e+00, with an active set of 41 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:07:11,998:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 57 iterations, i.e. alpha=3.672e+00, with an active set of 55 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:07:11,998:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:679: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 58 iterations, alpha=4.373e+00, previous alpha=3.606e+00, with an active set of 55 regressors.
  warnings.warn(

2023-06-05 23:07:12,014:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-06-05 23:07:12,014:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=2.417e+01, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:07:12,017:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=1.655e+01, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:07:12,017:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=1.209e+01, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:07:12,017:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=8.139e+00, with an active set of 18 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:07:12,017:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=6.576e+00, with an active set of 23 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:07:12,017:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=6.362e+00, with an active set of 24 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:07:12,017:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:679: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 32 iterations, alpha=5.066e+00, previous alpha=4.981e+00, with an active set of 31 regressors.
  warnings.warn(

2023-06-05 23:07:12,017:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-06-05 23:07:12,017:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=3.020e+01, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:07:12,030:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=1.506e+01, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:07:12,030:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:732: RuntimeWarning: overflow encountered in divide
  g1 = arrayfuncs.min_pos((C - Cov) / (AA - corr_eq_dir + tiny32))

2023-06-05 23:07:12,030:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=9.367e+00, with an active set of 18 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:07:12,030:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=7.452e+00, with an active set of 20 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:07:12,030:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 36 iterations, i.e. alpha=4.816e+00, with an active set of 34 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:07:12,030:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 36 iterations, i.e. alpha=4.815e+00, with an active set of 34 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:07:12,030:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=4.289e+00, with an active set of 40 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:07:12,030:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 50 iterations, i.e. alpha=3.633e+00, with an active set of 48 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:07:12,030:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 54 iterations, i.e. alpha=3.125e+00, with an active set of 52 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:07:12,030:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-06-05 23:07:12,030:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 63 iterations, i.e. alpha=2.635e+00, with an active set of 61 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:07:12,047:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=1.570e+01, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:07:12,047:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 74 iterations, i.e. alpha=2.285e+00, with an active set of 72 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:07:12,049:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 75 iterations, i.e. alpha=2.214e+00, with an active set of 73 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:07:12,050:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:679: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 76 iterations, alpha=2.468e+00, previous alpha=2.214e+00, with an active set of 73 regressors.
  warnings.warn(

2023-06-05 23:07:12,051:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-06-05 23:07:12,051:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-06-05 23:07:12,051:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=7.852e+00, with an active set of 21 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:07:12,051:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 34 iterations, i.e. alpha=5.323e+00, with an active set of 32 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:07:12,051:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 36 iterations, i.e. alpha=5.108e+00, with an active set of 34 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:07:12,051:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=1.874e+01, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:07:12,051:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:732: RuntimeWarning: overflow encountered in divide
  g1 = arrayfuncs.min_pos((C - Cov) / (AA - corr_eq_dir + tiny32))

2023-06-05 23:07:12,051:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=6.933e+00, with an active set of 20 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:07:12,051:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=1.005e+01, with an active set of 16 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:07:12,051:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:679: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 22 iterations, alpha=7.870e+00, previous alpha=7.746e+00, with an active set of 21 regressors.
  warnings.warn(

2023-06-05 23:07:12,051:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:679: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 55 iterations, alpha=3.000e+00, previous alpha=2.983e+00, with an active set of 52 regressors.
  warnings.warn(

eters.
  warnings.warn(

2023-06-05 23:07:12,066:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 45 iterations, i.e. alpha=3.298e+00, with an active set of 45 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:07:12,067:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 55 iterations, i.e. alpha=2.878e+00, with an active set of 55 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:07:12,070:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 63 iterations, i.e. alpha=2.469e+00, with an active set of 63 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:07:12,070:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 65 iterations, i.e. alpha=2.435e+00, with an active set of 65 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:07:12,070:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:732: RuntimeWarning: overflow encountered in divide
  g1 = arrayfuncs.min_pos((C - Cov) / (AA - corr_eq_dir + tiny32))

2023-06-05 23:07:12,070:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:736: RuntimeWarning: overflow encountered in divide
  g2 = arrayfuncs.min_pos((C + Cov) / (AA + corr_eq_dir + tiny32))

2023-06-05 23:07:12,070:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 67 iterations, i.e. alpha=2.417e+00, with an active set of 67 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:07:12,076:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 84 iterations, i.e. alpha=1.752e+00, with an active set of 80 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:07:12,078:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 90 iterations, i.e. alpha=1.464e+00, with an active set of 86 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:07:12,079:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:679: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 92 iterations, alpha=1.450e+00, previous alpha=1.428e+00, with an active set of 87 regressors.
  warnings.warn(

2023-06-05 23:07:12,121:INFO:Calculating mean and std
2023-06-05 23:07:12,123:INFO:Creating metrics dataframe
2023-06-05 23:07:12,132:INFO:Uploading results into container
2023-06-05 23:07:12,132:INFO:Uploading model into container now
2023-06-05 23:07:12,132:INFO:_master_model_container: 6
2023-06-05 23:07:12,132:INFO:_display_container: 2
2023-06-05 23:07:12,132:INFO:LassoLars(random_state=123)
2023-06-05 23:07:12,132:INFO:create_model() successfully completed......................................
2023-06-05 23:07:12,221:INFO:SubProcess create_model() end ==================================
2023-06-05 23:07:12,221:INFO:Creating metrics dataframe
2023-06-05 23:07:12,236:INFO:Initializing Orthogonal Matching Pursuit
2023-06-05 23:07:12,236:INFO:Total runtime is 0.1774423917134603 minutes
2023-06-05 23:07:12,243:INFO:SubProcess create_model() called ==================================
2023-06-05 23:07:12,243:INFO:Initializing create_model()
2023-06-05 23:07:12,243:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020E25C03C70>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020E295358A0>, model_only=True, return_train_score=False, kwargs={})
2023-06-05 23:07:12,243:INFO:Checking exceptions
2023-06-05 23:07:12,243:INFO:Importing libraries
2023-06-05 23:07:12,243:INFO:Copying training dataset
2023-06-05 23:07:12,248:INFO:Defining folds
2023-06-05 23:07:12,248:INFO:Declaring metric variables
2023-06-05 23:07:12,257:INFO:Importing untrained model
2023-06-05 23:07:12,261:INFO:Orthogonal Matching Pursuit Imported successfully
2023-06-05 23:07:12,268:INFO:Starting cross validation
2023-06-05 23:07:12,275:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-05 23:07:12,388:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-06-05 23:07:12,403:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-06-05 23:07:12,403:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-06-05 23:07:12,418:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-06-05 23:07:12,419:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-06-05 23:07:12,435:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-06-05 23:07:12,450:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-06-05 23:07:12,472:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-06-05 23:07:12,479:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-06-05 23:07:12,498:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-06-05 23:07:12,554:INFO:Calculating mean and std
2023-06-05 23:07:12,556:INFO:Creating metrics dataframe
2023-06-05 23:07:12,565:INFO:Uploading results into container
2023-06-05 23:07:12,566:INFO:Uploading model into container now
2023-06-05 23:07:12,566:INFO:_master_model_container: 7
2023-06-05 23:07:12,566:INFO:_display_container: 2
2023-06-05 23:07:12,566:INFO:OrthogonalMatchingPursuit()
2023-06-05 23:07:12,566:INFO:create_model() successfully completed......................................
2023-06-05 23:07:12,674:INFO:SubProcess create_model() end ==================================
2023-06-05 23:07:12,674:INFO:Creating metrics dataframe
2023-06-05 23:07:12,677:INFO:Initializing Bayesian Ridge
2023-06-05 23:07:12,677:INFO:Total runtime is 0.18478212753931683 minutes
2023-06-05 23:07:12,685:INFO:SubProcess create_model() called ==================================
2023-06-05 23:07:12,686:INFO:Initializing create_model()
2023-06-05 23:07:12,686:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020E25C03C70>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020E295358A0>, model_only=True, return_train_score=False, kwargs={})
2023-06-05 23:07:12,686:INFO:Checking exceptions
2023-06-05 23:07:12,686:INFO:Importing libraries
2023-06-05 23:07:12,686:INFO:Copying training dataset
2023-06-05 23:07:12,692:INFO:Defining folds
2023-06-05 23:07:12,692:INFO:Declaring metric variables
2023-06-05 23:07:12,698:INFO:Importing untrained model
2023-06-05 23:07:12,698:INFO:Bayesian Ridge Imported successfully
2023-06-05 23:07:12,712:INFO:Starting cross validation
2023-06-05 23:07:12,712:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-05 23:07:12,960:INFO:Calculating mean and std
2023-06-05 23:07:12,960:INFO:Creating metrics dataframe
2023-06-05 23:07:12,969:INFO:Uploading results into container
2023-06-05 23:07:12,970:INFO:Uploading model into container now
2023-06-05 23:07:12,970:INFO:_master_model_container: 8
2023-06-05 23:07:12,970:INFO:_display_container: 2
2023-06-05 23:07:12,970:INFO:BayesianRidge()
2023-06-05 23:07:12,970:INFO:create_model() successfully completed......................................
2023-06-05 23:07:13,068:INFO:SubProcess create_model() end ==================================
2023-06-05 23:07:13,068:INFO:Creating metrics dataframe
2023-06-05 23:07:13,068:INFO:Initializing Passive Aggressive Regressor
2023-06-05 23:07:13,068:INFO:Total runtime is 0.19129777749379479 minutes
2023-06-05 23:07:13,084:INFO:SubProcess create_model() called ==================================
2023-06-05 23:07:13,084:INFO:Initializing create_model()
2023-06-05 23:07:13,084:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020E25C03C70>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020E295358A0>, model_only=True, return_train_score=False, kwargs={})
2023-06-05 23:07:13,084:INFO:Checking exceptions
2023-06-05 23:07:13,085:INFO:Importing libraries
2023-06-05 23:07:13,085:INFO:Copying training dataset
2023-06-05 23:07:13,093:INFO:Defining folds
2023-06-05 23:07:13,093:INFO:Declaring metric variables
2023-06-05 23:07:13,099:INFO:Importing untrained model
2023-06-05 23:07:13,102:INFO:Passive Aggressive Regressor Imported successfully
2023-06-05 23:07:13,115:INFO:Starting cross validation
2023-06-05 23:07:13,115:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-05 23:07:13,360:INFO:Calculating mean and std
2023-06-05 23:07:13,360:INFO:Creating metrics dataframe
2023-06-05 23:07:13,377:INFO:Uploading results into container
2023-06-05 23:07:13,377:INFO:Uploading model into container now
2023-06-05 23:07:13,377:INFO:_master_model_container: 9
2023-06-05 23:07:13,377:INFO:_display_container: 2
2023-06-05 23:07:13,377:INFO:PassiveAggressiveRegressor(random_state=123)
2023-06-05 23:07:13,377:INFO:create_model() successfully completed......................................
2023-06-05 23:07:13,467:INFO:SubProcess create_model() end ==================================
2023-06-05 23:07:13,467:INFO:Creating metrics dataframe
2023-06-05 23:07:13,482:INFO:Initializing Huber Regressor
2023-06-05 23:07:13,482:INFO:Total runtime is 0.19820386171340945 minutes
2023-06-05 23:07:13,482:INFO:SubProcess create_model() called ==================================
2023-06-05 23:07:13,482:INFO:Initializing create_model()
2023-06-05 23:07:13,482:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020E25C03C70>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020E295358A0>, model_only=True, return_train_score=False, kwargs={})
2023-06-05 23:07:13,482:INFO:Checking exceptions
2023-06-05 23:07:13,482:INFO:Importing libraries
2023-06-05 23:07:13,482:INFO:Copying training dataset
2023-06-05 23:07:13,496:INFO:Defining folds
2023-06-05 23:07:13,496:INFO:Declaring metric variables
2023-06-05 23:07:13,496:INFO:Importing untrained model
2023-06-05 23:07:13,496:INFO:Huber Regressor Imported successfully
2023-06-05 23:07:13,518:INFO:Starting cross validation
2023-06-05 23:07:13,520:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-05 23:07:13,951:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-05 23:07:13,967:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-05 23:07:13,982:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-05 23:07:13,998:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-05 23:07:13,998:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-05 23:07:13,998:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-05 23:07:13,998:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-05 23:07:13,998:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-05 23:07:13,998:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-05 23:07:14,029:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-05 23:07:14,274:INFO:Calculating mean and std
2023-06-05 23:07:14,274:INFO:Creating metrics dataframe
2023-06-05 23:07:14,289:INFO:Uploading results into container
2023-06-05 23:07:14,290:INFO:Uploading model into container now
2023-06-05 23:07:14,290:INFO:_master_model_container: 10
2023-06-05 23:07:14,290:INFO:_display_container: 2
2023-06-05 23:07:14,290:INFO:HuberRegressor()
2023-06-05 23:07:14,290:INFO:create_model() successfully completed......................................
2023-06-05 23:07:14,375:INFO:SubProcess create_model() end ==================================
2023-06-05 23:07:14,375:INFO:Creating metrics dataframe
2023-06-05 23:07:14,391:INFO:Initializing K Neighbors Regressor
2023-06-05 23:07:14,391:INFO:Total runtime is 0.21335082848866782 minutes
2023-06-05 23:07:14,402:INFO:SubProcess create_model() called ==================================
2023-06-05 23:07:14,402:INFO:Initializing create_model()
2023-06-05 23:07:14,402:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020E25C03C70>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020E295358A0>, model_only=True, return_train_score=False, kwargs={})
2023-06-05 23:07:14,402:INFO:Checking exceptions
2023-06-05 23:07:14,402:INFO:Importing libraries
2023-06-05 23:07:14,403:INFO:Copying training dataset
2023-06-05 23:07:14,405:INFO:Defining folds
2023-06-05 23:07:14,405:INFO:Declaring metric variables
2023-06-05 23:07:14,405:INFO:Importing untrained model
2023-06-05 23:07:14,405:INFO:K Neighbors Regressor Imported successfully
2023-06-05 23:07:14,422:INFO:Starting cross validation
2023-06-05 23:07:14,422:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-05 23:07:14,737:INFO:Calculating mean and std
2023-06-05 23:07:14,738:INFO:Creating metrics dataframe
2023-06-05 23:07:14,751:INFO:Uploading results into container
2023-06-05 23:07:14,752:INFO:Uploading model into container now
2023-06-05 23:07:14,752:INFO:_master_model_container: 11
2023-06-05 23:07:14,752:INFO:_display_container: 2
2023-06-05 23:07:14,752:INFO:KNeighborsRegressor(n_jobs=-1)
2023-06-05 23:07:14,752:INFO:create_model() successfully completed......................................
2023-06-05 23:07:14,853:INFO:SubProcess create_model() end ==================================
2023-06-05 23:07:14,853:INFO:Creating metrics dataframe
2023-06-05 23:07:14,862:INFO:Initializing Decision Tree Regressor
2023-06-05 23:07:14,863:INFO:Total runtime is 0.22122705380121868 minutes
2023-06-05 23:07:14,865:INFO:SubProcess create_model() called ==================================
2023-06-05 23:07:14,866:INFO:Initializing create_model()
2023-06-05 23:07:14,866:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020E25C03C70>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020E295358A0>, model_only=True, return_train_score=False, kwargs={})
2023-06-05 23:07:14,866:INFO:Checking exceptions
2023-06-05 23:07:14,866:INFO:Importing libraries
2023-06-05 23:07:14,866:INFO:Copying training dataset
2023-06-05 23:07:14,872:INFO:Defining folds
2023-06-05 23:07:14,872:INFO:Declaring metric variables
2023-06-05 23:07:14,879:INFO:Importing untrained model
2023-06-05 23:07:14,884:INFO:Decision Tree Regressor Imported successfully
2023-06-05 23:07:14,890:INFO:Starting cross validation
2023-06-05 23:07:14,890:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-05 23:07:15,163:INFO:Calculating mean and std
2023-06-05 23:07:15,163:INFO:Creating metrics dataframe
2023-06-05 23:07:15,183:INFO:Uploading results into container
2023-06-05 23:07:15,183:INFO:Uploading model into container now
2023-06-05 23:07:15,183:INFO:_master_model_container: 12
2023-06-05 23:07:15,183:INFO:_display_container: 2
2023-06-05 23:07:15,183:INFO:DecisionTreeRegressor(random_state=123)
2023-06-05 23:07:15,183:INFO:create_model() successfully completed......................................
2023-06-05 23:07:15,295:INFO:SubProcess create_model() end ==================================
2023-06-05 23:07:15,295:INFO:Creating metrics dataframe
2023-06-05 23:07:15,295:INFO:Initializing Random Forest Regressor
2023-06-05 23:07:15,295:INFO:Total runtime is 0.2284172296524048 minutes
2023-06-05 23:07:15,310:INFO:SubProcess create_model() called ==================================
2023-06-05 23:07:15,310:INFO:Initializing create_model()
2023-06-05 23:07:15,310:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020E25C03C70>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020E295358A0>, model_only=True, return_train_score=False, kwargs={})
2023-06-05 23:07:15,311:INFO:Checking exceptions
2023-06-05 23:07:15,311:INFO:Importing libraries
2023-06-05 23:07:15,311:INFO:Copying training dataset
2023-06-05 23:07:15,325:INFO:Defining folds
2023-06-05 23:07:15,325:INFO:Declaring metric variables
2023-06-05 23:07:15,331:INFO:Importing untrained model
2023-06-05 23:07:15,337:INFO:Random Forest Regressor Imported successfully
2023-06-05 23:07:15,344:INFO:Starting cross validation
2023-06-05 23:07:15,345:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-05 23:07:16,648:INFO:Calculating mean and std
2023-06-05 23:07:16,648:INFO:Creating metrics dataframe
2023-06-05 23:07:16,666:INFO:Uploading results into container
2023-06-05 23:07:16,666:INFO:Uploading model into container now
2023-06-05 23:07:16,666:INFO:_master_model_container: 13
2023-06-05 23:07:16,666:INFO:_display_container: 2
2023-06-05 23:07:16,666:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2023-06-05 23:07:16,666:INFO:create_model() successfully completed......................................
2023-06-05 23:07:16,760:INFO:SubProcess create_model() end ==================================
2023-06-05 23:07:16,760:INFO:Creating metrics dataframe
2023-06-05 23:07:16,774:INFO:Initializing Extra Trees Regressor
2023-06-05 23:07:16,774:INFO:Total runtime is 0.25307732820510864 minutes
2023-06-05 23:07:16,786:INFO:SubProcess create_model() called ==================================
2023-06-05 23:07:16,786:INFO:Initializing create_model()
2023-06-05 23:07:16,786:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020E25C03C70>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020E295358A0>, model_only=True, return_train_score=False, kwargs={})
2023-06-05 23:07:16,787:INFO:Checking exceptions
2023-06-05 23:07:16,787:INFO:Importing libraries
2023-06-05 23:07:16,787:INFO:Copying training dataset
2023-06-05 23:07:16,793:INFO:Defining folds
2023-06-05 23:07:16,793:INFO:Declaring metric variables
2023-06-05 23:07:16,798:INFO:Importing untrained model
2023-06-05 23:07:16,798:INFO:Extra Trees Regressor Imported successfully
2023-06-05 23:07:16,808:INFO:Starting cross validation
2023-06-05 23:07:16,810:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-05 23:07:18,067:INFO:Calculating mean and std
2023-06-05 23:07:18,067:INFO:Creating metrics dataframe
2023-06-05 23:07:18,097:INFO:Uploading results into container
2023-06-05 23:07:18,097:INFO:Uploading model into container now
2023-06-05 23:07:18,097:INFO:_master_model_container: 14
2023-06-05 23:07:18,097:INFO:_display_container: 2
2023-06-05 23:07:18,097:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-06-05 23:07:18,097:INFO:create_model() successfully completed......................................
2023-06-05 23:07:18,194:INFO:SubProcess create_model() end ==================================
2023-06-05 23:07:18,194:INFO:Creating metrics dataframe
2023-06-05 23:07:18,194:INFO:Initializing AdaBoost Regressor
2023-06-05 23:07:18,194:INFO:Total runtime is 0.2767340938250224 minutes
2023-06-05 23:07:18,212:INFO:SubProcess create_model() called ==================================
2023-06-05 23:07:18,213:INFO:Initializing create_model()
2023-06-05 23:07:18,213:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020E25C03C70>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020E295358A0>, model_only=True, return_train_score=False, kwargs={})
2023-06-05 23:07:18,213:INFO:Checking exceptions
2023-06-05 23:07:18,213:INFO:Importing libraries
2023-06-05 23:07:18,213:INFO:Copying training dataset
2023-06-05 23:07:18,221:INFO:Defining folds
2023-06-05 23:07:18,222:INFO:Declaring metric variables
2023-06-05 23:07:18,227:INFO:Importing untrained model
2023-06-05 23:07:18,234:INFO:AdaBoost Regressor Imported successfully
2023-06-05 23:07:18,247:INFO:Starting cross validation
2023-06-05 23:07:18,249:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-05 23:07:18,925:INFO:Calculating mean and std
2023-06-05 23:07:18,925:INFO:Creating metrics dataframe
2023-06-05 23:07:18,956:INFO:Uploading results into container
2023-06-05 23:07:18,956:INFO:Uploading model into container now
2023-06-05 23:07:18,956:INFO:_master_model_container: 15
2023-06-05 23:07:18,956:INFO:_display_container: 2
2023-06-05 23:07:18,956:INFO:AdaBoostRegressor(random_state=123)
2023-06-05 23:07:18,956:INFO:create_model() successfully completed......................................
2023-06-05 23:07:19,049:INFO:SubProcess create_model() end ==================================
2023-06-05 23:07:19,049:INFO:Creating metrics dataframe
2023-06-05 23:07:19,064:INFO:Initializing Gradient Boosting Regressor
2023-06-05 23:07:19,064:INFO:Total runtime is 0.291241721312205 minutes
2023-06-05 23:07:19,080:INFO:SubProcess create_model() called ==================================
2023-06-05 23:07:19,080:INFO:Initializing create_model()
2023-06-05 23:07:19,080:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020E25C03C70>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020E295358A0>, model_only=True, return_train_score=False, kwargs={})
2023-06-05 23:07:19,080:INFO:Checking exceptions
2023-06-05 23:07:19,080:INFO:Importing libraries
2023-06-05 23:07:19,080:INFO:Copying training dataset
2023-06-05 23:07:19,080:INFO:Defining folds
2023-06-05 23:07:19,080:INFO:Declaring metric variables
2023-06-05 23:07:19,100:INFO:Importing untrained model
2023-06-05 23:07:19,105:INFO:Gradient Boosting Regressor Imported successfully
2023-06-05 23:07:19,115:INFO:Starting cross validation
2023-06-05 23:07:19,117:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-05 23:07:20,068:INFO:Calculating mean and std
2023-06-05 23:07:20,068:INFO:Creating metrics dataframe
2023-06-05 23:07:20,107:INFO:Uploading results into container
2023-06-05 23:07:20,107:INFO:Uploading model into container now
2023-06-05 23:07:20,107:INFO:_master_model_container: 16
2023-06-05 23:07:20,107:INFO:_display_container: 2
2023-06-05 23:07:20,107:INFO:GradientBoostingRegressor(random_state=123)
2023-06-05 23:07:20,107:INFO:create_model() successfully completed......................................
2023-06-05 23:07:20,201:INFO:SubProcess create_model() end ==================================
2023-06-05 23:07:20,201:INFO:Creating metrics dataframe
2023-06-05 23:07:20,216:INFO:Initializing Light Gradient Boosting Machine
2023-06-05 23:07:20,216:INFO:Total runtime is 0.3104424118995667 minutes
2023-06-05 23:07:20,216:INFO:SubProcess create_model() called ==================================
2023-06-05 23:07:20,216:INFO:Initializing create_model()
2023-06-05 23:07:20,216:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020E25C03C70>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020E295358A0>, model_only=True, return_train_score=False, kwargs={})
2023-06-05 23:07:20,216:INFO:Checking exceptions
2023-06-05 23:07:20,216:INFO:Importing libraries
2023-06-05 23:07:20,216:INFO:Copying training dataset
2023-06-05 23:07:20,231:INFO:Defining folds
2023-06-05 23:07:20,231:INFO:Declaring metric variables
2023-06-05 23:07:20,233:INFO:Importing untrained model
2023-06-05 23:07:20,233:INFO:Light Gradient Boosting Machine Imported successfully
2023-06-05 23:07:20,246:INFO:Starting cross validation
2023-06-05 23:07:20,252:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-05 23:07:20,757:INFO:Calculating mean and std
2023-06-05 23:07:20,757:INFO:Creating metrics dataframe
2023-06-05 23:07:20,798:INFO:Uploading results into container
2023-06-05 23:07:20,798:INFO:Uploading model into container now
2023-06-05 23:07:20,798:INFO:_master_model_container: 17
2023-06-05 23:07:20,798:INFO:_display_container: 2
2023-06-05 23:07:20,799:INFO:LGBMRegressor(random_state=123)
2023-06-05 23:07:20,799:INFO:create_model() successfully completed......................................
2023-06-05 23:07:20,895:INFO:SubProcess create_model() end ==================================
2023-06-05 23:07:20,895:INFO:Creating metrics dataframe
2023-06-05 23:07:20,895:INFO:Initializing Dummy Regressor
2023-06-05 23:07:20,895:INFO:Total runtime is 0.32175491253534955 minutes
2023-06-05 23:07:20,912:INFO:SubProcess create_model() called ==================================
2023-06-05 23:07:20,912:INFO:Initializing create_model()
2023-06-05 23:07:20,912:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020E25C03C70>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020E295358A0>, model_only=True, return_train_score=False, kwargs={})
2023-06-05 23:07:20,912:INFO:Checking exceptions
2023-06-05 23:07:20,912:INFO:Importing libraries
2023-06-05 23:07:20,912:INFO:Copying training dataset
2023-06-05 23:07:20,932:INFO:Defining folds
2023-06-05 23:07:20,932:INFO:Declaring metric variables
2023-06-05 23:07:20,932:INFO:Importing untrained model
2023-06-05 23:07:20,940:INFO:Dummy Regressor Imported successfully
2023-06-05 23:07:20,947:INFO:Starting cross validation
2023-06-05 23:07:20,949:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-05 23:07:21,356:INFO:Calculating mean and std
2023-06-05 23:07:21,356:INFO:Creating metrics dataframe
2023-06-05 23:07:21,393:INFO:Uploading results into container
2023-06-05 23:07:21,393:INFO:Uploading model into container now
2023-06-05 23:07:21,394:INFO:_master_model_container: 18
2023-06-05 23:07:21,394:INFO:_display_container: 2
2023-06-05 23:07:21,394:INFO:DummyRegressor()
2023-06-05 23:07:21,394:INFO:create_model() successfully completed......................................
2023-06-05 23:07:21,476:INFO:SubProcess create_model() end ==================================
2023-06-05 23:07:21,491:INFO:Creating metrics dataframe
2023-06-05 23:07:21,516:INFO:Initializing create_model()
2023-06-05 23:07:21,516:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020E25C03C70>, estimator=GradientBoostingRegressor(random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-05 23:07:21,516:INFO:Checking exceptions
2023-06-05 23:07:21,521:INFO:Importing libraries
2023-06-05 23:07:21,521:INFO:Copying training dataset
2023-06-05 23:07:21,525:INFO:Defining folds
2023-06-05 23:07:21,527:INFO:Declaring metric variables
2023-06-05 23:07:21,527:INFO:Importing untrained model
2023-06-05 23:07:21,527:INFO:Declaring custom model
2023-06-05 23:07:21,527:INFO:Gradient Boosting Regressor Imported successfully
2023-06-05 23:07:21,529:INFO:Cross validation set to False
2023-06-05 23:07:21,529:INFO:Fitting Model
2023-06-05 23:07:21,907:INFO:GradientBoostingRegressor(random_state=123)
2023-06-05 23:07:21,907:INFO:create_model() successfully completed......................................
2023-06-05 23:07:22,017:INFO:Creating Dashboard logs
2023-06-05 23:07:22,028:INFO:Model: Gradient Boosting Regressor
2023-06-05 23:07:22,069:INFO:Logged params: {'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': None, 'random_state': 123, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2023-06-05 23:07:22,184:INFO:Initializing predict_model()
2023-06-05 23:07:22,184:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020E25C03C70>, estimator=GradientBoostingRegressor(random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x0000020E2A018310>)
2023-06-05 23:07:22,184:INFO:Checking exceptions
2023-06-05 23:07:22,184:INFO:Preloading libraries
2023-06-05 23:07:22,609:INFO:Creating Dashboard logs
2023-06-05 23:07:22,609:INFO:Model: Random Forest Regressor
2023-06-05 23:07:22,665:INFO:Logged params: {'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': 1.0, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 123, 'verbose': 0, 'warm_start': False}
2023-06-05 23:07:22,901:INFO:Creating Dashboard logs
2023-06-05 23:07:22,901:INFO:Model: Extra Trees Regressor
2023-06-05 23:07:22,959:INFO:Logged params: {'bootstrap': False, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': 1.0, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 123, 'verbose': 0, 'warm_start': False}
2023-06-05 23:07:23,218:INFO:Creating Dashboard logs
2023-06-05 23:07:23,221:INFO:Model: Light Gradient Boosting Machine
2023-06-05 23:07:23,267:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 123, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-06-05 23:07:23,530:INFO:Creating Dashboard logs
2023-06-05 23:07:23,530:INFO:Model: Elastic Net
2023-06-05 23:07:23,584:INFO:Logged params: {'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'l1_ratio': 0.5, 'max_iter': 1000, 'normalize': 'deprecated', 'positive': False, 'precompute': False, 'random_state': 123, 'selection': 'cyclic', 'tol': 0.0001, 'warm_start': False}
2023-06-05 23:07:23,830:INFO:Creating Dashboard logs
2023-06-05 23:07:23,830:INFO:Model: Bayesian Ridge
2023-06-05 23:07:23,890:INFO:Logged params: {'alpha_1': 1e-06, 'alpha_2': 1e-06, 'alpha_init': None, 'compute_score': False, 'copy_X': True, 'fit_intercept': True, 'lambda_1': 1e-06, 'lambda_2': 1e-06, 'lambda_init': None, 'n_iter': 300, 'normalize': 'deprecated', 'tol': 0.001, 'verbose': False}
2023-06-05 23:07:24,133:INFO:Creating Dashboard logs
2023-06-05 23:07:24,133:INFO:Model: K Neighbors Regressor
2023-06-05 23:07:24,192:INFO:Logged params: {'algorithm': 'auto', 'leaf_size': 30, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': -1, 'n_neighbors': 5, 'p': 2, 'weights': 'uniform'}
2023-06-05 23:07:24,437:INFO:Creating Dashboard logs
2023-06-05 23:07:24,437:INFO:Model: Lasso Least Angle Regression
2023-06-05 23:07:24,491:INFO:Logged params: {'alpha': 1.0, 'copy_X': True, 'eps': 2.220446049250313e-16, 'fit_intercept': True, 'fit_path': True, 'jitter': None, 'max_iter': 500, 'normalize': 'deprecated', 'positive': False, 'precompute': 'auto', 'random_state': 123, 'verbose': False}
2023-06-05 23:07:24,730:INFO:Creating Dashboard logs
2023-06-05 23:07:24,746:INFO:Model: Orthogonal Matching Pursuit
2023-06-05 23:07:24,796:INFO:Logged params: {'fit_intercept': True, 'n_nonzero_coefs': None, 'normalize': 'deprecated', 'precompute': 'auto', 'tol': None}
2023-06-05 23:07:25,022:INFO:Creating Dashboard logs
2023-06-05 23:07:25,031:INFO:Model: Passive Aggressive Regressor
2023-06-05 23:07:25,067:INFO:Logged params: {'C': 1.0, 'average': False, 'early_stopping': False, 'epsilon': 0.1, 'fit_intercept': True, 'loss': 'epsilon_insensitive', 'max_iter': 1000, 'n_iter_no_change': 5, 'random_state': 123, 'shuffle': True, 'tol': 0.001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2023-06-05 23:07:25,343:INFO:Creating Dashboard logs
2023-06-05 23:07:25,346:INFO:Model: AdaBoost Regressor
2023-06-05 23:07:25,393:INFO:Logged params: {'base_estimator': None, 'learning_rate': 1.0, 'loss': 'linear', 'n_estimators': 50, 'random_state': 123}
2023-06-05 23:07:25,633:INFO:Creating Dashboard logs
2023-06-05 23:07:25,633:INFO:Model: Ridge Regression
2023-06-05 23:07:25,679:INFO:Logged params: {'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'normalize': 'deprecated', 'positive': False, 'random_state': 123, 'solver': 'auto', 'tol': 0.001}
2023-06-05 23:07:25,919:INFO:Creating Dashboard logs
2023-06-05 23:07:25,919:INFO:Model: Huber Regressor
2023-06-05 23:07:25,974:INFO:Logged params: {'alpha': 0.0001, 'epsilon': 1.35, 'fit_intercept': True, 'max_iter': 100, 'tol': 1e-05, 'warm_start': False}
2023-06-05 23:07:26,214:INFO:Creating Dashboard logs
2023-06-05 23:07:26,214:INFO:Model: Lasso Regression
2023-06-05 23:07:26,270:INFO:Logged params: {'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'max_iter': 1000, 'normalize': 'deprecated', 'positive': False, 'precompute': False, 'random_state': 123, 'selection': 'cyclic', 'tol': 0.0001, 'warm_start': False}
2023-06-05 23:07:26,508:INFO:Creating Dashboard logs
2023-06-05 23:07:26,508:INFO:Model: Decision Tree Regressor
2023-06-05 23:07:26,577:INFO:Logged params: {'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'random_state': 123, 'splitter': 'best'}
2023-06-05 23:07:26,832:INFO:Creating Dashboard logs
2023-06-05 23:07:26,832:INFO:Model: Dummy Regressor
2023-06-05 23:07:26,895:INFO:Logged params: {'constant': None, 'quantile': None, 'strategy': 'mean'}
2023-06-05 23:07:27,153:INFO:Creating Dashboard logs
2023-06-05 23:07:27,156:INFO:Model: Linear Regression
2023-06-05 23:07:27,213:INFO:Logged params: {'copy_X': True, 'fit_intercept': True, 'n_jobs': -1, 'normalize': 'deprecated', 'positive': False}
2023-06-05 23:07:27,456:INFO:Creating Dashboard logs
2023-06-05 23:07:27,459:INFO:Model: Least Angle Regression
2023-06-05 23:07:27,508:INFO:Logged params: {'copy_X': True, 'eps': 2.220446049250313e-16, 'fit_intercept': True, 'fit_path': True, 'jitter': None, 'n_nonzero_coefs': 500, 'normalize': 'deprecated', 'precompute': 'auto', 'random_state': 123, 'verbose': False}
2023-06-05 23:07:27,747:INFO:_master_model_container: 18
2023-06-05 23:07:27,747:INFO:_display_container: 2
2023-06-05 23:07:27,747:INFO:GradientBoostingRegressor(random_state=123)
2023-06-05 23:07:27,747:INFO:compare_models() successfully completed......................................
2023-06-05 23:09:55,498:INFO:PyCaret RegressionExperiment
2023-06-05 23:09:55,498:INFO:Logging name: your_experiment_name
2023-06-05 23:09:55,498:INFO:ML Usecase: MLUsecase.REGRESSION
2023-06-05 23:09:55,498:INFO:version 3.0.0
2023-06-05 23:09:55,498:INFO:Initializing setup()
2023-06-05 23:09:55,498:INFO:self.USI: 327f
2023-06-05 23:09:55,498:INFO:self._variable_keys: {'pipeline', 'fold_shuffle_param', 'n_jobs_param', 'data', 'transform_target_param', 'exp_name_log', 'y', 'target_param', 'idx', '_ml_usecase', 'html_param', '_available_plots', 'y_test', 'USI', 'logging_param', 'gpu_param', 'X_train', 'gpu_n_jobs_param', 'seed', 'fold_groups_param', 'X', 'y_train', 'X_test', 'memory', 'log_plots_param', 'exp_id', 'fold_generator'}
2023-06-05 23:09:55,498:INFO:Checking environment
2023-06-05 23:09:55,498:INFO:python_version: 3.10.5
2023-06-05 23:09:55,498:INFO:python_build: ('tags/v3.10.5:f377153', 'Jun  6 2022 16:14:13')
2023-06-05 23:09:55,499:INFO:machine: AMD64
2023-06-05 23:09:55,499:INFO:platform: Windows-10-10.0.22621-SP0
2023-06-05 23:09:55,499:INFO:Memory: svmem(total=16497119232, available=6866046976, percent=58.4, used=9631072256, free=6866046976)
2023-06-05 23:09:55,499:INFO:Physical Core: 8
2023-06-05 23:09:55,499:INFO:Logical Core: 16
2023-06-05 23:09:55,499:INFO:Checking libraries
2023-06-05 23:09:55,499:INFO:System:
2023-06-05 23:09:55,499:INFO:    python: 3.10.5 (tags/v3.10.5:f377153, Jun  6 2022, 16:14:13) [MSC v.1929 64 bit (AMD64)]
2023-06-05 23:09:55,499:INFO:executable: C:\Users\Hashif\AppData\Local\Programs\Python\Python310\python.exe
2023-06-05 23:09:55,499:INFO:   machine: Windows-10-10.0.22621-SP0
2023-06-05 23:09:55,499:INFO:PyCaret required dependencies:
2023-06-05 23:09:55,499:INFO:                 pip: 23.1.1
2023-06-05 23:09:55,499:INFO:          setuptools: 58.1.0
2023-06-05 23:09:55,499:INFO:             pycaret: 3.0.0
2023-06-05 23:09:55,499:INFO:             IPython: 8.4.0
2023-06-05 23:09:55,499:INFO:          ipywidgets: 7.7.0
2023-06-05 23:09:55,499:INFO:                tqdm: 4.65.0
2023-06-05 23:09:55,499:INFO:               numpy: 1.23.0
2023-06-05 23:09:55,499:INFO:              pandas: 1.4.3
2023-06-05 23:09:55,500:INFO:              jinja2: 3.1.2
2023-06-05 23:09:55,500:INFO:               scipy: 1.9.3
2023-06-05 23:09:55,500:INFO:              joblib: 1.2.0
2023-06-05 23:09:55,500:INFO:             sklearn: 1.1.2
2023-06-05 23:09:55,500:INFO:                pyod: 1.0.9
2023-06-05 23:09:55,500:INFO:            imblearn: 0.10.1
2023-06-05 23:09:55,500:INFO:   category_encoders: 2.6.0
2023-06-05 23:09:55,500:INFO:            lightgbm: 3.3.5
2023-06-05 23:09:55,500:INFO:               numba: 0.56.4
2023-06-05 23:09:55,500:INFO:            requests: 2.28.1
2023-06-05 23:09:55,500:INFO:          matplotlib: 3.6.2
2023-06-05 23:09:55,500:INFO:          scikitplot: 0.3.7
2023-06-05 23:09:55,500:INFO:         yellowbrick: 1.5
2023-06-05 23:09:55,500:INFO:              plotly: 5.14.1
2023-06-05 23:09:55,500:INFO:             kaleido: 0.2.1
2023-06-05 23:09:55,500:INFO:         statsmodels: 0.13.5
2023-06-05 23:09:55,500:INFO:              sktime: 0.17.1
2023-06-05 23:09:55,500:INFO:               tbats: 1.1.3
2023-06-05 23:09:55,500:INFO:            pmdarima: 2.0.3
2023-06-05 23:09:55,500:INFO:              psutil: 5.9.1
2023-06-05 23:09:55,500:INFO:PyCaret optional dependencies:
2023-06-05 23:09:55,500:INFO:                shap: Not installed
2023-06-05 23:09:55,500:INFO:           interpret: Not installed
2023-06-05 23:09:55,500:INFO:                umap: Not installed
2023-06-05 23:09:55,500:INFO:    pandas_profiling: Not installed
2023-06-05 23:09:55,501:INFO:  explainerdashboard: Not installed
2023-06-05 23:09:55,501:INFO:             autoviz: Not installed
2023-06-05 23:09:55,501:INFO:           fairlearn: Not installed
2023-06-05 23:09:55,501:INFO:             xgboost: Not installed
2023-06-05 23:09:55,501:INFO:            catboost: Not installed
2023-06-05 23:09:55,501:INFO:              kmodes: Not installed
2023-06-05 23:09:55,501:INFO:             mlxtend: Not installed
2023-06-05 23:09:55,501:INFO:       statsforecast: Not installed
2023-06-05 23:09:55,501:INFO:        tune_sklearn: Not installed
2023-06-05 23:09:55,501:INFO:                 ray: Not installed
2023-06-05 23:09:55,501:INFO:            hyperopt: Not installed
2023-06-05 23:09:55,501:INFO:              optuna: Not installed
2023-06-05 23:09:55,501:INFO:               skopt: Not installed
2023-06-05 23:09:55,501:INFO:              mlflow: 2.3.0
2023-06-05 23:09:55,501:INFO:              gradio: Not installed
2023-06-05 23:09:55,501:INFO:             fastapi: Not installed
2023-06-05 23:09:55,501:INFO:             uvicorn: Not installed
2023-06-05 23:09:55,501:INFO:              m2cgen: Not installed
2023-06-05 23:09:55,501:INFO:           evidently: Not installed
2023-06-05 23:09:55,501:INFO:               fugue: Not installed
2023-06-05 23:09:55,501:INFO:           streamlit: Not installed
2023-06-05 23:09:55,501:INFO:             prophet: Not installed
2023-06-05 23:09:55,501:INFO:None
2023-06-05 23:09:55,501:INFO:Set up data.
2023-06-05 23:09:55,532:INFO:Set up train/test split.
2023-06-05 23:09:55,532:INFO:Set up index.
2023-06-05 23:09:55,532:INFO:Set up folding strategy.
2023-06-05 23:09:55,532:INFO:Assigning column types.
2023-06-05 23:09:55,548:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-06-05 23:09:55,548:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-06-05 23:09:55,548:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-06-05 23:09:55,548:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-05 23:09:55,611:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-05 23:09:55,642:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-05 23:09:55,642:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 23:09:55,642:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 23:09:55,642:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-06-05 23:09:55,658:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-06-05 23:09:55,658:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-05 23:09:55,721:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-05 23:09:55,768:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-05 23:09:55,768:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 23:09:55,768:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 23:09:55,768:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-06-05 23:09:55,768:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-06-05 23:09:55,783:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-05 23:09:55,831:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-05 23:09:55,877:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-05 23:09:55,877:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 23:09:55,877:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 23:09:55,877:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-06-05 23:09:55,891:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-05 23:09:55,940:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-05 23:09:55,987:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-05 23:09:55,987:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 23:09:55,987:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 23:09:55,987:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-06-05 23:09:55,991:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-05 23:09:56,050:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-05 23:09:56,091:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-05 23:09:56,091:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 23:09:56,091:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 23:09:56,098:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-05 23:09:56,160:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-05 23:09:56,192:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-05 23:09:56,192:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 23:09:56,192:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 23:09:56,192:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-06-05 23:09:56,254:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-05 23:09:56,302:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-05 23:09:56,302:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 23:09:56,302:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 23:09:56,364:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-05 23:09:56,411:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-05 23:09:56,411:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 23:09:56,411:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 23:09:56,411:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-06-05 23:09:56,489:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-05 23:09:56,524:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 23:09:56,524:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 23:09:56,601:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-05 23:09:56,633:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 23:09:56,633:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 23:09:56,633:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-06-05 23:09:56,752:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 23:09:56,752:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 23:09:56,878:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 23:09:56,878:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 23:09:56,878:INFO:Preparing preprocessing pipeline...
2023-06-05 23:09:56,878:INFO:Set up simple imputation.
2023-06-05 23:09:56,878:INFO:Set up feature normalization.
2023-06-05 23:09:56,878:INFO:Set up column name cleaning.
2023-06-05 23:09:56,910:INFO:Finished creating preprocessing pipeline.
2023-06-05 23:09:56,910:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Hashif\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['location', 'ratings', 'type',
                                             '( free', '( temporarily',
                                             ') exceptional', ') fitness',
                                             ') free', ') good',
                                             ') non-smoking', ') room', ') spa',
                                             '2 swimming', '24-hour front',
                                             'air conditioning',
                                             'airport shuttle', 'bar (',
                                             'bar air', 'bar breakfast'...
                                             'centre (', 'centre 24-hour',
                                             'centre daily',
                                             'centre facilities', 'centre free', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-06-05 23:09:56,910:INFO:Creating final display dataframe.
2023-06-05 23:09:57,051:INFO:Setup _display_container:                     Description                 Value
0                    Session id                   123
1                        Target                 price
2                   Target type            Regression
3           Original data shape            (735, 214)
4        Transformed data shape            (735, 214)
5   Transformed train set shape            (588, 214)
6    Transformed test set shape            (147, 214)
7              Numeric features                   213
8                    Preprocess                  True
9               Imputation type                simple
10           Numeric imputation                  mean
11       Categorical imputation                  mode
12                    Normalize                  True
13             Normalize method                zscore
14               Fold Generator                 KFold
15                  Fold Number                    10
16                     CPU Jobs                    -1
17                      Use GPU                 False
18               Log Experiment          MlflowLogger
19              Experiment Name  your_experiment_name
20                          USI                  327f
2023-06-05 23:09:57,166:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 23:09:57,166:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 23:09:57,276:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 23:09:57,276:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 23:09:57,276:INFO:Logging experiment in loggers
2023-06-05 23:09:57,339:INFO:SubProcess save_model() called ==================================
2023-06-05 23:09:57,355:INFO:Initializing save_model()
2023-06-05 23:09:57,355:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\Hashif\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['location', 'ratings', 'type',
                                             '( free', '( temporarily',
                                             ') exceptional', ') fitness',
                                             ') free', ') good',
                                             ') non-smoking', ') room', ') spa',
                                             '2 swimming', '24-hour front',
                                             'air conditioning',
                                             'airport shuttle', 'bar (',
                                             'bar air', 'bar breakfast'...
                                             'centre (', 'centre 24-hour',
                                             'centre daily',
                                             'centre facilities', 'centre free', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), model_name=C:\Users\Hashif\AppData\Local\Temp\tmpki3mrx3r\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\Hashif\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['location', 'ratings', 'type',
                                             '( free', '( temporarily',
                                             ') exceptional', ') fitness',
                                             ') free', ') good',
                                             ') non-smoking', ') room', ') spa',
                                             '2 swimming', '24-hour front',
                                             'air conditioning',
                                             'airport shuttle', 'bar (',
                                             'bar air', 'bar breakfast'...
                                             'centre (', 'centre 24-hour',
                                             'centre daily',
                                             'centre facilities', 'centre free', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=False, use_case=MLUsecase.REGRESSION, kwargs={})
2023-06-05 23:09:57,355:INFO:Adding model into prep_pipe
2023-06-05 23:09:57,355:WARNING:Only Model saved as it was a pipeline.
2023-06-05 23:09:57,355:INFO:C:\Users\Hashif\AppData\Local\Temp\tmpki3mrx3r\Transformation Pipeline.pkl saved in current working directory
2023-06-05 23:09:57,370:INFO:Pipeline(memory=FastMemory(location=C:\Users\Hashif\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['location', 'ratings', 'type',
                                             '( free', '( temporarily',
                                             ') exceptional', ') fitness',
                                             ') free', ') good',
                                             ') non-smoking', ') room', ') spa',
                                             '2 swimming', '24-hour front',
                                             'air conditioning',
                                             'airport shuttle', 'bar (',
                                             'bar air', 'bar breakfast'...
                                             'centre (', 'centre 24-hour',
                                             'centre daily',
                                             'centre facilities', 'centre free', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-06-05 23:09:57,370:INFO:save_model() successfully completed......................................
2023-06-05 23:09:57,496:INFO:SubProcess save_model() end ==================================
2023-06-05 23:09:57,543:INFO:setup() successfully completed in 1.8s...............
2023-06-05 23:09:57,559:INFO:Initializing compare_models()
2023-06-05 23:09:57,559:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020E25C00D90>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x0000020E25C00D90>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-06-05 23:09:57,559:INFO:Checking exceptions
2023-06-05 23:09:57,559:INFO:Preparing display monitor
2023-06-05 23:09:57,596:INFO:Initializing Linear Regression
2023-06-05 23:09:57,596:INFO:Total runtime is 0.0 minutes
2023-06-05 23:09:57,602:INFO:SubProcess create_model() called ==================================
2023-06-05 23:09:57,602:INFO:Initializing create_model()
2023-06-05 23:09:57,603:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020E25C00D90>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020E274E3700>, model_only=True, return_train_score=False, kwargs={})
2023-06-05 23:09:57,603:INFO:Checking exceptions
2023-06-05 23:09:57,603:INFO:Importing libraries
2023-06-05 23:09:57,604:INFO:Copying training dataset
2023-06-05 23:09:57,610:INFO:Defining folds
2023-06-05 23:09:57,611:INFO:Declaring metric variables
2023-06-05 23:09:57,614:INFO:Importing untrained model
2023-06-05 23:09:57,618:INFO:Linear Regression Imported successfully
2023-06-05 23:09:57,625:INFO:Starting cross validation
2023-06-05 23:09:57,628:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-05 23:09:58,014:INFO:Calculating mean and std
2023-06-05 23:09:58,014:INFO:Creating metrics dataframe
2023-06-05 23:09:58,045:INFO:Uploading results into container
2023-06-05 23:09:58,045:INFO:Uploading model into container now
2023-06-05 23:09:58,045:INFO:_master_model_container: 1
2023-06-05 23:09:58,045:INFO:_display_container: 2
2023-06-05 23:09:58,045:INFO:LinearRegression(n_jobs=-1)
2023-06-05 23:09:58,045:INFO:create_model() successfully completed......................................
2023-06-05 23:09:58,165:INFO:SubProcess create_model() end ==================================
2023-06-05 23:09:58,165:INFO:Creating metrics dataframe
2023-06-05 23:09:58,172:INFO:Initializing Lasso Regression
2023-06-05 23:09:58,173:INFO:Total runtime is 0.009612683455149333 minutes
2023-06-05 23:09:58,173:INFO:SubProcess create_model() called ==================================
2023-06-05 23:09:58,173:INFO:Initializing create_model()
2023-06-05 23:09:58,173:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020E25C00D90>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020E274E3700>, model_only=True, return_train_score=False, kwargs={})
2023-06-05 23:09:58,177:INFO:Checking exceptions
2023-06-05 23:09:58,177:INFO:Importing libraries
2023-06-05 23:09:58,177:INFO:Copying training dataset
2023-06-05 23:09:58,179:INFO:Defining folds
2023-06-05 23:09:58,179:INFO:Declaring metric variables
2023-06-05 23:09:58,179:INFO:Importing untrained model
2023-06-05 23:09:58,179:INFO:Lasso Regression Imported successfully
2023-06-05 23:09:58,198:INFO:Starting cross validation
2023-06-05 23:09:58,199:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-05 23:09:58,353:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.425e+05, tolerance: 2.126e+05
  model = cd_fast.enet_coordinate_descent(

2023-06-05 23:09:58,354:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.463e+05, tolerance: 2.492e+05
  model = cd_fast.enet_coordinate_descent(

2023-06-05 23:09:58,354:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.588e+05, tolerance: 2.437e+05
  model = cd_fast.enet_coordinate_descent(

2023-06-05 23:09:58,369:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.728e+05, tolerance: 2.388e+05
  model = cd_fast.enet_coordinate_descent(

2023-06-05 23:09:58,396:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.427e+05, tolerance: 2.238e+05
  model = cd_fast.enet_coordinate_descent(

2023-06-05 23:09:58,397:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.602e+06, tolerance: 2.377e+05
  model = cd_fast.enet_coordinate_descent(

2023-06-05 23:09:58,431:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.326e+06, tolerance: 2.501e+05
  model = cd_fast.enet_coordinate_descent(

2023-06-05 23:09:58,438:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.104e+06, tolerance: 2.354e+05
  model = cd_fast.enet_coordinate_descent(

2023-06-05 23:09:58,662:INFO:Calculating mean and std
2023-06-05 23:09:58,664:INFO:Creating metrics dataframe
2023-06-05 23:09:58,702:INFO:Uploading results into container
2023-06-05 23:09:58,703:INFO:Uploading model into container now
2023-06-05 23:09:58,703:INFO:_master_model_container: 2
2023-06-05 23:09:58,703:INFO:_display_container: 2
2023-06-05 23:09:58,703:INFO:Lasso(random_state=123)
2023-06-05 23:09:58,703:INFO:create_model() successfully completed......................................
2023-06-05 23:09:58,819:INFO:SubProcess create_model() end ==================================
2023-06-05 23:09:58,819:INFO:Creating metrics dataframe
2023-06-05 23:09:58,826:INFO:Initializing Ridge Regression
2023-06-05 23:09:58,826:INFO:Total runtime is 0.02050997813542684 minutes
2023-06-05 23:09:58,830:INFO:SubProcess create_model() called ==================================
2023-06-05 23:09:58,831:INFO:Initializing create_model()
2023-06-05 23:09:58,831:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020E25C00D90>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020E274E3700>, model_only=True, return_train_score=False, kwargs={})
2023-06-05 23:09:58,831:INFO:Checking exceptions
2023-06-05 23:09:58,831:INFO:Importing libraries
2023-06-05 23:09:58,831:INFO:Copying training dataset
2023-06-05 23:09:58,838:INFO:Defining folds
2023-06-05 23:09:58,838:INFO:Declaring metric variables
2023-06-05 23:09:58,843:INFO:Importing untrained model
2023-06-05 23:09:58,848:INFO:Ridge Regression Imported successfully
2023-06-05 23:09:58,856:INFO:Starting cross validation
2023-06-05 23:09:58,858:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-05 23:09:59,296:INFO:Calculating mean and std
2023-06-05 23:09:59,298:INFO:Creating metrics dataframe
2023-06-05 23:09:59,336:INFO:Uploading results into container
2023-06-05 23:09:59,337:INFO:Uploading model into container now
2023-06-05 23:09:59,337:INFO:_master_model_container: 3
2023-06-05 23:09:59,337:INFO:_display_container: 2
2023-06-05 23:09:59,337:INFO:Ridge(random_state=123)
2023-06-05 23:09:59,338:INFO:create_model() successfully completed......................................
2023-06-05 23:09:59,449:INFO:SubProcess create_model() end ==================================
2023-06-05 23:09:59,449:INFO:Creating metrics dataframe
2023-06-05 23:09:59,457:INFO:Initializing Elastic Net
2023-06-05 23:09:59,457:INFO:Total runtime is 0.03101401726404826 minutes
2023-06-05 23:09:59,461:INFO:SubProcess create_model() called ==================================
2023-06-05 23:09:59,461:INFO:Initializing create_model()
2023-06-05 23:09:59,461:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020E25C00D90>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020E274E3700>, model_only=True, return_train_score=False, kwargs={})
2023-06-05 23:09:59,461:INFO:Checking exceptions
2023-06-05 23:09:59,461:INFO:Importing libraries
2023-06-05 23:09:59,462:INFO:Copying training dataset
2023-06-05 23:09:59,470:INFO:Defining folds
2023-06-05 23:09:59,470:INFO:Declaring metric variables
2023-06-05 23:09:59,473:INFO:Importing untrained model
2023-06-05 23:09:59,478:INFO:Elastic Net Imported successfully
2023-06-05 23:09:59,486:INFO:Starting cross validation
2023-06-05 23:09:59,488:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-05 23:09:59,892:INFO:Calculating mean and std
2023-06-05 23:09:59,892:INFO:Creating metrics dataframe
2023-06-05 23:09:59,926:INFO:Uploading results into container
2023-06-05 23:09:59,926:INFO:Uploading model into container now
2023-06-05 23:09:59,926:INFO:_master_model_container: 4
2023-06-05 23:09:59,926:INFO:_display_container: 2
2023-06-05 23:09:59,926:INFO:ElasticNet(random_state=123)
2023-06-05 23:09:59,926:INFO:create_model() successfully completed......................................
2023-06-05 23:10:00,038:INFO:SubProcess create_model() end ==================================
2023-06-05 23:10:00,038:INFO:Creating metrics dataframe
2023-06-05 23:10:00,053:INFO:Initializing Least Angle Regression
2023-06-05 23:10:00,053:INFO:Total runtime is 0.04095526933670044 minutes
2023-06-05 23:10:00,059:INFO:SubProcess create_model() called ==================================
2023-06-05 23:10:00,059:INFO:Initializing create_model()
2023-06-05 23:10:00,059:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020E25C00D90>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020E274E3700>, model_only=True, return_train_score=False, kwargs={})
2023-06-05 23:10:00,059:INFO:Checking exceptions
2023-06-05 23:10:00,059:INFO:Importing libraries
2023-06-05 23:10:00,059:INFO:Copying training dataset
2023-06-05 23:10:00,059:INFO:Defining folds
2023-06-05 23:10:00,059:INFO:Declaring metric variables
2023-06-05 23:10:00,072:INFO:Importing untrained model
2023-06-05 23:10:00,076:INFO:Least Angle Regression Imported successfully
2023-06-05 23:10:00,083:INFO:Starting cross validation
2023-06-05 23:10:00,084:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-05 23:10:00,215:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-06-05 23:10:00,225:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=6.933e+00, with an active set of 20 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:10:00,225:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 27 iterations, i.e. alpha=5.755e+00, with an active set of 27 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:10:00,225:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 45 iterations, i.e. alpha=3.298e+00, with an active set of 45 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:10:00,225:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 55 iterations, i.e. alpha=2.878e+00, with an active set of 55 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:10:00,225:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 63 iterations, i.e. alpha=2.469e+00, with an active set of 63 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:10:00,225:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 65 iterations, i.e. alpha=2.435e+00, with an active set of 65 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:10:00,241:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:732: RuntimeWarning: overflow encountered in divide
  g1 = arrayfuncs.min_pos((C - Cov) / (AA - corr_eq_dir + tiny32))

2023-06-05 23:10:00,241:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:736: RuntimeWarning: overflow encountered in divide
  g2 = arrayfuncs.min_pos((C + Cov) / (AA + corr_eq_dir + tiny32))

2023-06-05 23:10:00,241:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 67 iterations, i.e. alpha=2.417e+00, with an active set of 67 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:10:00,241:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-06-05 23:10:00,241:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 83 iterations, i.e. alpha=1.926e+00, with an active set of 79 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:10:00,241:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 90 iterations, i.e. alpha=1.695e+00, with an active set of 86 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:10:00,241:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=1.570e+01, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:10:00,241:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 94 iterations, i.e. alpha=1.611e+00, with an active set of 89 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:10:00,241:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=8.286e+00, with an active set of 21 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:10:00,241:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 29 iterations, i.e. alpha=6.550e+00, with an active set of 28 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:10:00,241:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 30 iterations, i.e. alpha=6.385e+00, with an active set of 29 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:10:00,241:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 31 iterations, i.e. alpha=6.166e+00, with an active set of 30 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:10:00,241:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 101 iterations, i.e. alpha=1.481e+00, with an active set of 94 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:10:00,241:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 101 iterations, i.e. alpha=1.454e+00, with an active set of 94 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:10:00,241:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 102 iterations, i.e. alpha=1.444e+00, with an active set of 95 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:10:00,241:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:741: RuntimeWarning: overflow encountered in divide
  z = -coef[active] / (least_squares + tiny32)

2023-06-05 23:10:00,241:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 109 iterations, i.e. alpha=2.367e+00, with an active set of 99 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:10:00,241:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 109 iterations, i.e. alpha=2.267e+00, with an active set of 99 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:10:00,256:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 109 iterations, i.e. alpha=2.260e+00, with an active set of 99 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:10:00,257:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 110 iterations, i.e. alpha=2.194e+00, with an active set of 100 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:10:00,257:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 110 iterations, i.e. alpha=2.154e+00, with an active set of 100 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:10:00,257:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 122 iterations, i.e. alpha=2.617e+00, with an active set of 106 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:10:00,257:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 96 iterations, i.e. alpha=2.661e+03, with an active set of 73 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:10:00,257:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 126 iterations, i.e. alpha=2.573e+03, with an active set of 103 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:10:00,272:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 145 iterations, i.e. alpha=2.529e+03, with an active set of 120 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:10:00,285:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\extmath.py:152: RuntimeWarning: invalid value encountered in matmul
  ret = a @ b

2023-06-05 23:10:00,288:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 267, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_regression.py", line 196, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\validation.py", line 899, in check_array
    _assert_all_finite(
  File "C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\validation.py", line 146, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-06-05 23:10:00,288:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 216 iterations, i.e. alpha=6.197e+04, with an active set of 159 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:10:00,313:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 239 iterations, i.e. alpha=5.432e+06, with an active set of 184 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:10:00,316:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 241 iterations, i.e. alpha=5.008e+06, with an active set of 185 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:10:00,317:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 243 iterations, i.e. alpha=4.947e+06, with an active set of 187 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:10:00,317:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 247 iterations, i.e. alpha=4.793e+06, with an active set of 191 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:10:00,317:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 248 iterations, i.e. alpha=4.754e+06, with an active set of 192 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:10:00,320:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 252 iterations, i.e. alpha=6.003e+06, with an active set of 196 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:10:00,320:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 252 iterations, i.e. alpha=3.277e+06, with an active set of 196 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:10:00,320:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 253 iterations, i.e. alpha=2.137e+06, with an active set of 197 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:10:00,320:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 253 iterations, i.e. alpha=9.225e+05, with an active set of 197 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:10:00,476:INFO:Calculating mean and std
2023-06-05 23:10:00,476:INFO:Creating metrics dataframe
2023-06-05 23:10:00,523:INFO:Uploading results into container
2023-06-05 23:10:00,524:INFO:Uploading model into container now
2023-06-05 23:10:00,524:INFO:_master_model_container: 5
2023-06-05 23:10:00,524:INFO:_display_container: 2
2023-06-05 23:10:00,525:INFO:Lars(random_state=123)
2023-06-05 23:10:00,525:INFO:create_model() successfully completed......................................
2023-06-05 23:10:00,618:INFO:SubProcess create_model() end ==================================
2023-06-05 23:10:00,618:INFO:Creating metrics dataframe
2023-06-05 23:10:00,633:INFO:Initializing Lasso Least Angle Regression
2023-06-05 23:10:00,633:INFO:Total runtime is 0.05062562624613444 minutes
2023-06-05 23:10:00,640:INFO:SubProcess create_model() called ==================================
2023-06-05 23:10:00,641:INFO:Initializing create_model()
2023-06-05 23:10:00,641:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020E25C00D90>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020E274E3700>, model_only=True, return_train_score=False, kwargs={})
2023-06-05 23:10:00,641:INFO:Checking exceptions
2023-06-05 23:10:00,641:INFO:Importing libraries
2023-06-05 23:10:00,641:INFO:Copying training dataset
2023-06-05 23:10:00,648:INFO:Defining folds
2023-06-05 23:10:00,648:INFO:Declaring metric variables
2023-06-05 23:10:00,650:INFO:Importing untrained model
2023-06-05 23:10:00,655:INFO:Lasso Least Angle Regression Imported successfully
2023-06-05 23:10:00,662:INFO:Starting cross validation
2023-06-05 23:10:00,669:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-05 23:10:00,783:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-06-05 23:10:00,783:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-06-05 23:10:00,783:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=1.346e+01, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:10:00,783:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:732: RuntimeWarning: overflow encountered in divide
  g1 = arrayfuncs.min_pos((C - Cov) / (AA - corr_eq_dir + tiny32))

2023-06-05 23:10:00,783:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=6.730e+00, with an active set of 23 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:10:00,783:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:679: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 27 iterations, alpha=6.117e+00, previous alpha=6.116e+00, with an active set of 28 regressors.
  warnings.warn(

2023-06-05 23:10:00,783:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 44 iterations, i.e. alpha=4.414e+00, with an active set of 36 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:10:00,799:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-06-05 23:10:00,799:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:741: RuntimeWarning: overflow encountered in divide
  z = -coef[active] / (least_squares + tiny32)

2023-06-05 23:10:00,799:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=3.014e+01, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:10:00,799:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:732: RuntimeWarning: overflow encountered in divide
  g1 = arrayfuncs.min_pos((C - Cov) / (AA - corr_eq_dir + tiny32))

2023-06-05 23:10:00,799:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=1.843e+01, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:10:00,799:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=1.513e+01, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:10:00,799:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:679: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 86 iterations, alpha=2.465e+00, previous alpha=2.412e+00, with an active set of 69 regressors.
  warnings.warn(

2023-06-05 23:10:00,799:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=9.745e+00, with an active set of 16 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:10:00,799:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=8.894e+00, with an active set of 17 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:10:00,815:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=7.859e+00, with an active set of 20 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:10:00,815:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-06-05 23:10:00,815:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-06-05 23:10:00,815:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=1.850e+01, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:10:00,815:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 43 iterations, i.e. alpha=5.133e+00, with an active set of 41 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:10:00,815:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=9.988e+00, with an active set of 17 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:10:00,815:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=9.248e+00, with an active set of 18 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:10:00,815:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=1.874e+01, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:10:00,815:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:732: RuntimeWarning: overflow encountered in divide
  g1 = arrayfuncs.min_pos((C - Cov) / (AA - corr_eq_dir + tiny32))

2023-06-05 23:10:00,815:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=6.161e+00, with an active set of 24 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:10:00,815:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=6.097e+00, with an active set of 25 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:10:00,815:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:732: RuntimeWarning: overflow encountered in divide
  g1 = arrayfuncs.min_pos((C - Cov) / (AA - corr_eq_dir + tiny32))

2023-06-05 23:10:00,815:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 27 iterations, i.e. alpha=6.078e+00, with an active set of 27 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:10:00,815:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 57 iterations, i.e. alpha=3.672e+00, with an active set of 55 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:10:00,815:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:679: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 58 iterations, alpha=4.373e+00, previous alpha=3.606e+00, with an active set of 55 regressors.
  warnings.warn(

2023-06-05 23:10:00,815:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:679: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 22 iterations, alpha=7.870e+00, previous alpha=7.746e+00, with an active set of 21 regressors.
  warnings.warn(

2023-06-05 23:10:00,815:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:679: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 38 iterations, alpha=4.580e+00, previous alpha=4.415e+00, with an active set of 35 regressors.
  warnings.warn(

2023-06-05 23:10:00,830:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-06-05 23:10:00,830:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=2.417e+01, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:10:00,830:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=1.655e+01, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:10:00,830:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=1.209e+01, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:10:00,830:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=8.139e+00, with an active set of 18 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:10:00,830:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=6.576e+00, with an active set of 23 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:10:00,830:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=6.362e+00, with an active set of 24 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:10:00,830:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:679: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 32 iterations, alpha=5.066e+00, previous alpha=4.981e+00, with an active set of 31 regressors.
  warnings.warn(

2023-06-05 23:10:00,846:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-06-05 23:10:00,846:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-06-05 23:10:00,862:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=3.020e+01, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:10:00,862:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:732: RuntimeWarning: overflow encountered in divide
  g1 = arrayfuncs.min_pos((C - Cov) / (AA - corr_eq_dir + tiny32))

2023-06-05 23:10:00,862:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=1.506e+01, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:10:00,862:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:732: RuntimeWarning: overflow encountered in divide
  g1 = arrayfuncs.min_pos((C - Cov) / (AA - corr_eq_dir + tiny32))

2023-06-05 23:10:00,862:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=9.367e+00, with an active set of 18 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:10:00,862:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=6.475e+00, with an active set of 21 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:10:00,862:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=7.452e+00, with an active set of 20 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:10:00,862:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:736: RuntimeWarning: overflow encountered in divide
  g2 = arrayfuncs.min_pos((C + Cov) / (AA + corr_eq_dir + tiny32))

2023-06-05 23:10:00,862:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=6.270e+00, with an active set of 23 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:10:00,862:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 36 iterations, i.e. alpha=4.816e+00, with an active set of 34 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:10:00,862:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 36 iterations, i.e. alpha=4.815e+00, with an active set of 34 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:10:00,862:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=4.289e+00, with an active set of 40 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:10:00,862:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-06-05 23:10:00,862:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 50 iterations, i.e. alpha=3.633e+00, with an active set of 48 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:10:00,862:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 54 iterations, i.e. alpha=3.125e+00, with an active set of 52 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:10:00,862:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 63 iterations, i.e. alpha=2.635e+00, with an active set of 61 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:10:00,878:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 62 iterations, i.e. alpha=2.647e+00, with an active set of 60 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:10:00,878:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=6.933e+00, with an active set of 20 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:10:00,878:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 74 iterations, i.e. alpha=2.285e+00, with an active set of 72 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:10:00,878:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 75 iterations, i.e. alpha=2.214e+00, with an active set of 73 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:10:00,878:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 27 iterations, i.e. alpha=5.755e+00, with an active set of 27 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:10:00,878:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:679: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 76 iterations, alpha=2.468e+00, previous alpha=2.214e+00, with an active set of 73 regressors.
  warnings.warn(

2023-06-05 23:10:00,878:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 45 iterations, i.e. alpha=3.298e+00, with an active set of 45 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:10:00,878:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:679: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 86 iterations, alpha=1.770e+00, previous alpha=1.692e+00, with an active set of 83 regressors.
  warnings.warn(

2023-06-05 23:10:00,878:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 55 iterations, i.e. alpha=2.878e+00, with an active set of 55 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:10:00,878:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-06-05 23:10:00,878:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 63 iterations, i.e. alpha=2.469e+00, with an active set of 63 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:10:00,878:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 65 iterations, i.e. alpha=2.435e+00, with an active set of 65 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:10:00,878:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:732: RuntimeWarning: overflow encountered in divide
  g1 = arrayfuncs.min_pos((C - Cov) / (AA - corr_eq_dir + tiny32))

2023-06-05 23:10:00,878:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:736: RuntimeWarning: overflow encountered in divide
  g2 = arrayfuncs.min_pos((C + Cov) / (AA + corr_eq_dir + tiny32))

2023-06-05 23:10:00,878:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 67 iterations, i.e. alpha=2.417e+00, with an active set of 67 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:10:00,878:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=1.570e+01, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:10:00,894:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=7.852e+00, with an active set of 21 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:10:00,894:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 84 iterations, i.e. alpha=1.752e+00, with an active set of 80 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:10:00,898:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 90 iterations, i.e. alpha=1.464e+00, with an active set of 86 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:10:00,898:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 34 iterations, i.e. alpha=5.323e+00, with an active set of 32 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:10:00,899:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:679: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 92 iterations, alpha=1.450e+00, previous alpha=1.428e+00, with an active set of 87 regressors.
  warnings.warn(

2023-06-05 23:10:00,899:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 36 iterations, i.e. alpha=5.108e+00, with an active set of 34 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-05 23:10:00,905:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:679: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 55 iterations, alpha=3.000e+00, previous alpha=2.983e+00, with an active set of 52 regressors.
  warnings.warn(

2023-06-05 23:10:01,099:INFO:Calculating mean and std
2023-06-05 23:10:01,099:INFO:Creating metrics dataframe
2023-06-05 23:10:01,143:INFO:Uploading results into container
2023-06-05 23:10:01,143:INFO:Uploading model into container now
2023-06-05 23:10:01,144:INFO:_master_model_container: 6
2023-06-05 23:10:01,144:INFO:_display_container: 2
2023-06-05 23:10:01,144:INFO:LassoLars(random_state=123)
2023-06-05 23:10:01,144:INFO:create_model() successfully completed......................................
2023-06-05 23:10:01,235:INFO:SubProcess create_model() end ==================================
2023-06-05 23:10:01,235:INFO:Creating metrics dataframe
2023-06-05 23:10:01,250:INFO:Initializing Orthogonal Matching Pursuit
2023-06-05 23:10:01,250:INFO:Total runtime is 0.060908130804697674 minutes
2023-06-05 23:10:01,264:INFO:SubProcess create_model() called ==================================
2023-06-05 23:10:01,264:INFO:Initializing create_model()
2023-06-05 23:10:01,264:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020E25C00D90>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020E274E3700>, model_only=True, return_train_score=False, kwargs={})
2023-06-05 23:10:01,264:INFO:Checking exceptions
2023-06-05 23:10:01,264:INFO:Importing libraries
2023-06-05 23:10:01,264:INFO:Copying training dataset
2023-06-05 23:10:01,266:INFO:Defining folds
2023-06-05 23:10:01,266:INFO:Declaring metric variables
2023-06-05 23:10:01,266:INFO:Importing untrained model
2023-06-05 23:10:01,279:INFO:Orthogonal Matching Pursuit Imported successfully
2023-06-05 23:10:01,287:INFO:Starting cross validation
2023-06-05 23:10:01,287:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-05 23:10:01,385:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-06-05 23:10:01,400:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-06-05 23:10:01,415:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-06-05 23:10:01,415:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-06-05 23:10:01,431:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-06-05 23:10:01,447:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-06-05 23:10:01,463:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-06-05 23:10:01,463:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-06-05 23:10:01,479:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-06-05 23:10:01,479:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-06-05 23:10:01,697:INFO:Calculating mean and std
2023-06-05 23:10:01,698:INFO:Creating metrics dataframe
2023-06-05 23:10:01,731:INFO:Uploading results into container
2023-06-05 23:10:01,731:INFO:Uploading model into container now
2023-06-05 23:10:01,733:INFO:_master_model_container: 7
2023-06-05 23:10:01,733:INFO:_display_container: 2
2023-06-05 23:10:01,733:INFO:OrthogonalMatchingPursuit()
2023-06-05 23:10:01,733:INFO:create_model() successfully completed......................................
2023-06-05 23:10:01,833:INFO:SubProcess create_model() end ==================================
2023-06-05 23:10:01,833:INFO:Creating metrics dataframe
2023-06-05 23:10:01,833:INFO:Initializing Bayesian Ridge
2023-06-05 23:10:01,833:INFO:Total runtime is 0.0706162412961324 minutes
2023-06-05 23:10:01,850:INFO:SubProcess create_model() called ==================================
2023-06-05 23:10:01,850:INFO:Initializing create_model()
2023-06-05 23:10:01,850:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020E25C00D90>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020E274E3700>, model_only=True, return_train_score=False, kwargs={})
2023-06-05 23:10:01,850:INFO:Checking exceptions
2023-06-05 23:10:01,850:INFO:Importing libraries
2023-06-05 23:10:01,850:INFO:Copying training dataset
2023-06-05 23:10:01,851:INFO:Defining folds
2023-06-05 23:10:01,851:INFO:Declaring metric variables
2023-06-05 23:10:01,851:INFO:Importing untrained model
2023-06-05 23:10:01,867:INFO:Bayesian Ridge Imported successfully
2023-06-05 23:10:01,869:INFO:Starting cross validation
2023-06-05 23:10:01,876:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-05 23:10:02,287:INFO:Calculating mean and std
2023-06-05 23:10:02,287:INFO:Creating metrics dataframe
2023-06-05 23:10:02,333:INFO:Uploading results into container
2023-06-05 23:10:02,334:INFO:Uploading model into container now
2023-06-05 23:10:02,334:INFO:_master_model_container: 8
2023-06-05 23:10:02,334:INFO:_display_container: 2
2023-06-05 23:10:02,334:INFO:BayesianRidge()
2023-06-05 23:10:02,334:INFO:create_model() successfully completed......................................
2023-06-05 23:10:02,428:INFO:SubProcess create_model() end ==================================
2023-06-05 23:10:02,428:INFO:Creating metrics dataframe
2023-06-05 23:10:02,444:INFO:Initializing Passive Aggressive Regressor
2023-06-05 23:10:02,444:INFO:Total runtime is 0.08080042997996012 minutes
2023-06-05 23:10:02,450:INFO:SubProcess create_model() called ==================================
2023-06-05 23:10:02,451:INFO:Initializing create_model()
2023-06-05 23:10:02,451:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020E25C00D90>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020E274E3700>, model_only=True, return_train_score=False, kwargs={})
2023-06-05 23:10:02,451:INFO:Checking exceptions
2023-06-05 23:10:02,451:INFO:Importing libraries
2023-06-05 23:10:02,451:INFO:Copying training dataset
2023-06-05 23:10:02,453:INFO:Defining folds
2023-06-05 23:10:02,453:INFO:Declaring metric variables
2023-06-05 23:10:02,453:INFO:Importing untrained model
2023-06-05 23:10:02,466:INFO:Passive Aggressive Regressor Imported successfully
2023-06-05 23:10:02,476:INFO:Starting cross validation
2023-06-05 23:10:02,478:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-05 23:10:02,860:INFO:Calculating mean and std
2023-06-05 23:10:02,860:INFO:Creating metrics dataframe
2023-06-05 23:10:02,903:INFO:Uploading results into container
2023-06-05 23:10:02,903:INFO:Uploading model into container now
2023-06-05 23:10:02,903:INFO:_master_model_container: 9
2023-06-05 23:10:02,903:INFO:_display_container: 2
2023-06-05 23:10:02,903:INFO:PassiveAggressiveRegressor(random_state=123)
2023-06-05 23:10:02,903:INFO:create_model() successfully completed......................................
2023-06-05 23:10:03,013:INFO:SubProcess create_model() end ==================================
2023-06-05 23:10:03,013:INFO:Creating metrics dataframe
2023-06-05 23:10:03,013:INFO:Initializing Huber Regressor
2023-06-05 23:10:03,013:INFO:Total runtime is 0.0902903159459432 minutes
2023-06-05 23:10:03,013:INFO:SubProcess create_model() called ==================================
2023-06-05 23:10:03,013:INFO:Initializing create_model()
2023-06-05 23:10:03,013:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020E25C00D90>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020E274E3700>, model_only=True, return_train_score=False, kwargs={})
2023-06-05 23:10:03,013:INFO:Checking exceptions
2023-06-05 23:10:03,013:INFO:Importing libraries
2023-06-05 23:10:03,013:INFO:Copying training dataset
2023-06-05 23:10:03,029:INFO:Defining folds
2023-06-05 23:10:03,029:INFO:Declaring metric variables
2023-06-05 23:10:03,029:INFO:Importing untrained model
2023-06-05 23:10:03,045:INFO:Huber Regressor Imported successfully
2023-06-05 23:10:03,049:INFO:Starting cross validation
2023-06-05 23:10:03,055:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-05 23:10:03,450:INFO:Calculating mean and std
2023-06-05 23:10:03,466:INFO:Creating metrics dataframe
2023-06-05 23:10:03,502:INFO:Uploading results into container
2023-06-05 23:10:03,502:INFO:Uploading model into container now
2023-06-05 23:10:03,502:INFO:_master_model_container: 10
2023-06-05 23:10:03,502:INFO:_display_container: 2
2023-06-05 23:10:03,502:INFO:HuberRegressor()
2023-06-05 23:10:03,502:INFO:create_model() successfully completed......................................
2023-06-05 23:10:03,610:INFO:SubProcess create_model() end ==================================
2023-06-05 23:10:03,610:INFO:Creating metrics dataframe
2023-06-05 23:10:03,610:INFO:Initializing K Neighbors Regressor
2023-06-05 23:10:03,610:INFO:Total runtime is 0.10022916793823242 minutes
2023-06-05 23:10:03,630:INFO:SubProcess create_model() called ==================================
2023-06-05 23:10:03,630:INFO:Initializing create_model()
2023-06-05 23:10:03,630:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020E25C00D90>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020E274E3700>, model_only=True, return_train_score=False, kwargs={})
2023-06-05 23:10:03,630:INFO:Checking exceptions
2023-06-05 23:10:03,630:INFO:Importing libraries
2023-06-05 23:10:03,630:INFO:Copying training dataset
2023-06-05 23:10:03,638:INFO:Defining folds
2023-06-05 23:10:03,638:INFO:Declaring metric variables
2023-06-05 23:10:03,642:INFO:Importing untrained model
2023-06-05 23:10:03,647:INFO:K Neighbors Regressor Imported successfully
2023-06-05 23:10:03,660:INFO:Starting cross validation
2023-06-05 23:10:03,668:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-05 23:10:04,103:INFO:Calculating mean and std
2023-06-05 23:10:04,103:INFO:Creating metrics dataframe
2023-06-05 23:10:04,138:INFO:Uploading results into container
2023-06-05 23:10:04,138:INFO:Uploading model into container now
2023-06-05 23:10:04,138:INFO:_master_model_container: 11
2023-06-05 23:10:04,138:INFO:_display_container: 2
2023-06-05 23:10:04,138:INFO:KNeighborsRegressor(n_jobs=-1)
2023-06-05 23:10:04,138:INFO:create_model() successfully completed......................................
2023-06-05 23:10:04,249:INFO:SubProcess create_model() end ==================================
2023-06-05 23:10:04,249:INFO:Creating metrics dataframe
2023-06-05 23:10:04,249:INFO:Initializing Decision Tree Regressor
2023-06-05 23:10:04,249:INFO:Total runtime is 0.11087812980016072 minutes
2023-06-05 23:10:04,263:INFO:SubProcess create_model() called ==================================
2023-06-05 23:10:04,264:INFO:Initializing create_model()
2023-06-05 23:10:04,264:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020E25C00D90>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020E274E3700>, model_only=True, return_train_score=False, kwargs={})
2023-06-05 23:10:04,264:INFO:Checking exceptions
2023-06-05 23:10:04,264:INFO:Importing libraries
2023-06-05 23:10:04,264:INFO:Copying training dataset
2023-06-05 23:10:04,270:INFO:Defining folds
2023-06-05 23:10:04,270:INFO:Declaring metric variables
2023-06-05 23:10:04,270:INFO:Importing untrained model
2023-06-05 23:10:04,270:INFO:Decision Tree Regressor Imported successfully
2023-06-05 23:10:04,289:INFO:Starting cross validation
2023-06-05 23:10:04,291:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-05 23:10:04,686:INFO:Calculating mean and std
2023-06-05 23:10:04,686:INFO:Creating metrics dataframe
2023-06-05 23:10:04,720:INFO:Uploading results into container
2023-06-05 23:10:04,720:INFO:Uploading model into container now
2023-06-05 23:10:04,720:INFO:_master_model_container: 12
2023-06-05 23:10:04,720:INFO:_display_container: 2
2023-06-05 23:10:04,720:INFO:DecisionTreeRegressor(random_state=123)
2023-06-05 23:10:04,720:INFO:create_model() successfully completed......................................
2023-06-05 23:10:04,830:INFO:SubProcess create_model() end ==================================
2023-06-05 23:10:04,830:INFO:Creating metrics dataframe
2023-06-05 23:10:04,830:INFO:Initializing Random Forest Regressor
2023-06-05 23:10:04,830:INFO:Total runtime is 0.12057391802469888 minutes
2023-06-05 23:10:04,830:INFO:SubProcess create_model() called ==================================
2023-06-05 23:10:04,830:INFO:Initializing create_model()
2023-06-05 23:10:04,830:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020E25C00D90>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020E274E3700>, model_only=True, return_train_score=False, kwargs={})
2023-06-05 23:10:04,830:INFO:Checking exceptions
2023-06-05 23:10:04,830:INFO:Importing libraries
2023-06-05 23:10:04,830:INFO:Copying training dataset
2023-06-05 23:10:04,846:INFO:Defining folds
2023-06-05 23:10:04,846:INFO:Declaring metric variables
2023-06-05 23:10:04,846:INFO:Importing untrained model
2023-06-05 23:10:04,846:INFO:Random Forest Regressor Imported successfully
2023-06-05 23:10:04,884:INFO:Starting cross validation
2023-06-05 23:10:04,886:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-05 23:10:05,418:INFO:Calculating mean and std
2023-06-05 23:10:05,418:INFO:Creating metrics dataframe
2023-06-05 23:10:05,456:INFO:Uploading results into container
2023-06-05 23:10:05,456:INFO:Uploading model into container now
2023-06-05 23:10:05,456:INFO:_master_model_container: 13
2023-06-05 23:10:05,456:INFO:_display_container: 2
2023-06-05 23:10:05,456:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2023-06-05 23:10:05,456:INFO:create_model() successfully completed......................................
2023-06-05 23:10:05,566:INFO:SubProcess create_model() end ==================================
2023-06-05 23:10:05,566:INFO:Creating metrics dataframe
2023-06-05 23:10:05,591:INFO:Initializing Extra Trees Regressor
2023-06-05 23:10:05,591:INFO:Total runtime is 0.13324787219365436 minutes
2023-06-05 23:10:05,595:INFO:SubProcess create_model() called ==================================
2023-06-05 23:10:05,596:INFO:Initializing create_model()
2023-06-05 23:10:05,596:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020E25C00D90>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020E274E3700>, model_only=True, return_train_score=False, kwargs={})
2023-06-05 23:10:05,596:INFO:Checking exceptions
2023-06-05 23:10:05,596:INFO:Importing libraries
2023-06-05 23:10:05,596:INFO:Copying training dataset
2023-06-05 23:10:05,601:INFO:Defining folds
2023-06-05 23:10:05,605:INFO:Declaring metric variables
2023-06-05 23:10:05,608:INFO:Importing untrained model
2023-06-05 23:10:05,613:INFO:Extra Trees Regressor Imported successfully
2023-06-05 23:10:05,623:INFO:Starting cross validation
2023-06-05 23:10:05,625:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-05 23:10:06,142:INFO:Calculating mean and std
2023-06-05 23:10:06,142:INFO:Creating metrics dataframe
2023-06-05 23:10:06,184:INFO:Uploading results into container
2023-06-05 23:10:06,184:INFO:Uploading model into container now
2023-06-05 23:10:06,184:INFO:_master_model_container: 14
2023-06-05 23:10:06,184:INFO:_display_container: 2
2023-06-05 23:10:06,184:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-06-05 23:10:06,184:INFO:create_model() successfully completed......................................
2023-06-05 23:10:06,278:INFO:SubProcess create_model() end ==================================
2023-06-05 23:10:06,278:INFO:Creating metrics dataframe
2023-06-05 23:10:06,294:INFO:Initializing AdaBoost Regressor
2023-06-05 23:10:06,294:INFO:Total runtime is 0.14496978123982746 minutes
2023-06-05 23:10:06,305:INFO:SubProcess create_model() called ==================================
2023-06-05 23:10:06,306:INFO:Initializing create_model()
2023-06-05 23:10:06,306:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020E25C00D90>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020E274E3700>, model_only=True, return_train_score=False, kwargs={})
2023-06-05 23:10:06,306:INFO:Checking exceptions
2023-06-05 23:10:06,306:INFO:Importing libraries
2023-06-05 23:10:06,306:INFO:Copying training dataset
2023-06-05 23:10:06,311:INFO:Defining folds
2023-06-05 23:10:06,311:INFO:Declaring metric variables
2023-06-05 23:10:06,311:INFO:Importing untrained model
2023-06-05 23:10:06,311:INFO:AdaBoost Regressor Imported successfully
2023-06-05 23:10:06,329:INFO:Starting cross validation
2023-06-05 23:10:06,330:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-05 23:10:06,759:INFO:Calculating mean and std
2023-06-05 23:10:06,759:INFO:Creating metrics dataframe
2023-06-05 23:10:06,795:INFO:Uploading results into container
2023-06-05 23:10:06,795:INFO:Uploading model into container now
2023-06-05 23:10:06,795:INFO:_master_model_container: 15
2023-06-05 23:10:06,795:INFO:_display_container: 2
2023-06-05 23:10:06,795:INFO:AdaBoostRegressor(random_state=123)
2023-06-05 23:10:06,795:INFO:create_model() successfully completed......................................
2023-06-05 23:10:06,888:INFO:SubProcess create_model() end ==================================
2023-06-05 23:10:06,888:INFO:Creating metrics dataframe
2023-06-05 23:10:06,906:INFO:Initializing Gradient Boosting Regressor
2023-06-05 23:10:06,906:INFO:Total runtime is 0.15516693194707232 minutes
2023-06-05 23:10:06,906:INFO:SubProcess create_model() called ==================================
2023-06-05 23:10:06,906:INFO:Initializing create_model()
2023-06-05 23:10:06,906:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020E25C00D90>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020E274E3700>, model_only=True, return_train_score=False, kwargs={})
2023-06-05 23:10:06,906:INFO:Checking exceptions
2023-06-05 23:10:06,906:INFO:Importing libraries
2023-06-05 23:10:06,906:INFO:Copying training dataset
2023-06-05 23:10:06,922:INFO:Defining folds
2023-06-05 23:10:06,922:INFO:Declaring metric variables
2023-06-05 23:10:06,927:INFO:Importing untrained model
2023-06-05 23:10:06,933:INFO:Gradient Boosting Regressor Imported successfully
2023-06-05 23:10:06,941:INFO:Starting cross validation
2023-06-05 23:10:06,941:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-05 23:10:07,384:INFO:Calculating mean and std
2023-06-05 23:10:07,384:INFO:Creating metrics dataframe
2023-06-05 23:10:07,419:INFO:Uploading results into container
2023-06-05 23:10:07,419:INFO:Uploading model into container now
2023-06-05 23:10:07,419:INFO:_master_model_container: 16
2023-06-05 23:10:07,419:INFO:_display_container: 2
2023-06-05 23:10:07,419:INFO:GradientBoostingRegressor(random_state=123)
2023-06-05 23:10:07,419:INFO:create_model() successfully completed......................................
2023-06-05 23:10:07,550:INFO:SubProcess create_model() end ==================================
2023-06-05 23:10:07,550:INFO:Creating metrics dataframe
2023-06-05 23:10:07,562:INFO:Initializing Light Gradient Boosting Machine
2023-06-05 23:10:07,562:INFO:Total runtime is 0.16609621842702227 minutes
2023-06-05 23:10:07,565:INFO:SubProcess create_model() called ==================================
2023-06-05 23:10:07,565:INFO:Initializing create_model()
2023-06-05 23:10:07,566:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020E25C00D90>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020E274E3700>, model_only=True, return_train_score=False, kwargs={})
2023-06-05 23:10:07,566:INFO:Checking exceptions
2023-06-05 23:10:07,566:INFO:Importing libraries
2023-06-05 23:10:07,566:INFO:Copying training dataset
2023-06-05 23:10:07,571:INFO:Defining folds
2023-06-05 23:10:07,571:INFO:Declaring metric variables
2023-06-05 23:10:07,575:INFO:Importing untrained model
2023-06-05 23:10:07,578:INFO:Light Gradient Boosting Machine Imported successfully
2023-06-05 23:10:07,585:INFO:Starting cross validation
2023-06-05 23:10:07,587:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-05 23:10:08,014:INFO:Calculating mean and std
2023-06-05 23:10:08,014:INFO:Creating metrics dataframe
2023-06-05 23:10:08,062:INFO:Uploading results into container
2023-06-05 23:10:08,062:INFO:Uploading model into container now
2023-06-05 23:10:08,063:INFO:_master_model_container: 17
2023-06-05 23:10:08,063:INFO:_display_container: 2
2023-06-05 23:10:08,063:INFO:LGBMRegressor(random_state=123)
2023-06-05 23:10:08,063:INFO:create_model() successfully completed......................................
2023-06-05 23:10:08,154:INFO:SubProcess create_model() end ==================================
2023-06-05 23:10:08,154:INFO:Creating metrics dataframe
2023-06-05 23:10:08,169:INFO:Initializing Dummy Regressor
2023-06-05 23:10:08,169:INFO:Total runtime is 0.17622012694676714 minutes
2023-06-05 23:10:08,169:INFO:SubProcess create_model() called ==================================
2023-06-05 23:10:08,169:INFO:Initializing create_model()
2023-06-05 23:10:08,182:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020E25C00D90>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020E274E3700>, model_only=True, return_train_score=False, kwargs={})
2023-06-05 23:10:08,182:INFO:Checking exceptions
2023-06-05 23:10:08,182:INFO:Importing libraries
2023-06-05 23:10:08,182:INFO:Copying training dataset
2023-06-05 23:10:08,189:INFO:Defining folds
2023-06-05 23:10:08,189:INFO:Declaring metric variables
2023-06-05 23:10:08,190:INFO:Importing untrained model
2023-06-05 23:10:08,197:INFO:Dummy Regressor Imported successfully
2023-06-05 23:10:08,203:INFO:Starting cross validation
2023-06-05 23:10:08,205:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-05 23:10:08,604:INFO:Calculating mean and std
2023-06-05 23:10:08,605:INFO:Creating metrics dataframe
2023-06-05 23:10:08,639:INFO:Uploading results into container
2023-06-05 23:10:08,639:INFO:Uploading model into container now
2023-06-05 23:10:08,640:INFO:_master_model_container: 18
2023-06-05 23:10:08,640:INFO:_display_container: 2
2023-06-05 23:10:08,640:INFO:DummyRegressor()
2023-06-05 23:10:08,640:INFO:create_model() successfully completed......................................
2023-06-05 23:10:08,743:INFO:SubProcess create_model() end ==================================
2023-06-05 23:10:08,743:INFO:Creating metrics dataframe
2023-06-05 23:10:08,758:INFO:Initializing create_model()
2023-06-05 23:10:08,758:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020E25C00D90>, estimator=GradientBoostingRegressor(random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-05 23:10:08,758:INFO:Checking exceptions
2023-06-05 23:10:08,758:INFO:Importing libraries
2023-06-05 23:10:08,758:INFO:Copying training dataset
2023-06-05 23:10:08,771:INFO:Defining folds
2023-06-05 23:10:08,771:INFO:Declaring metric variables
2023-06-05 23:10:08,771:INFO:Importing untrained model
2023-06-05 23:10:08,771:INFO:Declaring custom model
2023-06-05 23:10:08,772:INFO:Gradient Boosting Regressor Imported successfully
2023-06-05 23:10:08,772:INFO:Cross validation set to False
2023-06-05 23:10:08,772:INFO:Fitting Model
2023-06-05 23:10:08,839:INFO:GradientBoostingRegressor(random_state=123)
2023-06-05 23:10:08,839:INFO:create_model() successfully completed......................................
2023-06-05 23:10:08,949:INFO:Creating Dashboard logs
2023-06-05 23:10:08,949:INFO:Model: Gradient Boosting Regressor
2023-06-05 23:10:09,008:INFO:Logged params: {'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': None, 'random_state': 123, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2023-06-05 23:10:09,099:INFO:Initializing predict_model()
2023-06-05 23:10:09,099:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020E25C00D90>, estimator=GradientBoostingRegressor(random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x0000020E2AD41C60>)
2023-06-05 23:10:09,099:INFO:Checking exceptions
2023-06-05 23:10:09,099:INFO:Preloading libraries
2023-06-05 23:10:09,440:INFO:Creating Dashboard logs
2023-06-05 23:10:09,440:INFO:Model: Random Forest Regressor
2023-06-05 23:10:09,508:INFO:Logged params: {'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': 1.0, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 123, 'verbose': 0, 'warm_start': False}
2023-06-05 23:10:09,766:INFO:Creating Dashboard logs
2023-06-05 23:10:09,766:INFO:Model: Extra Trees Regressor
2023-06-05 23:10:09,813:INFO:Logged params: {'bootstrap': False, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': 1.0, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 123, 'verbose': 0, 'warm_start': False}
2023-06-05 23:10:10,063:INFO:Creating Dashboard logs
2023-06-05 23:10:10,063:INFO:Model: Light Gradient Boosting Machine
2023-06-05 23:10:10,122:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 123, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-06-05 23:10:10,371:INFO:Creating Dashboard logs
2023-06-05 23:10:10,371:INFO:Model: Elastic Net
2023-06-05 23:10:10,431:INFO:Logged params: {'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'l1_ratio': 0.5, 'max_iter': 1000, 'normalize': 'deprecated', 'positive': False, 'precompute': False, 'random_state': 123, 'selection': 'cyclic', 'tol': 0.0001, 'warm_start': False}
2023-06-05 23:10:10,690:INFO:Creating Dashboard logs
2023-06-05 23:10:10,690:INFO:Model: Bayesian Ridge
2023-06-05 23:10:10,750:INFO:Logged params: {'alpha_1': 1e-06, 'alpha_2': 1e-06, 'alpha_init': None, 'compute_score': False, 'copy_X': True, 'fit_intercept': True, 'lambda_1': 1e-06, 'lambda_2': 1e-06, 'lambda_init': None, 'n_iter': 300, 'normalize': 'deprecated', 'tol': 0.001, 'verbose': False}
2023-06-05 23:10:10,986:INFO:Creating Dashboard logs
2023-06-05 23:10:10,986:INFO:Model: K Neighbors Regressor
2023-06-05 23:10:11,055:INFO:Logged params: {'algorithm': 'auto', 'leaf_size': 30, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': -1, 'n_neighbors': 5, 'p': 2, 'weights': 'uniform'}
2023-06-05 23:10:11,286:INFO:Creating Dashboard logs
2023-06-05 23:10:11,301:INFO:Model: Lasso Least Angle Regression
2023-06-05 23:10:11,332:INFO:Logged params: {'alpha': 1.0, 'copy_X': True, 'eps': 2.220446049250313e-16, 'fit_intercept': True, 'fit_path': True, 'jitter': None, 'max_iter': 500, 'normalize': 'deprecated', 'positive': False, 'precompute': 'auto', 'random_state': 123, 'verbose': False}
2023-06-05 23:10:11,584:INFO:Creating Dashboard logs
2023-06-05 23:10:11,584:INFO:Model: Orthogonal Matching Pursuit
2023-06-05 23:10:11,630:INFO:Logged params: {'fit_intercept': True, 'n_nonzero_coefs': None, 'normalize': 'deprecated', 'precompute': 'auto', 'tol': None}
2023-06-05 23:10:11,880:INFO:Creating Dashboard logs
2023-06-05 23:10:11,880:INFO:Model: Passive Aggressive Regressor
2023-06-05 23:10:11,922:INFO:Logged params: {'C': 1.0, 'average': False, 'early_stopping': False, 'epsilon': 0.1, 'fit_intercept': True, 'loss': 'epsilon_insensitive', 'max_iter': 1000, 'n_iter_no_change': 5, 'random_state': 123, 'shuffle': True, 'tol': 0.001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2023-06-05 23:10:12,189:INFO:Creating Dashboard logs
2023-06-05 23:10:12,205:INFO:Model: AdaBoost Regressor
2023-06-05 23:10:12,252:INFO:Logged params: {'base_estimator': None, 'learning_rate': 1.0, 'loss': 'linear', 'n_estimators': 50, 'random_state': 123}
2023-06-05 23:10:12,491:INFO:Creating Dashboard logs
2023-06-05 23:10:12,491:INFO:Model: Ridge Regression
2023-06-05 23:10:12,548:INFO:Logged params: {'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'normalize': 'deprecated', 'positive': False, 'random_state': 123, 'solver': 'auto', 'tol': 0.001}
2023-06-05 23:10:12,788:INFO:Creating Dashboard logs
2023-06-05 23:10:12,791:INFO:Model: Huber Regressor
2023-06-05 23:10:12,856:INFO:Logged params: {'alpha': 0.0001, 'epsilon': 1.35, 'fit_intercept': True, 'max_iter': 100, 'tol': 1e-05, 'warm_start': False}
2023-06-05 23:10:13,092:INFO:Creating Dashboard logs
2023-06-05 23:10:13,092:INFO:Model: Lasso Regression
2023-06-05 23:10:13,143:INFO:Logged params: {'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'max_iter': 1000, 'normalize': 'deprecated', 'positive': False, 'precompute': False, 'random_state': 123, 'selection': 'cyclic', 'tol': 0.0001, 'warm_start': False}
2023-06-05 23:10:13,386:INFO:Creating Dashboard logs
2023-06-05 23:10:13,386:INFO:Model: Decision Tree Regressor
2023-06-05 23:10:13,427:INFO:Logged params: {'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'random_state': 123, 'splitter': 'best'}
2023-06-05 23:10:13,679:INFO:Creating Dashboard logs
2023-06-05 23:10:13,679:INFO:Model: Dummy Regressor
2023-06-05 23:10:13,745:INFO:Logged params: {'constant': None, 'quantile': None, 'strategy': 'mean'}
2023-06-05 23:10:13,982:INFO:Creating Dashboard logs
2023-06-05 23:10:13,997:INFO:Model: Linear Regression
2023-06-05 23:10:14,044:INFO:Logged params: {'copy_X': True, 'fit_intercept': True, 'n_jobs': -1, 'normalize': 'deprecated', 'positive': False}
2023-06-05 23:10:14,271:INFO:Creating Dashboard logs
2023-06-05 23:10:14,287:INFO:Model: Least Angle Regression
2023-06-05 23:10:14,335:INFO:Logged params: {'copy_X': True, 'eps': 2.220446049250313e-16, 'fit_intercept': True, 'fit_path': True, 'jitter': None, 'n_nonzero_coefs': 500, 'normalize': 'deprecated', 'precompute': 'auto', 'random_state': 123, 'verbose': False}
2023-06-05 23:10:14,578:INFO:_master_model_container: 18
2023-06-05 23:10:14,578:INFO:_display_container: 2
2023-06-05 23:10:14,578:INFO:GradientBoostingRegressor(random_state=123)
2023-06-05 23:10:14,578:INFO:compare_models() successfully completed......................................
2023-06-05 23:10:59,036:INFO:PyCaret RegressionExperiment
2023-06-05 23:10:59,036:INFO:Logging name: your_experiment_name
2023-06-05 23:10:59,036:INFO:ML Usecase: MLUsecase.REGRESSION
2023-06-05 23:10:59,036:INFO:version 3.0.0
2023-06-05 23:10:59,036:INFO:Initializing setup()
2023-06-05 23:10:59,036:INFO:self.USI: c038
2023-06-05 23:10:59,036:INFO:self._variable_keys: {'pipeline', 'fold_shuffle_param', 'n_jobs_param', 'data', 'transform_target_param', 'exp_name_log', 'y', 'target_param', 'idx', '_ml_usecase', 'html_param', '_available_plots', 'y_test', 'USI', 'logging_param', 'gpu_param', 'X_train', 'gpu_n_jobs_param', 'seed', 'fold_groups_param', 'X', 'y_train', 'X_test', 'memory', 'log_plots_param', 'exp_id', 'fold_generator'}
2023-06-05 23:10:59,036:INFO:Checking environment
2023-06-05 23:10:59,036:INFO:python_version: 3.10.5
2023-06-05 23:10:59,036:INFO:python_build: ('tags/v3.10.5:f377153', 'Jun  6 2022 16:14:13')
2023-06-05 23:10:59,036:INFO:machine: AMD64
2023-06-05 23:10:59,036:INFO:platform: Windows-10-10.0.22621-SP0
2023-06-05 23:10:59,036:INFO:Memory: svmem(total=16497119232, available=6912413696, percent=58.1, used=9584705536, free=6912413696)
2023-06-05 23:10:59,037:INFO:Physical Core: 8
2023-06-05 23:10:59,037:INFO:Logical Core: 16
2023-06-05 23:10:59,037:INFO:Checking libraries
2023-06-05 23:10:59,037:INFO:System:
2023-06-05 23:10:59,037:INFO:    python: 3.10.5 (tags/v3.10.5:f377153, Jun  6 2022, 16:14:13) [MSC v.1929 64 bit (AMD64)]
2023-06-05 23:10:59,037:INFO:executable: C:\Users\Hashif\AppData\Local\Programs\Python\Python310\python.exe
2023-06-05 23:10:59,037:INFO:   machine: Windows-10-10.0.22621-SP0
2023-06-05 23:10:59,037:INFO:PyCaret required dependencies:
2023-06-05 23:10:59,037:INFO:                 pip: 23.1.1
2023-06-05 23:10:59,037:INFO:          setuptools: 58.1.0
2023-06-05 23:10:59,037:INFO:             pycaret: 3.0.0
2023-06-05 23:10:59,037:INFO:             IPython: 8.4.0
2023-06-05 23:10:59,037:INFO:          ipywidgets: 7.7.0
2023-06-05 23:10:59,037:INFO:                tqdm: 4.65.0
2023-06-05 23:10:59,037:INFO:               numpy: 1.23.0
2023-06-05 23:10:59,037:INFO:              pandas: 1.4.3
2023-06-05 23:10:59,037:INFO:              jinja2: 3.1.2
2023-06-05 23:10:59,037:INFO:               scipy: 1.9.3
2023-06-05 23:10:59,037:INFO:              joblib: 1.2.0
2023-06-05 23:10:59,037:INFO:             sklearn: 1.1.2
2023-06-05 23:10:59,037:INFO:                pyod: 1.0.9
2023-06-05 23:10:59,037:INFO:            imblearn: 0.10.1
2023-06-05 23:10:59,037:INFO:   category_encoders: 2.6.0
2023-06-05 23:10:59,037:INFO:            lightgbm: 3.3.5
2023-06-05 23:10:59,037:INFO:               numba: 0.56.4
2023-06-05 23:10:59,037:INFO:            requests: 2.28.1
2023-06-05 23:10:59,037:INFO:          matplotlib: 3.6.2
2023-06-05 23:10:59,037:INFO:          scikitplot: 0.3.7
2023-06-05 23:10:59,037:INFO:         yellowbrick: 1.5
2023-06-05 23:10:59,037:INFO:              plotly: 5.14.1
2023-06-05 23:10:59,037:INFO:             kaleido: 0.2.1
2023-06-05 23:10:59,037:INFO:         statsmodels: 0.13.5
2023-06-05 23:10:59,037:INFO:              sktime: 0.17.1
2023-06-05 23:10:59,038:INFO:               tbats: 1.1.3
2023-06-05 23:10:59,038:INFO:            pmdarima: 2.0.3
2023-06-05 23:10:59,038:INFO:              psutil: 5.9.1
2023-06-05 23:10:59,038:INFO:PyCaret optional dependencies:
2023-06-05 23:10:59,038:INFO:                shap: Not installed
2023-06-05 23:10:59,038:INFO:           interpret: Not installed
2023-06-05 23:10:59,038:INFO:                umap: Not installed
2023-06-05 23:10:59,038:INFO:    pandas_profiling: Not installed
2023-06-05 23:10:59,038:INFO:  explainerdashboard: Not installed
2023-06-05 23:10:59,038:INFO:             autoviz: Not installed
2023-06-05 23:10:59,038:INFO:           fairlearn: Not installed
2023-06-05 23:10:59,038:INFO:             xgboost: Not installed
2023-06-05 23:10:59,038:INFO:            catboost: Not installed
2023-06-05 23:10:59,038:INFO:              kmodes: Not installed
2023-06-05 23:10:59,038:INFO:             mlxtend: Not installed
2023-06-05 23:10:59,038:INFO:       statsforecast: Not installed
2023-06-05 23:10:59,038:INFO:        tune_sklearn: Not installed
2023-06-05 23:10:59,038:INFO:                 ray: Not installed
2023-06-05 23:10:59,038:INFO:            hyperopt: Not installed
2023-06-05 23:10:59,038:INFO:              optuna: Not installed
2023-06-05 23:10:59,038:INFO:               skopt: Not installed
2023-06-05 23:10:59,038:INFO:              mlflow: 2.3.0
2023-06-05 23:10:59,038:INFO:              gradio: Not installed
2023-06-05 23:10:59,038:INFO:             fastapi: Not installed
2023-06-05 23:10:59,038:INFO:             uvicorn: Not installed
2023-06-05 23:10:59,038:INFO:              m2cgen: Not installed
2023-06-05 23:10:59,038:INFO:           evidently: Not installed
2023-06-05 23:10:59,038:INFO:               fugue: Not installed
2023-06-05 23:10:59,038:INFO:           streamlit: Not installed
2023-06-05 23:10:59,038:INFO:             prophet: Not installed
2023-06-05 23:10:59,038:INFO:None
2023-06-05 23:10:59,038:INFO:Set up data.
2023-06-05 23:10:59,040:INFO:Set up train/test split.
2023-06-05 23:10:59,040:INFO:Set up index.
2023-06-05 23:10:59,040:INFO:Set up folding strategy.
2023-06-05 23:10:59,040:INFO:Assigning column types.
2023-06-05 23:10:59,040:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-06-05 23:10:59,040:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-06-05 23:10:59,040:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-06-05 23:10:59,056:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-05 23:10:59,103:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-05 23:10:59,154:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-05 23:10:59,155:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 23:10:59,155:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 23:10:59,155:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-06-05 23:10:59,159:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-06-05 23:10:59,164:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-05 23:10:59,212:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-05 23:10:59,259:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-05 23:10:59,259:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 23:10:59,259:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 23:10:59,259:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-06-05 23:10:59,259:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-06-05 23:10:59,259:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-05 23:10:59,322:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-05 23:10:59,369:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-05 23:10:59,369:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 23:10:59,369:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 23:10:59,369:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-06-05 23:10:59,389:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-05 23:10:59,438:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-05 23:10:59,478:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-05 23:10:59,478:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 23:10:59,478:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 23:10:59,478:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-06-05 23:10:59,494:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-05 23:10:59,541:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-05 23:10:59,592:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-05 23:10:59,592:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 23:10:59,592:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 23:10:59,592:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-05 23:10:59,651:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-05 23:10:59,692:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-05 23:10:59,692:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 23:10:59,692:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 23:10:59,698:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-06-05 23:10:59,745:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-05 23:10:59,792:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-05 23:10:59,792:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 23:10:59,792:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 23:10:59,855:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-05 23:10:59,902:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-05 23:10:59,902:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 23:10:59,902:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 23:10:59,902:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-06-05 23:10:59,965:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-05 23:11:00,012:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 23:11:00,012:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 23:11:00,107:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-05 23:11:00,151:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 23:11:00,151:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 23:11:00,151:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-06-05 23:11:00,266:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 23:11:00,266:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 23:11:00,385:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 23:11:00,385:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 23:11:00,385:INFO:Preparing preprocessing pipeline...
2023-06-05 23:11:00,385:INFO:Set up simple imputation.
2023-06-05 23:11:00,385:INFO:Set up feature normalization.
2023-06-05 23:11:00,394:INFO:Finished creating preprocessing pipeline.
2023-06-05 23:11:00,394:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Hashif\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['PC1', 'PC2'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))])
2023-06-05 23:11:00,408:INFO:Creating final display dataframe.
2023-06-05 23:11:00,470:INFO:Setup _display_container:                     Description                 Value
0                    Session id                   123
1                        Target                 price
2                   Target type            Regression
3           Original data shape              (735, 3)
4        Transformed data shape              (735, 3)
5   Transformed train set shape              (588, 3)
6    Transformed test set shape              (147, 3)
7              Numeric features                     2
8                    Preprocess                  True
9               Imputation type                simple
10           Numeric imputation                  mean
11       Categorical imputation                  mode
12                    Normalize                  True
13             Normalize method                zscore
14               Fold Generator                 KFold
15                  Fold Number                    10
16                     CPU Jobs                    -1
17                      Use GPU                 False
18               Log Experiment          MlflowLogger
19              Experiment Name  your_experiment_name
20                          USI                  c038
2023-06-05 23:11:00,580:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 23:11:00,580:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 23:11:00,694:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 23:11:00,694:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 23:11:00,694:INFO:Logging experiment in loggers
2023-06-05 23:11:00,772:INFO:SubProcess save_model() called ==================================
2023-06-05 23:11:00,779:INFO:Initializing save_model()
2023-06-05 23:11:00,779:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\Hashif\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['PC1', 'PC2'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))]), model_name=C:\Users\Hashif\AppData\Local\Temp\tmpmtzj8jlq\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\Hashif\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['PC1', 'PC2'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))]), verbose=False, use_case=MLUsecase.REGRESSION, kwargs={})
2023-06-05 23:11:00,779:INFO:Adding model into prep_pipe
2023-06-05 23:11:00,779:WARNING:Only Model saved as it was a pipeline.
2023-06-05 23:11:00,781:INFO:C:\Users\Hashif\AppData\Local\Temp\tmpmtzj8jlq\Transformation Pipeline.pkl saved in current working directory
2023-06-05 23:11:00,784:INFO:Pipeline(memory=FastMemory(location=C:\Users\Hashif\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['PC1', 'PC2'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))])
2023-06-05 23:11:00,784:INFO:save_model() successfully completed......................................
2023-06-05 23:11:00,910:INFO:SubProcess save_model() end ==================================
2023-06-05 23:11:00,964:INFO:setup() successfully completed in 1.68s...............
2023-06-05 23:11:00,988:INFO:Initializing compare_models()
2023-06-05 23:11:00,988:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020E2A974370>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x0000020E2A974370>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-06-05 23:11:00,988:INFO:Checking exceptions
2023-06-05 23:11:00,988:INFO:Preparing display monitor
2023-06-05 23:11:01,018:INFO:Initializing Linear Regression
2023-06-05 23:11:01,018:INFO:Total runtime is 0.0 minutes
2023-06-05 23:11:01,021:INFO:SubProcess create_model() called ==================================
2023-06-05 23:11:01,021:INFO:Initializing create_model()
2023-06-05 23:11:01,022:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020E2A974370>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020E2A50BB50>, model_only=True, return_train_score=False, kwargs={})
2023-06-05 23:11:01,022:INFO:Checking exceptions
2023-06-05 23:11:01,022:INFO:Importing libraries
2023-06-05 23:11:01,022:INFO:Copying training dataset
2023-06-05 23:11:01,026:INFO:Defining folds
2023-06-05 23:11:01,026:INFO:Declaring metric variables
2023-06-05 23:11:01,030:INFO:Importing untrained model
2023-06-05 23:11:01,034:INFO:Linear Regression Imported successfully
2023-06-05 23:11:01,040:INFO:Starting cross validation
2023-06-05 23:11:01,043:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-05 23:11:01,370:INFO:Calculating mean and std
2023-06-05 23:11:01,370:INFO:Creating metrics dataframe
2023-06-05 23:11:01,402:INFO:Uploading results into container
2023-06-05 23:11:01,402:INFO:Uploading model into container now
2023-06-05 23:11:01,402:INFO:_master_model_container: 1
2023-06-05 23:11:01,402:INFO:_display_container: 2
2023-06-05 23:11:01,402:INFO:LinearRegression(n_jobs=-1)
2023-06-05 23:11:01,402:INFO:create_model() successfully completed......................................
2023-06-05 23:11:01,527:INFO:SubProcess create_model() end ==================================
2023-06-05 23:11:01,527:INFO:Creating metrics dataframe
2023-06-05 23:11:01,527:INFO:Initializing Lasso Regression
2023-06-05 23:11:01,527:INFO:Total runtime is 0.008491305510203044 minutes
2023-06-05 23:11:01,543:INFO:SubProcess create_model() called ==================================
2023-06-05 23:11:01,543:INFO:Initializing create_model()
2023-06-05 23:11:01,543:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020E2A974370>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020E2A50BB50>, model_only=True, return_train_score=False, kwargs={})
2023-06-05 23:11:01,543:INFO:Checking exceptions
2023-06-05 23:11:01,543:INFO:Importing libraries
2023-06-05 23:11:01,543:INFO:Copying training dataset
2023-06-05 23:11:01,549:INFO:Defining folds
2023-06-05 23:11:01,549:INFO:Declaring metric variables
2023-06-05 23:11:01,552:INFO:Importing untrained model
2023-06-05 23:11:01,557:INFO:Lasso Regression Imported successfully
2023-06-05 23:11:01,563:INFO:Starting cross validation
2023-06-05 23:11:01,565:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-05 23:11:01,885:INFO:Calculating mean and std
2023-06-05 23:11:01,885:INFO:Creating metrics dataframe
2023-06-05 23:11:01,927:INFO:Uploading results into container
2023-06-05 23:11:01,927:INFO:Uploading model into container now
2023-06-05 23:11:01,928:INFO:_master_model_container: 2
2023-06-05 23:11:01,928:INFO:_display_container: 2
2023-06-05 23:11:01,928:INFO:Lasso(random_state=123)
2023-06-05 23:11:01,928:INFO:create_model() successfully completed......................................
2023-06-05 23:11:02,034:INFO:SubProcess create_model() end ==================================
2023-06-05 23:11:02,034:INFO:Creating metrics dataframe
2023-06-05 23:11:02,041:INFO:Initializing Ridge Regression
2023-06-05 23:11:02,041:INFO:Total runtime is 0.017058372497558594 minutes
2023-06-05 23:11:02,044:INFO:SubProcess create_model() called ==================================
2023-06-05 23:11:02,045:INFO:Initializing create_model()
2023-06-05 23:11:02,045:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020E2A974370>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020E2A50BB50>, model_only=True, return_train_score=False, kwargs={})
2023-06-05 23:11:02,045:INFO:Checking exceptions
2023-06-05 23:11:02,045:INFO:Importing libraries
2023-06-05 23:11:02,045:INFO:Copying training dataset
2023-06-05 23:11:02,048:INFO:Defining folds
2023-06-05 23:11:02,049:INFO:Declaring metric variables
2023-06-05 23:11:02,052:INFO:Importing untrained model
2023-06-05 23:11:02,056:INFO:Ridge Regression Imported successfully
2023-06-05 23:11:02,065:INFO:Starting cross validation
2023-06-05 23:11:02,066:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-05 23:11:02,392:INFO:Calculating mean and std
2023-06-05 23:11:02,397:INFO:Creating metrics dataframe
2023-06-05 23:11:02,435:INFO:Uploading results into container
2023-06-05 23:11:02,435:INFO:Uploading model into container now
2023-06-05 23:11:02,435:INFO:_master_model_container: 3
2023-06-05 23:11:02,435:INFO:_display_container: 2
2023-06-05 23:11:02,435:INFO:Ridge(random_state=123)
2023-06-05 23:11:02,435:INFO:create_model() successfully completed......................................
2023-06-05 23:11:02,559:INFO:SubProcess create_model() end ==================================
2023-06-05 23:11:02,559:INFO:Creating metrics dataframe
2023-06-05 23:11:02,569:INFO:Initializing Elastic Net
2023-06-05 23:11:02,569:INFO:Total runtime is 0.025858541329701744 minutes
2023-06-05 23:11:02,573:INFO:SubProcess create_model() called ==================================
2023-06-05 23:11:02,574:INFO:Initializing create_model()
2023-06-05 23:11:02,574:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020E2A974370>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020E2A50BB50>, model_only=True, return_train_score=False, kwargs={})
2023-06-05 23:11:02,574:INFO:Checking exceptions
2023-06-05 23:11:02,574:INFO:Importing libraries
2023-06-05 23:11:02,574:INFO:Copying training dataset
2023-06-05 23:11:02,579:INFO:Defining folds
2023-06-05 23:11:02,579:INFO:Declaring metric variables
2023-06-05 23:11:02,583:INFO:Importing untrained model
2023-06-05 23:11:02,587:INFO:Elastic Net Imported successfully
2023-06-05 23:11:02,595:INFO:Starting cross validation
2023-06-05 23:11:02,596:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-05 23:11:02,928:INFO:Calculating mean and std
2023-06-05 23:11:02,929:INFO:Creating metrics dataframe
2023-06-05 23:11:02,970:INFO:Uploading results into container
2023-06-05 23:11:02,971:INFO:Uploading model into container now
2023-06-05 23:11:02,971:INFO:_master_model_container: 4
2023-06-05 23:11:02,971:INFO:_display_container: 2
2023-06-05 23:11:02,971:INFO:ElasticNet(random_state=123)
2023-06-05 23:11:02,971:INFO:create_model() successfully completed......................................
2023-06-05 23:11:03,087:INFO:SubProcess create_model() end ==================================
2023-06-05 23:11:03,088:INFO:Creating metrics dataframe
2023-06-05 23:11:03,096:INFO:Initializing Least Angle Regression
2023-06-05 23:11:03,096:INFO:Total runtime is 0.03462624152501424 minutes
2023-06-05 23:11:03,100:INFO:SubProcess create_model() called ==================================
2023-06-05 23:11:03,100:INFO:Initializing create_model()
2023-06-05 23:11:03,101:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020E2A974370>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020E2A50BB50>, model_only=True, return_train_score=False, kwargs={})
2023-06-05 23:11:03,101:INFO:Checking exceptions
2023-06-05 23:11:03,101:INFO:Importing libraries
2023-06-05 23:11:03,101:INFO:Copying training dataset
2023-06-05 23:11:03,108:INFO:Defining folds
2023-06-05 23:11:03,108:INFO:Declaring metric variables
2023-06-05 23:11:03,114:INFO:Importing untrained model
2023-06-05 23:11:03,118:INFO:Least Angle Regression Imported successfully
2023-06-05 23:11:03,126:INFO:Starting cross validation
2023-06-05 23:11:03,127:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-05 23:11:03,176:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-06-05 23:11:03,189:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-06-05 23:11:03,204:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-06-05 23:11:03,210:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-06-05 23:11:03,217:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-06-05 23:11:03,224:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-06-05 23:11:03,233:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-06-05 23:11:03,245:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-06-05 23:11:03,253:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-06-05 23:11:03,263:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-06-05 23:11:03,472:INFO:Calculating mean and std
2023-06-05 23:11:03,472:INFO:Creating metrics dataframe
2023-06-05 23:11:03,516:INFO:Uploading results into container
2023-06-05 23:11:03,517:INFO:Uploading model into container now
2023-06-05 23:11:03,517:INFO:_master_model_container: 5
2023-06-05 23:11:03,517:INFO:_display_container: 2
2023-06-05 23:11:03,517:INFO:Lars(random_state=123)
2023-06-05 23:11:03,517:INFO:create_model() successfully completed......................................
2023-06-05 23:11:03,635:INFO:SubProcess create_model() end ==================================
2023-06-05 23:11:03,635:INFO:Creating metrics dataframe
2023-06-05 23:11:03,647:INFO:Initializing Lasso Least Angle Regression
2023-06-05 23:11:03,647:INFO:Total runtime is 0.04381932417551677 minutes
2023-06-05 23:11:03,654:INFO:SubProcess create_model() called ==================================
2023-06-05 23:11:03,655:INFO:Initializing create_model()
2023-06-05 23:11:03,655:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020E2A974370>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020E2A50BB50>, model_only=True, return_train_score=False, kwargs={})
2023-06-05 23:11:03,655:INFO:Checking exceptions
2023-06-05 23:11:03,655:INFO:Importing libraries
2023-06-05 23:11:03,655:INFO:Copying training dataset
2023-06-05 23:11:03,660:INFO:Defining folds
2023-06-05 23:11:03,660:INFO:Declaring metric variables
2023-06-05 23:11:03,663:INFO:Importing untrained model
2023-06-05 23:11:03,667:INFO:Lasso Least Angle Regression Imported successfully
2023-06-05 23:11:03,675:INFO:Starting cross validation
2023-06-05 23:11:03,677:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-05 23:11:03,727:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-06-05 23:11:03,732:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-06-05 23:11:03,748:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-06-05 23:11:03,754:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-06-05 23:11:03,759:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-06-05 23:11:03,784:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-06-05 23:11:03,791:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-06-05 23:11:03,799:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-06-05 23:11:03,813:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-06-05 23:11:03,813:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-06-05 23:11:04,010:INFO:Calculating mean and std
2023-06-05 23:11:04,010:INFO:Creating metrics dataframe
2023-06-05 23:11:04,060:INFO:Uploading results into container
2023-06-05 23:11:04,061:INFO:Uploading model into container now
2023-06-05 23:11:04,061:INFO:_master_model_container: 6
2023-06-05 23:11:04,061:INFO:_display_container: 2
2023-06-05 23:11:04,061:INFO:LassoLars(random_state=123)
2023-06-05 23:11:04,061:INFO:create_model() successfully completed......................................
2023-06-05 23:11:04,155:INFO:SubProcess create_model() end ==================================
2023-06-05 23:11:04,155:INFO:Creating metrics dataframe
2023-06-05 23:11:04,171:INFO:Initializing Orthogonal Matching Pursuit
2023-06-05 23:11:04,171:INFO:Total runtime is 0.05254406531651815 minutes
2023-06-05 23:11:04,171:INFO:SubProcess create_model() called ==================================
2023-06-05 23:11:04,171:INFO:Initializing create_model()
2023-06-05 23:11:04,171:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020E2A974370>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020E2A50BB50>, model_only=True, return_train_score=False, kwargs={})
2023-06-05 23:11:04,171:INFO:Checking exceptions
2023-06-05 23:11:04,171:INFO:Importing libraries
2023-06-05 23:11:04,171:INFO:Copying training dataset
2023-06-05 23:11:04,182:INFO:Defining folds
2023-06-05 23:11:04,182:INFO:Declaring metric variables
2023-06-05 23:11:04,185:INFO:Importing untrained model
2023-06-05 23:11:04,189:INFO:Orthogonal Matching Pursuit Imported successfully
2023-06-05 23:11:04,197:INFO:Starting cross validation
2023-06-05 23:11:04,199:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-05 23:11:04,243:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-06-05 23:11:04,243:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-06-05 23:11:04,243:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-06-05 23:11:04,263:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-06-05 23:11:04,275:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-06-05 23:11:04,275:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-06-05 23:11:04,297:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-06-05 23:11:04,306:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-06-05 23:11:04,322:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-06-05 23:11:04,322:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-06-05 23:11:04,527:INFO:Calculating mean and std
2023-06-05 23:11:04,527:INFO:Creating metrics dataframe
2023-06-05 23:11:04,563:INFO:Uploading results into container
2023-06-05 23:11:04,564:INFO:Uploading model into container now
2023-06-05 23:11:04,565:INFO:_master_model_container: 7
2023-06-05 23:11:04,565:INFO:_display_container: 2
2023-06-05 23:11:04,565:INFO:OrthogonalMatchingPursuit()
2023-06-05 23:11:04,565:INFO:create_model() successfully completed......................................
2023-06-05 23:11:04,669:INFO:SubProcess create_model() end ==================================
2023-06-05 23:11:04,669:INFO:Creating metrics dataframe
2023-06-05 23:11:04,685:INFO:Initializing Bayesian Ridge
2023-06-05 23:11:04,685:INFO:Total runtime is 0.06111594835917156 minutes
2023-06-05 23:11:04,694:INFO:SubProcess create_model() called ==================================
2023-06-05 23:11:04,694:INFO:Initializing create_model()
2023-06-05 23:11:04,694:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020E2A974370>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020E2A50BB50>, model_only=True, return_train_score=False, kwargs={})
2023-06-05 23:11:04,694:INFO:Checking exceptions
2023-06-05 23:11:04,694:INFO:Importing libraries
2023-06-05 23:11:04,694:INFO:Copying training dataset
2023-06-05 23:11:04,698:INFO:Defining folds
2023-06-05 23:11:04,698:INFO:Declaring metric variables
2023-06-05 23:11:04,704:INFO:Importing untrained model
2023-06-05 23:11:04,707:INFO:Bayesian Ridge Imported successfully
2023-06-05 23:11:04,716:INFO:Starting cross validation
2023-06-05 23:11:04,717:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-05 23:11:05,046:INFO:Calculating mean and std
2023-06-05 23:11:05,046:INFO:Creating metrics dataframe
2023-06-05 23:11:05,086:INFO:Uploading results into container
2023-06-05 23:11:05,086:INFO:Uploading model into container now
2023-06-05 23:11:05,087:INFO:_master_model_container: 8
2023-06-05 23:11:05,087:INFO:_display_container: 2
2023-06-05 23:11:05,087:INFO:BayesianRidge()
2023-06-05 23:11:05,087:INFO:create_model() successfully completed......................................
2023-06-05 23:11:05,189:INFO:SubProcess create_model() end ==================================
2023-06-05 23:11:05,189:INFO:Creating metrics dataframe
2023-06-05 23:11:05,198:INFO:Initializing Passive Aggressive Regressor
2023-06-05 23:11:05,198:INFO:Total runtime is 0.06967352231343588 minutes
2023-06-05 23:11:05,205:INFO:SubProcess create_model() called ==================================
2023-06-05 23:11:05,206:INFO:Initializing create_model()
2023-06-05 23:11:05,206:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020E2A974370>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020E2A50BB50>, model_only=True, return_train_score=False, kwargs={})
2023-06-05 23:11:05,206:INFO:Checking exceptions
2023-06-05 23:11:05,206:INFO:Importing libraries
2023-06-05 23:11:05,206:INFO:Copying training dataset
2023-06-05 23:11:05,207:INFO:Defining folds
2023-06-05 23:11:05,207:INFO:Declaring metric variables
2023-06-05 23:11:05,207:INFO:Importing untrained model
2023-06-05 23:11:05,220:INFO:Passive Aggressive Regressor Imported successfully
2023-06-05 23:11:05,227:INFO:Starting cross validation
2023-06-05 23:11:05,227:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-05 23:11:05,559:INFO:Calculating mean and std
2023-06-05 23:11:05,559:INFO:Creating metrics dataframe
2023-06-05 23:11:05,608:INFO:Uploading results into container
2023-06-05 23:11:05,608:INFO:Uploading model into container now
2023-06-05 23:11:05,608:INFO:_master_model_container: 9
2023-06-05 23:11:05,608:INFO:_display_container: 2
2023-06-05 23:11:05,608:INFO:PassiveAggressiveRegressor(random_state=123)
2023-06-05 23:11:05,608:INFO:create_model() successfully completed......................................
2023-06-05 23:11:05,718:INFO:SubProcess create_model() end ==================================
2023-06-05 23:11:05,718:INFO:Creating metrics dataframe
2023-06-05 23:11:05,718:INFO:Initializing Huber Regressor
2023-06-05 23:11:05,718:INFO:Total runtime is 0.07833966414133708 minutes
2023-06-05 23:11:05,737:INFO:SubProcess create_model() called ==================================
2023-06-05 23:11:05,737:INFO:Initializing create_model()
2023-06-05 23:11:05,737:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020E2A974370>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020E2A50BB50>, model_only=True, return_train_score=False, kwargs={})
2023-06-05 23:11:05,737:INFO:Checking exceptions
2023-06-05 23:11:05,737:INFO:Importing libraries
2023-06-05 23:11:05,737:INFO:Copying training dataset
2023-06-05 23:11:05,739:INFO:Defining folds
2023-06-05 23:11:05,739:INFO:Declaring metric variables
2023-06-05 23:11:05,739:INFO:Importing untrained model
2023-06-05 23:11:05,739:INFO:Huber Regressor Imported successfully
2023-06-05 23:11:05,754:INFO:Starting cross validation
2023-06-05 23:11:05,754:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-05 23:11:06,103:INFO:Calculating mean and std
2023-06-05 23:11:06,103:INFO:Creating metrics dataframe
2023-06-05 23:11:06,136:INFO:Uploading results into container
2023-06-05 23:11:06,136:INFO:Uploading model into container now
2023-06-05 23:11:06,136:INFO:_master_model_container: 10
2023-06-05 23:11:06,136:INFO:_display_container: 2
2023-06-05 23:11:06,136:INFO:HuberRegressor()
2023-06-05 23:11:06,136:INFO:create_model() successfully completed......................................
2023-06-05 23:11:06,246:INFO:SubProcess create_model() end ==================================
2023-06-05 23:11:06,246:INFO:Creating metrics dataframe
2023-06-05 23:11:06,246:INFO:Initializing K Neighbors Regressor
2023-06-05 23:11:06,246:INFO:Total runtime is 0.0871288537979126 minutes
2023-06-05 23:11:06,263:INFO:SubProcess create_model() called ==================================
2023-06-05 23:11:06,263:INFO:Initializing create_model()
2023-06-05 23:11:06,263:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020E2A974370>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020E2A50BB50>, model_only=True, return_train_score=False, kwargs={})
2023-06-05 23:11:06,263:INFO:Checking exceptions
2023-06-05 23:11:06,264:INFO:Importing libraries
2023-06-05 23:11:06,264:INFO:Copying training dataset
2023-06-05 23:11:06,267:INFO:Defining folds
2023-06-05 23:11:06,267:INFO:Declaring metric variables
2023-06-05 23:11:06,267:INFO:Importing untrained model
2023-06-05 23:11:06,267:INFO:K Neighbors Regressor Imported successfully
2023-06-05 23:11:06,282:INFO:Starting cross validation
2023-06-05 23:11:06,288:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-05 23:11:06,634:INFO:Calculating mean and std
2023-06-05 23:11:06,634:INFO:Creating metrics dataframe
2023-06-05 23:11:06,677:INFO:Uploading results into container
2023-06-05 23:11:06,677:INFO:Uploading model into container now
2023-06-05 23:11:06,677:INFO:_master_model_container: 11
2023-06-05 23:11:06,677:INFO:_display_container: 2
2023-06-05 23:11:06,677:INFO:KNeighborsRegressor(n_jobs=-1)
2023-06-05 23:11:06,677:INFO:create_model() successfully completed......................................
2023-06-05 23:11:06,787:INFO:SubProcess create_model() end ==================================
2023-06-05 23:11:06,787:INFO:Creating metrics dataframe
2023-06-05 23:11:06,803:INFO:Initializing Decision Tree Regressor
2023-06-05 23:11:06,803:INFO:Total runtime is 0.09641912778218588 minutes
2023-06-05 23:11:06,812:INFO:SubProcess create_model() called ==================================
2023-06-05 23:11:06,812:INFO:Initializing create_model()
2023-06-05 23:11:06,813:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020E2A974370>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020E2A50BB50>, model_only=True, return_train_score=False, kwargs={})
2023-06-05 23:11:06,813:INFO:Checking exceptions
2023-06-05 23:11:06,813:INFO:Importing libraries
2023-06-05 23:11:06,813:INFO:Copying training dataset
2023-06-05 23:11:06,816:INFO:Defining folds
2023-06-05 23:11:06,816:INFO:Declaring metric variables
2023-06-05 23:11:06,816:INFO:Importing untrained model
2023-06-05 23:11:06,816:INFO:Decision Tree Regressor Imported successfully
2023-06-05 23:11:06,831:INFO:Starting cross validation
2023-06-05 23:11:06,836:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-05 23:11:07,169:INFO:Calculating mean and std
2023-06-05 23:11:07,169:INFO:Creating metrics dataframe
2023-06-05 23:11:07,211:INFO:Uploading results into container
2023-06-05 23:11:07,211:INFO:Uploading model into container now
2023-06-05 23:11:07,211:INFO:_master_model_container: 12
2023-06-05 23:11:07,211:INFO:_display_container: 2
2023-06-05 23:11:07,211:INFO:DecisionTreeRegressor(random_state=123)
2023-06-05 23:11:07,211:INFO:create_model() successfully completed......................................
2023-06-05 23:11:07,321:INFO:SubProcess create_model() end ==================================
2023-06-05 23:11:07,321:INFO:Creating metrics dataframe
2023-06-05 23:11:07,321:INFO:Initializing Random Forest Regressor
2023-06-05 23:11:07,321:INFO:Total runtime is 0.10505549510320028 minutes
2023-06-05 23:11:07,334:INFO:SubProcess create_model() called ==================================
2023-06-05 23:11:07,334:INFO:Initializing create_model()
2023-06-05 23:11:07,334:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020E2A974370>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020E2A50BB50>, model_only=True, return_train_score=False, kwargs={})
2023-06-05 23:11:07,334:INFO:Checking exceptions
2023-06-05 23:11:07,335:INFO:Importing libraries
2023-06-05 23:11:07,335:INFO:Copying training dataset
2023-06-05 23:11:07,338:INFO:Defining folds
2023-06-05 23:11:07,338:INFO:Declaring metric variables
2023-06-05 23:11:07,338:INFO:Importing untrained model
2023-06-05 23:11:07,338:INFO:Random Forest Regressor Imported successfully
2023-06-05 23:11:07,350:INFO:Starting cross validation
2023-06-05 23:11:07,357:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-05 23:11:08,102:INFO:Calculating mean and std
2023-06-05 23:11:08,102:INFO:Creating metrics dataframe
2023-06-05 23:11:08,150:INFO:Uploading results into container
2023-06-05 23:11:08,150:INFO:Uploading model into container now
2023-06-05 23:11:08,150:INFO:_master_model_container: 13
2023-06-05 23:11:08,150:INFO:_display_container: 2
2023-06-05 23:11:08,150:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2023-06-05 23:11:08,150:INFO:create_model() successfully completed......................................
2023-06-05 23:11:08,259:INFO:SubProcess create_model() end ==================================
2023-06-05 23:11:08,259:INFO:Creating metrics dataframe
2023-06-05 23:11:08,259:INFO:Initializing Extra Trees Regressor
2023-06-05 23:11:08,259:INFO:Total runtime is 0.12069121599197388 minutes
2023-06-05 23:11:08,273:INFO:SubProcess create_model() called ==================================
2023-06-05 23:11:08,273:INFO:Initializing create_model()
2023-06-05 23:11:08,273:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020E2A974370>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020E2A50BB50>, model_only=True, return_train_score=False, kwargs={})
2023-06-05 23:11:08,273:INFO:Checking exceptions
2023-06-05 23:11:08,273:INFO:Importing libraries
2023-06-05 23:11:08,273:INFO:Copying training dataset
2023-06-05 23:11:08,273:INFO:Defining folds
2023-06-05 23:11:08,273:INFO:Declaring metric variables
2023-06-05 23:11:08,273:INFO:Importing untrained model
2023-06-05 23:11:08,273:INFO:Extra Trees Regressor Imported successfully
2023-06-05 23:11:08,293:INFO:Starting cross validation
2023-06-05 23:11:08,293:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-05 23:11:09,018:INFO:Calculating mean and std
2023-06-05 23:11:09,034:INFO:Creating metrics dataframe
2023-06-05 23:11:09,085:INFO:Uploading results into container
2023-06-05 23:11:09,085:INFO:Uploading model into container now
2023-06-05 23:11:09,085:INFO:_master_model_container: 14
2023-06-05 23:11:09,085:INFO:_display_container: 2
2023-06-05 23:11:09,085:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-06-05 23:11:09,085:INFO:create_model() successfully completed......................................
2023-06-05 23:11:09,212:INFO:SubProcess create_model() end ==================================
2023-06-05 23:11:09,212:INFO:Creating metrics dataframe
2023-06-05 23:11:09,212:INFO:Initializing AdaBoost Regressor
2023-06-05 23:11:09,228:INFO:Total runtime is 0.13683480024337769 minutes
2023-06-05 23:11:09,232:INFO:SubProcess create_model() called ==================================
2023-06-05 23:11:09,232:INFO:Initializing create_model()
2023-06-05 23:11:09,232:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020E2A974370>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020E2A50BB50>, model_only=True, return_train_score=False, kwargs={})
2023-06-05 23:11:09,232:INFO:Checking exceptions
2023-06-05 23:11:09,232:INFO:Importing libraries
2023-06-05 23:11:09,233:INFO:Copying training dataset
2023-06-05 23:11:09,237:INFO:Defining folds
2023-06-05 23:11:09,237:INFO:Declaring metric variables
2023-06-05 23:11:09,237:INFO:Importing untrained model
2023-06-05 23:11:09,237:INFO:AdaBoost Regressor Imported successfully
2023-06-05 23:11:09,257:INFO:Starting cross validation
2023-06-05 23:11:09,258:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-05 23:11:09,700:INFO:Calculating mean and std
2023-06-05 23:11:09,705:INFO:Creating metrics dataframe
2023-06-05 23:11:09,736:INFO:Uploading results into container
2023-06-05 23:11:09,736:INFO:Uploading model into container now
2023-06-05 23:11:09,736:INFO:_master_model_container: 15
2023-06-05 23:11:09,736:INFO:_display_container: 2
2023-06-05 23:11:09,736:INFO:AdaBoostRegressor(random_state=123)
2023-06-05 23:11:09,736:INFO:create_model() successfully completed......................................
2023-06-05 23:11:09,846:INFO:SubProcess create_model() end ==================================
2023-06-05 23:11:09,846:INFO:Creating metrics dataframe
2023-06-05 23:11:09,862:INFO:Initializing Gradient Boosting Regressor
2023-06-05 23:11:09,862:INFO:Total runtime is 0.1473980704943339 minutes
2023-06-05 23:11:09,874:INFO:SubProcess create_model() called ==================================
2023-06-05 23:11:09,874:INFO:Initializing create_model()
2023-06-05 23:11:09,874:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020E2A974370>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020E2A50BB50>, model_only=True, return_train_score=False, kwargs={})
2023-06-05 23:11:09,874:INFO:Checking exceptions
2023-06-05 23:11:09,874:INFO:Importing libraries
2023-06-05 23:11:09,874:INFO:Copying training dataset
2023-06-05 23:11:09,883:INFO:Defining folds
2023-06-05 23:11:09,883:INFO:Declaring metric variables
2023-06-05 23:11:09,894:INFO:Importing untrained model
2023-06-05 23:11:09,902:INFO:Gradient Boosting Regressor Imported successfully
2023-06-05 23:11:09,915:INFO:Starting cross validation
2023-06-05 23:11:09,916:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-05 23:11:10,406:INFO:Calculating mean and std
2023-06-05 23:11:10,406:INFO:Creating metrics dataframe
2023-06-05 23:11:10,443:INFO:Uploading results into container
2023-06-05 23:11:10,443:INFO:Uploading model into container now
2023-06-05 23:11:10,458:INFO:_master_model_container: 16
2023-06-05 23:11:10,458:INFO:_display_container: 2
2023-06-05 23:11:10,458:INFO:GradientBoostingRegressor(random_state=123)
2023-06-05 23:11:10,458:INFO:create_model() successfully completed......................................
2023-06-05 23:11:10,553:INFO:SubProcess create_model() end ==================================
2023-06-05 23:11:10,553:INFO:Creating metrics dataframe
2023-06-05 23:11:10,569:INFO:Initializing Light Gradient Boosting Machine
2023-06-05 23:11:10,569:INFO:Total runtime is 0.15917879740397134 minutes
2023-06-05 23:11:10,579:INFO:SubProcess create_model() called ==================================
2023-06-05 23:11:10,581:INFO:Initializing create_model()
2023-06-05 23:11:10,581:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020E2A974370>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020E2A50BB50>, model_only=True, return_train_score=False, kwargs={})
2023-06-05 23:11:10,581:INFO:Checking exceptions
2023-06-05 23:11:10,581:INFO:Importing libraries
2023-06-05 23:11:10,581:INFO:Copying training dataset
2023-06-05 23:11:10,583:INFO:Defining folds
2023-06-05 23:11:10,583:INFO:Declaring metric variables
2023-06-05 23:11:10,583:INFO:Importing untrained model
2023-06-05 23:11:10,583:INFO:Light Gradient Boosting Machine Imported successfully
2023-06-05 23:11:10,602:INFO:Starting cross validation
2023-06-05 23:11:10,603:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-05 23:11:11,031:INFO:Calculating mean and std
2023-06-05 23:11:11,031:INFO:Creating metrics dataframe
2023-06-05 23:11:11,072:INFO:Uploading results into container
2023-06-05 23:11:11,072:INFO:Uploading model into container now
2023-06-05 23:11:11,072:INFO:_master_model_container: 17
2023-06-05 23:11:11,072:INFO:_display_container: 2
2023-06-05 23:11:11,072:INFO:LGBMRegressor(random_state=123)
2023-06-05 23:11:11,072:INFO:create_model() successfully completed......................................
2023-06-05 23:11:11,182:INFO:SubProcess create_model() end ==================================
2023-06-05 23:11:11,182:INFO:Creating metrics dataframe
2023-06-05 23:11:11,198:INFO:Initializing Dummy Regressor
2023-06-05 23:11:11,198:INFO:Total runtime is 0.16966682672500608 minutes
2023-06-05 23:11:11,205:INFO:SubProcess create_model() called ==================================
2023-06-05 23:11:11,207:INFO:Initializing create_model()
2023-06-05 23:11:11,207:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020E2A974370>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020E2A50BB50>, model_only=True, return_train_score=False, kwargs={})
2023-06-05 23:11:11,207:INFO:Checking exceptions
2023-06-05 23:11:11,207:INFO:Importing libraries
2023-06-05 23:11:11,207:INFO:Copying training dataset
2023-06-05 23:11:11,208:INFO:Defining folds
2023-06-05 23:11:11,208:INFO:Declaring metric variables
2023-06-05 23:11:11,208:INFO:Importing untrained model
2023-06-05 23:11:11,208:INFO:Dummy Regressor Imported successfully
2023-06-05 23:11:11,228:INFO:Starting cross validation
2023-06-05 23:11:11,229:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-05 23:11:11,593:INFO:Calculating mean and std
2023-06-05 23:11:11,593:INFO:Creating metrics dataframe
2023-06-05 23:11:11,646:INFO:Uploading results into container
2023-06-05 23:11:11,646:INFO:Uploading model into container now
2023-06-05 23:11:11,646:INFO:_master_model_container: 18
2023-06-05 23:11:11,646:INFO:_display_container: 2
2023-06-05 23:11:11,646:INFO:DummyRegressor()
2023-06-05 23:11:11,646:INFO:create_model() successfully completed......................................
2023-06-05 23:11:11,756:INFO:SubProcess create_model() end ==================================
2023-06-05 23:11:11,756:INFO:Creating metrics dataframe
2023-06-05 23:11:11,771:INFO:Initializing create_model()
2023-06-05 23:11:11,771:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020E2A974370>, estimator=KNeighborsRegressor(n_jobs=-1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-05 23:11:11,771:INFO:Checking exceptions
2023-06-05 23:11:11,771:INFO:Importing libraries
2023-06-05 23:11:11,771:INFO:Copying training dataset
2023-06-05 23:11:11,789:INFO:Defining folds
2023-06-05 23:11:11,789:INFO:Declaring metric variables
2023-06-05 23:11:11,789:INFO:Importing untrained model
2023-06-05 23:11:11,789:INFO:Declaring custom model
2023-06-05 23:11:11,789:INFO:K Neighbors Regressor Imported successfully
2023-06-05 23:11:11,789:INFO:Cross validation set to False
2023-06-05 23:11:11,789:INFO:Fitting Model
2023-06-05 23:11:11,840:INFO:KNeighborsRegressor(n_jobs=-1)
2023-06-05 23:11:11,840:INFO:create_model() successfully completed......................................
2023-06-05 23:11:11,958:INFO:Creating Dashboard logs
2023-06-05 23:11:11,960:INFO:Model: K Neighbors Regressor
2023-06-05 23:11:12,012:INFO:Logged params: {'algorithm': 'auto', 'leaf_size': 30, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': -1, 'n_neighbors': 5, 'p': 2, 'weights': 'uniform'}
2023-06-05 23:11:12,099:INFO:Initializing predict_model()
2023-06-05 23:11:12,100:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020E2A974370>, estimator=KNeighborsRegressor(n_jobs=-1), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x0000020E2A2CBAC0>)
2023-06-05 23:11:12,100:INFO:Checking exceptions
2023-06-05 23:11:12,100:INFO:Preloading libraries
2023-06-05 23:11:12,430:INFO:Creating Dashboard logs
2023-06-05 23:11:12,430:INFO:Model: Gradient Boosting Regressor
2023-06-05 23:11:12,483:INFO:Logged params: {'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': None, 'random_state': 123, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2023-06-05 23:11:12,743:INFO:Creating Dashboard logs
2023-06-05 23:11:12,754:INFO:Model: Random Forest Regressor
2023-06-05 23:11:12,809:INFO:Logged params: {'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': 1.0, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 123, 'verbose': 0, 'warm_start': False}
2023-06-05 23:11:13,071:INFO:Creating Dashboard logs
2023-06-05 23:11:13,071:INFO:Model: Light Gradient Boosting Machine
2023-06-05 23:11:13,138:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 123, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-06-05 23:11:13,405:INFO:Creating Dashboard logs
2023-06-05 23:11:13,409:INFO:Model: Extra Trees Regressor
2023-06-05 23:11:13,464:INFO:Logged params: {'bootstrap': False, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': 1.0, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 123, 'verbose': 0, 'warm_start': False}
2023-06-05 23:11:13,729:INFO:Creating Dashboard logs
2023-06-05 23:11:13,729:INFO:Model: Huber Regressor
2023-06-05 23:11:13,782:INFO:Logged params: {'alpha': 0.0001, 'epsilon': 1.35, 'fit_intercept': True, 'max_iter': 100, 'tol': 1e-05, 'warm_start': False}
2023-06-05 23:11:14,041:INFO:Creating Dashboard logs
2023-06-05 23:11:14,041:INFO:Model: Lasso Least Angle Regression
2023-06-05 23:11:14,095:INFO:Logged params: {'alpha': 1.0, 'copy_X': True, 'eps': 2.220446049250313e-16, 'fit_intercept': True, 'fit_path': True, 'jitter': None, 'max_iter': 500, 'normalize': 'deprecated', 'positive': False, 'precompute': 'auto', 'random_state': 123, 'verbose': False}
2023-06-05 23:11:14,353:INFO:Creating Dashboard logs
2023-06-05 23:11:14,353:INFO:Model: Bayesian Ridge
2023-06-05 23:11:14,415:INFO:Logged params: {'alpha_1': 1e-06, 'alpha_2': 1e-06, 'alpha_init': None, 'compute_score': False, 'copy_X': True, 'fit_intercept': True, 'lambda_1': 1e-06, 'lambda_2': 1e-06, 'lambda_init': None, 'n_iter': 300, 'normalize': 'deprecated', 'tol': 0.001, 'verbose': False}
2023-06-05 23:11:14,673:INFO:Creating Dashboard logs
2023-06-05 23:11:14,673:INFO:Model: Ridge Regression
2023-06-05 23:11:14,734:INFO:Logged params: {'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'normalize': 'deprecated', 'positive': False, 'random_state': 123, 'solver': 'auto', 'tol': 0.001}
2023-06-05 23:11:14,985:INFO:Creating Dashboard logs
2023-06-05 23:11:14,985:INFO:Model: Lasso Regression
2023-06-05 23:11:15,051:INFO:Logged params: {'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'max_iter': 1000, 'normalize': 'deprecated', 'positive': False, 'precompute': False, 'random_state': 123, 'selection': 'cyclic', 'tol': 0.0001, 'warm_start': False}
2023-06-05 23:11:15,327:INFO:Creating Dashboard logs
2023-06-05 23:11:15,327:INFO:Model: Linear Regression
2023-06-05 23:11:15,382:INFO:Logged params: {'copy_X': True, 'fit_intercept': True, 'n_jobs': -1, 'normalize': 'deprecated', 'positive': False}
2023-06-05 23:11:15,630:INFO:Creating Dashboard logs
2023-06-05 23:11:15,630:INFO:Model: Least Angle Regression
2023-06-05 23:11:15,692:INFO:Logged params: {'copy_X': True, 'eps': 2.220446049250313e-16, 'fit_intercept': True, 'fit_path': True, 'jitter': None, 'n_nonzero_coefs': 500, 'normalize': 'deprecated', 'precompute': 'auto', 'random_state': 123, 'verbose': False}
2023-06-05 23:11:15,942:INFO:Creating Dashboard logs
2023-06-05 23:11:15,942:INFO:Model: Passive Aggressive Regressor
2023-06-05 23:11:16,013:INFO:Logged params: {'C': 1.0, 'average': False, 'early_stopping': False, 'epsilon': 0.1, 'fit_intercept': True, 'loss': 'epsilon_insensitive', 'max_iter': 1000, 'n_iter_no_change': 5, 'random_state': 123, 'shuffle': True, 'tol': 0.001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2023-06-05 23:11:16,275:INFO:Creating Dashboard logs
2023-06-05 23:11:16,284:INFO:Model: Orthogonal Matching Pursuit
2023-06-05 23:11:16,351:INFO:Logged params: {'fit_intercept': True, 'n_nonzero_coefs': None, 'normalize': 'deprecated', 'precompute': 'auto', 'tol': None}
2023-06-05 23:11:16,593:INFO:Creating Dashboard logs
2023-06-05 23:11:16,593:INFO:Model: Elastic Net
2023-06-05 23:11:16,659:INFO:Logged params: {'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'l1_ratio': 0.5, 'max_iter': 1000, 'normalize': 'deprecated', 'positive': False, 'precompute': False, 'random_state': 123, 'selection': 'cyclic', 'tol': 0.0001, 'warm_start': False}
2023-06-05 23:11:16,922:INFO:Creating Dashboard logs
2023-06-05 23:11:16,922:INFO:Model: Dummy Regressor
2023-06-05 23:11:16,979:INFO:Logged params: {'constant': None, 'quantile': None, 'strategy': 'mean'}
2023-06-05 23:11:17,267:INFO:Creating Dashboard logs
2023-06-05 23:11:17,270:INFO:Model: AdaBoost Regressor
2023-06-05 23:11:17,321:INFO:Logged params: {'base_estimator': None, 'learning_rate': 1.0, 'loss': 'linear', 'n_estimators': 50, 'random_state': 123}
2023-06-05 23:11:17,599:INFO:Creating Dashboard logs
2023-06-05 23:11:17,602:INFO:Model: Decision Tree Regressor
2023-06-05 23:11:17,659:INFO:Logged params: {'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'random_state': 123, 'splitter': 'best'}
2023-06-05 23:11:17,956:INFO:_master_model_container: 18
2023-06-05 23:11:17,956:INFO:_display_container: 2
2023-06-05 23:11:17,957:INFO:KNeighborsRegressor(n_jobs=-1)
2023-06-05 23:11:17,957:INFO:compare_models() successfully completed......................................
2023-06-05 23:12:33,334:INFO:PyCaret RegressionExperiment
2023-06-05 23:12:33,335:INFO:Logging name: your_experiment_name
2023-06-05 23:12:33,335:INFO:ML Usecase: MLUsecase.REGRESSION
2023-06-05 23:12:33,335:INFO:version 3.0.0
2023-06-05 23:12:33,335:INFO:Initializing setup()
2023-06-05 23:12:33,335:INFO:self.USI: c973
2023-06-05 23:12:33,335:INFO:self._variable_keys: {'pipeline', 'fold_shuffle_param', 'n_jobs_param', 'data', 'transform_target_param', 'exp_name_log', 'y', 'target_param', 'idx', '_ml_usecase', 'html_param', '_available_plots', 'y_test', 'USI', 'logging_param', 'gpu_param', 'X_train', 'gpu_n_jobs_param', 'seed', 'fold_groups_param', 'X', 'y_train', 'X_test', 'memory', 'log_plots_param', 'exp_id', 'fold_generator'}
2023-06-05 23:12:33,335:INFO:Checking environment
2023-06-05 23:12:33,335:INFO:python_version: 3.10.5
2023-06-05 23:12:33,335:INFO:python_build: ('tags/v3.10.5:f377153', 'Jun  6 2022 16:14:13')
2023-06-05 23:12:33,335:INFO:machine: AMD64
2023-06-05 23:12:33,335:INFO:platform: Windows-10-10.0.22621-SP0
2023-06-05 23:12:33,335:INFO:Memory: svmem(total=16497119232, available=7123075072, percent=56.8, used=9374044160, free=7123075072)
2023-06-05 23:12:33,335:INFO:Physical Core: 8
2023-06-05 23:12:33,335:INFO:Logical Core: 16
2023-06-05 23:12:33,335:INFO:Checking libraries
2023-06-05 23:12:33,335:INFO:System:
2023-06-05 23:12:33,335:INFO:    python: 3.10.5 (tags/v3.10.5:f377153, Jun  6 2022, 16:14:13) [MSC v.1929 64 bit (AMD64)]
2023-06-05 23:12:33,335:INFO:executable: C:\Users\Hashif\AppData\Local\Programs\Python\Python310\python.exe
2023-06-05 23:12:33,335:INFO:   machine: Windows-10-10.0.22621-SP0
2023-06-05 23:12:33,335:INFO:PyCaret required dependencies:
2023-06-05 23:12:33,335:INFO:                 pip: 23.1.1
2023-06-05 23:12:33,335:INFO:          setuptools: 58.1.0
2023-06-05 23:12:33,335:INFO:             pycaret: 3.0.0
2023-06-05 23:12:33,335:INFO:             IPython: 8.4.0
2023-06-05 23:12:33,335:INFO:          ipywidgets: 7.7.0
2023-06-05 23:12:33,335:INFO:                tqdm: 4.65.0
2023-06-05 23:12:33,335:INFO:               numpy: 1.23.0
2023-06-05 23:12:33,335:INFO:              pandas: 1.4.3
2023-06-05 23:12:33,335:INFO:              jinja2: 3.1.2
2023-06-05 23:12:33,335:INFO:               scipy: 1.9.3
2023-06-05 23:12:33,336:INFO:              joblib: 1.2.0
2023-06-05 23:12:33,336:INFO:             sklearn: 1.1.2
2023-06-05 23:12:33,336:INFO:                pyod: 1.0.9
2023-06-05 23:12:33,336:INFO:            imblearn: 0.10.1
2023-06-05 23:12:33,336:INFO:   category_encoders: 2.6.0
2023-06-05 23:12:33,336:INFO:            lightgbm: 3.3.5
2023-06-05 23:12:33,336:INFO:               numba: 0.56.4
2023-06-05 23:12:33,336:INFO:            requests: 2.28.1
2023-06-05 23:12:33,336:INFO:          matplotlib: 3.6.2
2023-06-05 23:12:33,336:INFO:          scikitplot: 0.3.7
2023-06-05 23:12:33,336:INFO:         yellowbrick: 1.5
2023-06-05 23:12:33,336:INFO:              plotly: 5.14.1
2023-06-05 23:12:33,336:INFO:             kaleido: 0.2.1
2023-06-05 23:12:33,336:INFO:         statsmodels: 0.13.5
2023-06-05 23:12:33,336:INFO:              sktime: 0.17.1
2023-06-05 23:12:33,336:INFO:               tbats: 1.1.3
2023-06-05 23:12:33,336:INFO:            pmdarima: 2.0.3
2023-06-05 23:12:33,336:INFO:              psutil: 5.9.1
2023-06-05 23:12:33,336:INFO:PyCaret optional dependencies:
2023-06-05 23:12:33,336:INFO:                shap: Not installed
2023-06-05 23:12:33,336:INFO:           interpret: Not installed
2023-06-05 23:12:33,336:INFO:                umap: Not installed
2023-06-05 23:12:33,336:INFO:    pandas_profiling: Not installed
2023-06-05 23:12:33,336:INFO:  explainerdashboard: Not installed
2023-06-05 23:12:33,336:INFO:             autoviz: Not installed
2023-06-05 23:12:33,336:INFO:           fairlearn: Not installed
2023-06-05 23:12:33,336:INFO:             xgboost: Not installed
2023-06-05 23:12:33,336:INFO:            catboost: Not installed
2023-06-05 23:12:33,336:INFO:              kmodes: Not installed
2023-06-05 23:12:33,336:INFO:             mlxtend: Not installed
2023-06-05 23:12:33,336:INFO:       statsforecast: Not installed
2023-06-05 23:12:33,336:INFO:        tune_sklearn: Not installed
2023-06-05 23:12:33,336:INFO:                 ray: Not installed
2023-06-05 23:12:33,336:INFO:            hyperopt: Not installed
2023-06-05 23:12:33,337:INFO:              optuna: Not installed
2023-06-05 23:12:33,337:INFO:               skopt: Not installed
2023-06-05 23:12:33,337:INFO:              mlflow: 2.3.0
2023-06-05 23:12:33,337:INFO:              gradio: Not installed
2023-06-05 23:12:33,337:INFO:             fastapi: Not installed
2023-06-05 23:12:33,337:INFO:             uvicorn: Not installed
2023-06-05 23:12:33,337:INFO:              m2cgen: Not installed
2023-06-05 23:12:33,337:INFO:           evidently: Not installed
2023-06-05 23:12:33,337:INFO:               fugue: Not installed
2023-06-05 23:12:33,337:INFO:           streamlit: Not installed
2023-06-05 23:12:33,337:INFO:             prophet: Not installed
2023-06-05 23:12:33,337:INFO:None
2023-06-05 23:12:33,337:INFO:Set up data.
2023-06-05 23:12:33,337:INFO:Set up train/test split.
2023-06-05 23:12:33,337:INFO:Set up index.
2023-06-05 23:12:33,337:INFO:Set up folding strategy.
2023-06-05 23:12:33,337:INFO:Assigning column types.
2023-06-05 23:12:33,337:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-06-05 23:12:33,337:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-06-05 23:12:33,349:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-06-05 23:12:33,353:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-05 23:12:33,400:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-05 23:12:33,440:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-05 23:12:33,440:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 23:12:33,440:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 23:12:33,440:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-06-05 23:12:33,458:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-06-05 23:12:33,458:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-05 23:12:33,533:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-05 23:12:33,581:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-05 23:12:33,581:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 23:12:33,581:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 23:12:33,581:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-06-05 23:12:33,581:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-06-05 23:12:33,581:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-05 23:12:33,643:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-05 23:12:33,675:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-05 23:12:33,675:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 23:12:33,675:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 23:12:33,691:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-06-05 23:12:33,691:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-05 23:12:33,759:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-05 23:12:33,800:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-05 23:12:33,800:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 23:12:33,800:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 23:12:33,800:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-06-05 23:12:33,816:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-05 23:12:33,879:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-05 23:12:33,925:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-05 23:12:33,925:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 23:12:33,925:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 23:12:33,925:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-05 23:12:34,004:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-05 23:12:34,054:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-05 23:12:34,054:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 23:12:34,054:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 23:12:34,054:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-06-05 23:12:34,113:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-05 23:12:34,161:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-05 23:12:34,161:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 23:12:34,161:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 23:12:34,223:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-05 23:12:34,259:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-05 23:12:34,259:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 23:12:34,259:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 23:12:34,259:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-06-05 23:12:34,341:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-05 23:12:34,384:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 23:12:34,384:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 23:12:34,447:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-05 23:12:34,478:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 23:12:34,478:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 23:12:34,478:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-06-05 23:12:34,597:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 23:12:34,597:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 23:12:34,707:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 23:12:34,707:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 23:12:34,707:INFO:Preparing preprocessing pipeline...
2023-06-05 23:12:34,707:INFO:Set up simple imputation.
2023-06-05 23:12:34,707:INFO:Set up feature normalization.
2023-06-05 23:12:34,723:INFO:Finished creating preprocessing pipeline.
2023-06-05 23:12:34,723:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Hashif\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['PC1', 'PC2', 'PC3'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))])
2023-06-05 23:12:34,723:INFO:Creating final display dataframe.
2023-06-05 23:12:34,770:INFO:Setup _display_container:                     Description                 Value
0                    Session id                   123
1                        Target                 price
2                   Target type            Regression
3           Original data shape              (735, 4)
4        Transformed data shape              (735, 4)
5   Transformed train set shape              (588, 4)
6    Transformed test set shape              (147, 4)
7              Numeric features                     3
8                    Preprocess                  True
9               Imputation type                simple
10           Numeric imputation                  mean
11       Categorical imputation                  mode
12                    Normalize                  True
13             Normalize method                zscore
14               Fold Generator                 KFold
15                  Fold Number                    10
16                     CPU Jobs                    -1
17                      Use GPU                 False
18               Log Experiment          MlflowLogger
19              Experiment Name  your_experiment_name
20                          USI                  c973
2023-06-05 23:12:34,892:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 23:12:34,892:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 23:12:34,986:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 23:12:34,986:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-05 23:12:34,986:INFO:Logging experiment in loggers
2023-06-05 23:12:35,081:INFO:SubProcess save_model() called ==================================
2023-06-05 23:12:35,081:INFO:Initializing save_model()
2023-06-05 23:12:35,081:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\Hashif\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['PC1', 'PC2', 'PC3'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))]), model_name=C:\Users\Hashif\AppData\Local\Temp\tmpr49puedt\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\Hashif\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['PC1', 'PC2', 'PC3'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))]), verbose=False, use_case=MLUsecase.REGRESSION, kwargs={})
2023-06-05 23:12:35,081:INFO:Adding model into prep_pipe
2023-06-05 23:12:35,081:WARNING:Only Model saved as it was a pipeline.
2023-06-05 23:12:35,081:INFO:C:\Users\Hashif\AppData\Local\Temp\tmpr49puedt\Transformation Pipeline.pkl saved in current working directory
2023-06-05 23:12:35,081:INFO:Pipeline(memory=FastMemory(location=C:\Users\Hashif\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['PC1', 'PC2', 'PC3'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))])
2023-06-05 23:12:35,081:INFO:save_model() successfully completed......................................
2023-06-05 23:12:35,222:INFO:SubProcess save_model() end ==================================
2023-06-05 23:12:35,270:INFO:setup() successfully completed in 1.69s...............
2023-06-05 23:12:35,300:INFO:Initializing compare_models()
2023-06-05 23:12:35,300:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020E2A40BC70>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x0000020E2A40BC70>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-06-05 23:12:35,300:INFO:Checking exceptions
2023-06-05 23:12:35,300:INFO:Preparing display monitor
2023-06-05 23:12:35,327:INFO:Initializing Linear Regression
2023-06-05 23:12:35,327:INFO:Total runtime is 3.5921732584635416e-06 minutes
2023-06-05 23:12:35,332:INFO:SubProcess create_model() called ==================================
2023-06-05 23:12:35,332:INFO:Initializing create_model()
2023-06-05 23:12:35,332:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020E2A40BC70>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020E2A3FA110>, model_only=True, return_train_score=False, kwargs={})
2023-06-05 23:12:35,332:INFO:Checking exceptions
2023-06-05 23:12:35,332:INFO:Importing libraries
2023-06-05 23:12:35,332:INFO:Copying training dataset
2023-06-05 23:12:35,335:INFO:Defining folds
2023-06-05 23:12:35,335:INFO:Declaring metric variables
2023-06-05 23:12:35,339:INFO:Importing untrained model
2023-06-05 23:12:35,342:INFO:Linear Regression Imported successfully
2023-06-05 23:12:35,350:INFO:Starting cross validation
2023-06-05 23:12:35,351:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-05 23:12:35,722:INFO:Calculating mean and std
2023-06-05 23:12:35,722:INFO:Creating metrics dataframe
2023-06-05 23:12:35,774:INFO:Uploading results into container
2023-06-05 23:12:35,774:INFO:Uploading model into container now
2023-06-05 23:12:35,774:INFO:_master_model_container: 1
2023-06-05 23:12:35,774:INFO:_display_container: 2
2023-06-05 23:12:35,774:INFO:LinearRegression(n_jobs=-1)
2023-06-05 23:12:35,774:INFO:create_model() successfully completed......................................
2023-06-05 23:12:35,889:INFO:SubProcess create_model() end ==================================
2023-06-05 23:12:35,889:INFO:Creating metrics dataframe
2023-06-05 23:12:35,897:INFO:Initializing Lasso Regression
2023-06-05 23:12:35,897:INFO:Total runtime is 0.009493247667948405 minutes
2023-06-05 23:12:35,901:INFO:SubProcess create_model() called ==================================
2023-06-05 23:12:35,902:INFO:Initializing create_model()
2023-06-05 23:12:35,902:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020E2A40BC70>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020E2A3FA110>, model_only=True, return_train_score=False, kwargs={})
2023-06-05 23:12:35,902:INFO:Checking exceptions
2023-06-05 23:12:35,902:INFO:Importing libraries
2023-06-05 23:12:35,902:INFO:Copying training dataset
2023-06-05 23:12:35,906:INFO:Defining folds
2023-06-05 23:12:35,907:INFO:Declaring metric variables
2023-06-05 23:12:35,910:INFO:Importing untrained model
2023-06-05 23:12:35,914:INFO:Lasso Regression Imported successfully
2023-06-05 23:12:35,923:INFO:Starting cross validation
2023-06-05 23:12:35,924:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-05 23:12:36,322:INFO:Calculating mean and std
2023-06-05 23:12:36,322:INFO:Creating metrics dataframe
2023-06-05 23:12:36,378:INFO:Uploading results into container
2023-06-05 23:12:36,378:INFO:Uploading model into container now
2023-06-05 23:12:36,378:INFO:_master_model_container: 2
2023-06-05 23:12:36,378:INFO:_display_container: 2
2023-06-05 23:12:36,378:INFO:Lasso(random_state=123)
2023-06-05 23:12:36,378:INFO:create_model() successfully completed......................................
2023-06-05 23:12:36,502:INFO:SubProcess create_model() end ==================================
2023-06-05 23:12:36,502:INFO:Creating metrics dataframe
2023-06-05 23:12:36,510:INFO:Initializing Ridge Regression
2023-06-05 23:12:36,510:INFO:Total runtime is 0.019709511597951253 minutes
2023-06-05 23:12:36,514:INFO:SubProcess create_model() called ==================================
2023-06-05 23:12:36,514:INFO:Initializing create_model()
2023-06-05 23:12:36,514:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020E2A40BC70>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020E2A3FA110>, model_only=True, return_train_score=False, kwargs={})
2023-06-05 23:12:36,514:INFO:Checking exceptions
2023-06-05 23:12:36,514:INFO:Importing libraries
2023-06-05 23:12:36,514:INFO:Copying training dataset
2023-06-05 23:12:36,520:INFO:Defining folds
2023-06-05 23:12:36,520:INFO:Declaring metric variables
2023-06-05 23:12:36,525:INFO:Importing untrained model
2023-06-05 23:12:36,530:INFO:Ridge Regression Imported successfully
2023-06-05 23:12:36,537:INFO:Starting cross validation
2023-06-05 23:12:36,538:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-05 23:12:36,947:INFO:Calculating mean and std
2023-06-05 23:12:36,947:INFO:Creating metrics dataframe
2023-06-05 23:12:37,002:INFO:Uploading results into container
2023-06-05 23:12:37,003:INFO:Uploading model into container now
2023-06-05 23:12:37,003:INFO:_master_model_container: 3
2023-06-05 23:12:37,003:INFO:_display_container: 2
2023-06-05 23:12:37,004:INFO:Ridge(random_state=123)
2023-06-05 23:12:37,004:INFO:create_model() successfully completed......................................
2023-06-05 23:12:37,123:INFO:SubProcess create_model() end ==================================
2023-06-05 23:12:37,123:INFO:Creating metrics dataframe
2023-06-05 23:12:37,132:INFO:Initializing Elastic Net
2023-06-05 23:12:37,132:INFO:Total runtime is 0.03007727861404419 minutes
2023-06-05 23:12:37,135:INFO:SubProcess create_model() called ==================================
2023-06-05 23:12:37,136:INFO:Initializing create_model()
2023-06-05 23:12:37,136:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020E2A40BC70>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020E2A3FA110>, model_only=True, return_train_score=False, kwargs={})
2023-06-05 23:12:37,136:INFO:Checking exceptions
2023-06-05 23:12:37,136:INFO:Importing libraries
2023-06-05 23:12:37,136:INFO:Copying training dataset
2023-06-05 23:12:37,140:INFO:Defining folds
2023-06-05 23:12:37,140:INFO:Declaring metric variables
2023-06-05 23:12:37,144:INFO:Importing untrained model
2023-06-05 23:12:37,149:INFO:Elastic Net Imported successfully
2023-06-05 23:12:37,157:INFO:Starting cross validation
2023-06-05 23:12:37,157:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-05 23:12:37,575:INFO:Calculating mean and std
2023-06-05 23:12:37,576:INFO:Creating metrics dataframe
2023-06-05 23:12:37,625:INFO:Uploading results into container
2023-06-05 23:12:37,626:INFO:Uploading model into container now
2023-06-05 23:12:37,626:INFO:_master_model_container: 4
2023-06-05 23:12:37,626:INFO:_display_container: 2
2023-06-05 23:12:37,627:INFO:ElasticNet(random_state=123)
2023-06-05 23:12:37,627:INFO:create_model() successfully completed......................................
2023-06-05 23:12:37,746:INFO:SubProcess create_model() end ==================================
2023-06-05 23:12:37,747:INFO:Creating metrics dataframe
2023-06-05 23:12:37,756:INFO:Initializing Least Angle Regression
2023-06-05 23:12:37,756:INFO:Total runtime is 0.04047369956970215 minutes
2023-06-05 23:12:37,759:INFO:SubProcess create_model() called ==================================
2023-06-05 23:12:37,759:INFO:Initializing create_model()
2023-06-05 23:12:37,759:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020E2A40BC70>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020E2A3FA110>, model_only=True, return_train_score=False, kwargs={})
2023-06-05 23:12:37,759:INFO:Checking exceptions
2023-06-05 23:12:37,759:INFO:Importing libraries
2023-06-05 23:12:37,759:INFO:Copying training dataset
2023-06-05 23:12:37,763:INFO:Defining folds
2023-06-05 23:12:37,763:INFO:Declaring metric variables
2023-06-05 23:12:37,766:INFO:Importing untrained model
2023-06-05 23:12:37,770:INFO:Least Angle Regression Imported successfully
2023-06-05 23:12:37,776:INFO:Starting cross validation
2023-06-05 23:12:37,777:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-05 23:12:37,822:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-06-05 23:12:37,822:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-06-05 23:12:37,837:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-06-05 23:12:37,837:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-06-05 23:12:37,853:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-06-05 23:12:37,869:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-06-05 23:12:37,869:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-06-05 23:12:37,885:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-06-05 23:12:37,917:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-06-05 23:12:37,922:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-06-05 23:12:38,186:INFO:Calculating mean and std
2023-06-05 23:12:38,186:INFO:Creating metrics dataframe
2023-06-05 23:12:38,234:INFO:Uploading results into container
2023-06-05 23:12:38,235:INFO:Uploading model into container now
2023-06-05 23:12:38,235:INFO:_master_model_container: 5
2023-06-05 23:12:38,235:INFO:_display_container: 2
2023-06-05 23:12:38,236:INFO:Lars(random_state=123)
2023-06-05 23:12:38,236:INFO:create_model() successfully completed......................................
2023-06-05 23:12:38,355:INFO:SubProcess create_model() end ==================================
2023-06-05 23:12:38,356:INFO:Creating metrics dataframe
2023-06-05 23:12:38,365:INFO:Initializing Lasso Least Angle Regression
2023-06-05 23:12:38,365:INFO:Total runtime is 0.050626730918884276 minutes
2023-06-05 23:12:38,369:INFO:SubProcess create_model() called ==================================
2023-06-05 23:12:38,369:INFO:Initializing create_model()
2023-06-05 23:12:38,369:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020E2A40BC70>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020E2A3FA110>, model_only=True, return_train_score=False, kwargs={})
2023-06-05 23:12:38,369:INFO:Checking exceptions
2023-06-05 23:12:38,369:INFO:Importing libraries
2023-06-05 23:12:38,369:INFO:Copying training dataset
2023-06-05 23:12:38,374:INFO:Defining folds
2023-06-05 23:12:38,374:INFO:Declaring metric variables
2023-06-05 23:12:38,379:INFO:Importing untrained model
2023-06-05 23:12:38,383:INFO:Lasso Least Angle Regression Imported successfully
2023-06-05 23:12:38,390:INFO:Starting cross validation
2023-06-05 23:12:38,391:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-05 23:12:38,430:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-06-05 23:12:38,446:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-06-05 23:12:38,453:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-06-05 23:12:38,477:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-06-05 23:12:38,493:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-06-05 23:12:38,493:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-06-05 23:12:38,508:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-06-05 23:12:38,508:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-06-05 23:12:38,523:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-06-05 23:12:38,539:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-06-05 23:12:38,854:INFO:Calculating mean and std
2023-06-05 23:12:38,855:INFO:Creating metrics dataframe
2023-06-05 23:12:38,902:INFO:Uploading results into container
2023-06-05 23:12:38,902:INFO:Uploading model into container now
2023-06-05 23:12:38,903:INFO:_master_model_container: 6
2023-06-05 23:12:38,903:INFO:_display_container: 2
2023-06-05 23:12:38,903:INFO:LassoLars(random_state=123)
2023-06-05 23:12:38,903:INFO:create_model() successfully completed......................................
2023-06-05 23:12:38,998:INFO:SubProcess create_model() end ==================================
2023-06-05 23:12:38,998:INFO:Creating metrics dataframe
2023-06-05 23:12:39,013:INFO:Initializing Orthogonal Matching Pursuit
2023-06-05 23:12:39,013:INFO:Total runtime is 0.061434515317281085 minutes
2023-06-05 23:12:39,025:INFO:SubProcess create_model() called ==================================
2023-06-05 23:12:39,025:INFO:Initializing create_model()
2023-06-05 23:12:39,025:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020E2A40BC70>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020E2A3FA110>, model_only=True, return_train_score=False, kwargs={})
2023-06-05 23:12:39,026:INFO:Checking exceptions
2023-06-05 23:12:39,026:INFO:Importing libraries
2023-06-05 23:12:39,026:INFO:Copying training dataset
2023-06-05 23:12:39,030:INFO:Defining folds
2023-06-05 23:12:39,030:INFO:Declaring metric variables
2023-06-05 23:12:39,055:INFO:Importing untrained model
2023-06-05 23:12:39,060:INFO:Orthogonal Matching Pursuit Imported successfully
2023-06-05 23:12:39,067:INFO:Starting cross validation
2023-06-05 23:12:39,068:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-05 23:12:39,111:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-06-05 23:12:39,111:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-06-05 23:12:39,111:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-06-05 23:12:39,126:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-06-05 23:12:39,142:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-06-05 23:12:39,158:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-06-05 23:12:39,165:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-06-05 23:12:39,174:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-06-05 23:12:39,190:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-06-05 23:12:39,190:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-06-05 23:12:39,455:INFO:Calculating mean and std
2023-06-05 23:12:39,455:INFO:Creating metrics dataframe
2023-06-05 23:12:39,508:INFO:Uploading results into container
2023-06-05 23:12:39,508:INFO:Uploading model into container now
2023-06-05 23:12:39,508:INFO:_master_model_container: 7
2023-06-05 23:12:39,508:INFO:_display_container: 2
2023-06-05 23:12:39,508:INFO:OrthogonalMatchingPursuit()
2023-06-05 23:12:39,508:INFO:create_model() successfully completed......................................
2023-06-05 23:12:39,613:INFO:SubProcess create_model() end ==================================
2023-06-05 23:12:39,613:INFO:Creating metrics dataframe
2023-06-05 23:12:39,613:INFO:Initializing Bayesian Ridge
2023-06-05 23:12:39,613:INFO:Total runtime is 0.07143127918243408 minutes
2023-06-05 23:12:39,627:INFO:SubProcess create_model() called ==================================
2023-06-05 23:12:39,628:INFO:Initializing create_model()
2023-06-05 23:12:39,628:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020E2A40BC70>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020E2A3FA110>, model_only=True, return_train_score=False, kwargs={})
2023-06-05 23:12:39,628:INFO:Checking exceptions
2023-06-05 23:12:39,628:INFO:Importing libraries
2023-06-05 23:12:39,628:INFO:Copying training dataset
2023-06-05 23:12:39,629:INFO:Defining folds
2023-06-05 23:12:39,629:INFO:Declaring metric variables
2023-06-05 23:12:39,637:INFO:Importing untrained model
2023-06-05 23:12:39,642:INFO:Bayesian Ridge Imported successfully
2023-06-05 23:12:39,649:INFO:Starting cross validation
2023-06-05 23:12:39,650:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-05 23:12:40,044:INFO:Calculating mean and std
2023-06-05 23:12:40,044:INFO:Creating metrics dataframe
2023-06-05 23:12:40,094:INFO:Uploading results into container
2023-06-05 23:12:40,094:INFO:Uploading model into container now
2023-06-05 23:12:40,094:INFO:_master_model_container: 8
2023-06-05 23:12:40,094:INFO:_display_container: 2
2023-06-05 23:12:40,094:INFO:BayesianRidge()
2023-06-05 23:12:40,094:INFO:create_model() successfully completed......................................
2023-06-05 23:12:40,191:INFO:SubProcess create_model() end ==================================
2023-06-05 23:12:40,191:INFO:Creating metrics dataframe
2023-06-05 23:12:40,206:INFO:Initializing Passive Aggressive Regressor
2023-06-05 23:12:40,206:INFO:Total runtime is 0.08131959835688274 minutes
2023-06-05 23:12:40,213:INFO:SubProcess create_model() called ==================================
2023-06-05 23:12:40,213:INFO:Initializing create_model()
2023-06-05 23:12:40,213:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020E2A40BC70>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020E2A3FA110>, model_only=True, return_train_score=False, kwargs={})
2023-06-05 23:12:40,213:INFO:Checking exceptions
2023-06-05 23:12:40,213:INFO:Importing libraries
2023-06-05 23:12:40,213:INFO:Copying training dataset
2023-06-05 23:12:40,213:INFO:Defining folds
2023-06-05 23:12:40,213:INFO:Declaring metric variables
2023-06-05 23:12:40,213:INFO:Importing untrained model
2023-06-05 23:12:40,228:INFO:Passive Aggressive Regressor Imported successfully
2023-06-05 23:12:40,238:INFO:Starting cross validation
2023-06-05 23:12:40,239:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-05 23:12:40,630:INFO:Calculating mean and std
2023-06-05 23:12:40,630:INFO:Creating metrics dataframe
2023-06-05 23:12:40,691:INFO:Uploading results into container
2023-06-05 23:12:40,692:INFO:Uploading model into container now
2023-06-05 23:12:40,692:INFO:_master_model_container: 9
2023-06-05 23:12:40,692:INFO:_display_container: 2
2023-06-05 23:12:40,693:INFO:PassiveAggressiveRegressor(random_state=123)
2023-06-05 23:12:40,693:INFO:create_model() successfully completed......................................
2023-06-05 23:12:40,793:INFO:SubProcess create_model() end ==================================
2023-06-05 23:12:40,793:INFO:Creating metrics dataframe
2023-06-05 23:12:40,793:INFO:Initializing Huber Regressor
2023-06-05 23:12:40,793:INFO:Total runtime is 0.09109503825505576 minutes
2023-06-05 23:12:40,811:INFO:SubProcess create_model() called ==================================
2023-06-05 23:12:40,811:INFO:Initializing create_model()
2023-06-05 23:12:40,811:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020E2A40BC70>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020E2A3FA110>, model_only=True, return_train_score=False, kwargs={})
2023-06-05 23:12:40,811:INFO:Checking exceptions
2023-06-05 23:12:40,811:INFO:Importing libraries
2023-06-05 23:12:40,811:INFO:Copying training dataset
2023-06-05 23:12:40,815:INFO:Defining folds
2023-06-05 23:12:40,815:INFO:Declaring metric variables
2023-06-05 23:12:40,821:INFO:Importing untrained model
2023-06-05 23:12:40,824:INFO:Huber Regressor Imported successfully
2023-06-05 23:12:40,834:INFO:Starting cross validation
2023-06-05 23:12:40,835:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-05 23:12:41,231:INFO:Calculating mean and std
2023-06-05 23:12:41,231:INFO:Creating metrics dataframe
2023-06-05 23:12:41,300:INFO:Uploading results into container
2023-06-05 23:12:41,300:INFO:Uploading model into container now
2023-06-05 23:12:41,301:INFO:_master_model_container: 10
2023-06-05 23:12:41,301:INFO:_display_container: 2
2023-06-05 23:12:41,301:INFO:HuberRegressor()
2023-06-05 23:12:41,301:INFO:create_model() successfully completed......................................
2023-06-05 23:12:41,405:INFO:SubProcess create_model() end ==================================
2023-06-05 23:12:41,405:INFO:Creating metrics dataframe
2023-06-05 23:12:41,405:INFO:Initializing K Neighbors Regressor
2023-06-05 23:12:41,405:INFO:Total runtime is 0.1012894113858541 minutes
2023-06-05 23:12:41,419:INFO:SubProcess create_model() called ==================================
2023-06-05 23:12:41,419:INFO:Initializing create_model()
2023-06-05 23:12:41,419:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020E2A40BC70>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020E2A3FA110>, model_only=True, return_train_score=False, kwargs={})
2023-06-05 23:12:41,419:INFO:Checking exceptions
2023-06-05 23:12:41,419:INFO:Importing libraries
2023-06-05 23:12:41,419:INFO:Copying training dataset
2023-06-05 23:12:41,423:INFO:Defining folds
2023-06-05 23:12:41,424:INFO:Declaring metric variables
2023-06-05 23:12:41,426:INFO:Importing untrained model
2023-06-05 23:12:41,433:INFO:K Neighbors Regressor Imported successfully
2023-06-05 23:12:41,439:INFO:Starting cross validation
2023-06-05 23:12:41,440:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-05 23:12:41,851:INFO:Calculating mean and std
2023-06-05 23:12:41,851:INFO:Creating metrics dataframe
2023-06-05 23:12:41,898:INFO:Uploading results into container
2023-06-05 23:12:41,898:INFO:Uploading model into container now
2023-06-05 23:12:41,898:INFO:_master_model_container: 11
2023-06-05 23:12:41,898:INFO:_display_container: 2
2023-06-05 23:12:41,898:INFO:KNeighborsRegressor(n_jobs=-1)
2023-06-05 23:12:41,898:INFO:create_model() successfully completed......................................
2023-06-05 23:12:42,008:INFO:SubProcess create_model() end ==================================
2023-06-05 23:12:42,008:INFO:Creating metrics dataframe
2023-06-05 23:12:42,008:INFO:Initializing Decision Tree Regressor
2023-06-05 23:12:42,008:INFO:Total runtime is 0.11135321060816447 minutes
2023-06-05 23:12:42,027:INFO:SubProcess create_model() called ==================================
2023-06-05 23:12:42,028:INFO:Initializing create_model()
2023-06-05 23:12:42,028:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020E2A40BC70>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020E2A3FA110>, model_only=True, return_train_score=False, kwargs={})
2023-06-05 23:12:42,028:INFO:Checking exceptions
2023-06-05 23:12:42,028:INFO:Importing libraries
2023-06-05 23:12:42,028:INFO:Copying training dataset
2023-06-05 23:12:42,032:INFO:Defining folds
2023-06-05 23:12:42,032:INFO:Declaring metric variables
2023-06-05 23:12:42,035:INFO:Importing untrained model
2023-06-05 23:12:42,039:INFO:Decision Tree Regressor Imported successfully
2023-06-05 23:12:42,046:INFO:Starting cross validation
2023-06-05 23:12:42,047:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-05 23:12:42,439:INFO:Calculating mean and std
2023-06-05 23:12:42,439:INFO:Creating metrics dataframe
2023-06-05 23:12:42,492:INFO:Uploading results into container
2023-06-05 23:12:42,492:INFO:Uploading model into container now
2023-06-05 23:12:42,492:INFO:_master_model_container: 12
2023-06-05 23:12:42,492:INFO:_display_container: 2
2023-06-05 23:12:42,492:INFO:DecisionTreeRegressor(random_state=123)
2023-06-05 23:12:42,492:INFO:create_model() successfully completed......................................
2023-06-05 23:12:42,599:INFO:SubProcess create_model() end ==================================
2023-06-05 23:12:42,599:INFO:Creating metrics dataframe
2023-06-05 23:12:42,600:INFO:Initializing Random Forest Regressor
2023-06-05 23:12:42,600:INFO:Total runtime is 0.1212199568748474 minutes
2023-06-05 23:12:42,613:INFO:SubProcess create_model() called ==================================
2023-06-05 23:12:42,613:INFO:Initializing create_model()
2023-06-05 23:12:42,613:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020E2A40BC70>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020E2A3FA110>, model_only=True, return_train_score=False, kwargs={})
2023-06-05 23:12:42,613:INFO:Checking exceptions
2023-06-05 23:12:42,613:INFO:Importing libraries
2023-06-05 23:12:42,613:INFO:Copying training dataset
2023-06-05 23:12:42,613:INFO:Defining folds
2023-06-05 23:12:42,613:INFO:Declaring metric variables
2023-06-05 23:12:42,629:INFO:Importing untrained model
2023-06-05 23:12:42,641:INFO:Random Forest Regressor Imported successfully
2023-06-05 23:12:42,649:INFO:Starting cross validation
2023-06-05 23:12:42,649:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-05 23:12:43,493:INFO:Calculating mean and std
2023-06-05 23:12:43,493:INFO:Creating metrics dataframe
2023-06-05 23:12:43,549:INFO:Uploading results into container
2023-06-05 23:12:43,550:INFO:Uploading model into container now
2023-06-05 23:12:43,550:INFO:_master_model_container: 13
2023-06-05 23:12:43,550:INFO:_display_container: 2
2023-06-05 23:12:43,550:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2023-06-05 23:12:43,550:INFO:create_model() successfully completed......................................
2023-06-05 23:12:43,648:INFO:SubProcess create_model() end ==================================
2023-06-05 23:12:43,648:INFO:Creating metrics dataframe
2023-06-05 23:12:43,659:INFO:Initializing Extra Trees Regressor
2023-06-05 23:12:43,659:INFO:Total runtime is 0.13886431455612183 minutes
2023-06-05 23:12:43,674:INFO:SubProcess create_model() called ==================================
2023-06-05 23:12:43,674:INFO:Initializing create_model()
2023-06-05 23:12:43,674:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020E2A40BC70>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020E2A3FA110>, model_only=True, return_train_score=False, kwargs={})
2023-06-05 23:12:43,674:INFO:Checking exceptions
2023-06-05 23:12:43,674:INFO:Importing libraries
2023-06-05 23:12:43,674:INFO:Copying training dataset
2023-06-05 23:12:43,683:INFO:Defining folds
2023-06-05 23:12:43,683:INFO:Declaring metric variables
2023-06-05 23:12:43,692:INFO:Importing untrained model
2023-06-05 23:12:43,701:INFO:Extra Trees Regressor Imported successfully
2023-06-05 23:12:43,709:INFO:Starting cross validation
2023-06-05 23:12:43,710:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-05 23:12:44,552:INFO:Calculating mean and std
2023-06-05 23:12:44,557:INFO:Creating metrics dataframe
2023-06-05 23:12:44,621:INFO:Uploading results into container
2023-06-05 23:12:44,622:INFO:Uploading model into container now
2023-06-05 23:12:44,622:INFO:_master_model_container: 14
2023-06-05 23:12:44,622:INFO:_display_container: 2
2023-06-05 23:12:44,622:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-06-05 23:12:44,622:INFO:create_model() successfully completed......................................
2023-06-05 23:12:44,746:INFO:SubProcess create_model() end ==================================
2023-06-05 23:12:44,747:INFO:Creating metrics dataframe
2023-06-05 23:12:44,747:INFO:Initializing AdaBoost Regressor
2023-06-05 23:12:44,747:INFO:Total runtime is 0.1569889585177104 minutes
2023-06-05 23:12:44,759:INFO:SubProcess create_model() called ==================================
2023-06-05 23:12:44,760:INFO:Initializing create_model()
2023-06-05 23:12:44,760:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020E2A40BC70>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020E2A3FA110>, model_only=True, return_train_score=False, kwargs={})
2023-06-05 23:12:44,761:INFO:Checking exceptions
2023-06-05 23:12:44,761:INFO:Importing libraries
2023-06-05 23:12:44,761:INFO:Copying training dataset
2023-06-05 23:12:44,763:INFO:Defining folds
2023-06-05 23:12:44,763:INFO:Declaring metric variables
2023-06-05 23:12:44,770:INFO:Importing untrained model
2023-06-05 23:12:44,776:INFO:AdaBoost Regressor Imported successfully
2023-06-05 23:12:44,783:INFO:Starting cross validation
2023-06-05 23:12:44,783:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-05 23:12:45,274:INFO:Calculating mean and std
2023-06-05 23:12:45,288:INFO:Creating metrics dataframe
2023-06-05 23:12:45,343:INFO:Uploading results into container
2023-06-05 23:12:45,343:INFO:Uploading model into container now
2023-06-05 23:12:45,343:INFO:_master_model_container: 15
2023-06-05 23:12:45,343:INFO:_display_container: 2
2023-06-05 23:12:45,343:INFO:AdaBoostRegressor(random_state=123)
2023-06-05 23:12:45,343:INFO:create_model() successfully completed......................................
2023-06-05 23:12:45,452:INFO:SubProcess create_model() end ==================================
2023-06-05 23:12:45,454:INFO:Creating metrics dataframe
2023-06-05 23:12:45,458:INFO:Initializing Gradient Boosting Regressor
2023-06-05 23:12:45,458:INFO:Total runtime is 0.16884077390034996 minutes
2023-06-05 23:12:45,468:INFO:SubProcess create_model() called ==================================
2023-06-05 23:12:45,468:INFO:Initializing create_model()
2023-06-05 23:12:45,468:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020E2A40BC70>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020E2A3FA110>, model_only=True, return_train_score=False, kwargs={})
2023-06-05 23:12:45,468:INFO:Checking exceptions
2023-06-05 23:12:45,468:INFO:Importing libraries
2023-06-05 23:12:45,468:INFO:Copying training dataset
2023-06-05 23:12:45,472:INFO:Defining folds
2023-06-05 23:12:45,472:INFO:Declaring metric variables
2023-06-05 23:12:45,482:INFO:Importing untrained model
2023-06-05 23:12:45,492:INFO:Gradient Boosting Regressor Imported successfully
2023-06-05 23:12:45,501:INFO:Starting cross validation
2023-06-05 23:12:45,502:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-05 23:12:46,072:INFO:Calculating mean and std
2023-06-05 23:12:46,072:INFO:Creating metrics dataframe
2023-06-05 23:12:46,133:INFO:Uploading results into container
2023-06-05 23:12:46,133:INFO:Uploading model into container now
2023-06-05 23:12:46,133:INFO:_master_model_container: 16
2023-06-05 23:12:46,134:INFO:_display_container: 2
2023-06-05 23:12:46,134:INFO:GradientBoostingRegressor(random_state=123)
2023-06-05 23:12:46,134:INFO:create_model() successfully completed......................................
2023-06-05 23:12:46,232:INFO:SubProcess create_model() end ==================================
2023-06-05 23:12:46,232:INFO:Creating metrics dataframe
2023-06-05 23:12:46,247:INFO:Initializing Light Gradient Boosting Machine
2023-06-05 23:12:46,247:INFO:Total runtime is 0.18200060526529951 minutes
2023-06-05 23:12:46,256:INFO:SubProcess create_model() called ==================================
2023-06-05 23:12:46,256:INFO:Initializing create_model()
2023-06-05 23:12:46,256:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020E2A40BC70>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020E2A3FA110>, model_only=True, return_train_score=False, kwargs={})
2023-06-05 23:12:46,256:INFO:Checking exceptions
2023-06-05 23:12:46,256:INFO:Importing libraries
2023-06-05 23:12:46,256:INFO:Copying training dataset
2023-06-05 23:12:46,261:INFO:Defining folds
2023-06-05 23:12:46,261:INFO:Declaring metric variables
2023-06-05 23:12:46,270:INFO:Importing untrained model
2023-06-05 23:12:46,289:INFO:Light Gradient Boosting Machine Imported successfully
2023-06-05 23:12:46,301:INFO:Starting cross validation
2023-06-05 23:12:46,303:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-05 23:12:46,790:INFO:Calculating mean and std
2023-06-05 23:12:46,790:INFO:Creating metrics dataframe
2023-06-05 23:12:46,864:INFO:Uploading results into container
2023-06-05 23:12:46,865:INFO:Uploading model into container now
2023-06-05 23:12:46,865:INFO:_master_model_container: 17
2023-06-05 23:12:46,865:INFO:_display_container: 2
2023-06-05 23:12:46,866:INFO:LGBMRegressor(random_state=123)
2023-06-05 23:12:46,866:INFO:create_model() successfully completed......................................
2023-06-05 23:12:46,972:INFO:SubProcess create_model() end ==================================
2023-06-05 23:12:46,972:INFO:Creating metrics dataframe
2023-06-05 23:12:46,972:INFO:Initializing Dummy Regressor
2023-06-05 23:12:46,972:INFO:Total runtime is 0.19408673445383712 minutes
2023-06-05 23:12:46,988:INFO:SubProcess create_model() called ==================================
2023-06-05 23:12:46,988:INFO:Initializing create_model()
2023-06-05 23:12:46,988:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020E2A40BC70>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020E2A3FA110>, model_only=True, return_train_score=False, kwargs={})
2023-06-05 23:12:46,988:INFO:Checking exceptions
2023-06-05 23:12:46,989:INFO:Importing libraries
2023-06-05 23:12:46,989:INFO:Copying training dataset
2023-06-05 23:12:46,994:INFO:Defining folds
2023-06-05 23:12:46,998:INFO:Declaring metric variables
2023-06-05 23:12:47,003:INFO:Importing untrained model
2023-06-05 23:12:47,007:INFO:Dummy Regressor Imported successfully
2023-06-05 23:12:47,016:INFO:Starting cross validation
2023-06-05 23:12:47,017:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-05 23:12:47,492:INFO:Calculating mean and std
2023-06-05 23:12:47,492:INFO:Creating metrics dataframe
2023-06-05 23:12:47,551:INFO:Uploading results into container
2023-06-05 23:12:47,551:INFO:Uploading model into container now
2023-06-05 23:12:47,551:INFO:_master_model_container: 18
2023-06-05 23:12:47,551:INFO:_display_container: 2
2023-06-05 23:12:47,551:INFO:DummyRegressor()
2023-06-05 23:12:47,551:INFO:create_model() successfully completed......................................
2023-06-05 23:12:47,655:INFO:SubProcess create_model() end ==================================
2023-06-05 23:12:47,655:INFO:Creating metrics dataframe
2023-06-05 23:12:47,677:INFO:Initializing create_model()
2023-06-05 23:12:47,677:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020E2A40BC70>, estimator=RandomForestRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-05 23:12:47,677:INFO:Checking exceptions
2023-06-05 23:12:47,677:INFO:Importing libraries
2023-06-05 23:12:47,677:INFO:Copying training dataset
2023-06-05 23:12:47,677:INFO:Defining folds
2023-06-05 23:12:47,677:INFO:Declaring metric variables
2023-06-05 23:12:47,677:INFO:Importing untrained model
2023-06-05 23:12:47,677:INFO:Declaring custom model
2023-06-05 23:12:47,677:INFO:Random Forest Regressor Imported successfully
2023-06-05 23:12:47,677:INFO:Cross validation set to False
2023-06-05 23:12:47,677:INFO:Fitting Model
2023-06-05 23:12:47,898:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2023-06-05 23:12:47,898:INFO:create_model() successfully completed......................................
2023-06-05 23:12:48,007:INFO:Creating Dashboard logs
2023-06-05 23:12:48,007:INFO:Model: Random Forest Regressor
2023-06-05 23:12:48,064:INFO:Logged params: {'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': 1.0, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 123, 'verbose': 0, 'warm_start': False}
2023-06-05 23:12:48,152:INFO:Initializing predict_model()
2023-06-05 23:12:48,152:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020E2A40BC70>, estimator=RandomForestRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x0000020E2B2C1990>)
2023-06-05 23:12:48,152:INFO:Checking exceptions
2023-06-05 23:12:48,152:INFO:Preloading libraries
2023-06-05 23:12:48,503:INFO:Creating Dashboard logs
2023-06-05 23:12:48,519:INFO:Model: Gradient Boosting Regressor
2023-06-05 23:12:48,574:INFO:Logged params: {'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': None, 'random_state': 123, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2023-06-05 23:12:48,839:INFO:Creating Dashboard logs
2023-06-05 23:12:48,839:INFO:Model: Extra Trees Regressor
2023-06-05 23:12:48,897:INFO:Logged params: {'bootstrap': False, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': 1.0, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 123, 'verbose': 0, 'warm_start': False}
2023-06-05 23:12:49,163:INFO:Creating Dashboard logs
2023-06-05 23:12:49,163:INFO:Model: Light Gradient Boosting Machine
2023-06-05 23:12:49,224:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 123, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-06-05 23:12:49,513:INFO:Creating Dashboard logs
2023-06-05 23:12:49,516:INFO:Model: K Neighbors Regressor
2023-06-05 23:12:49,568:INFO:Logged params: {'algorithm': 'auto', 'leaf_size': 30, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': -1, 'n_neighbors': 5, 'p': 2, 'weights': 'uniform'}
2023-06-05 23:12:49,817:INFO:Creating Dashboard logs
2023-06-05 23:12:49,817:INFO:Model: Huber Regressor
2023-06-05 23:12:49,883:INFO:Logged params: {'alpha': 0.0001, 'epsilon': 1.35, 'fit_intercept': True, 'max_iter': 100, 'tol': 1e-05, 'warm_start': False}
2023-06-05 23:12:50,135:INFO:Creating Dashboard logs
2023-06-05 23:12:50,135:INFO:Model: Passive Aggressive Regressor
2023-06-05 23:12:50,197:INFO:Logged params: {'C': 1.0, 'average': False, 'early_stopping': False, 'epsilon': 0.1, 'fit_intercept': True, 'loss': 'epsilon_insensitive', 'max_iter': 1000, 'n_iter_no_change': 5, 'random_state': 123, 'shuffle': True, 'tol': 0.001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2023-06-05 23:12:50,466:INFO:Creating Dashboard logs
2023-06-05 23:12:50,475:INFO:Model: Lasso Least Angle Regression
2023-06-05 23:12:50,531:INFO:Logged params: {'alpha': 1.0, 'copy_X': True, 'eps': 2.220446049250313e-16, 'fit_intercept': True, 'fit_path': True, 'jitter': None, 'max_iter': 500, 'normalize': 'deprecated', 'positive': False, 'precompute': 'auto', 'random_state': 123, 'verbose': False}
2023-06-05 23:12:50,811:INFO:Creating Dashboard logs
2023-06-05 23:12:50,815:INFO:Model: Bayesian Ridge
2023-06-05 23:12:50,864:INFO:Logged params: {'alpha_1': 1e-06, 'alpha_2': 1e-06, 'alpha_init': None, 'compute_score': False, 'copy_X': True, 'fit_intercept': True, 'lambda_1': 1e-06, 'lambda_2': 1e-06, 'lambda_init': None, 'n_iter': 300, 'normalize': 'deprecated', 'tol': 0.001, 'verbose': False}
2023-06-05 23:12:51,122:INFO:Creating Dashboard logs
2023-06-05 23:12:51,122:INFO:Model: Ridge Regression
2023-06-05 23:12:51,180:INFO:Logged params: {'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'normalize': 'deprecated', 'positive': False, 'random_state': 123, 'solver': 'auto', 'tol': 0.001}
2023-06-05 23:12:51,433:INFO:Creating Dashboard logs
2023-06-05 23:12:51,433:INFO:Model: Linear Regression
2023-06-05 23:12:51,488:INFO:Logged params: {'copy_X': True, 'fit_intercept': True, 'n_jobs': -1, 'normalize': 'deprecated', 'positive': False}
2023-06-05 23:12:51,753:INFO:Creating Dashboard logs
2023-06-05 23:12:51,753:INFO:Model: Lasso Regression
2023-06-05 23:12:51,804:INFO:Logged params: {'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'max_iter': 1000, 'normalize': 'deprecated', 'positive': False, 'precompute': False, 'random_state': 123, 'selection': 'cyclic', 'tol': 0.0001, 'warm_start': False}
2023-06-05 23:12:52,082:INFO:Creating Dashboard logs
2023-06-05 23:12:52,085:INFO:Model: Least Angle Regression
2023-06-05 23:12:52,139:INFO:Logged params: {'copy_X': True, 'eps': 2.220446049250313e-16, 'fit_intercept': True, 'fit_path': True, 'jitter': None, 'n_nonzero_coefs': 500, 'normalize': 'deprecated', 'precompute': 'auto', 'random_state': 123, 'verbose': False}
2023-06-05 23:12:52,442:INFO:Creating Dashboard logs
2023-06-05 23:12:52,446:INFO:Model: Elastic Net
2023-06-05 23:12:52,498:INFO:Logged params: {'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'l1_ratio': 0.5, 'max_iter': 1000, 'normalize': 'deprecated', 'positive': False, 'precompute': False, 'random_state': 123, 'selection': 'cyclic', 'tol': 0.0001, 'warm_start': False}
2023-06-05 23:12:52,796:INFO:Creating Dashboard logs
2023-06-05 23:12:52,811:INFO:Model: Orthogonal Matching Pursuit
2023-06-05 23:12:52,863:INFO:Logged params: {'fit_intercept': True, 'n_nonzero_coefs': None, 'normalize': 'deprecated', 'precompute': 'auto', 'tol': None}
2023-06-05 23:12:53,135:INFO:Creating Dashboard logs
2023-06-05 23:12:53,139:INFO:Model: AdaBoost Regressor
2023-06-05 23:12:53,193:INFO:Logged params: {'base_estimator': None, 'learning_rate': 1.0, 'loss': 'linear', 'n_estimators': 50, 'random_state': 123}
2023-06-05 23:12:53,488:INFO:Creating Dashboard logs
2023-06-05 23:12:53,491:INFO:Model: Dummy Regressor
2023-06-05 23:12:53,542:INFO:Logged params: {'constant': None, 'quantile': None, 'strategy': 'mean'}
2023-06-05 23:12:53,829:INFO:Creating Dashboard logs
2023-06-05 23:12:53,832:INFO:Model: Decision Tree Regressor
2023-06-05 23:12:53,880:INFO:Logged params: {'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'random_state': 123, 'splitter': 'best'}
2023-06-05 23:12:54,187:INFO:_master_model_container: 18
2023-06-05 23:12:54,187:INFO:_display_container: 2
2023-06-05 23:12:54,187:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2023-06-05 23:12:54,187:INFO:compare_models() successfully completed......................................
2023-06-07 23:25:37,878:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-07 23:25:37,878:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-07 23:25:37,878:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-07 23:25:37,878:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-07 23:25:40,128:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-06-07 23:25:40,984:INFO:PyCaret RegressionExperiment
2023-06-07 23:25:40,984:INFO:Logging name: your_experiment_name
2023-06-07 23:25:40,984:INFO:ML Usecase: MLUsecase.REGRESSION
2023-06-07 23:25:40,984:INFO:version 3.0.0
2023-06-07 23:25:40,984:INFO:Initializing setup()
2023-06-07 23:25:40,984:INFO:self.USI: d4b3
2023-06-07 23:25:40,984:INFO:self._variable_keys: {'target_param', 'gpu_n_jobs_param', 'y', 'data', 'exp_name_log', 'transform_target_param', 'y_train', 'y_test', 'X_test', 'USI', 'html_param', '_available_plots', 'log_plots_param', 'seed', 'idx', 'pipeline', 'exp_id', 'X_train', 'X', 'fold_generator', '_ml_usecase', 'memory', 'fold_groups_param', 'fold_shuffle_param', 'logging_param', 'n_jobs_param', 'gpu_param'}
2023-06-07 23:25:40,984:INFO:Checking environment
2023-06-07 23:25:40,984:INFO:python_version: 3.10.5
2023-06-07 23:25:40,984:INFO:python_build: ('tags/v3.10.5:f377153', 'Jun  6 2022 16:14:13')
2023-06-07 23:25:40,984:INFO:machine: AMD64
2023-06-07 23:25:40,984:INFO:platform: Windows-10-10.0.22621-SP0
2023-06-07 23:25:40,984:INFO:Memory: svmem(total=16497119232, available=8471977984, percent=48.6, used=8025141248, free=8471977984)
2023-06-07 23:25:40,984:INFO:Physical Core: 8
2023-06-07 23:25:40,984:INFO:Logical Core: 16
2023-06-07 23:25:40,984:INFO:Checking libraries
2023-06-07 23:25:40,984:INFO:System:
2023-06-07 23:25:40,984:INFO:    python: 3.10.5 (tags/v3.10.5:f377153, Jun  6 2022, 16:14:13) [MSC v.1929 64 bit (AMD64)]
2023-06-07 23:25:40,984:INFO:executable: C:\Users\Hashif\AppData\Local\Programs\Python\Python310\python.exe
2023-06-07 23:25:40,984:INFO:   machine: Windows-10-10.0.22621-SP0
2023-06-07 23:25:40,984:INFO:PyCaret required dependencies:
2023-06-07 23:25:40,984:INFO:                 pip: 23.1.1
2023-06-07 23:25:40,984:INFO:          setuptools: 58.1.0
2023-06-07 23:25:40,984:INFO:             pycaret: 3.0.0
2023-06-07 23:25:40,984:INFO:             IPython: 8.4.0
2023-06-07 23:25:40,984:INFO:          ipywidgets: 7.7.0
2023-06-07 23:25:40,984:INFO:                tqdm: 4.65.0
2023-06-07 23:25:40,984:INFO:               numpy: 1.23.0
2023-06-07 23:25:40,984:INFO:              pandas: 1.4.3
2023-06-07 23:25:40,984:INFO:              jinja2: 3.1.2
2023-06-07 23:25:40,984:INFO:               scipy: 1.9.3
2023-06-07 23:25:40,984:INFO:              joblib: 1.2.0
2023-06-07 23:25:40,984:INFO:             sklearn: 1.1.2
2023-06-07 23:25:40,984:INFO:                pyod: 1.0.9
2023-06-07 23:25:40,984:INFO:            imblearn: 0.10.1
2023-06-07 23:25:40,984:INFO:   category_encoders: 2.6.0
2023-06-07 23:25:40,984:INFO:            lightgbm: 3.3.5
2023-06-07 23:25:40,984:INFO:               numba: 0.56.4
2023-06-07 23:25:40,984:INFO:            requests: 2.28.1
2023-06-07 23:25:40,984:INFO:          matplotlib: 3.6.2
2023-06-07 23:25:40,984:INFO:          scikitplot: 0.3.7
2023-06-07 23:25:40,984:INFO:         yellowbrick: 1.5
2023-06-07 23:25:40,984:INFO:              plotly: 5.14.1
2023-06-07 23:25:40,984:INFO:             kaleido: 0.2.1
2023-06-07 23:25:40,984:INFO:         statsmodels: 0.13.5
2023-06-07 23:25:40,984:INFO:              sktime: 0.17.1
2023-06-07 23:25:40,984:INFO:               tbats: 1.1.3
2023-06-07 23:25:40,984:INFO:            pmdarima: 2.0.3
2023-06-07 23:25:40,984:INFO:              psutil: 5.9.1
2023-06-07 23:25:40,984:INFO:PyCaret optional dependencies:
2023-06-07 23:25:41,000:INFO:                shap: Not installed
2023-06-07 23:25:41,000:INFO:           interpret: Not installed
2023-06-07 23:25:41,000:INFO:                umap: Not installed
2023-06-07 23:25:41,000:INFO:    pandas_profiling: Not installed
2023-06-07 23:25:41,000:INFO:  explainerdashboard: Not installed
2023-06-07 23:25:41,000:INFO:             autoviz: Not installed
2023-06-07 23:25:41,000:INFO:           fairlearn: Not installed
2023-06-07 23:25:41,000:INFO:             xgboost: Not installed
2023-06-07 23:25:41,000:INFO:            catboost: Not installed
2023-06-07 23:25:41,000:INFO:              kmodes: Not installed
2023-06-07 23:25:41,000:INFO:             mlxtend: Not installed
2023-06-07 23:25:41,000:INFO:       statsforecast: Not installed
2023-06-07 23:25:41,000:INFO:        tune_sklearn: Not installed
2023-06-07 23:25:41,000:INFO:                 ray: Not installed
2023-06-07 23:25:41,000:INFO:            hyperopt: Not installed
2023-06-07 23:25:41,000:INFO:              optuna: Not installed
2023-06-07 23:25:41,000:INFO:               skopt: Not installed
2023-06-07 23:25:41,000:INFO:              mlflow: 2.3.0
2023-06-07 23:25:41,000:INFO:              gradio: Not installed
2023-06-07 23:25:41,000:INFO:             fastapi: Not installed
2023-06-07 23:25:41,000:INFO:             uvicorn: Not installed
2023-06-07 23:25:41,016:INFO:              m2cgen: Not installed
2023-06-07 23:25:41,016:INFO:           evidently: Not installed
2023-06-07 23:25:41,016:INFO:               fugue: Not installed
2023-06-07 23:25:41,016:INFO:           streamlit: Not installed
2023-06-07 23:25:41,016:INFO:             prophet: Not installed
2023-06-07 23:25:41,016:INFO:None
2023-06-07 23:25:41,016:INFO:Set up data.
2023-06-07 23:25:41,016:INFO:Set up train/test split.
2023-06-07 23:25:41,032:INFO:Set up index.
2023-06-07 23:25:41,032:INFO:Set up folding strategy.
2023-06-07 23:25:41,032:INFO:Assigning column types.
2023-06-07 23:25:41,032:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-06-07 23:25:41,032:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-06-07 23:25:41,048:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-06-07 23:25:41,048:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-07 23:25:41,154:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-07 23:25:41,222:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-07 23:25:41,222:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-07 23:25:41,284:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-07 23:25:41,284:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-06-07 23:25:41,284:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-06-07 23:25:41,301:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-07 23:25:41,394:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-07 23:25:41,479:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-07 23:25:41,479:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-07 23:25:41,479:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-07 23:25:41,479:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-06-07 23:25:41,495:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-06-07 23:25:41,495:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-07 23:25:41,589:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-07 23:25:41,668:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-07 23:25:41,668:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-07 23:25:41,668:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-07 23:25:41,668:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-06-07 23:25:41,685:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-07 23:25:41,778:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-07 23:25:41,879:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-07 23:25:41,879:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-07 23:25:41,879:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-07 23:25:41,879:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-06-07 23:25:41,895:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-07 23:25:41,989:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-07 23:25:42,068:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-07 23:25:42,068:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-07 23:25:42,068:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-07 23:25:42,084:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-07 23:25:42,178:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-07 23:25:42,257:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-07 23:25:42,257:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-07 23:25:42,257:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-07 23:25:42,257:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-06-07 23:25:42,366:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-07 23:25:42,445:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-07 23:25:42,445:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-07 23:25:42,445:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-07 23:25:42,556:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-07 23:25:42,619:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-07 23:25:42,619:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-07 23:25:42,619:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-07 23:25:42,619:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-06-07 23:25:42,729:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-07 23:25:42,792:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-07 23:25:42,792:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-07 23:25:42,949:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-07 23:25:43,028:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-07 23:25:43,028:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-07 23:25:43,028:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-06-07 23:25:43,216:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-07 23:25:43,216:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-07 23:25:43,389:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-07 23:25:43,389:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-07 23:25:43,405:INFO:Preparing preprocessing pipeline...
2023-06-07 23:25:43,405:INFO:Set up simple imputation.
2023-06-07 23:25:43,405:INFO:Set up feature normalization.
2023-06-07 23:25:43,452:INFO:Finished creating preprocessing pipeline.
2023-06-07 23:25:43,469:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Hashif\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['PC1', 'PC2', 'PC3'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))])
2023-06-07 23:25:43,469:INFO:Creating final display dataframe.
2023-06-07 23:25:43,582:INFO:Setup _display_container:                     Description                 Value
0                    Session id                   123
1                        Target                 price
2                   Target type            Regression
3           Original data shape              (735, 4)
4        Transformed data shape              (735, 4)
5   Transformed train set shape              (588, 4)
6    Transformed test set shape              (147, 4)
7              Numeric features                     3
8                    Preprocess                  True
9               Imputation type                simple
10           Numeric imputation                  mean
11       Categorical imputation                  mode
12                    Normalize                  True
13             Normalize method                zscore
14               Fold Generator                 KFold
15                  Fold Number                    10
16                     CPU Jobs                    -1
17                      Use GPU                 False
18               Log Experiment          MlflowLogger
19              Experiment Name  your_experiment_name
20                          USI                  d4b3
2023-06-07 23:25:43,782:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-07 23:25:43,782:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-07 23:25:43,954:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-07 23:25:43,954:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-07 23:25:43,954:INFO:Logging experiment in loggers
2023-06-07 23:25:44,382:INFO:SubProcess save_model() called ==================================
2023-06-07 23:25:44,398:INFO:Initializing save_model()
2023-06-07 23:25:44,398:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\Hashif\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['PC1', 'PC2', 'PC3'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))]), model_name=C:\Users\Hashif\AppData\Local\Temp\tmpayng44qu\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\Hashif\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['PC1', 'PC2', 'PC3'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))]), verbose=False, use_case=MLUsecase.REGRESSION, kwargs={})
2023-06-07 23:25:44,398:INFO:Adding model into prep_pipe
2023-06-07 23:25:44,398:WARNING:Only Model saved as it was a pipeline.
2023-06-07 23:25:44,398:INFO:C:\Users\Hashif\AppData\Local\Temp\tmpayng44qu\Transformation Pipeline.pkl saved in current working directory
2023-06-07 23:25:44,413:INFO:Pipeline(memory=FastMemory(location=C:\Users\Hashif\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['PC1', 'PC2', 'PC3'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))])
2023-06-07 23:25:44,413:INFO:save_model() successfully completed......................................
2023-06-07 23:25:44,555:INFO:SubProcess save_model() end ==================================
2023-06-07 23:25:44,652:INFO:setup() successfully completed in 3.1s...............
2023-06-07 23:25:44,652:INFO:Initializing compare_models()
2023-06-07 23:25:44,652:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E224FEFEE0>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001E224FEFEE0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-06-07 23:25:44,652:INFO:Checking exceptions
2023-06-07 23:25:44,652:INFO:Preparing display monitor
2023-06-07 23:25:44,701:INFO:Initializing Linear Regression
2023-06-07 23:25:44,701:INFO:Total runtime is 0.0 minutes
2023-06-07 23:25:44,708:INFO:SubProcess create_model() called ==================================
2023-06-07 23:25:44,708:INFO:Initializing create_model()
2023-06-07 23:25:44,708:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E224FEFEE0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E26966A230>, model_only=True, return_train_score=False, kwargs={})
2023-06-07 23:25:44,708:INFO:Checking exceptions
2023-06-07 23:25:44,708:INFO:Importing libraries
2023-06-07 23:25:44,708:INFO:Copying training dataset
2023-06-07 23:25:44,718:INFO:Defining folds
2023-06-07 23:25:44,718:INFO:Declaring metric variables
2023-06-07 23:25:44,721:INFO:Importing untrained model
2023-06-07 23:25:44,728:INFO:Linear Regression Imported successfully
2023-06-07 23:25:44,735:INFO:Starting cross validation
2023-06-07 23:25:44,753:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-07 23:25:49,114:INFO:Calculating mean and std
2023-06-07 23:25:49,114:INFO:Creating metrics dataframe
2023-06-07 23:25:49,186:INFO:Uploading results into container
2023-06-07 23:25:49,186:INFO:Uploading model into container now
2023-06-07 23:25:49,186:INFO:_master_model_container: 1
2023-06-07 23:25:49,186:INFO:_display_container: 2
2023-06-07 23:25:49,186:INFO:LinearRegression(n_jobs=-1)
2023-06-07 23:25:49,186:INFO:create_model() successfully completed......................................
2023-06-07 23:25:49,249:INFO:SubProcess create_model() end ==================================
2023-06-07 23:25:49,249:INFO:Creating metrics dataframe
2023-06-07 23:25:49,265:INFO:Initializing Lasso Regression
2023-06-07 23:25:49,265:INFO:Total runtime is 0.07606724898020427 minutes
2023-06-07 23:25:49,265:INFO:SubProcess create_model() called ==================================
2023-06-07 23:25:49,265:INFO:Initializing create_model()
2023-06-07 23:25:49,265:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E224FEFEE0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E26966A230>, model_only=True, return_train_score=False, kwargs={})
2023-06-07 23:25:49,265:INFO:Checking exceptions
2023-06-07 23:25:49,265:INFO:Importing libraries
2023-06-07 23:25:49,265:INFO:Copying training dataset
2023-06-07 23:25:49,273:INFO:Defining folds
2023-06-07 23:25:49,273:INFO:Declaring metric variables
2023-06-07 23:25:49,273:INFO:Importing untrained model
2023-06-07 23:25:49,281:INFO:Lasso Regression Imported successfully
2023-06-07 23:25:49,287:INFO:Starting cross validation
2023-06-07 23:25:49,293:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-07 23:25:51,883:INFO:Calculating mean and std
2023-06-07 23:25:51,883:INFO:Creating metrics dataframe
2023-06-07 23:25:51,971:INFO:Uploading results into container
2023-06-07 23:25:51,971:INFO:Uploading model into container now
2023-06-07 23:25:51,971:INFO:_master_model_container: 2
2023-06-07 23:25:51,971:INFO:_display_container: 2
2023-06-07 23:25:51,971:INFO:Lasso(random_state=123)
2023-06-07 23:25:51,971:INFO:create_model() successfully completed......................................
2023-06-07 23:25:52,035:INFO:SubProcess create_model() end ==================================
2023-06-07 23:25:52,035:INFO:Creating metrics dataframe
2023-06-07 23:25:52,050:INFO:Initializing Ridge Regression
2023-06-07 23:25:52,050:INFO:Total runtime is 0.1224884827931722 minutes
2023-06-07 23:25:52,058:INFO:SubProcess create_model() called ==================================
2023-06-07 23:25:52,058:INFO:Initializing create_model()
2023-06-07 23:25:52,058:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E224FEFEE0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E26966A230>, model_only=True, return_train_score=False, kwargs={})
2023-06-07 23:25:52,058:INFO:Checking exceptions
2023-06-07 23:25:52,058:INFO:Importing libraries
2023-06-07 23:25:52,058:INFO:Copying training dataset
2023-06-07 23:25:52,067:INFO:Defining folds
2023-06-07 23:25:52,069:INFO:Declaring metric variables
2023-06-07 23:25:52,069:INFO:Importing untrained model
2023-06-07 23:25:52,077:INFO:Ridge Regression Imported successfully
2023-06-07 23:25:52,084:INFO:Starting cross validation
2023-06-07 23:25:52,084:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-07 23:25:52,582:INFO:Calculating mean and std
2023-06-07 23:25:52,582:INFO:Creating metrics dataframe
2023-06-07 23:25:52,654:INFO:Uploading results into container
2023-06-07 23:25:52,654:INFO:Uploading model into container now
2023-06-07 23:25:52,654:INFO:_master_model_container: 3
2023-06-07 23:25:52,654:INFO:_display_container: 2
2023-06-07 23:25:52,654:INFO:Ridge(random_state=123)
2023-06-07 23:25:52,654:INFO:create_model() successfully completed......................................
2023-06-07 23:25:52,734:INFO:SubProcess create_model() end ==================================
2023-06-07 23:25:52,734:INFO:Creating metrics dataframe
2023-06-07 23:25:52,734:INFO:Initializing Elastic Net
2023-06-07 23:25:52,734:INFO:Total runtime is 0.13387900590896606 minutes
2023-06-07 23:25:52,747:INFO:SubProcess create_model() called ==================================
2023-06-07 23:25:52,747:INFO:Initializing create_model()
2023-06-07 23:25:52,747:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E224FEFEE0>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E26966A230>, model_only=True, return_train_score=False, kwargs={})
2023-06-07 23:25:52,747:INFO:Checking exceptions
2023-06-07 23:25:52,747:INFO:Importing libraries
2023-06-07 23:25:52,747:INFO:Copying training dataset
2023-06-07 23:25:52,755:INFO:Defining folds
2023-06-07 23:25:52,755:INFO:Declaring metric variables
2023-06-07 23:25:52,762:INFO:Importing untrained model
2023-06-07 23:25:52,762:INFO:Elastic Net Imported successfully
2023-06-07 23:25:52,776:INFO:Starting cross validation
2023-06-07 23:25:52,776:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-07 23:25:53,271:INFO:Calculating mean and std
2023-06-07 23:25:53,271:INFO:Creating metrics dataframe
2023-06-07 23:25:53,353:INFO:Uploading results into container
2023-06-07 23:25:53,353:INFO:Uploading model into container now
2023-06-07 23:25:53,353:INFO:_master_model_container: 4
2023-06-07 23:25:53,353:INFO:_display_container: 2
2023-06-07 23:25:53,353:INFO:ElasticNet(random_state=123)
2023-06-07 23:25:53,353:INFO:create_model() successfully completed......................................
2023-06-07 23:25:53,427:INFO:SubProcess create_model() end ==================================
2023-06-07 23:25:53,427:INFO:Creating metrics dataframe
2023-06-07 23:25:53,435:INFO:Initializing Least Angle Regression
2023-06-07 23:25:53,435:INFO:Total runtime is 0.14555758635203045 minutes
2023-06-07 23:25:53,438:INFO:SubProcess create_model() called ==================================
2023-06-07 23:25:53,438:INFO:Initializing create_model()
2023-06-07 23:25:53,438:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E224FEFEE0>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E26966A230>, model_only=True, return_train_score=False, kwargs={})
2023-06-07 23:25:53,438:INFO:Checking exceptions
2023-06-07 23:25:53,441:INFO:Importing libraries
2023-06-07 23:25:53,441:INFO:Copying training dataset
2023-06-07 23:25:53,444:INFO:Defining folds
2023-06-07 23:25:53,444:INFO:Declaring metric variables
2023-06-07 23:25:53,449:INFO:Importing untrained model
2023-06-07 23:25:53,455:INFO:Least Angle Regression Imported successfully
2023-06-07 23:25:53,462:INFO:Starting cross validation
2023-06-07 23:25:53,462:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-07 23:25:53,529:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-06-07 23:25:53,529:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-06-07 23:25:53,529:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-06-07 23:25:53,529:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-06-07 23:25:53,545:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-06-07 23:25:53,560:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-06-07 23:25:53,560:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-06-07 23:25:53,576:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-06-07 23:25:53,576:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-06-07 23:25:53,592:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-06-07 23:25:53,986:INFO:Calculating mean and std
2023-06-07 23:25:53,986:INFO:Creating metrics dataframe
2023-06-07 23:25:54,050:INFO:Uploading results into container
2023-06-07 23:25:54,050:INFO:Uploading model into container now
2023-06-07 23:25:54,050:INFO:_master_model_container: 5
2023-06-07 23:25:54,050:INFO:_display_container: 2
2023-06-07 23:25:54,050:INFO:Lars(random_state=123)
2023-06-07 23:25:54,066:INFO:create_model() successfully completed......................................
2023-06-07 23:25:54,129:INFO:SubProcess create_model() end ==================================
2023-06-07 23:25:54,129:INFO:Creating metrics dataframe
2023-06-07 23:25:54,129:INFO:Initializing Lasso Least Angle Regression
2023-06-07 23:25:54,129:INFO:Total runtime is 0.15713239510854088 minutes
2023-06-07 23:25:54,145:INFO:SubProcess create_model() called ==================================
2023-06-07 23:25:54,145:INFO:Initializing create_model()
2023-06-07 23:25:54,145:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E224FEFEE0>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E26966A230>, model_only=True, return_train_score=False, kwargs={})
2023-06-07 23:25:54,145:INFO:Checking exceptions
2023-06-07 23:25:54,145:INFO:Importing libraries
2023-06-07 23:25:54,146:INFO:Copying training dataset
2023-06-07 23:25:54,151:INFO:Defining folds
2023-06-07 23:25:54,151:INFO:Declaring metric variables
2023-06-07 23:25:54,157:INFO:Importing untrained model
2023-06-07 23:25:54,163:INFO:Lasso Least Angle Regression Imported successfully
2023-06-07 23:25:54,169:INFO:Starting cross validation
2023-06-07 23:25:54,169:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-07 23:25:54,210:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-06-07 23:25:54,229:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-06-07 23:25:54,229:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-06-07 23:25:54,242:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-06-07 23:25:54,273:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-06-07 23:25:54,273:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-06-07 23:25:54,273:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-06-07 23:25:54,289:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-06-07 23:25:54,304:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-06-07 23:25:54,304:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-06-07 23:25:54,666:INFO:Calculating mean and std
2023-06-07 23:25:54,666:INFO:Creating metrics dataframe
2023-06-07 23:25:54,748:INFO:Uploading results into container
2023-06-07 23:25:54,748:INFO:Uploading model into container now
2023-06-07 23:25:54,748:INFO:_master_model_container: 6
2023-06-07 23:25:54,748:INFO:_display_container: 2
2023-06-07 23:25:54,748:INFO:LassoLars(random_state=123)
2023-06-07 23:25:54,748:INFO:create_model() successfully completed......................................
2023-06-07 23:25:54,827:INFO:SubProcess create_model() end ==================================
2023-06-07 23:25:54,827:INFO:Creating metrics dataframe
2023-06-07 23:25:54,830:INFO:Initializing Orthogonal Matching Pursuit
2023-06-07 23:25:54,830:INFO:Total runtime is 0.16881941954294843 minutes
2023-06-07 23:25:54,839:INFO:SubProcess create_model() called ==================================
2023-06-07 23:25:54,839:INFO:Initializing create_model()
2023-06-07 23:25:54,839:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E224FEFEE0>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E26966A230>, model_only=True, return_train_score=False, kwargs={})
2023-06-07 23:25:54,839:INFO:Checking exceptions
2023-06-07 23:25:54,839:INFO:Importing libraries
2023-06-07 23:25:54,839:INFO:Copying training dataset
2023-06-07 23:25:54,845:INFO:Defining folds
2023-06-07 23:25:54,845:INFO:Declaring metric variables
2023-06-07 23:25:54,851:INFO:Importing untrained model
2023-06-07 23:25:54,857:INFO:Orthogonal Matching Pursuit Imported successfully
2023-06-07 23:25:54,871:INFO:Starting cross validation
2023-06-07 23:25:54,871:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-07 23:25:54,915:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-06-07 23:25:54,930:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-06-07 23:25:54,946:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-06-07 23:25:54,946:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-06-07 23:25:54,977:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-06-07 23:25:54,993:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-06-07 23:25:54,993:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-06-07 23:25:54,993:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-06-07 23:25:54,993:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-06-07 23:25:55,009:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-06-07 23:25:55,403:INFO:Calculating mean and std
2023-06-07 23:25:55,403:INFO:Creating metrics dataframe
2023-06-07 23:25:55,486:INFO:Uploading results into container
2023-06-07 23:25:55,487:INFO:Uploading model into container now
2023-06-07 23:25:55,487:INFO:_master_model_container: 7
2023-06-07 23:25:55,487:INFO:_display_container: 2
2023-06-07 23:25:55,487:INFO:OrthogonalMatchingPursuit()
2023-06-07 23:25:55,487:INFO:create_model() successfully completed......................................
2023-06-07 23:25:55,550:INFO:SubProcess create_model() end ==================================
2023-06-07 23:25:55,550:INFO:Creating metrics dataframe
2023-06-07 23:25:55,550:INFO:Initializing Bayesian Ridge
2023-06-07 23:25:55,550:INFO:Total runtime is 0.18081907033920291 minutes
2023-06-07 23:25:55,566:INFO:SubProcess create_model() called ==================================
2023-06-07 23:25:55,566:INFO:Initializing create_model()
2023-06-07 23:25:55,566:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E224FEFEE0>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E26966A230>, model_only=True, return_train_score=False, kwargs={})
2023-06-07 23:25:55,566:INFO:Checking exceptions
2023-06-07 23:25:55,566:INFO:Importing libraries
2023-06-07 23:25:55,566:INFO:Copying training dataset
2023-06-07 23:25:55,572:INFO:Defining folds
2023-06-07 23:25:55,572:INFO:Declaring metric variables
2023-06-07 23:25:55,578:INFO:Importing untrained model
2023-06-07 23:25:55,578:INFO:Bayesian Ridge Imported successfully
2023-06-07 23:25:55,592:INFO:Starting cross validation
2023-06-07 23:25:55,593:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-07 23:25:56,087:INFO:Calculating mean and std
2023-06-07 23:25:56,087:INFO:Creating metrics dataframe
2023-06-07 23:25:56,168:INFO:Uploading results into container
2023-06-07 23:25:56,168:INFO:Uploading model into container now
2023-06-07 23:25:56,168:INFO:_master_model_container: 8
2023-06-07 23:25:56,168:INFO:_display_container: 2
2023-06-07 23:25:56,168:INFO:BayesianRidge()
2023-06-07 23:25:56,168:INFO:create_model() successfully completed......................................
2023-06-07 23:25:56,232:INFO:SubProcess create_model() end ==================================
2023-06-07 23:25:56,232:INFO:Creating metrics dataframe
2023-06-07 23:25:56,232:INFO:Initializing Passive Aggressive Regressor
2023-06-07 23:25:56,232:INFO:Total runtime is 0.1921823342641195 minutes
2023-06-07 23:25:56,248:INFO:SubProcess create_model() called ==================================
2023-06-07 23:25:56,248:INFO:Initializing create_model()
2023-06-07 23:25:56,248:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E224FEFEE0>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E26966A230>, model_only=True, return_train_score=False, kwargs={})
2023-06-07 23:25:56,248:INFO:Checking exceptions
2023-06-07 23:25:56,248:INFO:Importing libraries
2023-06-07 23:25:56,248:INFO:Copying training dataset
2023-06-07 23:25:56,255:INFO:Defining folds
2023-06-07 23:25:56,255:INFO:Declaring metric variables
2023-06-07 23:25:56,261:INFO:Importing untrained model
2023-06-07 23:25:56,265:INFO:Passive Aggressive Regressor Imported successfully
2023-06-07 23:25:56,272:INFO:Starting cross validation
2023-06-07 23:25:56,272:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-07 23:25:56,787:INFO:Calculating mean and std
2023-06-07 23:25:56,787:INFO:Creating metrics dataframe
2023-06-07 23:25:56,854:INFO:Uploading results into container
2023-06-07 23:25:56,854:INFO:Uploading model into container now
2023-06-07 23:25:56,854:INFO:_master_model_container: 9
2023-06-07 23:25:56,854:INFO:_display_container: 2
2023-06-07 23:25:56,854:INFO:PassiveAggressiveRegressor(random_state=123)
2023-06-07 23:25:56,854:INFO:create_model() successfully completed......................................
2023-06-07 23:25:56,933:INFO:SubProcess create_model() end ==================================
2023-06-07 23:25:56,933:INFO:Creating metrics dataframe
2023-06-07 23:25:56,949:INFO:Initializing Huber Regressor
2023-06-07 23:25:56,949:INFO:Total runtime is 0.20413143634796144 minutes
2023-06-07 23:25:56,949:INFO:SubProcess create_model() called ==================================
2023-06-07 23:25:56,949:INFO:Initializing create_model()
2023-06-07 23:25:56,949:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E224FEFEE0>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E26966A230>, model_only=True, return_train_score=False, kwargs={})
2023-06-07 23:25:56,949:INFO:Checking exceptions
2023-06-07 23:25:56,949:INFO:Importing libraries
2023-06-07 23:25:56,949:INFO:Copying training dataset
2023-06-07 23:25:56,957:INFO:Defining folds
2023-06-07 23:25:56,957:INFO:Declaring metric variables
2023-06-07 23:25:56,962:INFO:Importing untrained model
2023-06-07 23:25:56,969:INFO:Huber Regressor Imported successfully
2023-06-07 23:25:56,974:INFO:Starting cross validation
2023-06-07 23:25:56,980:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-07 23:25:57,491:INFO:Calculating mean and std
2023-06-07 23:25:57,491:INFO:Creating metrics dataframe
2023-06-07 23:25:57,572:INFO:Uploading results into container
2023-06-07 23:25:57,572:INFO:Uploading model into container now
2023-06-07 23:25:57,572:INFO:_master_model_container: 10
2023-06-07 23:25:57,572:INFO:_display_container: 2
2023-06-07 23:25:57,572:INFO:HuberRegressor()
2023-06-07 23:25:57,572:INFO:create_model() successfully completed......................................
2023-06-07 23:25:57,648:INFO:SubProcess create_model() end ==================================
2023-06-07 23:25:57,648:INFO:Creating metrics dataframe
2023-06-07 23:25:57,655:INFO:Initializing K Neighbors Regressor
2023-06-07 23:25:57,655:INFO:Total runtime is 0.21589163939158124 minutes
2023-06-07 23:25:57,662:INFO:SubProcess create_model() called ==================================
2023-06-07 23:25:57,662:INFO:Initializing create_model()
2023-06-07 23:25:57,662:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E224FEFEE0>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E26966A230>, model_only=True, return_train_score=False, kwargs={})
2023-06-07 23:25:57,662:INFO:Checking exceptions
2023-06-07 23:25:57,662:INFO:Importing libraries
2023-06-07 23:25:57,662:INFO:Copying training dataset
2023-06-07 23:25:57,669:INFO:Defining folds
2023-06-07 23:25:57,669:INFO:Declaring metric variables
2023-06-07 23:25:57,673:INFO:Importing untrained model
2023-06-07 23:25:57,680:INFO:K Neighbors Regressor Imported successfully
2023-06-07 23:25:57,688:INFO:Starting cross validation
2023-06-07 23:25:57,688:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-07 23:25:58,251:INFO:Calculating mean and std
2023-06-07 23:25:58,251:INFO:Creating metrics dataframe
2023-06-07 23:25:58,311:INFO:Uploading results into container
2023-06-07 23:25:58,311:INFO:Uploading model into container now
2023-06-07 23:25:58,311:INFO:_master_model_container: 11
2023-06-07 23:25:58,311:INFO:_display_container: 2
2023-06-07 23:25:58,311:INFO:KNeighborsRegressor(n_jobs=-1)
2023-06-07 23:25:58,311:INFO:create_model() successfully completed......................................
2023-06-07 23:25:58,390:INFO:SubProcess create_model() end ==================================
2023-06-07 23:25:58,390:INFO:Creating metrics dataframe
2023-06-07 23:25:58,390:INFO:Initializing Decision Tree Regressor
2023-06-07 23:25:58,390:INFO:Total runtime is 0.22815055449803673 minutes
2023-06-07 23:25:58,405:INFO:SubProcess create_model() called ==================================
2023-06-07 23:25:58,405:INFO:Initializing create_model()
2023-06-07 23:25:58,405:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E224FEFEE0>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E26966A230>, model_only=True, return_train_score=False, kwargs={})
2023-06-07 23:25:58,405:INFO:Checking exceptions
2023-06-07 23:25:58,405:INFO:Importing libraries
2023-06-07 23:25:58,405:INFO:Copying training dataset
2023-06-07 23:25:58,412:INFO:Defining folds
2023-06-07 23:25:58,412:INFO:Declaring metric variables
2023-06-07 23:25:58,416:INFO:Importing untrained model
2023-06-07 23:25:58,422:INFO:Decision Tree Regressor Imported successfully
2023-06-07 23:25:58,432:INFO:Starting cross validation
2023-06-07 23:25:58,433:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-07 23:25:58,903:INFO:Calculating mean and std
2023-06-07 23:25:58,903:INFO:Creating metrics dataframe
2023-06-07 23:25:58,960:INFO:Uploading results into container
2023-06-07 23:25:58,960:INFO:Uploading model into container now
2023-06-07 23:25:58,960:INFO:_master_model_container: 12
2023-06-07 23:25:58,960:INFO:_display_container: 2
2023-06-07 23:25:58,960:INFO:DecisionTreeRegressor(random_state=123)
2023-06-07 23:25:58,960:INFO:create_model() successfully completed......................................
2023-06-07 23:25:59,034:INFO:SubProcess create_model() end ==================================
2023-06-07 23:25:59,034:INFO:Creating metrics dataframe
2023-06-07 23:25:59,040:INFO:Initializing Random Forest Regressor
2023-06-07 23:25:59,040:INFO:Total runtime is 0.23897396723429365 minutes
2023-06-07 23:25:59,051:INFO:SubProcess create_model() called ==================================
2023-06-07 23:25:59,051:INFO:Initializing create_model()
2023-06-07 23:25:59,051:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E224FEFEE0>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E26966A230>, model_only=True, return_train_score=False, kwargs={})
2023-06-07 23:25:59,051:INFO:Checking exceptions
2023-06-07 23:25:59,051:INFO:Importing libraries
2023-06-07 23:25:59,051:INFO:Copying training dataset
2023-06-07 23:25:59,051:INFO:Defining folds
2023-06-07 23:25:59,051:INFO:Declaring metric variables
2023-06-07 23:25:59,062:INFO:Importing untrained model
2023-06-07 23:25:59,062:INFO:Random Forest Regressor Imported successfully
2023-06-07 23:25:59,068:INFO:Starting cross validation
2023-06-07 23:25:59,075:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-07 23:26:00,148:INFO:Calculating mean and std
2023-06-07 23:26:00,148:INFO:Creating metrics dataframe
2023-06-07 23:26:00,229:INFO:Uploading results into container
2023-06-07 23:26:00,229:INFO:Uploading model into container now
2023-06-07 23:26:00,229:INFO:_master_model_container: 13
2023-06-07 23:26:00,229:INFO:_display_container: 2
2023-06-07 23:26:00,229:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2023-06-07 23:26:00,229:INFO:create_model() successfully completed......................................
2023-06-07 23:26:00,292:INFO:SubProcess create_model() end ==================================
2023-06-07 23:26:00,292:INFO:Creating metrics dataframe
2023-06-07 23:26:00,308:INFO:Initializing Extra Trees Regressor
2023-06-07 23:26:00,308:INFO:Total runtime is 0.26010836362838746 minutes
2023-06-07 23:26:00,308:INFO:SubProcess create_model() called ==================================
2023-06-07 23:26:00,308:INFO:Initializing create_model()
2023-06-07 23:26:00,308:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E224FEFEE0>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E26966A230>, model_only=True, return_train_score=False, kwargs={})
2023-06-07 23:26:00,308:INFO:Checking exceptions
2023-06-07 23:26:00,308:INFO:Importing libraries
2023-06-07 23:26:00,314:INFO:Copying training dataset
2023-06-07 23:26:00,316:INFO:Defining folds
2023-06-07 23:26:00,316:INFO:Declaring metric variables
2023-06-07 23:26:00,321:INFO:Importing untrained model
2023-06-07 23:26:00,324:INFO:Extra Trees Regressor Imported successfully
2023-06-07 23:26:00,330:INFO:Starting cross validation
2023-06-07 23:26:00,337:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-07 23:26:01,337:INFO:Calculating mean and std
2023-06-07 23:26:01,349:INFO:Creating metrics dataframe
2023-06-07 23:26:01,437:INFO:Uploading results into container
2023-06-07 23:26:01,437:INFO:Uploading model into container now
2023-06-07 23:26:01,437:INFO:_master_model_container: 14
2023-06-07 23:26:01,437:INFO:_display_container: 2
2023-06-07 23:26:01,437:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-06-07 23:26:01,437:INFO:create_model() successfully completed......................................
2023-06-07 23:26:01,503:INFO:SubProcess create_model() end ==================================
2023-06-07 23:26:01,503:INFO:Creating metrics dataframe
2023-06-07 23:26:01,503:INFO:Initializing AdaBoost Regressor
2023-06-07 23:26:01,503:INFO:Total runtime is 0.2800342202186585 minutes
2023-06-07 23:26:01,521:INFO:SubProcess create_model() called ==================================
2023-06-07 23:26:01,521:INFO:Initializing create_model()
2023-06-07 23:26:01,521:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E224FEFEE0>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E26966A230>, model_only=True, return_train_score=False, kwargs={})
2023-06-07 23:26:01,521:INFO:Checking exceptions
2023-06-07 23:26:01,521:INFO:Importing libraries
2023-06-07 23:26:01,521:INFO:Copying training dataset
2023-06-07 23:26:01,527:INFO:Defining folds
2023-06-07 23:26:01,527:INFO:Declaring metric variables
2023-06-07 23:26:01,535:INFO:Importing untrained model
2023-06-07 23:26:01,539:INFO:AdaBoost Regressor Imported successfully
2023-06-07 23:26:01,539:INFO:Starting cross validation
2023-06-07 23:26:01,539:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-07 23:26:02,280:INFO:Calculating mean and std
2023-06-07 23:26:02,280:INFO:Creating metrics dataframe
2023-06-07 23:26:02,372:INFO:Uploading results into container
2023-06-07 23:26:02,372:INFO:Uploading model into container now
2023-06-07 23:26:02,372:INFO:_master_model_container: 15
2023-06-07 23:26:02,372:INFO:_display_container: 2
2023-06-07 23:26:02,372:INFO:AdaBoostRegressor(random_state=123)
2023-06-07 23:26:02,372:INFO:create_model() successfully completed......................................
2023-06-07 23:26:02,438:INFO:SubProcess create_model() end ==================================
2023-06-07 23:26:02,438:INFO:Creating metrics dataframe
2023-06-07 23:26:02,451:INFO:Initializing Gradient Boosting Regressor
2023-06-07 23:26:02,451:INFO:Total runtime is 0.29583835999170943 minutes
2023-06-07 23:26:02,461:INFO:SubProcess create_model() called ==================================
2023-06-07 23:26:02,461:INFO:Initializing create_model()
2023-06-07 23:26:02,461:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E224FEFEE0>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E26966A230>, model_only=True, return_train_score=False, kwargs={})
2023-06-07 23:26:02,461:INFO:Checking exceptions
2023-06-07 23:26:02,461:INFO:Importing libraries
2023-06-07 23:26:02,461:INFO:Copying training dataset
2023-06-07 23:26:02,461:INFO:Defining folds
2023-06-07 23:26:02,461:INFO:Declaring metric variables
2023-06-07 23:26:02,477:INFO:Importing untrained model
2023-06-07 23:26:02,481:INFO:Gradient Boosting Regressor Imported successfully
2023-06-07 23:26:02,489:INFO:Starting cross validation
2023-06-07 23:26:02,489:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-07 23:26:03,266:INFO:Calculating mean and std
2023-06-07 23:26:03,266:INFO:Creating metrics dataframe
2023-06-07 23:26:03,380:INFO:Uploading results into container
2023-06-07 23:26:03,380:INFO:Uploading model into container now
2023-06-07 23:26:03,380:INFO:_master_model_container: 16
2023-06-07 23:26:03,380:INFO:_display_container: 2
2023-06-07 23:26:03,380:INFO:GradientBoostingRegressor(random_state=123)
2023-06-07 23:26:03,380:INFO:create_model() successfully completed......................................
2023-06-07 23:26:03,445:INFO:SubProcess create_model() end ==================================
2023-06-07 23:26:03,445:INFO:Creating metrics dataframe
2023-06-07 23:26:03,460:INFO:Initializing Light Gradient Boosting Machine
2023-06-07 23:26:03,460:INFO:Total runtime is 0.3126511732737224 minutes
2023-06-07 23:26:03,464:INFO:SubProcess create_model() called ==================================
2023-06-07 23:26:03,464:INFO:Initializing create_model()
2023-06-07 23:26:03,464:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E224FEFEE0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E26966A230>, model_only=True, return_train_score=False, kwargs={})
2023-06-07 23:26:03,464:INFO:Checking exceptions
2023-06-07 23:26:03,464:INFO:Importing libraries
2023-06-07 23:26:03,464:INFO:Copying training dataset
2023-06-07 23:26:03,469:INFO:Defining folds
2023-06-07 23:26:03,469:INFO:Declaring metric variables
2023-06-07 23:26:03,474:INFO:Importing untrained model
2023-06-07 23:26:03,479:INFO:Light Gradient Boosting Machine Imported successfully
2023-06-07 23:26:03,490:INFO:Starting cross validation
2023-06-07 23:26:03,490:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-07 23:26:04,178:INFO:Calculating mean and std
2023-06-07 23:26:04,178:INFO:Creating metrics dataframe
2023-06-07 23:26:04,273:INFO:Uploading results into container
2023-06-07 23:26:04,273:INFO:Uploading model into container now
2023-06-07 23:26:04,281:INFO:_master_model_container: 17
2023-06-07 23:26:04,281:INFO:_display_container: 2
2023-06-07 23:26:04,281:INFO:LGBMRegressor(random_state=123)
2023-06-07 23:26:04,281:INFO:create_model() successfully completed......................................
2023-06-07 23:26:04,347:INFO:SubProcess create_model() end ==================================
2023-06-07 23:26:04,347:INFO:Creating metrics dataframe
2023-06-07 23:26:04,347:INFO:Initializing Dummy Regressor
2023-06-07 23:26:04,363:INFO:Total runtime is 0.3276952425638835 minutes
2023-06-07 23:26:04,365:INFO:SubProcess create_model() called ==================================
2023-06-07 23:26:04,365:INFO:Initializing create_model()
2023-06-07 23:26:04,365:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E224FEFEE0>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E26966A230>, model_only=True, return_train_score=False, kwargs={})
2023-06-07 23:26:04,365:INFO:Checking exceptions
2023-06-07 23:26:04,365:INFO:Importing libraries
2023-06-07 23:26:04,365:INFO:Copying training dataset
2023-06-07 23:26:04,371:INFO:Defining folds
2023-06-07 23:26:04,371:INFO:Declaring metric variables
2023-06-07 23:26:04,375:INFO:Importing untrained model
2023-06-07 23:26:04,379:INFO:Dummy Regressor Imported successfully
2023-06-07 23:26:04,389:INFO:Starting cross validation
2023-06-07 23:26:04,389:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-07 23:26:04,992:INFO:Calculating mean and std
2023-06-07 23:26:04,992:INFO:Creating metrics dataframe
2023-06-07 23:26:05,140:INFO:Uploading results into container
2023-06-07 23:26:05,140:INFO:Uploading model into container now
2023-06-07 23:26:05,151:INFO:_master_model_container: 18
2023-06-07 23:26:05,151:INFO:_display_container: 2
2023-06-07 23:26:05,151:INFO:DummyRegressor()
2023-06-07 23:26:05,151:INFO:create_model() successfully completed......................................
2023-06-07 23:26:05,223:INFO:SubProcess create_model() end ==================================
2023-06-07 23:26:05,223:INFO:Creating metrics dataframe
2023-06-07 23:26:05,247:INFO:Initializing create_model()
2023-06-07 23:26:05,247:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E224FEFEE0>, estimator=RandomForestRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-07 23:26:05,247:INFO:Checking exceptions
2023-06-07 23:26:05,247:INFO:Importing libraries
2023-06-07 23:26:05,247:INFO:Copying training dataset
2023-06-07 23:26:05,255:INFO:Defining folds
2023-06-07 23:26:05,255:INFO:Declaring metric variables
2023-06-07 23:26:05,255:INFO:Importing untrained model
2023-06-07 23:26:05,255:INFO:Declaring custom model
2023-06-07 23:26:05,255:INFO:Random Forest Regressor Imported successfully
2023-06-07 23:26:05,255:INFO:Cross validation set to False
2023-06-07 23:26:05,255:INFO:Fitting Model
2023-06-07 23:26:05,512:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2023-06-07 23:26:05,512:INFO:create_model() successfully completed......................................
2023-06-07 23:26:05,589:INFO:Creating Dashboard logs
2023-06-07 23:26:05,596:INFO:Model: Random Forest Regressor
2023-06-07 23:26:05,652:INFO:Logged params: {'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': 1.0, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 123, 'verbose': 0, 'warm_start': False}
2023-06-07 23:26:05,763:INFO:Initializing predict_model()
2023-06-07 23:26:05,763:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E224FEFEE0>, estimator=RandomForestRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000001E26E824280>)
2023-06-07 23:26:05,763:INFO:Checking exceptions
2023-06-07 23:26:05,763:INFO:Preloading libraries
2023-06-07 23:26:06,142:INFO:Creating Dashboard logs
2023-06-07 23:26:06,157:INFO:Model: Gradient Boosting Regressor
2023-06-07 23:26:06,206:INFO:Logged params: {'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': None, 'random_state': 123, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2023-06-07 23:26:06,460:INFO:Creating Dashboard logs
2023-06-07 23:26:06,460:INFO:Model: K Neighbors Regressor
2023-06-07 23:26:06,519:INFO:Logged params: {'algorithm': 'auto', 'leaf_size': 30, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': -1, 'n_neighbors': 5, 'p': 2, 'weights': 'uniform'}
2023-06-07 23:26:06,757:INFO:Creating Dashboard logs
2023-06-07 23:26:06,777:INFO:Model: Light Gradient Boosting Machine
2023-06-07 23:26:06,842:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 123, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-06-07 23:26:07,094:INFO:Creating Dashboard logs
2023-06-07 23:26:07,094:INFO:Model: Extra Trees Regressor
2023-06-07 23:26:07,147:INFO:Logged params: {'bootstrap': False, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': 1.0, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 123, 'verbose': 0, 'warm_start': False}
2023-06-07 23:26:07,400:INFO:Creating Dashboard logs
2023-06-07 23:26:07,400:INFO:Model: Huber Regressor
2023-06-07 23:26:07,454:INFO:Logged params: {'alpha': 0.0001, 'epsilon': 1.35, 'fit_intercept': True, 'max_iter': 100, 'tol': 1e-05, 'warm_start': False}
2023-06-07 23:26:07,696:INFO:Creating Dashboard logs
2023-06-07 23:26:07,710:INFO:Model: Lasso Least Angle Regression
2023-06-07 23:26:07,758:INFO:Logged params: {'alpha': 1.0, 'copy_X': True, 'eps': 2.220446049250313e-16, 'fit_intercept': True, 'fit_path': True, 'jitter': None, 'max_iter': 500, 'normalize': 'deprecated', 'positive': False, 'precompute': 'auto', 'random_state': 123, 'verbose': False}
2023-06-07 23:26:08,007:INFO:Creating Dashboard logs
2023-06-07 23:26:08,022:INFO:Model: Bayesian Ridge
2023-06-07 23:26:08,070:INFO:Logged params: {'alpha_1': 1e-06, 'alpha_2': 1e-06, 'alpha_init': None, 'compute_score': False, 'copy_X': True, 'fit_intercept': True, 'lambda_1': 1e-06, 'lambda_2': 1e-06, 'lambda_init': None, 'n_iter': 300, 'normalize': 'deprecated', 'tol': 0.001, 'verbose': False}
2023-06-07 23:26:08,345:INFO:Creating Dashboard logs
2023-06-07 23:26:08,345:INFO:Model: Ridge Regression
2023-06-07 23:26:08,396:INFO:Logged params: {'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'normalize': 'deprecated', 'positive': False, 'random_state': 123, 'solver': 'auto', 'tol': 0.001}
2023-06-07 23:26:08,659:INFO:Creating Dashboard logs
2023-06-07 23:26:08,674:INFO:Model: Lasso Regression
2023-06-07 23:26:08,722:INFO:Logged params: {'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'max_iter': 1000, 'normalize': 'deprecated', 'positive': False, 'precompute': False, 'random_state': 123, 'selection': 'cyclic', 'tol': 0.0001, 'warm_start': False}
2023-06-07 23:26:09,043:INFO:Creating Dashboard logs
2023-06-07 23:26:09,043:INFO:Model: Linear Regression
2023-06-07 23:26:09,113:INFO:Logged params: {'copy_X': True, 'fit_intercept': True, 'n_jobs': -1, 'normalize': 'deprecated', 'positive': False}
2023-06-07 23:26:09,383:INFO:Creating Dashboard logs
2023-06-07 23:26:09,390:INFO:Model: Least Angle Regression
2023-06-07 23:26:09,475:INFO:Logged params: {'copy_X': True, 'eps': 2.220446049250313e-16, 'fit_intercept': True, 'fit_path': True, 'jitter': None, 'n_nonzero_coefs': 500, 'normalize': 'deprecated', 'precompute': 'auto', 'random_state': 123, 'verbose': False}
2023-06-07 23:26:09,726:INFO:Creating Dashboard logs
2023-06-07 23:26:09,726:INFO:Model: Passive Aggressive Regressor
2023-06-07 23:26:09,781:INFO:Logged params: {'C': 1.0, 'average': False, 'early_stopping': False, 'epsilon': 0.1, 'fit_intercept': True, 'loss': 'epsilon_insensitive', 'max_iter': 1000, 'n_iter_no_change': 5, 'random_state': 123, 'shuffle': True, 'tol': 0.001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2023-06-07 23:26:10,060:INFO:Creating Dashboard logs
2023-06-07 23:26:10,060:INFO:Model: Elastic Net
2023-06-07 23:26:10,108:INFO:Logged params: {'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'l1_ratio': 0.5, 'max_iter': 1000, 'normalize': 'deprecated', 'positive': False, 'precompute': False, 'random_state': 123, 'selection': 'cyclic', 'tol': 0.0001, 'warm_start': False}
2023-06-07 23:26:10,346:INFO:Creating Dashboard logs
2023-06-07 23:26:10,361:INFO:Model: Orthogonal Matching Pursuit
2023-06-07 23:26:10,409:INFO:Logged params: {'fit_intercept': True, 'n_nonzero_coefs': None, 'normalize': 'deprecated', 'precompute': 'auto', 'tol': None}
2023-06-07 23:26:10,645:INFO:Creating Dashboard logs
2023-06-07 23:26:10,645:INFO:Model: Decision Tree Regressor
2023-06-07 23:26:10,710:INFO:Logged params: {'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'random_state': 123, 'splitter': 'best'}
2023-06-07 23:26:10,964:INFO:Creating Dashboard logs
2023-06-07 23:26:10,964:INFO:Model: AdaBoost Regressor
2023-06-07 23:26:11,028:INFO:Logged params: {'base_estimator': None, 'learning_rate': 1.0, 'loss': 'linear', 'n_estimators': 50, 'random_state': 123}
2023-06-07 23:26:11,269:INFO:Creating Dashboard logs
2023-06-07 23:26:11,269:INFO:Model: Dummy Regressor
2023-06-07 23:26:11,328:INFO:Logged params: {'constant': None, 'quantile': None, 'strategy': 'mean'}
2023-06-07 23:26:11,593:INFO:_master_model_container: 18
2023-06-07 23:26:11,593:INFO:_display_container: 2
2023-06-07 23:26:11,593:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2023-06-07 23:26:11,593:INFO:compare_models() successfully completed......................................
2023-06-07 23:26:48,563:INFO:PyCaret RegressionExperiment
2023-06-07 23:26:48,563:INFO:Logging name: your_experiment_name
2023-06-07 23:26:48,563:INFO:ML Usecase: MLUsecase.REGRESSION
2023-06-07 23:26:48,563:INFO:version 3.0.0
2023-06-07 23:26:48,563:INFO:Initializing setup()
2023-06-07 23:26:48,563:INFO:self.USI: 2bb1
2023-06-07 23:26:48,563:INFO:self._variable_keys: {'target_param', 'gpu_n_jobs_param', 'y', 'data', 'exp_name_log', 'transform_target_param', 'y_train', 'y_test', 'X_test', 'USI', 'html_param', '_available_plots', 'log_plots_param', 'seed', 'idx', 'pipeline', 'exp_id', 'X_train', 'X', 'fold_generator', '_ml_usecase', 'memory', 'fold_groups_param', 'fold_shuffle_param', 'logging_param', 'n_jobs_param', 'gpu_param'}
2023-06-07 23:26:48,563:INFO:Checking environment
2023-06-07 23:26:48,563:INFO:python_version: 3.10.5
2023-06-07 23:26:48,563:INFO:python_build: ('tags/v3.10.5:f377153', 'Jun  6 2022 16:14:13')
2023-06-07 23:26:48,563:INFO:machine: AMD64
2023-06-07 23:26:48,563:INFO:platform: Windows-10-10.0.22621-SP0
2023-06-07 23:26:48,563:INFO:Memory: svmem(total=16497119232, available=6665519104, percent=59.6, used=9831600128, free=6665519104)
2023-06-07 23:26:48,563:INFO:Physical Core: 8
2023-06-07 23:26:48,563:INFO:Logical Core: 16
2023-06-07 23:26:48,563:INFO:Checking libraries
2023-06-07 23:26:48,563:INFO:System:
2023-06-07 23:26:48,563:INFO:    python: 3.10.5 (tags/v3.10.5:f377153, Jun  6 2022, 16:14:13) [MSC v.1929 64 bit (AMD64)]
2023-06-07 23:26:48,563:INFO:executable: C:\Users\Hashif\AppData\Local\Programs\Python\Python310\python.exe
2023-06-07 23:26:48,563:INFO:   machine: Windows-10-10.0.22621-SP0
2023-06-07 23:26:48,563:INFO:PyCaret required dependencies:
2023-06-07 23:26:48,563:INFO:                 pip: 23.1.1
2023-06-07 23:26:48,563:INFO:          setuptools: 58.1.0
2023-06-07 23:26:48,563:INFO:             pycaret: 3.0.0
2023-06-07 23:26:48,563:INFO:             IPython: 8.4.0
2023-06-07 23:26:48,563:INFO:          ipywidgets: 7.7.0
2023-06-07 23:26:48,563:INFO:                tqdm: 4.65.0
2023-06-07 23:26:48,563:INFO:               numpy: 1.23.0
2023-06-07 23:26:48,563:INFO:              pandas: 1.4.3
2023-06-07 23:26:48,563:INFO:              jinja2: 3.1.2
2023-06-07 23:26:48,563:INFO:               scipy: 1.9.3
2023-06-07 23:26:48,563:INFO:              joblib: 1.2.0
2023-06-07 23:26:48,563:INFO:             sklearn: 1.1.2
2023-06-07 23:26:48,563:INFO:                pyod: 1.0.9
2023-06-07 23:26:48,563:INFO:            imblearn: 0.10.1
2023-06-07 23:26:48,563:INFO:   category_encoders: 2.6.0
2023-06-07 23:26:48,563:INFO:            lightgbm: 3.3.5
2023-06-07 23:26:48,563:INFO:               numba: 0.56.4
2023-06-07 23:26:48,563:INFO:            requests: 2.28.1
2023-06-07 23:26:48,563:INFO:          matplotlib: 3.6.2
2023-06-07 23:26:48,563:INFO:          scikitplot: 0.3.7
2023-06-07 23:26:48,563:INFO:         yellowbrick: 1.5
2023-06-07 23:26:48,563:INFO:              plotly: 5.14.1
2023-06-07 23:26:48,563:INFO:             kaleido: 0.2.1
2023-06-07 23:26:48,563:INFO:         statsmodels: 0.13.5
2023-06-07 23:26:48,563:INFO:              sktime: 0.17.1
2023-06-07 23:26:48,563:INFO:               tbats: 1.1.3
2023-06-07 23:26:48,563:INFO:            pmdarima: 2.0.3
2023-06-07 23:26:48,563:INFO:              psutil: 5.9.1
2023-06-07 23:26:48,563:INFO:PyCaret optional dependencies:
2023-06-07 23:26:48,563:INFO:                shap: Not installed
2023-06-07 23:26:48,563:INFO:           interpret: Not installed
2023-06-07 23:26:48,563:INFO:                umap: Not installed
2023-06-07 23:26:48,563:INFO:    pandas_profiling: Not installed
2023-06-07 23:26:48,563:INFO:  explainerdashboard: Not installed
2023-06-07 23:26:48,563:INFO:             autoviz: Not installed
2023-06-07 23:26:48,563:INFO:           fairlearn: Not installed
2023-06-07 23:26:48,563:INFO:             xgboost: Not installed
2023-06-07 23:26:48,563:INFO:            catboost: Not installed
2023-06-07 23:26:48,563:INFO:              kmodes: Not installed
2023-06-07 23:26:48,563:INFO:             mlxtend: Not installed
2023-06-07 23:26:48,563:INFO:       statsforecast: Not installed
2023-06-07 23:26:48,563:INFO:        tune_sklearn: Not installed
2023-06-07 23:26:48,563:INFO:                 ray: Not installed
2023-06-07 23:26:48,563:INFO:            hyperopt: Not installed
2023-06-07 23:26:48,563:INFO:              optuna: Not installed
2023-06-07 23:26:48,563:INFO:               skopt: Not installed
2023-06-07 23:26:48,563:INFO:              mlflow: 2.3.0
2023-06-07 23:26:48,563:INFO:              gradio: Not installed
2023-06-07 23:26:48,563:INFO:             fastapi: Not installed
2023-06-07 23:26:48,563:INFO:             uvicorn: Not installed
2023-06-07 23:26:48,563:INFO:              m2cgen: Not installed
2023-06-07 23:26:48,563:INFO:           evidently: Not installed
2023-06-07 23:26:48,563:INFO:               fugue: Not installed
2023-06-07 23:26:48,563:INFO:           streamlit: Not installed
2023-06-07 23:26:48,563:INFO:             prophet: Not installed
2023-06-07 23:26:48,563:INFO:None
2023-06-07 23:26:48,563:INFO:Set up data.
2023-06-07 23:26:48,577:INFO:Set up train/test split.
2023-06-07 23:26:48,593:INFO:Set up index.
2023-06-07 23:26:48,593:INFO:Set up folding strategy.
2023-06-07 23:26:48,593:INFO:Assigning column types.
2023-06-07 23:26:48,593:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-06-07 23:26:48,593:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-06-07 23:26:48,593:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-06-07 23:26:48,615:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-07 23:26:48,703:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-07 23:26:48,766:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-07 23:26:48,766:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-07 23:26:48,766:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-07 23:26:48,766:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-06-07 23:26:48,782:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-06-07 23:26:48,782:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-07 23:26:48,891:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-07 23:26:48,970:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-07 23:26:48,970:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-07 23:26:48,970:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-07 23:26:48,970:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-06-07 23:26:48,970:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-06-07 23:26:48,986:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-07 23:26:49,080:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-07 23:26:49,158:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-07 23:26:49,158:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-07 23:26:49,158:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-07 23:26:49,158:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-06-07 23:26:49,174:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-07 23:26:49,268:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-07 23:26:49,347:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-07 23:26:49,347:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-07 23:26:49,347:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-07 23:26:49,347:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-06-07 23:26:49,362:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-07 23:26:49,457:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-07 23:26:49,541:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-07 23:26:49,541:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-07 23:26:49,541:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-07 23:26:49,557:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-07 23:26:49,667:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-07 23:26:49,755:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-07 23:26:49,755:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-07 23:26:49,755:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-07 23:26:49,755:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-06-07 23:26:49,865:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-07 23:26:49,959:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-07 23:26:49,959:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-07 23:26:49,959:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-07 23:26:50,069:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-07 23:26:50,148:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-07 23:26:50,148:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-07 23:26:50,148:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-07 23:26:50,148:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-06-07 23:26:50,258:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-07 23:26:50,336:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-07 23:26:50,336:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-07 23:26:50,448:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-07 23:26:50,541:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-07 23:26:50,541:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-07 23:26:50,541:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-06-07 23:26:50,746:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-07 23:26:50,746:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-07 23:26:50,919:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-07 23:26:50,919:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-07 23:26:50,919:INFO:Preparing preprocessing pipeline...
2023-06-07 23:26:50,919:INFO:Set up simple imputation.
2023-06-07 23:26:50,919:INFO:Set up feature normalization.
2023-06-07 23:26:50,919:INFO:Set up column name cleaning.
2023-06-07 23:26:50,965:INFO:Finished creating preprocessing pipeline.
2023-06-07 23:26:50,981:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Hashif\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Unnamed: 0', 'location',
                                             'ratings', 'type', 'air',
                                             'air conditioning', 'bar',
                                             'breakfast', 'centre', 'closed',
                                             'conditioning', 'desk',
                                             'facilities', 'facilities guests',
                                             'family', 'fitness', 'front',
                                             'garden', 'guests', 'housekeeping',
                                             '...
                                             'parking', 'pool', 'restaurant',
                                             'room', 'room service', 'service',
                                             'shuttle', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-06-07 23:26:50,981:INFO:Creating final display dataframe.
2023-06-07 23:26:51,124:INFO:Setup _display_container:                     Description                 Value
0                    Session id                   123
1                        Target                 price
2                   Target type            Regression
3           Original data shape             (735, 40)
4        Transformed data shape             (735, 40)
5   Transformed train set shape             (588, 40)
6    Transformed test set shape             (147, 40)
7              Numeric features                    39
8                    Preprocess                  True
9               Imputation type                simple
10           Numeric imputation                  mean
11       Categorical imputation                  mode
12                    Normalize                  True
13             Normalize method                zscore
14               Fold Generator                 KFold
15                  Fold Number                    10
16                     CPU Jobs                    -1
17                      Use GPU                 False
18               Log Experiment          MlflowLogger
19              Experiment Name  your_experiment_name
20                          USI                  2bb1
2023-06-07 23:26:51,300:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-07 23:26:51,300:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-07 23:26:51,494:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-07 23:26:51,494:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-07 23:26:51,494:INFO:Logging experiment in loggers
2023-06-07 23:26:51,652:INFO:SubProcess save_model() called ==================================
2023-06-07 23:26:51,667:INFO:Initializing save_model()
2023-06-07 23:26:51,667:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\Hashif\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Unnamed: 0', 'location',
                                             'ratings', 'type', 'air',
                                             'air conditioning', 'bar',
                                             'breakfast', 'centre', 'closed',
                                             'conditioning', 'desk',
                                             'facilities', 'facilities guests',
                                             'family', 'fitness', 'front',
                                             'garden', 'guests', 'housekeeping',
                                             '...
                                             'parking', 'pool', 'restaurant',
                                             'room', 'room service', 'service',
                                             'shuttle', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), model_name=C:\Users\Hashif\AppData\Local\Temp\tmpgz5c4d2q\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\Hashif\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Unnamed: 0', 'location',
                                             'ratings', 'type', 'air',
                                             'air conditioning', 'bar',
                                             'breakfast', 'centre', 'closed',
                                             'conditioning', 'desk',
                                             'facilities', 'facilities guests',
                                             'family', 'fitness', 'front',
                                             'garden', 'guests', 'housekeeping',
                                             '...
                                             'parking', 'pool', 'restaurant',
                                             'room', 'room service', 'service',
                                             'shuttle', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=False, use_case=MLUsecase.REGRESSION, kwargs={})
2023-06-07 23:26:51,667:INFO:Adding model into prep_pipe
2023-06-07 23:26:51,667:WARNING:Only Model saved as it was a pipeline.
2023-06-07 23:26:51,667:INFO:C:\Users\Hashif\AppData\Local\Temp\tmpgz5c4d2q\Transformation Pipeline.pkl saved in current working directory
2023-06-07 23:26:51,667:INFO:Pipeline(memory=FastMemory(location=C:\Users\Hashif\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Unnamed: 0', 'location',
                                             'ratings', 'type', 'air',
                                             'air conditioning', 'bar',
                                             'breakfast', 'centre', 'closed',
                                             'conditioning', 'desk',
                                             'facilities', 'facilities guests',
                                             'family', 'fitness', 'front',
                                             'garden', 'guests', 'housekeeping',
                                             '...
                                             'parking', 'pool', 'restaurant',
                                             'room', 'room service', 'service',
                                             'shuttle', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-06-07 23:26:51,667:INFO:save_model() successfully completed......................................
2023-06-07 23:26:51,841:INFO:SubProcess save_model() end ==================================
2023-06-07 23:26:51,931:INFO:setup() successfully completed in 3.02s...............
2023-06-07 23:26:52,000:INFO:Initializing compare_models()
2023-06-07 23:26:52,000:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E26D334940>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001E26D334940>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-06-07 23:26:52,000:INFO:Checking exceptions
2023-06-07 23:26:52,000:INFO:Preparing display monitor
2023-06-07 23:26:52,033:INFO:Initializing Linear Regression
2023-06-07 23:26:52,033:INFO:Total runtime is 0.0 minutes
2023-06-07 23:26:52,042:INFO:SubProcess create_model() called ==================================
2023-06-07 23:26:52,047:INFO:Initializing create_model()
2023-06-07 23:26:52,047:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E26D334940>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E26F23D060>, model_only=True, return_train_score=False, kwargs={})
2023-06-07 23:26:52,047:INFO:Checking exceptions
2023-06-07 23:26:52,047:INFO:Importing libraries
2023-06-07 23:26:52,047:INFO:Copying training dataset
2023-06-07 23:26:52,049:INFO:Defining folds
2023-06-07 23:26:52,049:INFO:Declaring metric variables
2023-06-07 23:26:52,057:INFO:Importing untrained model
2023-06-07 23:26:52,063:INFO:Linear Regression Imported successfully
2023-06-07 23:26:52,076:INFO:Starting cross validation
2023-06-07 23:26:52,076:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-07 23:26:53,097:INFO:Calculating mean and std
2023-06-07 23:26:53,097:INFO:Creating metrics dataframe
2023-06-07 23:26:53,256:INFO:Uploading results into container
2023-06-07 23:26:53,256:INFO:Uploading model into container now
2023-06-07 23:26:53,256:INFO:_master_model_container: 1
2023-06-07 23:26:53,261:INFO:_display_container: 2
2023-06-07 23:26:53,261:INFO:LinearRegression(n_jobs=-1)
2023-06-07 23:26:53,261:INFO:create_model() successfully completed......................................
2023-06-07 23:26:53,354:INFO:SubProcess create_model() end ==================================
2023-06-07 23:26:53,354:INFO:Creating metrics dataframe
2023-06-07 23:26:53,368:INFO:Initializing Lasso Regression
2023-06-07 23:26:53,368:INFO:Total runtime is 0.022249225775400797 minutes
2023-06-07 23:26:53,373:INFO:SubProcess create_model() called ==================================
2023-06-07 23:26:53,373:INFO:Initializing create_model()
2023-06-07 23:26:53,373:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E26D334940>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E26F23D060>, model_only=True, return_train_score=False, kwargs={})
2023-06-07 23:26:53,373:INFO:Checking exceptions
2023-06-07 23:26:53,373:INFO:Importing libraries
2023-06-07 23:26:53,373:INFO:Copying training dataset
2023-06-07 23:26:53,381:INFO:Defining folds
2023-06-07 23:26:53,385:INFO:Declaring metric variables
2023-06-07 23:26:53,391:INFO:Importing untrained model
2023-06-07 23:26:53,395:INFO:Lasso Regression Imported successfully
2023-06-07 23:26:53,408:INFO:Starting cross validation
2023-06-07 23:26:53,408:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-07 23:26:53,662:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.186e+07, tolerance: 2.390e+05
  model = cd_fast.enet_coordinate_descent(

2023-06-07 23:26:54,371:INFO:Calculating mean and std
2023-06-07 23:26:54,371:INFO:Creating metrics dataframe
2023-06-07 23:26:54,527:INFO:Uploading results into container
2023-06-07 23:26:54,536:INFO:Uploading model into container now
2023-06-07 23:26:54,536:INFO:_master_model_container: 2
2023-06-07 23:26:54,536:INFO:_display_container: 2
2023-06-07 23:26:54,538:INFO:Lasso(random_state=123)
2023-06-07 23:26:54,538:INFO:create_model() successfully completed......................................
2023-06-07 23:26:54,616:INFO:SubProcess create_model() end ==================================
2023-06-07 23:26:54,616:INFO:Creating metrics dataframe
2023-06-07 23:26:54,622:INFO:Initializing Ridge Regression
2023-06-07 23:26:54,622:INFO:Total runtime is 0.04315227667490641 minutes
2023-06-07 23:26:54,633:INFO:SubProcess create_model() called ==================================
2023-06-07 23:26:54,633:INFO:Initializing create_model()
2023-06-07 23:26:54,633:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E26D334940>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E26F23D060>, model_only=True, return_train_score=False, kwargs={})
2023-06-07 23:26:54,633:INFO:Checking exceptions
2023-06-07 23:26:54,633:INFO:Importing libraries
2023-06-07 23:26:54,633:INFO:Copying training dataset
2023-06-07 23:26:54,641:INFO:Defining folds
2023-06-07 23:26:54,645:INFO:Declaring metric variables
2023-06-07 23:26:54,651:INFO:Importing untrained model
2023-06-07 23:26:54,658:INFO:Ridge Regression Imported successfully
2023-06-07 23:26:54,666:INFO:Starting cross validation
2023-06-07 23:26:54,669:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-07 23:26:55,563:INFO:Calculating mean and std
2023-06-07 23:26:55,563:INFO:Creating metrics dataframe
2023-06-07 23:26:55,723:INFO:Uploading results into container
2023-06-07 23:26:55,723:INFO:Uploading model into container now
2023-06-07 23:26:55,723:INFO:_master_model_container: 3
2023-06-07 23:26:55,723:INFO:_display_container: 2
2023-06-07 23:26:55,723:INFO:Ridge(random_state=123)
2023-06-07 23:26:55,723:INFO:create_model() successfully completed......................................
2023-06-07 23:26:55,816:INFO:SubProcess create_model() end ==================================
2023-06-07 23:26:55,818:INFO:Creating metrics dataframe
2023-06-07 23:26:55,836:INFO:Initializing Elastic Net
2023-06-07 23:26:55,836:INFO:Total runtime is 0.06338177522023519 minutes
2023-06-07 23:26:55,836:INFO:SubProcess create_model() called ==================================
2023-06-07 23:26:55,836:INFO:Initializing create_model()
2023-06-07 23:26:55,844:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E26D334940>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E26F23D060>, model_only=True, return_train_score=False, kwargs={})
2023-06-07 23:26:55,844:INFO:Checking exceptions
2023-06-07 23:26:55,844:INFO:Importing libraries
2023-06-07 23:26:55,844:INFO:Copying training dataset
2023-06-07 23:26:55,848:INFO:Defining folds
2023-06-07 23:26:55,851:INFO:Declaring metric variables
2023-06-07 23:26:55,855:INFO:Importing untrained model
2023-06-07 23:26:55,862:INFO:Elastic Net Imported successfully
2023-06-07 23:26:55,873:INFO:Starting cross validation
2023-06-07 23:26:55,873:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-07 23:26:56,592:INFO:Calculating mean and std
2023-06-07 23:26:56,592:INFO:Creating metrics dataframe
2023-06-07 23:26:56,706:INFO:Uploading results into container
2023-06-07 23:26:56,706:INFO:Uploading model into container now
2023-06-07 23:26:56,706:INFO:_master_model_container: 4
2023-06-07 23:26:56,706:INFO:_display_container: 2
2023-06-07 23:26:56,706:INFO:ElasticNet(random_state=123)
2023-06-07 23:26:56,706:INFO:create_model() successfully completed......................................
2023-06-07 23:26:56,780:INFO:SubProcess create_model() end ==================================
2023-06-07 23:26:56,780:INFO:Creating metrics dataframe
2023-06-07 23:26:56,780:INFO:Initializing Least Angle Regression
2023-06-07 23:26:56,780:INFO:Total runtime is 0.0791220227877299 minutes
2023-06-07 23:26:56,793:INFO:SubProcess create_model() called ==================================
2023-06-07 23:26:56,793:INFO:Initializing create_model()
2023-06-07 23:26:56,793:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E26D334940>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E26F23D060>, model_only=True, return_train_score=False, kwargs={})
2023-06-07 23:26:56,793:INFO:Checking exceptions
2023-06-07 23:26:56,793:INFO:Importing libraries
2023-06-07 23:26:56,793:INFO:Copying training dataset
2023-06-07 23:26:56,799:INFO:Defining folds
2023-06-07 23:26:56,799:INFO:Declaring metric variables
2023-06-07 23:26:56,802:INFO:Importing untrained model
2023-06-07 23:26:56,806:INFO:Least Angle Regression Imported successfully
2023-06-07 23:26:56,813:INFO:Starting cross validation
2023-06-07 23:26:56,814:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-07 23:26:56,891:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-06-07 23:26:56,895:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-06-07 23:26:56,895:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-06-07 23:26:56,907:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-06-07 23:26:56,907:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-06-07 23:26:56,925:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=8.042e+00, with an active set of 10 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:56,925:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-06-07 23:26:56,925:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=3.967e+00, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:56,925:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=5.241e+00, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:56,925:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=4.345e+00, with an active set of 14 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:56,925:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=2.191e+00, with an active set of 19 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:56,925:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=4.021e+00, with an active set of 17 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:56,925:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=2.872e+00, with an active set of 20 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:56,925:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=3.940e+00, with an active set of 17 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:56,925:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=2.118e+00, with an active set of 22 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:56,925:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=3.368e+00, with an active set of 18 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:56,925:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=1.014e+00, with an active set of 25 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:56,925:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=1.853e+00, with an active set of 22 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:56,925:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=6.307e+00, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:56,925:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=1.208e+00, with an active set of 24 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:56,925:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 28 iterations, i.e. alpha=6.456e-01, with an active set of 27 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:56,925:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=1.657e+00, with an active set of 21 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:56,925:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=1.640e+00, with an active set of 21 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:56,925:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=3.357e+00, with an active set of 19 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:56,925:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=3.318e+00, with an active set of 19 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:56,925:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=2.950e+00, with an active set of 19 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:56,925:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=1.558e+00, with an active set of 24 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:56,925:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=6.580e+00, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:56,925:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=2.950e+00, with an active set of 19 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:56,925:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 29 iterations, i.e. alpha=1.682e+00, with an active set of 27 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:56,925:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=2.862e+00, with an active set of 19 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:56,925:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 27 iterations, i.e. alpha=1.334e+00, with an active set of 25 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:56,925:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 29 iterations, i.e. alpha=1.034e+00, with an active set of 27 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:56,925:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 27 iterations, i.e. alpha=1.334e+00, with an active set of 25 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:56,925:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=2.664e+00, with an active set of 19 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:56,925:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 29 iterations, i.e. alpha=9.514e-01, with an active set of 27 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:56,925:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 27 iterations, i.e. alpha=9.585e-01, with an active set of 25 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:56,925:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=2.490e+00, with an active set of 20 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:56,925:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 30 iterations, i.e. alpha=4.850e-01, with an active set of 28 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:56,925:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=2.428e+00, with an active set of 20 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:56,925:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 29 iterations, i.e. alpha=2.932e-01, with an active set of 27 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:56,925:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 30 iterations, i.e. alpha=4.028e-01, with an active set of 28 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:56,925:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 29 iterations, i.e. alpha=2.932e-01, with an active set of 27 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:56,925:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=1.601e+00, with an active set of 21 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:56,925:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 31 iterations, i.e. alpha=1.547e-01, with an active set of 29 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:56,925:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 31 iterations, i.e. alpha=1.261e-01, with an active set of 29 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:56,925:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=1.075e+00, with an active set of 24 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:56,939:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 32 iterations, i.e. alpha=5.998e-02, with an active set of 30 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:56,939:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=9.228e-01, with an active set of 25 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:56,939:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 32 iterations, i.e. alpha=5.998e-02, with an active set of 30 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:56,939:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 32 iterations, i.e. alpha=1.326e-01, with an active set of 30 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:56,939:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=7.285e-01, with an active set of 26 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:56,939:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 32 iterations, i.e. alpha=1.326e-01, with an active set of 30 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:56,939:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 30 iterations, i.e. alpha=1.993e-01, with an active set of 29 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:56,939:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 27 iterations, i.e. alpha=4.081e-01, with an active set of 27 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:56,939:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 27 iterations, i.e. alpha=4.081e-01, with an active set of 27 regressors, and the smallest cholesky pivot element being 6.409e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:56,939:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 33 iterations, i.e. alpha=1.384e-02, with an active set of 31 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:56,939:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 27 iterations, i.e. alpha=2.558e-01, with an active set of 27 regressors, and the smallest cholesky pivot element being 6.409e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:56,939:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 33 iterations, i.e. alpha=1.384e-02, with an active set of 31 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:56,939:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 31 iterations, i.e. alpha=4.209e-02, with an active set of 30 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:56,939:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 27 iterations, i.e. alpha=2.558e-01, with an active set of 27 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:56,939:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 27 iterations, i.e. alpha=2.550e-01, with an active set of 27 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:56,939:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 27 iterations, i.e. alpha=2.246e-01, with an active set of 27 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:56,939:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 32 iterations, i.e. alpha=1.668e-02, with an active set of 31 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:56,939:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 27 iterations, i.e. alpha=9.450e-02, with an active set of 27 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:56,939:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 28 iterations, i.e. alpha=7.008e-02, with an active set of 28 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:56,939:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 30 iterations, i.e. alpha=3.042e-02, with an active set of 30 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:56,939:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 30 iterations, i.e. alpha=1.389e-02, with an active set of 30 regressors, and the smallest cholesky pivot element being 6.409e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:56,939:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-06-07 23:26:56,939:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=5.654e+00, with an active set of 11 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:56,954:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=4.968e+00, with an active set of 13 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:56,954:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=4.968e+00, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:56,954:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=7.311e+00, with an active set of 11 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:56,954:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=2.777e+00, with an active set of 18 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:56,954:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=5.325e+00, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:56,954:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=2.672e+00, with an active set of 18 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:56,954:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=3.739e+00, with an active set of 16 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:56,954:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=3.739e+00, with an active set of 16 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:56,954:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=2.367e+00, with an active set of 21 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:56,954:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=3.656e+00, with an active set of 17 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:56,954:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=3.567e+00, with an active set of 17 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:56,954:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=3.082e+00, with an active set of 17 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:56,954:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-06-07 23:26:56,954:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=2.625e+00, with an active set of 17 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:56,954:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=1.838e+00, with an active set of 25 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:56,954:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=2.299e+00, with an active set of 18 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:56,954:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-06-07 23:26:56,954:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 30 iterations, i.e. alpha=1.179e+00, with an active set of 28 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:56,954:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 31 iterations, i.e. alpha=8.017e-01, with an active set of 29 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:56,954:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=1.173e+00, with an active set of 25 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:56,954:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 31 iterations, i.e. alpha=6.552e-01, with an active set of 29 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:56,954:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=1.089e+00, with an active set of 25 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:56,954:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=1.089e+00, with an active set of 25 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:56,954:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 32 iterations, i.e. alpha=5.078e-01, with an active set of 30 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:56,954:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=1.089e+00, with an active set of 25 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:56,954:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 32 iterations, i.e. alpha=4.582e-01, with an active set of 30 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:56,954:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 32 iterations, i.e. alpha=3.037e-01, with an active set of 30 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:56,954:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 32 iterations, i.e. alpha=4.088e-02, with an active set of 30 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:56,954:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 28 iterations, i.e. alpha=5.413e-01, with an active set of 27 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:56,954:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 32 iterations, i.e. alpha=3.725e-02, with an active set of 30 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:56,954:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 28 iterations, i.e. alpha=5.413e-01, with an active set of 27 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:56,954:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 28 iterations, i.e. alpha=5.413e-01, with an active set of 27 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:56,954:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 32 iterations, i.e. alpha=1.910e-02, with an active set of 30 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:56,954:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 29 iterations, i.e. alpha=2.314e-01, with an active set of 28 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:56,954:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 29 iterations, i.e. alpha=2.314e-01, with an active set of 28 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:56,954:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=2.706e+00, with an active set of 20 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:56,954:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=6.241e+00, with an active set of 12 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:56,954:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=2.394e+00, with an active set of 20 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:56,954:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=2.394e+00, with an active set of 20 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:56,954:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=5.648e+00, with an active set of 13 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:56,954:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=5.648e+00, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:56,954:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 31 iterations, i.e. alpha=1.395e-01, with an active set of 30 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:56,954:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=1.741e+00, with an active set of 21 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:56,954:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 31 iterations, i.e. alpha=1.380e-01, with an active set of 30 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:56,954:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 31 iterations, i.e. alpha=6.887e-02, with an active set of 30 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:56,954:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 31 iterations, i.e. alpha=6.887e-02, with an active set of 30 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:56,954:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 31 iterations, i.e. alpha=6.887e-02, with an active set of 30 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:56,954:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 27 iterations, i.e. alpha=1.284e+00, with an active set of 25 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:56,954:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=3.183e+00, with an active set of 18 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:56,954:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 32 iterations, i.e. alpha=9.930e-03, with an active set of 31 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:56,954:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 29 iterations, i.e. alpha=5.399e-01, with an active set of 27 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:56,954:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 32 iterations, i.e. alpha=9.930e-03, with an active set of 31 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:56,954:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 29 iterations, i.e. alpha=5.399e-01, with an active set of 27 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:56,954:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=2.745e+00, with an active set of 21 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:56,970:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-06-07 23:26:56,970:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 32 iterations, i.e. alpha=9.930e-03, with an active set of 31 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:56,970:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=2.745e+00, with an active set of 21 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:56,970:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 29 iterations, i.e. alpha=5.343e-01, with an active set of 27 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:56,970:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=2.713e+00, with an active set of 21 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:56,970:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 29 iterations, i.e. alpha=4.352e-01, with an active set of 27 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:56,970:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=2.534e+00, with an active set of 22 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:56,970:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 30 iterations, i.e. alpha=1.397e-01, with an active set of 28 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:56,970:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 30 iterations, i.e. alpha=1.397e-01, with an active set of 28 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:56,970:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=1.361e+00, with an active set of 24 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:56,970:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 27 iterations, i.e. alpha=6.824e-01, with an active set of 26 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:56,970:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=1.173e+00, with an active set of 25 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:56,970:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=1.173e+00, with an active set of 25 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:56,970:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 31 iterations, i.e. alpha=6.534e-02, with an active set of 29 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:56,970:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=1.159e+00, with an active set of 25 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:56,970:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 31 iterations, i.e. alpha=3.079e-02, with an active set of 29 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:56,970:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 31 iterations, i.e. alpha=3.079e-02, with an active set of 29 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:56,970:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 28 iterations, i.e. alpha=1.010e+00, with an active set of 26 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:56,970:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 31 iterations, i.e. alpha=3.079e-02, with an active set of 29 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:56,970:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 29 iterations, i.e. alpha=9.816e-01, with an active set of 27 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:56,970:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 30 iterations, i.e. alpha=5.092e-01, with an active set of 28 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:56,970:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=6.064e+00, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:56,970:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 30 iterations, i.e. alpha=4.946e-01, with an active set of 28 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:56,970:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 31 iterations, i.e. alpha=3.837e-01, with an active set of 29 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:56,970:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 31 iterations, i.e. alpha=3.776e-01, with an active set of 29 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:56,970:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=6.056e+00, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:56,970:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 32 iterations, i.e. alpha=2.977e-01, with an active set of 30 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:56,970:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=6.046e+00, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:56,970:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 33 iterations, i.e. alpha=1.417e-01, with an active set of 31 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:56,970:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 33 iterations, i.e. alpha=1.030e-01, with an active set of 31 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:56,970:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 33 iterations, i.e. alpha=1.030e-01, with an active set of 31 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:56,970:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 33 iterations, i.e. alpha=3.945e-02, with an active set of 31 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:56,970:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=3.027e+00, with an active set of 18 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:56,970:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=3.022e+00, with an active set of 18 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:56,970:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=3.019e+00, with an active set of 18 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:56,970:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 27 iterations, i.e. alpha=6.824e-01, with an active set of 26 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:56,970:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 30 iterations, i.e. alpha=4.073e-01, with an active set of 29 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:56,970:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=1.628e+00, with an active set of 22 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:56,970:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 30 iterations, i.e. alpha=3.802e-01, with an active set of 29 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:56,970:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 30 iterations, i.e. alpha=2.956e-01, with an active set of 29 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:56,970:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 30 iterations, i.e. alpha=2.815e-01, with an active set of 29 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:56,970:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=1.300e+00, with an active set of 25 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:56,970:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 30 iterations, i.e. alpha=1.520e-01, with an active set of 29 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:56,970:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 32 iterations, i.e. alpha=1.005e-01, with an active set of 31 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:56,970:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 30 iterations, i.e. alpha=6.401e-01, with an active set of 28 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:56,970:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 32 iterations, i.e. alpha=1.005e-01, with an active set of 31 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:56,970:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 32 iterations, i.e. alpha=1.930e-02, with an active set of 31 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:56,970:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 32 iterations, i.e. alpha=1.930e-02, with an active set of 31 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:56,970:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 30 iterations, i.e. alpha=4.456e-01, with an active set of 28 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:56,970:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 30 iterations, i.e. alpha=3.871e-01, with an active set of 28 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:56,970:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 32 iterations, i.e. alpha=1.712e-01, with an active set of 30 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:56,970:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 32 iterations, i.e. alpha=1.480e-01, with an active set of 30 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:56,986:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 33 iterations, i.e. alpha=7.037e-02, with an active set of 31 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:57,478:INFO:Calculating mean and std
2023-06-07 23:26:57,478:INFO:Creating metrics dataframe
2023-06-07 23:26:57,571:INFO:Uploading results into container
2023-06-07 23:26:57,571:INFO:Uploading model into container now
2023-06-07 23:26:57,571:INFO:_master_model_container: 5
2023-06-07 23:26:57,571:INFO:_display_container: 2
2023-06-07 23:26:57,571:INFO:Lars(random_state=123)
2023-06-07 23:26:57,571:INFO:create_model() successfully completed......................................
2023-06-07 23:26:57,634:INFO:SubProcess create_model() end ==================================
2023-06-07 23:26:57,634:INFO:Creating metrics dataframe
2023-06-07 23:26:57,650:INFO:Initializing Lasso Least Angle Regression
2023-06-07 23:26:57,650:INFO:Total runtime is 0.0936211625734965 minutes
2023-06-07 23:26:57,660:INFO:SubProcess create_model() called ==================================
2023-06-07 23:26:57,660:INFO:Initializing create_model()
2023-06-07 23:26:57,660:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E26D334940>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E26F23D060>, model_only=True, return_train_score=False, kwargs={})
2023-06-07 23:26:57,660:INFO:Checking exceptions
2023-06-07 23:26:57,660:INFO:Importing libraries
2023-06-07 23:26:57,660:INFO:Copying training dataset
2023-06-07 23:26:57,668:INFO:Defining folds
2023-06-07 23:26:57,668:INFO:Declaring metric variables
2023-06-07 23:26:57,673:INFO:Importing untrained model
2023-06-07 23:26:57,676:INFO:Lasso Least Angle Regression Imported successfully
2023-06-07 23:26:57,683:INFO:Starting cross validation
2023-06-07 23:26:57,688:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-07 23:26:57,756:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-06-07 23:26:57,756:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=5.241e+00, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:57,763:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-06-07 23:26:57,772:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-06-07 23:26:57,772:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=6.307e+00, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:57,772:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=3.250e+00, with an active set of 16 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:57,772:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=2.620e+00, with an active set of 19 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:57,772:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=7.311e+00, with an active set of 11 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:57,772:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=2.291e+00, with an active set of 21 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:57,772:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=5.325e+00, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:57,772:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=1.436e+00, with an active set of 24 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:57,772:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=1.436e+00, with an active set of 24 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:57,772:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=3.739e+00, with an active set of 16 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:57,772:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=3.739e+00, with an active set of 16 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:57,772:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=3.154e+00, with an active set of 19 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:57,772:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 27 iterations, i.e. alpha=1.157e+00, with an active set of 25 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:57,772:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=3.154e+00, with an active set of 19 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:57,772:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=3.656e+00, with an active set of 17 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:57,772:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 27 iterations, i.e. alpha=1.020e+00, with an active set of 25 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:57,772:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=3.567e+00, with an active set of 17 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:57,772:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=2.170e+00, with an active set of 20 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:57,772:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=3.082e+00, with an active set of 17 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:57,788:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=2.625e+00, with an active set of 17 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:57,788:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:679: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 23 iterations, alpha=2.362e+00, previous alpha=2.170e+00, with an active set of 20 regressors.
  warnings.warn(

2023-06-07 23:26:57,788:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=2.299e+00, with an active set of 18 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:57,788:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=1.173e+00, with an active set of 25 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:57,788:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=1.089e+00, with an active set of 25 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:57,788:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=1.089e+00, with an active set of 25 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:57,788:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-06-07 23:26:57,788:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=1.089e+00, with an active set of 25 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:57,788:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=3.967e+00, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:57,788:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:679: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 18 iterations, alpha=2.956e+00, previous alpha=2.861e+00, with an active set of 17 regressors.
  warnings.warn(

2023-06-07 23:26:57,803:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-06-07 23:26:57,803:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-06-07 23:26:57,803:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=7.044e+00, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:57,803:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=8.042e+00, with an active set of 10 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:57,803:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=6.580e+00, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:57,803:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=4.345e+00, with an active set of 14 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:57,803:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=2.862e+00, with an active set of 19 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:57,803:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=4.021e+00, with an active set of 17 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:57,803:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=2.664e+00, with an active set of 19 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:57,803:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=3.940e+00, with an active set of 17 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:57,803:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=2.490e+00, with an active set of 20 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:57,803:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=2.428e+00, with an active set of 20 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:57,803:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=1.601e+00, with an active set of 21 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:57,803:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=1.676e+00, with an active set of 21 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:57,803:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=1.657e+00, with an active set of 21 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:57,803:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=1.075e+00, with an active set of 24 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:57,803:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=1.558e+00, with an active set of 24 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:57,819:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-06-07 23:26:57,826:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=5.654e+00, with an active set of 11 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:57,826:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=4.968e+00, with an active set of 13 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:57,826:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=4.968e+00, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:57,826:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=2.777e+00, with an active set of 18 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:57,826:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=2.672e+00, with an active set of 18 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:57,826:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=2.293e+00, with an active set of 20 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:57,826:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=2.248e+00, with an active set of 20 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:57,835:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 29 iterations, i.e. alpha=1.258e+00, with an active set of 27 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:57,835:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 30 iterations, i.e. alpha=1.088e+00, with an active set of 28 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:57,835:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=1.434e+00, with an active set of 24 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:57,835:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:679: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 27 iterations, alpha=2.319e+00, previous alpha=1.084e+00, with an active set of 26 regressors.
  warnings.warn(

2023-06-07 23:26:57,850:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-06-07 23:26:57,850:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=3.939e+00, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:57,850:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-06-07 23:26:57,866:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=1.969e+00, with an active set of 21 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:57,866:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=1.969e+00, with an active set of 21 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:57,867:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=1.969e+00, with an active set of 21 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:57,867:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=1.911e+00, with an active set of 21 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:57,867:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=1.150e+00, with an active set of 22 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:57,867:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 27 iterations, i.e. alpha=1.050e+00, with an active set of 23 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:57,867:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 27 iterations, i.e. alpha=1.045e+00, with an active set of 23 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:57,867:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=6.064e+00, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:57,867:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=6.056e+00, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:57,867:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=6.046e+00, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:57,867:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=3.027e+00, with an active set of 18 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:57,867:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=3.022e+00, with an active set of 18 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:57,867:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=3.019e+00, with an active set of 18 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:57,867:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:679: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 21 iterations, alpha=2.316e+00, previous alpha=2.243e+00, with an active set of 20 regressors.
  warnings.warn(

2023-06-07 23:26:57,867:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-06-07 23:26:57,867:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=6.241e+00, with an active set of 12 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:57,867:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=5.648e+00, with an active set of 13 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:57,867:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=5.648e+00, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:57,867:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=3.183e+00, with an active set of 18 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:57,882:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=2.745e+00, with an active set of 21 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:57,882:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=2.745e+00, with an active set of 21 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:57,882:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=2.713e+00, with an active set of 21 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-07 23:26:57,882:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:679: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 22 iterations, alpha=2.857e+00, previous alpha=2.206e+00, with an active set of 21 regressors.
  warnings.warn(

2023-06-07 23:26:58,339:INFO:Calculating mean and std
2023-06-07 23:26:58,339:INFO:Creating metrics dataframe
2023-06-07 23:26:58,431:INFO:Uploading results into container
2023-06-07 23:26:58,431:INFO:Uploading model into container now
2023-06-07 23:26:58,431:INFO:_master_model_container: 6
2023-06-07 23:26:58,431:INFO:_display_container: 2
2023-06-07 23:26:58,431:INFO:LassoLars(random_state=123)
2023-06-07 23:26:58,431:INFO:create_model() successfully completed......................................
2023-06-07 23:26:58,496:INFO:SubProcess create_model() end ==================================
2023-06-07 23:26:58,496:INFO:Creating metrics dataframe
2023-06-07 23:26:58,511:INFO:Initializing Orthogonal Matching Pursuit
2023-06-07 23:26:58,511:INFO:Total runtime is 0.10797476371129353 minutes
2023-06-07 23:26:58,520:INFO:SubProcess create_model() called ==================================
2023-06-07 23:26:58,520:INFO:Initializing create_model()
2023-06-07 23:26:58,520:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E26D334940>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E26F23D060>, model_only=True, return_train_score=False, kwargs={})
2023-06-07 23:26:58,520:INFO:Checking exceptions
2023-06-07 23:26:58,520:INFO:Importing libraries
2023-06-07 23:26:58,520:INFO:Copying training dataset
2023-06-07 23:26:58,529:INFO:Defining folds
2023-06-07 23:26:58,529:INFO:Declaring metric variables
2023-06-07 23:26:58,533:INFO:Importing untrained model
2023-06-07 23:26:58,536:INFO:Orthogonal Matching Pursuit Imported successfully
2023-06-07 23:26:58,544:INFO:Starting cross validation
2023-06-07 23:26:58,547:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-07 23:26:58,605:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-06-07 23:26:58,621:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-06-07 23:26:58,637:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-06-07 23:26:58,637:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-06-07 23:26:58,652:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-06-07 23:26:58,668:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-06-07 23:26:58,699:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-06-07 23:26:58,699:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-06-07 23:26:58,699:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-06-07 23:26:58,731:WARNING:C:\Users\Hashif\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-06-07 23:26:59,171:INFO:Calculating mean and std
2023-06-07 23:26:59,187:INFO:Creating metrics dataframe
2023-06-07 23:26:59,271:INFO:Uploading results into container
2023-06-07 23:26:59,271:INFO:Uploading model into container now
2023-06-07 23:26:59,271:INFO:_master_model_container: 7
2023-06-07 23:26:59,271:INFO:_display_container: 2
2023-06-07 23:26:59,271:INFO:OrthogonalMatchingPursuit()
2023-06-07 23:26:59,271:INFO:create_model() successfully completed......................................
2023-06-07 23:26:59,333:INFO:SubProcess create_model() end ==================================
2023-06-07 23:26:59,333:INFO:Creating metrics dataframe
2023-06-07 23:26:59,348:INFO:Initializing Bayesian Ridge
2023-06-07 23:26:59,348:INFO:Total runtime is 0.12192481358846027 minutes
2023-06-07 23:26:59,348:INFO:SubProcess create_model() called ==================================
2023-06-07 23:26:59,361:INFO:Initializing create_model()
2023-06-07 23:26:59,361:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E26D334940>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E26F23D060>, model_only=True, return_train_score=False, kwargs={})
2023-06-07 23:26:59,361:INFO:Checking exceptions
2023-06-07 23:26:59,361:INFO:Importing libraries
2023-06-07 23:26:59,361:INFO:Copying training dataset
2023-06-07 23:26:59,361:INFO:Defining folds
2023-06-07 23:26:59,361:INFO:Declaring metric variables
2023-06-07 23:26:59,373:INFO:Importing untrained model
2023-06-07 23:26:59,373:INFO:Bayesian Ridge Imported successfully
2023-06-07 23:26:59,381:INFO:Starting cross validation
2023-06-07 23:26:59,381:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-07 23:27:00,027:INFO:Calculating mean and std
2023-06-07 23:27:00,029:INFO:Creating metrics dataframe
2023-06-07 23:27:00,100:INFO:Uploading results into container
2023-06-07 23:27:00,100:INFO:Uploading model into container now
2023-06-07 23:27:00,100:INFO:_master_model_container: 8
2023-06-07 23:27:00,100:INFO:_display_container: 2
2023-06-07 23:27:00,100:INFO:BayesianRidge()
2023-06-07 23:27:00,100:INFO:create_model() successfully completed......................................
2023-06-07 23:27:00,164:INFO:SubProcess create_model() end ==================================
2023-06-07 23:27:00,164:INFO:Creating metrics dataframe
2023-06-07 23:27:00,164:INFO:Initializing Passive Aggressive Regressor
2023-06-07 23:27:00,164:INFO:Total runtime is 0.1355132540067037 minutes
2023-06-07 23:27:00,180:INFO:SubProcess create_model() called ==================================
2023-06-07 23:27:00,180:INFO:Initializing create_model()
2023-06-07 23:27:00,180:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E26D334940>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E26F23D060>, model_only=True, return_train_score=False, kwargs={})
2023-06-07 23:27:00,180:INFO:Checking exceptions
2023-06-07 23:27:00,180:INFO:Importing libraries
2023-06-07 23:27:00,180:INFO:Copying training dataset
2023-06-07 23:27:00,186:INFO:Defining folds
2023-06-07 23:27:00,186:INFO:Declaring metric variables
2023-06-07 23:27:00,192:INFO:Importing untrained model
2023-06-07 23:27:00,198:INFO:Passive Aggressive Regressor Imported successfully
2023-06-07 23:27:00,206:INFO:Starting cross validation
2023-06-07 23:27:00,206:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-07 23:27:00,840:INFO:Calculating mean and std
2023-06-07 23:27:00,840:INFO:Creating metrics dataframe
2023-06-07 23:27:00,947:INFO:Uploading results into container
2023-06-07 23:27:00,947:INFO:Uploading model into container now
2023-06-07 23:27:00,947:INFO:_master_model_container: 9
2023-06-07 23:27:00,947:INFO:_display_container: 2
2023-06-07 23:27:00,947:INFO:PassiveAggressiveRegressor(random_state=123)
2023-06-07 23:27:00,947:INFO:create_model() successfully completed......................................
2023-06-07 23:27:01,010:INFO:SubProcess create_model() end ==================================
2023-06-07 23:27:01,010:INFO:Creating metrics dataframe
2023-06-07 23:27:01,010:INFO:Initializing Huber Regressor
2023-06-07 23:27:01,010:INFO:Total runtime is 0.14961716334025066 minutes
2023-06-07 23:27:01,010:INFO:SubProcess create_model() called ==================================
2023-06-07 23:27:01,026:INFO:Initializing create_model()
2023-06-07 23:27:01,026:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E26D334940>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E26F23D060>, model_only=True, return_train_score=False, kwargs={})
2023-06-07 23:27:01,026:INFO:Checking exceptions
2023-06-07 23:27:01,026:INFO:Importing libraries
2023-06-07 23:27:01,026:INFO:Copying training dataset
2023-06-07 23:27:01,028:INFO:Defining folds
2023-06-07 23:27:01,031:INFO:Declaring metric variables
2023-06-07 23:27:01,035:INFO:Importing untrained model
2023-06-07 23:27:01,039:INFO:Huber Regressor Imported successfully
2023-06-07 23:27:01,045:INFO:Starting cross validation
2023-06-07 23:27:01,045:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-07 23:27:01,709:INFO:Calculating mean and std
2023-06-07 23:27:01,709:INFO:Creating metrics dataframe
2023-06-07 23:27:01,819:INFO:Uploading results into container
2023-06-07 23:27:01,819:INFO:Uploading model into container now
2023-06-07 23:27:01,819:INFO:_master_model_container: 10
2023-06-07 23:27:01,819:INFO:_display_container: 2
2023-06-07 23:27:01,819:INFO:HuberRegressor()
2023-06-07 23:27:01,819:INFO:create_model() successfully completed......................................
2023-06-07 23:27:01,883:INFO:SubProcess create_model() end ==================================
2023-06-07 23:27:01,883:INFO:Creating metrics dataframe
2023-06-07 23:27:01,905:INFO:Initializing K Neighbors Regressor
2023-06-07 23:27:01,905:INFO:Total runtime is 0.16452927986780802 minutes
2023-06-07 23:27:01,908:INFO:SubProcess create_model() called ==================================
2023-06-07 23:27:01,908:INFO:Initializing create_model()
2023-06-07 23:27:01,908:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E26D334940>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E26F23D060>, model_only=True, return_train_score=False, kwargs={})
2023-06-07 23:27:01,908:INFO:Checking exceptions
2023-06-07 23:27:01,908:INFO:Importing libraries
2023-06-07 23:27:01,908:INFO:Copying training dataset
2023-06-07 23:27:01,915:INFO:Defining folds
2023-06-07 23:27:01,915:INFO:Declaring metric variables
2023-06-07 23:27:01,915:INFO:Importing untrained model
2023-06-07 23:27:01,921:INFO:K Neighbors Regressor Imported successfully
2023-06-07 23:27:01,929:INFO:Starting cross validation
2023-06-07 23:27:01,932:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-07 23:27:02,698:INFO:Calculating mean and std
2023-06-07 23:27:02,698:INFO:Creating metrics dataframe
2023-06-07 23:27:02,800:INFO:Uploading results into container
2023-06-07 23:27:02,800:INFO:Uploading model into container now
2023-06-07 23:27:02,802:INFO:_master_model_container: 11
2023-06-07 23:27:02,802:INFO:_display_container: 2
2023-06-07 23:27:02,802:INFO:KNeighborsRegressor(n_jobs=-1)
2023-06-07 23:27:02,802:INFO:create_model() successfully completed......................................
2023-06-07 23:27:02,876:INFO:SubProcess create_model() end ==================================
2023-06-07 23:27:02,876:INFO:Creating metrics dataframe
2023-06-07 23:27:02,884:INFO:Initializing Decision Tree Regressor
2023-06-07 23:27:02,884:INFO:Total runtime is 0.1808573325475057 minutes
2023-06-07 23:27:02,892:INFO:SubProcess create_model() called ==================================
2023-06-07 23:27:02,892:INFO:Initializing create_model()
2023-06-07 23:27:02,892:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E26D334940>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E26F23D060>, model_only=True, return_train_score=False, kwargs={})
2023-06-07 23:27:02,892:INFO:Checking exceptions
2023-06-07 23:27:02,892:INFO:Importing libraries
2023-06-07 23:27:02,892:INFO:Copying training dataset
2023-06-07 23:27:02,897:INFO:Defining folds
2023-06-07 23:27:02,897:INFO:Declaring metric variables
2023-06-07 23:27:02,899:INFO:Importing untrained model
2023-06-07 23:27:02,907:INFO:Decision Tree Regressor Imported successfully
2023-06-07 23:27:02,914:INFO:Starting cross validation
2023-06-07 23:27:02,914:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-07 23:27:03,533:INFO:Calculating mean and std
2023-06-07 23:27:03,537:INFO:Creating metrics dataframe
2023-06-07 23:27:03,618:INFO:Uploading results into container
2023-06-07 23:27:03,618:INFO:Uploading model into container now
2023-06-07 23:27:03,618:INFO:_master_model_container: 12
2023-06-07 23:27:03,618:INFO:_display_container: 2
2023-06-07 23:27:03,618:INFO:DecisionTreeRegressor(random_state=123)
2023-06-07 23:27:03,618:INFO:create_model() successfully completed......................................
2023-06-07 23:27:03,682:INFO:SubProcess create_model() end ==================================
2023-06-07 23:27:03,696:INFO:Creating metrics dataframe
2023-06-07 23:27:03,696:INFO:Initializing Random Forest Regressor
2023-06-07 23:27:03,696:INFO:Total runtime is 0.1943906267484029 minutes
2023-06-07 23:27:03,708:INFO:SubProcess create_model() called ==================================
2023-06-07 23:27:03,708:INFO:Initializing create_model()
2023-06-07 23:27:03,708:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E26D334940>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E26F23D060>, model_only=True, return_train_score=False, kwargs={})
2023-06-07 23:27:03,708:INFO:Checking exceptions
2023-06-07 23:27:03,708:INFO:Importing libraries
2023-06-07 23:27:03,708:INFO:Copying training dataset
2023-06-07 23:27:03,716:INFO:Defining folds
2023-06-07 23:27:03,716:INFO:Declaring metric variables
2023-06-07 23:27:03,723:INFO:Importing untrained model
2023-06-07 23:27:03,723:INFO:Random Forest Regressor Imported successfully
2023-06-07 23:27:03,733:INFO:Starting cross validation
2023-06-07 23:27:03,737:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-07 23:27:05,288:INFO:Calculating mean and std
2023-06-07 23:27:05,288:INFO:Creating metrics dataframe
2023-06-07 23:27:05,399:INFO:Uploading results into container
2023-06-07 23:27:05,415:INFO:Uploading model into container now
2023-06-07 23:27:05,415:INFO:_master_model_container: 13
2023-06-07 23:27:05,415:INFO:_display_container: 2
2023-06-07 23:27:05,415:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2023-06-07 23:27:05,417:INFO:create_model() successfully completed......................................
2023-06-07 23:27:05,482:INFO:SubProcess create_model() end ==================================
2023-06-07 23:27:05,482:INFO:Creating metrics dataframe
2023-06-07 23:27:05,482:INFO:Initializing Extra Trees Regressor
2023-06-07 23:27:05,482:INFO:Total runtime is 0.22415746053059896 minutes
2023-06-07 23:27:05,482:INFO:SubProcess create_model() called ==================================
2023-06-07 23:27:05,482:INFO:Initializing create_model()
2023-06-07 23:27:05,482:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E26D334940>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E26F23D060>, model_only=True, return_train_score=False, kwargs={})
2023-06-07 23:27:05,482:INFO:Checking exceptions
2023-06-07 23:27:05,482:INFO:Importing libraries
2023-06-07 23:27:05,482:INFO:Copying training dataset
2023-06-07 23:27:05,499:INFO:Defining folds
2023-06-07 23:27:05,499:INFO:Declaring metric variables
2023-06-07 23:27:05,499:INFO:Importing untrained model
2023-06-07 23:27:05,506:INFO:Extra Trees Regressor Imported successfully
2023-06-07 23:27:05,513:INFO:Starting cross validation
2023-06-07 23:27:05,519:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-07 23:27:06,936:INFO:Calculating mean and std
2023-06-07 23:27:06,936:INFO:Creating metrics dataframe
2023-06-07 23:27:07,041:INFO:Uploading results into container
2023-06-07 23:27:07,041:INFO:Uploading model into container now
2023-06-07 23:27:07,041:INFO:_master_model_container: 14
2023-06-07 23:27:07,041:INFO:_display_container: 2
2023-06-07 23:27:07,041:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-06-07 23:27:07,048:INFO:create_model() successfully completed......................................
2023-06-07 23:27:07,107:INFO:SubProcess create_model() end ==================================
2023-06-07 23:27:07,107:INFO:Creating metrics dataframe
2023-06-07 23:27:07,122:INFO:Initializing AdaBoost Regressor
2023-06-07 23:27:07,122:INFO:Total runtime is 0.2514899969100952 minutes
2023-06-07 23:27:07,136:INFO:SubProcess create_model() called ==================================
2023-06-07 23:27:07,136:INFO:Initializing create_model()
2023-06-07 23:27:07,136:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E26D334940>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E26F23D060>, model_only=True, return_train_score=False, kwargs={})
2023-06-07 23:27:07,136:INFO:Checking exceptions
2023-06-07 23:27:07,136:INFO:Importing libraries
2023-06-07 23:27:07,136:INFO:Copying training dataset
2023-06-07 23:27:07,143:INFO:Defining folds
2023-06-07 23:27:07,143:INFO:Declaring metric variables
2023-06-07 23:27:07,150:INFO:Importing untrained model
2023-06-07 23:27:07,156:INFO:AdaBoost Regressor Imported successfully
2023-06-07 23:27:07,164:INFO:Starting cross validation
2023-06-07 23:27:07,164:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-07 23:27:08,199:INFO:Calculating mean and std
2023-06-07 23:27:08,199:INFO:Creating metrics dataframe
2023-06-07 23:27:08,322:INFO:Uploading results into container
2023-06-07 23:27:08,322:INFO:Uploading model into container now
2023-06-07 23:27:08,322:INFO:_master_model_container: 15
2023-06-07 23:27:08,322:INFO:_display_container: 2
2023-06-07 23:27:08,322:INFO:AdaBoostRegressor(random_state=123)
2023-06-07 23:27:08,322:INFO:create_model() successfully completed......................................
2023-06-07 23:27:08,390:INFO:SubProcess create_model() end ==================================
2023-06-07 23:27:08,390:INFO:Creating metrics dataframe
2023-06-07 23:27:08,406:INFO:Initializing Gradient Boosting Regressor
2023-06-07 23:27:08,406:INFO:Total runtime is 0.27288355827331545 minutes
2023-06-07 23:27:08,406:INFO:SubProcess create_model() called ==================================
2023-06-07 23:27:08,406:INFO:Initializing create_model()
2023-06-07 23:27:08,406:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E26D334940>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E26F23D060>, model_only=True, return_train_score=False, kwargs={})
2023-06-07 23:27:08,406:INFO:Checking exceptions
2023-06-07 23:27:08,406:INFO:Importing libraries
2023-06-07 23:27:08,406:INFO:Copying training dataset
2023-06-07 23:27:08,414:INFO:Defining folds
2023-06-07 23:27:08,414:INFO:Declaring metric variables
2023-06-07 23:27:08,414:INFO:Importing untrained model
2023-06-07 23:27:08,421:INFO:Gradient Boosting Regressor Imported successfully
2023-06-07 23:27:08,426:INFO:Starting cross validation
2023-06-07 23:27:08,433:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-07 23:27:09,553:INFO:Calculating mean and std
2023-06-07 23:27:09,553:INFO:Creating metrics dataframe
2023-06-07 23:27:09,681:INFO:Uploading results into container
2023-06-07 23:27:09,681:INFO:Uploading model into container now
2023-06-07 23:27:09,681:INFO:_master_model_container: 16
2023-06-07 23:27:09,681:INFO:_display_container: 2
2023-06-07 23:27:09,681:INFO:GradientBoostingRegressor(random_state=123)
2023-06-07 23:27:09,681:INFO:create_model() successfully completed......................................
2023-06-07 23:27:09,750:INFO:SubProcess create_model() end ==================================
2023-06-07 23:27:09,750:INFO:Creating metrics dataframe
2023-06-07 23:27:09,766:INFO:Initializing Light Gradient Boosting Machine
2023-06-07 23:27:09,766:INFO:Total runtime is 0.29554431835810346 minutes
2023-06-07 23:27:09,766:INFO:SubProcess create_model() called ==================================
2023-06-07 23:27:09,766:INFO:Initializing create_model()
2023-06-07 23:27:09,766:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E26D334940>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E26F23D060>, model_only=True, return_train_score=False, kwargs={})
2023-06-07 23:27:09,766:INFO:Checking exceptions
2023-06-07 23:27:09,766:INFO:Importing libraries
2023-06-07 23:27:09,766:INFO:Copying training dataset
2023-06-07 23:27:09,774:INFO:Defining folds
2023-06-07 23:27:09,774:INFO:Declaring metric variables
2023-06-07 23:27:09,774:INFO:Importing untrained model
2023-06-07 23:27:09,782:INFO:Light Gradient Boosting Machine Imported successfully
2023-06-07 23:27:09,792:INFO:Starting cross validation
2023-06-07 23:27:09,792:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-07 23:27:10,653:INFO:Calculating mean and std
2023-06-07 23:27:10,653:INFO:Creating metrics dataframe
2023-06-07 23:27:10,779:INFO:Uploading results into container
2023-06-07 23:27:10,779:INFO:Uploading model into container now
2023-06-07 23:27:10,779:INFO:_master_model_container: 17
2023-06-07 23:27:10,779:INFO:_display_container: 2
2023-06-07 23:27:10,779:INFO:LGBMRegressor(random_state=123)
2023-06-07 23:27:10,779:INFO:create_model() successfully completed......................................
2023-06-07 23:27:10,846:INFO:SubProcess create_model() end ==================================
2023-06-07 23:27:10,846:INFO:Creating metrics dataframe
2023-06-07 23:27:10,862:INFO:Initializing Dummy Regressor
2023-06-07 23:27:10,862:INFO:Total runtime is 0.31381663878758753 minutes
2023-06-07 23:27:10,866:INFO:SubProcess create_model() called ==================================
2023-06-07 23:27:10,866:INFO:Initializing create_model()
2023-06-07 23:27:10,866:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E26D334940>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E26F23D060>, model_only=True, return_train_score=False, kwargs={})
2023-06-07 23:27:10,866:INFO:Checking exceptions
2023-06-07 23:27:10,866:INFO:Importing libraries
2023-06-07 23:27:10,866:INFO:Copying training dataset
2023-06-07 23:27:10,870:INFO:Defining folds
2023-06-07 23:27:10,870:INFO:Declaring metric variables
2023-06-07 23:27:10,874:INFO:Importing untrained model
2023-06-07 23:27:10,876:INFO:Dummy Regressor Imported successfully
2023-06-07 23:27:10,885:INFO:Starting cross validation
2023-06-07 23:27:10,885:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-07 23:27:11,673:INFO:Calculating mean and std
2023-06-07 23:27:11,673:INFO:Creating metrics dataframe
2023-06-07 23:27:11,796:INFO:Uploading results into container
2023-06-07 23:27:11,796:INFO:Uploading model into container now
2023-06-07 23:27:11,796:INFO:_master_model_container: 18
2023-06-07 23:27:11,796:INFO:_display_container: 2
2023-06-07 23:27:11,796:INFO:DummyRegressor()
2023-06-07 23:27:11,796:INFO:create_model() successfully completed......................................
2023-06-07 23:27:11,857:INFO:SubProcess create_model() end ==================================
2023-06-07 23:27:11,857:INFO:Creating metrics dataframe
2023-06-07 23:27:11,887:INFO:Initializing create_model()
2023-06-07 23:27:11,891:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E26D334940>, estimator=GradientBoostingRegressor(random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-07 23:27:11,891:INFO:Checking exceptions
2023-06-07 23:27:11,891:INFO:Importing libraries
2023-06-07 23:27:11,891:INFO:Copying training dataset
2023-06-07 23:27:11,896:INFO:Defining folds
2023-06-07 23:27:11,896:INFO:Declaring metric variables
2023-06-07 23:27:11,896:INFO:Importing untrained model
2023-06-07 23:27:11,896:INFO:Declaring custom model
2023-06-07 23:27:11,896:INFO:Gradient Boosting Regressor Imported successfully
2023-06-07 23:27:11,896:INFO:Cross validation set to False
2023-06-07 23:27:11,896:INFO:Fitting Model
2023-06-07 23:27:12,177:INFO:GradientBoostingRegressor(random_state=123)
2023-06-07 23:27:12,177:INFO:create_model() successfully completed......................................
2023-06-07 23:27:12,255:INFO:Creating Dashboard logs
2023-06-07 23:27:12,263:INFO:Model: Gradient Boosting Regressor
2023-06-07 23:27:12,316:INFO:Logged params: {'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': None, 'random_state': 123, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2023-06-07 23:27:12,411:INFO:Initializing predict_model()
2023-06-07 23:27:12,411:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E26D334940>, estimator=GradientBoostingRegressor(random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000001E26EC47880>)
2023-06-07 23:27:12,411:INFO:Checking exceptions
2023-06-07 23:27:12,411:INFO:Preloading libraries
2023-06-07 23:27:12,711:INFO:Creating Dashboard logs
2023-06-07 23:27:12,711:INFO:Model: Extra Trees Regressor
2023-06-07 23:27:12,753:INFO:Logged params: {'bootstrap': False, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': 1.0, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 123, 'verbose': 0, 'warm_start': False}
2023-06-07 23:27:13,006:INFO:Creating Dashboard logs
2023-06-07 23:27:13,020:INFO:Model: Random Forest Regressor
2023-06-07 23:27:13,062:INFO:Logged params: {'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': 1.0, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 123, 'verbose': 0, 'warm_start': False}
2023-06-07 23:27:13,328:INFO:Creating Dashboard logs
2023-06-07 23:27:13,328:INFO:Model: Light Gradient Boosting Machine
2023-06-07 23:27:13,387:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 123, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-06-07 23:27:13,695:INFO:Creating Dashboard logs
2023-06-07 23:27:13,695:INFO:Model: Huber Regressor
2023-06-07 23:27:13,760:INFO:Logged params: {'alpha': 0.0001, 'epsilon': 1.35, 'fit_intercept': True, 'max_iter': 100, 'tol': 1e-05, 'warm_start': False}
2023-06-07 23:27:14,012:INFO:Creating Dashboard logs
2023-06-07 23:27:14,012:INFO:Model: Lasso Regression
2023-06-07 23:27:14,062:INFO:Logged params: {'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'max_iter': 1000, 'normalize': 'deprecated', 'positive': False, 'precompute': False, 'random_state': 123, 'selection': 'cyclic', 'tol': 0.0001, 'warm_start': False}
2023-06-07 23:27:14,313:INFO:Creating Dashboard logs
2023-06-07 23:27:14,313:INFO:Model: Ridge Regression
2023-06-07 23:27:14,369:INFO:Logged params: {'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'normalize': 'deprecated', 'positive': False, 'random_state': 123, 'solver': 'auto', 'tol': 0.001}
2023-06-07 23:27:14,636:INFO:Creating Dashboard logs
2023-06-07 23:27:14,636:INFO:Model: Lasso Least Angle Regression
2023-06-07 23:27:14,677:INFO:Logged params: {'alpha': 1.0, 'copy_X': True, 'eps': 2.220446049250313e-16, 'fit_intercept': True, 'fit_path': True, 'jitter': None, 'max_iter': 500, 'normalize': 'deprecated', 'positive': False, 'precompute': 'auto', 'random_state': 123, 'verbose': False}
2023-06-07 23:27:14,955:INFO:Creating Dashboard logs
2023-06-07 23:27:14,961:INFO:Model: Bayesian Ridge
2023-06-07 23:27:15,008:INFO:Logged params: {'alpha_1': 1e-06, 'alpha_2': 1e-06, 'alpha_init': None, 'compute_score': False, 'copy_X': True, 'fit_intercept': True, 'lambda_1': 1e-06, 'lambda_2': 1e-06, 'lambda_init': None, 'n_iter': 300, 'normalize': 'deprecated', 'tol': 0.001, 'verbose': False}
2023-06-07 23:27:15,280:INFO:Creating Dashboard logs
2023-06-07 23:27:15,295:INFO:Model: Least Angle Regression
2023-06-07 23:27:15,348:INFO:Logged params: {'copy_X': True, 'eps': 2.220446049250313e-16, 'fit_intercept': True, 'fit_path': True, 'jitter': None, 'n_nonzero_coefs': 500, 'normalize': 'deprecated', 'precompute': 'auto', 'random_state': 123, 'verbose': False}
2023-06-07 23:27:15,639:INFO:Creating Dashboard logs
2023-06-07 23:27:15,639:INFO:Model: Elastic Net
2023-06-07 23:27:15,688:INFO:Logged params: {'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'l1_ratio': 0.5, 'max_iter': 1000, 'normalize': 'deprecated', 'positive': False, 'precompute': False, 'random_state': 123, 'selection': 'cyclic', 'tol': 0.0001, 'warm_start': False}
2023-06-07 23:27:15,948:INFO:Creating Dashboard logs
2023-06-07 23:27:15,964:INFO:Model: Passive Aggressive Regressor
2023-06-07 23:27:16,005:INFO:Logged params: {'C': 1.0, 'average': False, 'early_stopping': False, 'epsilon': 0.1, 'fit_intercept': True, 'loss': 'epsilon_insensitive', 'max_iter': 1000, 'n_iter_no_change': 5, 'random_state': 123, 'shuffle': True, 'tol': 0.001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2023-06-07 23:27:16,384:INFO:Creating Dashboard logs
2023-06-07 23:27:16,384:INFO:Model: K Neighbors Regressor
2023-06-07 23:27:16,437:INFO:Logged params: {'algorithm': 'auto', 'leaf_size': 30, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': -1, 'n_neighbors': 5, 'p': 2, 'weights': 'uniform'}
2023-06-07 23:27:16,706:INFO:Creating Dashboard logs
2023-06-07 23:27:16,706:INFO:Model: Orthogonal Matching Pursuit
2023-06-07 23:27:16,762:INFO:Logged params: {'fit_intercept': True, 'n_nonzero_coefs': None, 'normalize': 'deprecated', 'precompute': 'auto', 'tol': None}
2023-06-07 23:27:17,013:INFO:Creating Dashboard logs
2023-06-07 23:27:17,013:INFO:Model: AdaBoost Regressor
2023-06-07 23:27:17,054:INFO:Logged params: {'base_estimator': None, 'learning_rate': 1.0, 'loss': 'linear', 'n_estimators': 50, 'random_state': 123}
2023-06-07 23:27:17,306:INFO:Creating Dashboard logs
2023-06-07 23:27:17,306:INFO:Model: Decision Tree Regressor
2023-06-07 23:27:17,359:INFO:Logged params: {'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'random_state': 123, 'splitter': 'best'}
2023-06-07 23:27:17,620:INFO:Creating Dashboard logs
2023-06-07 23:27:17,620:INFO:Model: Dummy Regressor
2023-06-07 23:27:17,675:INFO:Logged params: {'constant': None, 'quantile': None, 'strategy': 'mean'}
2023-06-07 23:27:17,913:INFO:Creating Dashboard logs
2023-06-07 23:27:17,913:INFO:Model: Linear Regression
2023-06-07 23:27:17,961:INFO:Logged params: {'copy_X': True, 'fit_intercept': True, 'n_jobs': -1, 'normalize': 'deprecated', 'positive': False}
2023-06-07 23:27:18,231:INFO:_master_model_container: 18
2023-06-07 23:27:18,231:INFO:_display_container: 2
2023-06-07 23:27:18,231:INFO:GradientBoostingRegressor(random_state=123)
2023-06-07 23:27:18,231:INFO:compare_models() successfully completed......................................
